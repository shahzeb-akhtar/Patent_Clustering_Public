[{"pair":"US-2017174261-A1 & US-9862364-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9276694351},{"pair":"US-2017174261-A1 & US-9669827-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9217148966},{"pair":"US-9983591-B2 & US-9862364-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9216816239},{"pair":"US-2018239361-A1 & US-9862364-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9213681379},{"pair":"US-9983591-B2 & US-9669827-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9197477237},{"pair":"US-2018239361-A1 & US-9669827-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.919133933},{"pair":"US-2019362168-A1 & US-9541410-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9165762581},{"pair":"US-10423847-B2 & US-9541410-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9161954979},{"pair":"US-10423847-B2 & US-9669827-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.912842262},{"pair":"US-2019362168-A1 & US-9669827-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9116023301},{"pair":"US-2017174261-A1 & US-10156851-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9110571537},{"pair":"US-2017174261-A1 & US-9557736-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9100298006},{"pair":"US-10259457-B2 & US-2018135972-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9089838515},{"pair":"US-10259457-B2 & US-2018143643-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9081384283},{"pair":"US-2017072962-A1 & US-2018135972-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9075835017},{"pair":"US-2017072962-A1 & US-2018143643-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9073475957},{"pair":"US-9983591-B2 & US-9557736-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9069205254},{"pair":"US-2018239361-A1 & US-9557736-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9066577968},{"pair":"US-2019012913-A1 & US-9551992-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9053828388},{"pair":"US-2017072962-A1 & US-10146223-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9043884488},{"pair":"US-10259457-B2 & US-9836052-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9037379899},{"pair":"US-2017072962-A1 & US-9836052-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9035610312},{"pair":"US-2017072962-A1 & US-10156851-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9034867935},{"pair":"US-10259457-B2 & US-10146223-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9034376542},{"pair":"US-9696721-B1 & US-9669827-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-03-21T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9033424124},{"pair":"US-2019012913-A1 & US-9740202-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9032036007},{"pair":"US-2017206426-A1 & US-9669827-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9025774049},{"pair":"US-9983591-B2 & US-2017341643-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9023633922},{"pair":"US-10259457-B2 & US-10156851-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9017713633},{"pair":"US-2018239361-A1 & US-2017341643-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9015565836},{"pair":"US-2017072962-A1 & US-9551992-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9015358642},{"pair":"US-9696721-B1 & US-9463794-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-03-21T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9013308395},{"pair":"US-10423847-B2 & US-9862364-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9012034256},{"pair":"US-2017174261-A1 & US-9766626-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9007570433},{"pair":"US-10259457-B2 & US-9551992-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9007348658},{"pair":"US-2019362168-A1 & US-9862364-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9005685584},{"pair":"US-2018239361-A1 & US-9541410-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.900098431},{"pair":"US-2017072962-A1 & US-2017341643-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8997478407},{"pair":"US-9983591-B2 & US-9541410-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8991983926},{"pair":"US-2019039616-A1 & US-10156851-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.898858619},{"pair":"US-10259457-B2 & US-2017341643-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8988200025},{"pair":"US-10423847-B2 & US-9557736-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8987238466},{"pair":"US-2017072962-A1 & US-9740202-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8987161533},{"pair":"US-2019039616-A1 & US-2017341643-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8986813494},{"pair":"US-2019012913-A1 & US-10156851-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8985569939},{"pair":"US-10259457-B2 & US-9740202-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.898505238},{"pair":"US-2019362168-A1 & US-9557736-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8978750027},{"pair":"US-2018239361-A1 & US-10059334-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8976513433},{"pair":"US-2017174261-A1 & US-2017341643-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8974798172},{"pair":"US-9983591-B2 & US-10156851-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8971555682},{"pair":"US-2017174261-A1 & US-10059334-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.896910873},{"pair":"US-2018120857-A1 & US-10198643-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8968808163},{"pair":"US-2018239361-A1 & US-10156851-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8966606291},{"pair":"US-9921581-B2 & US-9551992-B1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8966443256},{"pair":"US-2017192429-A1 & US-9551992-B1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8966443256},{"pair":"US-10528055-B2 & US-10198643-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8965403882},{"pair":"US-2019161085-A1 & US-9373045-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.896532188},{"pair":"US-2017072962-A1 & US-9463794-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8964661297},{"pair":"US-9983591-B2 & US-10059334-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8964259213},{"pair":"US-2017192429-A1 & US-9740202-B2","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8960980283},{"pair":"US-9921581-B2 & US-9740202-B2","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8960980283},{"pair":"US-2019101933-A1 & US-10156851-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8958901094},{"pair":"US-2019111922-A1 & US-2017341643-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8957594557},{"pair":"US-2019012913-A1 & US-2018143643-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8956437137},{"pair":"US-2019161085-A1 & US-2016187887-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8944877245},{"pair":"US-2018120857-A1 & US-9682707-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8944793557},{"pair":"US-2017364072-A1 & US-10146223-B1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8943838095},{"pair":"US-10037033-B2 & US-10146223-B1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8943838095},{"pair":"US-10259457-B2 & US-9400183-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2014-05-13T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8940431413},{"pair":"US-9983591-B2 & US-10496091-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8934203329},{"pair":"US-9696721-B1 & US-9557736-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-03-21T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8933674689},{"pair":"US-2017316691-A1 & US-9868391-B1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8933664209},{"pair":"US-10068477-B2 & US-9868391-B1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8933664209},{"pair":"US-10259457-B2 & US-9463794-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.893266385},{"pair":"US-2019012913-A1 & US-2018135972-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8931942036},{"pair":"US-2018239361-A1 & US-10496091-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8931447929},{"pair":"US-2017192429-A1 & US-10146223-B1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8930542126},{"pair":"US-9921581-B2 & US-10146223-B1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8930542126},{"pair":"US-10528055-B2 & US-9682707-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8930302864},{"pair":"US-2019039616-A1 & US-9551992-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8928250783},{"pair":"US-10589742-B2 & US-9373045-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":null,"abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.892730577},{"pair":"US-2018239361-A1 & US-9766626-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8926922022},{"pair":"US-2019039616-A1 & US-9862364-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8926683953},{"pair":"US-2017072962-A1 & US-10496091-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8925005431},{"pair":"US-2017174261-A1 & US-9463794-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8924800795},{"pair":"US-2019161085-A1 & US-9707966-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8923424677},{"pair":"US-2018120857-A1 & US-9400183-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2016-11-03T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8919366739},{"pair":"US-2018319402-A1 & US-10059334-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-05-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.891878759},{"pair":"US-2018120857-A1 & US-9255805-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8917364271},{"pair":"US-2019161085-A1 & US-9684836-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8916366937},{"pair":"US-10423847-B2 & US-10496091-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.891406076},{"pair":"US-2019039616-A1 & US-2016370801-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8913811598},{"pair":"US-2019161085-A1 & US-2017098129-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8913594468},{"pair":"US-10423847-B2 & US-2017341643-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912700633},{"pair":"US-10528055-B2 & US-9400183-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2016-11-03T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912456748},{"pair":"US-2017072962-A1 & US-9400183-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2014-05-13T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.891208127},{"pair":"US-9983591-B2 & US-9766626-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912060845},{"pair":"US-2019111922-A1 & US-9862364-B2","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8910740177},{"pair":"US-2019039616-A1 & US-9740202-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8910444652},{"pair":"US-2017072962-A1 & US-9255805-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8910045746},{"pair":"US-2019362168-A1 & US-10496091-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8909782322},{"pair":"US-2019362168-A1 & US-2017341643-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8908743056},{"pair":"US-10589742-B2 & US-9707966-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":null,"abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8906092518},{"pair":"US-2017072962-A1 & US-9682707-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8903713965},{"pair":"US-10528055-B2 & US-9255805-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8903487112},{"pair":"US-2018120857-A1 & US-9463794-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8902571424},{"pair":"US-10082796-B2 & US-9868391-B1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8902035088},{"pair":"US-2018120858-A1 & US-9868391-B1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8902035088},{"pair":"US-10259457-B2 & US-9255805-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8901883749},{"pair":"US-10259457-B2 & US-2018105174-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018105174-A1","title_2":"Planning stopping locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180105174A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to generating a speed plan for an autonomous vehicle. As an example, the vehicle is maneuvered in an autonomous driving mode along a route using pre-stored map information. This information identifies a plurality of keep clear regions where the vehicle should not stop but can drive through in the autonomous driving mode. Each keep clear region of the plurality of keep clear regions is associated with a priority value. A subset of the plurality of keep clear regions is identified based on the route. A speed plan for stopping the vehicle is generated based on the priority values associated with the keep clear regions of the subset. The speed plan identifies a location for stopping the vehicle. The speed plan is used to stop the vehicle in the location.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8899487747},{"pair":"US-10589742-B2 & US-2016187887-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8898500923},{"pair":"US-10259457-B2 & US-10496091-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8898149297},{"pair":"US-2020031468-A1 & US-10146223-B1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-12-14T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8897200311},{"pair":"US-2018081357-A1 & US-2018152628-A1","patent_1":"US-2018081357-A1","title_1":"Geocoded information aided vehicle warning ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20180081357A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Methods and apparatus are disclosed for geocoded information aided vehicle warning. An example disclosed vehicle includes range detection sensors and a threat detector. The example threat detector determines a threat level based on a location of the vehicle. Additionally, the example threat detector defines, with the range detection sensors, contours of detection zones around the vehicle based on the threat level. The example threat detector also performs first actions, via a body control module, to secure the vehicle in response to a threat detected in the detection zone.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-09-16T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8896946632},{"pair":"US-2018120857-A1 & US-9703291-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9703291-B1","title_2":"Object bounding box estimation ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9703291B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate generally to maneuvering autonomous vehicles. Specifically, the vehicle may use a laser to collect scan data for a section of roadway. The vehicle may access a detailed map including the section of the roadway. A disturbance indicative of an object and including a set of data points data may be identified from the scan data based on the detailed map. The detailed map may also be used to estimate a heading of the disturbance. A bounding box for the disturbance may be estimated using the set of data points as well as the estimated heading. The parameters of the bounding box may then be adjusted in order to increase or maximize the average density of data points of the disturbance along the edges of the bounding box visible to the laser. This adjusted bounding box may then used to maneuver the vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-01-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8896735023},{"pair":"US-10528055-B2 & US-9463794-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8893496131},{"pair":"US-2018033309-A1 & US-10139829-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2016-07-29T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8893190864},{"pair":"US-2017072962-A1 & US-2018105174-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018105174-A1","title_2":"Planning stopping locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180105174A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to generating a speed plan for an autonomous vehicle. As an example, the vehicle is maneuvered in an autonomous driving mode along a route using pre-stored map information. This information identifies a plurality of keep clear regions where the vehicle should not stop but can drive through in the autonomous driving mode. Each keep clear region of the plurality of keep clear regions is associated with a priority value. A subset of the plurality of keep clear regions is identified based on the route. A speed plan for stopping the vehicle is generated based on the priority values associated with the keep clear regions of the subset. The speed plan identifies a location for stopping the vehicle. The speed plan is used to stop the vehicle in the location.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8892898825},{"pair":"US-2019362168-A1 & US-9779621-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.889214219},{"pair":"US-2019039616-A1 & US-9679206-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8892077606},{"pair":"US-2018120857-A1 & US-10185324-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10185324-B1","title_2":"Building elevation maps from laser data ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10185324B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the present disclosure relate generally to generating elevation maps. More specifically, data points may be collected by a laser moving along a roadway and used to generate an elevation map of the roadway. The collected data points may be projected onto a two dimensional or \u201c2D\u201d grid. The grid may include a plurality of cells, each cell of the grid representing a geolocated second of the roadway. The data points of each cell may be evaluated to identify an elevation for the particular cell. For example, the data points in a particular cell may be filtered in various ways including occlusion, interpolation from neighboring cells, etc. The minimum value of the remaining data points within each cell may then be used as the elevation for the particular cell, and the elevation of a plurality of cells may be used to generate an elevation map of the roadway.","priority_1":"2016-11-03T00:00:00","priority_2":"2011-08-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8890281076},{"pair":"US-2018018869-A1 & US-2018102001-A1","patent_1":"US-2018018869-A1","title_1":"Autonomous Police Vehicle ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180018869A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Techniques pertaining to an autonomous police vehicle are described. A method may involve a processor associated with an autonomous vehicle obtaining an indication of violation of one or more traffic laws by a first vehicle. The method may also involve the processor maneuvering the autonomous vehicle to pursue the first vehicle. The method may further involve the processor remotely executing one or more actions with respect to the first vehicle.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-07-12T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8889545502},{"pair":"US-10269242-B2 & US-2018102001-A1","patent_1":"US-10269242-B2","title_1":"Autonomous police vehicle ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10269242B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Techniques pertaining to an autonomous police vehicle are described. A method may involve a processor associated with an autonomous vehicle obtaining an indication of violation of one or more traffic laws by a first vehicle. The method may also involve the processor maneuvering the autonomous vehicle to pursue the first vehicle. The method may further involve the processor remotely executing one or more actions with respect to the first vehicle.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-07-12T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8889545502},{"pair":"US-10528055-B2 & US-9703291-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9703291-B1","title_2":"Object bounding box estimation ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9703291B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to maneuvering autonomous vehicles. Specifically, the vehicle may use a laser to collect scan data for a section of roadway. The vehicle may access a detailed map including the section of the roadway. A disturbance indicative of an object and including a set of data points data may be identified from the scan data based on the detailed map. The detailed map may also be used to estimate a heading of the disturbance. A bounding box for the disturbance may be estimated using the set of data points as well as the estimated heading. The parameters of the bounding box may then be adjusted in order to increase or maximize the average density of data points of the disturbance along the edges of the bounding box visible to the laser. This adjusted bounding box may then used to maneuver the vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-01-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8888902061},{"pair":"US-2018319402-A1 & US-10156851-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-05-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8888401678},{"pair":"US-10423847-B2 & US-9779621-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.888677535},{"pair":"US-10528055-B2 & US-10185324-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10185324-B1","title_2":"Building elevation maps from laser data ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10185324B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate generally to generating elevation maps. More specifically, data points may be collected by a laser moving along a roadway and used to generate an elevation map of the roadway. The collected data points may be projected onto a two dimensional or \u201c2D\u201d grid. The grid may include a plurality of cells, each cell of the grid representing a geolocated second of the roadway. The data points of each cell may be evaluated to identify an elevation for the particular cell. For example, the data points in a particular cell may be filtered in various ways including occlusion, interpolation from neighboring cells, etc. The minimum value of the remaining data points within each cell may then be used as the elevation for the particular cell, and the elevation of a plurality of cells may be used to generate an elevation map of the roadway.","priority_1":"2016-11-03T00:00:00","priority_2":"2011-08-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.888650503},{"pair":"US-10410524-B2 & US-10139829-B1","patent_1":"US-10410524-B2","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US10410524B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has traveled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2016-07-29T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8885447278},{"pair":"US-2018224859-A1 & US-9669827-B1","patent_1":"US-2018224859-A1","title_1":"Tornado Detection Systems And Methods ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180224859A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Example tornado detection systems and methods are described. In one implementation, a method receives data from a sensor mounted to a vehicle and analyzes the received data using a deep neural network. The method determines whether a tornado is identified in the received data based on the analysis of the received data. If a tornado is identified in the received data, the method determines a trajectory of the tornado.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-02-08T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8884925408},{"pair":"US-2018341264-A1 & US-2018135972-A1","patent_1":"US-2018341264-A1","title_1":"Autonomous-vehicle control system ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180341264A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computer is programmed to receive, from a vehicle control device, data specifying a location of the control device outside a vehicle; receive data specifying a spatial boundary; generate a path avoiding the spatial boundary from a current location of the vehicle to a location within a predetermined distance of the control-device location; and navigate the vehicle along the path.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-05-24T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8884230905},{"pair":"US-2018120857-A1 & US-9690296-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8884130258},{"pair":"US-10037033-B2 & US-9551992-B1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.888408227},{"pair":"US-2017364072-A1 & US-9551992-B1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.888408227},{"pair":"US-10589742-B2 & US-9684836-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8882853715},{"pair":"US-2019025814-A1 & US-9551992-B1","patent_1":"US-2019025814-A1","title_1":"Remote vehicle instruction ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190025814A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a mobile computer programmed to receive, from a vehicle computer, an instruction to proceed to a location and vehicle operation data from an in-vehicle communications network. The mobile computer is programmed to determine that a vehicle is ready to proceed to the location based on the operation data. The mobile computer is programmed to receive user input approving transitioning from a boarding state to a driving state. The mobile computer is programmed to then instruct the vehicle computer to actuate vehicle components to proceed to the location.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-18T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8881401175},{"pair":"US-10528055-B2 & US-10168712-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10168712-B1","title_2":"Vison-based object detection using a polar grid ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10168712B1\/en","abstract_1":null,"abstract_2":"A computing device of a first vehicle may receive a first image and a second image of a second vehicle having flashing light signals. The computing device may determine, in the first image and the second image, an image region that bounds the second vehicle such that the image region substantially encompasses the second vehicle. The computing device may determine a polar grid that partitions the image region in the first image and the second image into polar bins, and identify portions of image data exhibiting a change in color and a change in brightness between the first image and the second image. The computing device may determine a type of the flashing light signals and a type of the second vehicle; and accordingly provide instructions to control the first vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-04-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8880149018},{"pair":"US-2020064850-A1 & US-9557737-B1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":null,"abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2018-08-22T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8879749119},{"pair":"US-2018120857-A1 & US-10168712-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10168712-B1","title_2":"Vison-based object detection using a polar grid ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10168712B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A computing device of a first vehicle may receive a first image and a second image of a second vehicle having flashing light signals. The computing device may determine, in the first image and the second image, an image region that bounds the second vehicle such that the image region substantially encompasses the second vehicle. The computing device may determine a polar grid that partitions the image region in the first image and the second image into polar bins, and identify portions of image data exhibiting a change in color and a change in brightness between the first image and the second image. The computing device may determine a type of the flashing light signals and a type of the second vehicle; and accordingly provide instructions to control the first vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-04-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.88783973},{"pair":"US-2017210291-A1 & US-9557736-B1","patent_1":"US-2017210291-A1","title_1":"Drive History Parking Barrier Alert ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170210291A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A driving assistance system includes a drive detection component, a presence component, and a notification component. The drive detection component is configured to determine that a vehicle or driver is exiting or preparing to exit a parking location. The presence component is configured to determine, from a drive history database, whether a parking barrier is present in front of or behind the parking location. The notification component is configured to provide an indication that the parking barrier is present to a human driver or an automated driving system of the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-09-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8878110358},{"pair":"US-10150412-B2 & US-9557736-B1","patent_1":"US-10150412-B2","title_1":"Drive history parking barrier alert ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10150412B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A driving assistance system includes a drive detection component, a presence component, and a notification component. The drive detection component is configured to determine that a vehicle or driver is exiting or preparing to exit a parking location. The presence component is configured to determine, from a drive history database, whether a parking barrier is present in front of or behind the parking location. The notification component is configured to provide an indication that the parking barrier is present to a human driver or an automated driving system of the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-09-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8878110358},{"pair":"US-10259457-B2 & US-9682707-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8877669357},{"pair":"US-10423847-B2 & US-9766626-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8877407963},{"pair":"US-2019039616-A1 & US-2016209844-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8876018661},{"pair":"US-2017308759-A1 & US-9557736-B1","patent_1":"US-2017308759-A1","title_1":"Perception-Based Speed Limit Estimation And Learning ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170308759A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for estimating a speed limit are disclosed herein. A system for estimating a speed limit includes one or more perception sensors, an arbitrated speed component, an attribute component, an estimator component, and a notification component. The one or more perception sensors are configured to generate perception data about a region near a vehicle. The arbitrated speed component is configured to determine that a high confidence or arbitrated speed limit is not available. The attribute component is configured to detect one or more environmental attributes based on the perception data. The estimator component is configured to determine an estimated speed limit based on the environmental attributes. The notification component is configured to provide the estimated speed limit to an automated driving system or driver assistance system of the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-10-21T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8875165908},{"pair":"US-2016210382-A1 & US-2018143643-A1","patent_1":"US-2016210382-A1","title_1":"Autonomous driving refined in virtual environments ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20160210382A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A computing device includes a processing circuit and a data storage medium. The computing device is programmed to receive a user input selecting at least one testing parameter associated with autonomously operating a virtual vehicle in a virtual environment, simulate the virtual environment incorporating the at least one testing parameter, virtually navigate the virtual vehicle through the virtual environment, collect virtual sensor data, and processing the collected virtual sensor data.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-01-21T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8874920837},{"pair":"US-10423847-B2 & US-10059334-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8874086566},{"pair":"US-10423847-B2 & US-10156851-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8873212463},{"pair":"US-2019347498-A1 & US-2018152628-A1","patent_1":"US-2019347498-A1","title_1":"Systems and methods for automated detection of trailer properties ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190347498A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Methods and apparatus are disclosed for automated detection of trailer properties. An example vehicle includes an inter-vehicle communication module and an infotainment head unit. The infotainment head unit is configured to detect presence of an attached trailer. The infotainment head unit is also configured to, in response to a determination that the attached trailer is an unrecognized trailer broadcast a request for images via the inter-vehicle communication module, perform semantic segmentation on the images, generate a three dimensional point cloud using the segmented images, and estimate a property of the attached trailer based on the three dimensional point cloud","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2018-05-09T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8872832172},{"pair":"US-2018099663-A1 & US-9669827-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8872065781},{"pair":"US-10528055-B2 & US-9690296-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8871337883},{"pair":"US-2017206426-A1 & US-9541410-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8871208143},{"pair":"US-2017139420-A1 & US-2018135972-A1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-07-16T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8870593287},{"pair":"US-2019111922-A1 & US-9255805-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.887014754},{"pair":"US-9983591-B2 & US-9463794-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8868826096},{"pair":"US-10406917-B2 & US-2018135972-A1","patent_1":"US-10406917-B2","title_1":"Systems and methods for vehicle cruise control smoothness adaptation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10406917B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Methods and systems are disclosed for vehicle cruise control smoothness adaptation. An example vehicle includes a GPS receiver for receiving expected road incline data, a camera for determining a half lane width position, and a radar for determining two respective leading vehicle angles of arrival. The vehicle also includes a processor for determining an actual road incline by filtering the expected road incline, half lane width position, and leading vehicle angles of arrival. And the processor is further for modifying a cruise control system based on the actual road incline.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-08-28T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8868531236},{"pair":"US-2017174261-A1 & US-9541410-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8868425611},{"pair":"US-2019362168-A1 & US-10156851-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867934134},{"pair":"US-10345822-B1 & US-9373045-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867764863},{"pair":"US-2019161085-A1 & US-9690296-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867688957},{"pair":"US-2018099663-A1 & US-2017341643-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867246271},{"pair":"US-2019210593-A1 & US-10247854-B2","patent_1":"US-2019210593-A1","title_1":"Vehicle vision ","patent_2":"US-10247854-B2","title_2":"Methods and systems for detecting weather conditions using vehicle onboard sensors ","link_1":"https:\/\/patents.google.com\/patent\/US20190210593A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10247854B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to detect water on a ground surface, actuate a vehicle exterior light to illuminate a grid pattern on the ground surface, detect a depression at a location of the detected water based on received reflections of the grid pattern, and move a vehicle based on the detected depression.","abstract_2":"Example methods and systems for detecting weather conditions using vehicle onboard sensors are provided. An example method includes receiving laser data collected for an environment of a vehicle, and the laser data includes a plurality of laser data points. The method also includes associating, by a computing device, laser data points of the plurality of laser data points with one or more objects in the environment, and determining given laser data points of the plurality of laser data points that are unassociated with the one or more objects in the environment as being representative of an untracked object. The method also includes based on one or more untracked objects being determined, identifying by the computing device an indication of a weather condition of the environment.","priority_1":"2018-01-09T00:00:00","priority_2":"2013-05-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867124014},{"pair":"US-10556584-B2 & US-10247854-B2","patent_1":"US-10556584-B2","title_1":"Vehicle vision ","patent_2":"US-10247854-B2","title_2":"Methods and systems for detecting weather conditions using vehicle onboard sensors ","link_1":"https:\/\/patents.google.com\/patent\/US10556584B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10247854B2\/en","abstract_1":null,"abstract_2":"Example methods and systems for detecting weather conditions using vehicle onboard sensors are provided. An example method includes receiving laser data collected for an environment of a vehicle, and the laser data includes a plurality of laser data points. The method also includes associating, by a computing device, laser data points of the plurality of laser data points with one or more objects in the environment, and determining given laser data points of the plurality of laser data points that are unassociated with the one or more objects in the environment as being representative of an untracked object. The method also includes based on one or more untracked objects being determined, identifying by the computing device an indication of a weather condition of the environment.","priority_1":"2018-01-09T00:00:00","priority_2":"2013-05-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867124014},{"pair":"US-2019061527-A1 & US-2018135972-A1","patent_1":"US-2019061527-A1","title_1":"Systems and methods for vehicle cruise control smoothness adaptation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190061527A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Methods and systems are disclosed for vehicle cruise control smoothness adaptation. An example vehicle includes a GPS receiver for receiving expected road incline data, a camera for determining a half lane width position, and a radar for determining two respective leading vehicle angles of arrival. The vehicle also includes a processor for determining an actual road incline by filtering the expected road incline, half lane width position, and leading vehicle angles of arrival. And the processor is further for modifying a cruise control system based on the actual road incline.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-08-28T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8866853752},{"pair":"US-10589742-B2 & US-2017098129-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8866139637},{"pair":"US-10037033-B2 & US-9740202-B2","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8865886998},{"pair":"US-2017364072-A1 & US-9740202-B2","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8865886998},{"pair":"US-2017327035-A1 & US-9868391-B1","patent_1":"US-2017327035-A1","title_1":"Methods and systems for beyond-the-horizon threat indication for vehicles ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170327035A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"Methods and systems for Beyond-the-Horizon Threat Indication (BHTI) for vehicles are described. A system and a method may involve receiving motion information of a first vehicle. The system and the method may also involve receiving vicinity data corresponding to a vicinity of the first vehicle. The system and the method may also involve determining whether the first vehicle is subject to a potential hazard within the vicinity based on the motion information and the vicinity data. The system and the method may further involves alerting the first vehicle about the potential hazard in response to the determining of the potential hazard.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-05-10T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8864999947},{"pair":"US-2019374151-A1 & US-9541410-B1","patent_1":"US-2019374151-A1","title_1":"Focus-Based Tagging Of Sensor Data ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190374151A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"Data from sensors of a vehicle is captured along with data tracking a driver's gaze. The route traveled by the vehicle may also be captured. The driver's gaze is evaluated with respect to the sensor data to determine a feature the driver was focused on. A focus record is created for the feature. Focus records for many drivers may be aggregated to determine a frequency of observation of the feature. A machine learning model may be trained using the focus records to identify a region of interest for a given scenario in order to more quickly identify relevant hazards.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2018-06-08T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8864395469},{"pair":"US-2017072962-A1 & US-2017277191-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2017277191-A1","title_2":"Arranging passenger pickups for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170277191A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to arranging a pickup between a driverless vehicle and a passenger. For instance, dispatch instructions dispatching the vehicle to a predetermined pickup area in order to pick up the passenger are received by the vehicle which begins maneuvering to the predetermined pickup area. While doing so, the vehicle receives from the passenger's client computing device the device's location. An indication that the passenger is interested in a fly-by pickup is identified. The fly-by pickup allows the passenger to safely enter the vehicle at a location outside of the predetermined pickup area and prior to the one or more processors have maneuvered the vehicle to the predetermined pickup area. The vehicle determines that the fly-by pickup is appropriate based on at least the location of the client computing device and the indication, and based on the determination, maneuvers itself in order to attempt the fly-by pickup.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-03-24T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8861965939},{"pair":"US-10275664-B2 & US-9557736-B1","patent_1":"US-10275664-B2","title_1":"Perception-based speed limit estimation and learning ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10275664B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for estimating a speed limit are disclosed herein. A system for estimating a speed limit includes one or more perception sensors, an arbitrated speed component, an attribute component, an estimator component, and a notification component. The one or more perception sensors are configured to generate perception data about a region near a vehicle. The arbitrated speed component is configured to determine that a high confidence or arbitrated speed limit is not available. The attribute component is configured to detect one or more environmental attributes based on the perception data. The estimator component is configured to determine an estimated speed limit based on the environmental attributes. The notification component is configured to provide the estimated speed limit to an automated driving system or driver assistance system of the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-10-21T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.886165659},{"pair":"US-2019025814-A1 & US-9740202-B2","patent_1":"US-2019025814-A1","title_1":"Remote vehicle instruction ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190025814A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A system includes a mobile computer programmed to receive, from a vehicle computer, an instruction to proceed to a location and vehicle operation data from an in-vehicle communications network. The mobile computer is programmed to determine that a vehicle is ready to proceed to the location based on the operation data. The mobile computer is programmed to receive user input approving transitioning from a boarding state to a driving state. The mobile computer is programmed to then instruct the vehicle computer to actuate vehicle components to proceed to the location.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-18T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8861093932},{"pair":"US-2017174261-A1 & US-10496091-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.886075253},{"pair":"US-10259457-B2 & US-9534918-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9534918-B2","title_2":"Determining and displaying auto drive lanes in an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9534918B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate generally to identifying and displaying traffic lanes that are available for autonomous driving. This information may be displayed to a driver of a vehicle having an autonomous driving mode, in order to inform the driver of where he or she can use the autonomous driving mode. In one example, the display may visually distinguishing between lanes that are available for auto-drive from those that are not. The display may also include an indicator of the position of a lane (autodrive or not) currently occupied by the vehicle. In addition, if that lane is an autodrive lane the display may include information indicating how much further the vehicle may continue in the autonomous driving mode in that particular lane. The display may also display information indicating the remaining autodrive distance in other lanes as well as the lane with the greatest remaining autodrive distance.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8860702036},{"pair":"US-2018239361-A1 & US-9463794-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8859512805},{"pair":"US-2019362168-A1 & US-10059334-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8859060165},{"pair":"US-2018281782-A1 & US-2018143643-A1","patent_1":"US-2018281782-A1","title_1":"Wrong-way vehicle detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180281782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.885823947},{"pair":"US-10442429-B2 & US-2018143643-A1","patent_1":"US-10442429-B2","title_1":"Wrong-way vehicle detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10442429B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.885823947},{"pair":"US-2019066510-A1 & US-9868391-B1","patent_1":"US-2019066510-A1","title_1":"Vehicular image projection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190066510A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A computer is programmed to determine a target area to project, along a planned travel path of a vehicle, a symbol based on detecting a target object. The computer is further programmed to actuate a light source to project the symbol moving within the target area.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.885791847},{"pair":"US-2018120857-A1 & US-9575490-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8857032446},{"pair":"US-10377376-B2 & US-9669827-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8856725154},{"pair":"US-10068477-B2 & US-2018011496-A1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.885638197},{"pair":"US-2017316691-A1 & US-2018011496-A1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.885638197},{"pair":"US-10152058-B2 & US-9779621-B1","patent_1":"US-10152058-B2","title_1":"Vehicle virtual map ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10152058B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"A vehicle includes: motor(s), local sensors, processor(s) configured to: generate a virtual map based on the local sensors; receive a plurality of reports from a plurality of external entities, statistically compare the plurality of reports, and identify an outlying report based on the statistical comparison; instruct the external entity responsible for the outlying report to mark future reports; ignore marked reports; generate the virtual map based on unmarked reports; reallocate virtual map processing resources based on unmarked reports.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2016-10-24T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8856138961},{"pair":"US-2018113459-A1 & US-9779621-B1","patent_1":"US-2018113459-A1","title_1":"Vehicle virtual map ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20180113459A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"A vehicle includes: motor(s), local sensors, processor(s) configured to: generate a virtual map based on the local sensors; receive a plurality of reports from a plurality of external entities, statistically compare the plurality of reports, and identify an outlying report based on the statistical comparison; instruct the external entity responsible for the outlying report to mark future reports; ignore marked reports; generate the virtual map based on unmarked reports; reallocate virtual map processing resources based on unmarked reports.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2016-10-24T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8856138961},{"pair":"US-10220769-B1 & US-9868391-B1","patent_1":"US-10220769-B1","title_1":"Vehicular image projection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10220769B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855783972},{"pair":"US-2019061611-A1 & US-9868391-B1","patent_1":"US-2019061611-A1","title_1":"Vehicular image projection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190061611A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855783972},{"pair":"US-10377376-B2 & US-2017341643-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855436649},{"pair":"US-2017192429-A1 & US-2018102001-A1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855103065},{"pair":"US-9921581-B2 & US-2018102001-A1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855103065},{"pair":"US-9696721-B1 & US-9862364-B2","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-03-21T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8854638523},{"pair":"US-2017072962-A1 & US-9534918-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9534918-B2","title_2":"Determining and displaying auto drive lanes in an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9534918B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate generally to identifying and displaying traffic lanes that are available for autonomous driving. This information may be displayed to a driver of a vehicle having an autonomous driving mode, in order to inform the driver of where he or she can use the autonomous driving mode. In one example, the display may visually distinguishing between lanes that are available for auto-drive from those that are not. The display may also include an indicator of the position of a lane (autodrive or not) currently occupied by the vehicle. In addition, if that lane is an autodrive lane the display may include information indicating how much further the vehicle may continue in the autonomous driving mode in that particular lane. The display may also display information indicating the remaining autodrive distance in other lanes as well as the lane with the greatest remaining autodrive distance.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8854149338},{"pair":"US-10259457-B2 & US-2017277191-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2017277191-A1","title_2":"Arranging passenger pickups for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170277191A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to arranging a pickup between a driverless vehicle and a passenger. For instance, dispatch instructions dispatching the vehicle to a predetermined pickup area in order to pick up the passenger are received by the vehicle which begins maneuvering to the predetermined pickup area. While doing so, the vehicle receives from the passenger's client computing device the device's location. An indication that the passenger is interested in a fly-by pickup is identified. The fly-by pickup allows the passenger to safely enter the vehicle at a location outside of the predetermined pickup area and prior to the one or more processors have maneuvered the vehicle to the predetermined pickup area. The vehicle determines that the fly-by pickup is appropriate based on at least the location of the client computing device and the indication, and based on the determination, maneuvers itself in order to attempt the fly-by pickup.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-03-24T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8853972511},{"pair":"US-10437244-B2 & US-9551992-B1","patent_1":"US-10437244-B2","title_1":"Remote vehicle insturction ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10437244B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a mobile computer programmed to receive, from a vehicle computer, an instruction to proceed to a location and vehicle operation data from an in-vehicle communications network. The mobile computer is programmed to determine that a vehicle is ready to proceed to the location based on the operation data. The mobile computer is programmed to receive user input approving transitioning from a boarding state to a driving state. The mobile computer is programmed to then instruct the vehicle computer to actuate vehicle components to proceed to the location.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-18T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8853893506},{"pair":"US-2019362168-A1 & US-9766626-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8853473968},{"pair":"US-2019161085-A1 & US-9494942-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.885329608},{"pair":"US-2018025640-A1 & US-10366502-B1","patent_1":"US-2018025640-A1","title_1":"Using Virtual Data To Test And Train Parking Space Detection Systems ","patent_2":"US-10366502-B1","title_2":"Vehicle heading prediction neural network ","link_1":"https:\/\/patents.google.com\/patent\/US20180025640A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10366502B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for using virtual data to test and train parking space detection systems. Aspects of the invention integrate a virtual driving environment with sensor models (e.g., of a radar system) to provide virtual radar data in relatively large quantities in a relatively short amount of time. The sensor models perceive values for relevant parameters of a training data set. Relevant parameters can be randomized in the recorded data to ensure a diverse training data set with minimal bias. Since the driving environment is virtualized, the training data set can be generated alongside ground truth data. The ground truth data is used to annotate true locations, which are used to train a parking space classification algorithms to detect the free space boundaries.","abstract_2":"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating vehicle heading predictions from point cloud data using a neural network. One of the methods includes receiving a plurality of different projections of point cloud data, wherein the point cloud data represents different sensor measurements of electromagnetic radiation reflected off a vehicle. Each of the plurality of projections of point cloud data is provided as input to a neural network subsystem trained to receive projections of point cloud data for a vehicle and to generate one or more vehicle heading classifications as an output. At the output of the neural network subsystem, one or more vehicle heading predictions is received.","priority_1":"2016-07-19T00:00:00","priority_2":"2016-12-09T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8852227214},{"pair":"US-2019012913-A1 & US-2017341643-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8851730787},{"pair":"US-2018120857-A1 & US-2018143643-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.885050048},{"pair":"US-2018281782-A1 & US-2018135972-A1","patent_1":"US-2018281782-A1","title_1":"Wrong-way vehicle detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180281782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-03-30T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.884774433},{"pair":"US-10442429-B2 & US-2018135972-A1","patent_1":"US-10442429-B2","title_1":"Wrong-way vehicle detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10442429B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-03-30T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.884774433},{"pair":"US-2019012913-A1 & US-9862364-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8846464417},{"pair":"US-10528055-B2 & US-9575490-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.884580413},{"pair":"US-2019066509-A1 & US-9868391-B1","patent_1":"US-2019066509-A1","title_1":"Vehicular image projection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190066509A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A computer programmed to actuate a light source to project a symbol outwardly from a vehicle. The computer is further programmed to actuate the light source to modify the projection based on a determination that a trajectory of the vehicle is changing.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845479769},{"pair":"US-2019012913-A1 & US-10146223-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845377034},{"pair":"US-10528055-B2 & US-2018143643-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845368785},{"pair":"US-2017247040-A1 & US-9766626-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845065977},{"pair":"US-2018137756-A1 & US-9868391-B1","patent_1":"US-2018137756-A1","title_1":"Detecting and responding to emergency vehicles in a roadway ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180137756A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for detecting and responding to emergency vehicles in a roadway. Aspects of the invention can be used to detect emergency vehicles and properly yield to emergency vehicles depending on roadway configuration. A vehicle includes a plurality of sensors. The vehicle also includes vehicle to vehicle (V2V) communication capabilities and has access to map data. Sensor data from the plurality of sensors along with map data is provided as input to a neural network (either in the vehicle or in the cloud). Based on sensor data, the neural network detects when one or more emergency vehicles are approaching the vehicle. From a roadway configuration, a vehicle can use the plurality of sensors to automatically (and safely) yield to detected emergency vehicle(s). Automatically yielding can include one or more of: slowing down, changing lanes, stopping, etc.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-11-17T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8844899567},{"pair":"US-2017139420-A1 & US-9575490-B2","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2014-07-16T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8844200645},{"pair":"US-2019111922-A1 & US-9766626-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8844196098},{"pair":"US-2018239361-A1 & US-10146223-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8843374501},{"pair":"US-2018281782-A1 & US-9551992-B1","patent_1":"US-2018281782-A1","title_1":"Wrong-way vehicle detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180281782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8843126594},{"pair":"US-10442429-B2 & US-9551992-B1","patent_1":"US-10442429-B2","title_1":"Wrong-way vehicle detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10442429B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8843126594},{"pair":"US-2018215374-A1 & US-10496091-B1","patent_1":"US-2018215374-A1","title_1":"Self-parking vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180215374A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A computer is programmed to, upon determining that a user has departed a vehicle, identify available parking spaces based at least in part on one of stored parking restrictions and vehicle sensor data. The computer is programmed to select one of the parking spaces based at least in part on a distance to a respective parking space and an environmental condition. The computer navigates the vehicle to park at the selected parking space.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841548785},{"pair":"US-10282984-B2 & US-9463794-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-05-30T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841431037},{"pair":"US-2018350234-A1 & US-9463794-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-05-30T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841431037},{"pair":"US-9983591-B2 & US-10146223-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841261491},{"pair":"US-2020073405-A1 & US-9400183-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2018-09-05T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841174469},{"pair":"US-10442429-B2 & US-9740202-B2","patent_1":"US-10442429-B2","title_1":"Wrong-way vehicle detection ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10442429B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8839856166},{"pair":"US-2018281782-A1 & US-9740202-B2","patent_1":"US-2018281782-A1","title_1":"Wrong-way vehicle detection ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180281782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8839856166},{"pair":"US-2018224859-A1 & US-9862364-B2","patent_1":"US-2018224859-A1","title_1":"Tornado Detection Systems And Methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180224859A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example tornado detection systems and methods are described. In one implementation, a method receives data from a sensor mounted to a vehicle and analyzes the received data using a deep neural network. The method determines whether a tornado is identified in the received data based on the analysis of the received data. If a tornado is identified in the received data, the method determines a trajectory of the tornado.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-02-08T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8838206257},{"pair":"US-2019161085-A1 & US-9594379-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9594379-B1","title_2":"Detecting sensor degradation by actively controlling an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9594379B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems are disclosed for determining sensor degradation by actively controlling an autonomous vehicle. Determining sensor degradation may include obtaining sensor readings from a sensor of an autonomous vehicle, and determining baseline state information from the obtained sensor readings. A movement characteristic of the autonomous vehicle, such as speed or position, may then be changed. The sensor may then obtain additional sensor readings, and second state information may be determined from these additional sensor readings. Expected state information may be determined from the baseline state information and the change in the movement characteristic of the autonomous vehicle. A comparison of the expected state information and the second state information may then be performed. Based on this comparison, a determination may be made as to whether the sensor has degraded.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8837899664},{"pair":"US-2019362168-A1 & US-10146223-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8837252185},{"pair":"US-2017247040-A1 & US-9557737-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8836872315},{"pair":"US-2019161085-A1 & US-10204278-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8836129197},{"pair":"US-2018099663-A1 & US-9862364-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835688565},{"pair":"US-2018319402-A1 & US-9766626-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-05-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835680584},{"pair":"US-2018215374-A1 & US-2018143643-A1","patent_1":"US-2018215374-A1","title_1":"Self-parking vehicle ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180215374A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A computer is programmed to, upon determining that a user has departed a vehicle, identify available parking spaces based at least in part on one of stored parking restrictions and vehicle sensor data. The computer is programmed to select one of the parking spaces based at least in part on a distance to a respective parking space and an environmental condition. The computer navigates the vehicle to park at the selected parking space.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835576841},{"pair":"US-10423847-B2 & US-10146223-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835307773},{"pair":"US-10430968-B2 & US-2019311209-A1","patent_1":"US-10430968-B2","title_1":"Vehicle localization using cameras ","patent_2":"US-2019311209-A1","title_2":"Feature Recognition Assisted Super-resolution Method ","link_1":"https:\/\/patents.google.com\/patent\/US10430968B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311209A1\/en","abstract_1":"According to one embodiment, a system for determining a position of a vehicle includes an image sensor, a top-down view component, a comparison component, and a location component. The image sensor obtains an image of an environment near a vehicle. The top-down view component is configured to generate a top-down view of a ground surface based on the image of the environment. The comparison component is configured to compare the top-down image with a map, the map comprising a top-down light LIDAR intensity map or a vector-based semantic map. The location component is configured to determine a location of the vehicle on the map based on the comparison.","abstract_2":"A vehicle mounted imaging system tracks and resolves image using an object image regions of interest at a higher resolution than that which can be provided by typical wide-angle optics. The imaging system includes an object identification camera, a sampling camera, and one or more computing devices. The one or more computing devices obtain a full-frame image from the object identification camera and identify at least one region of interest within the full frame image. The one or more computing devices then configure the sampling camera to capture images of a sampling area containing the region of interest, wherein the sampling area consists of some, but not all, of a field of view of the sampling camera. Using a super-image resolution technique, the one or more computing devices create a high-resolution image of the region of interest from a plurality of images captured by the sampling camera.","priority_1":"2017-03-14T00:00:00","priority_2":"2016-12-09T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835174248},{"pair":"US-10437244-B2 & US-9740202-B2","patent_1":"US-10437244-B2","title_1":"Remote vehicle insturction ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10437244B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A system includes a mobile computer programmed to receive, from a vehicle computer, an instruction to proceed to a location and vehicle operation data from an in-vehicle communications network. The mobile computer is programmed to determine that a vehicle is ready to proceed to the location based on the operation data. The mobile computer is programmed to receive user input approving transitioning from a boarding state to a driving state. The mobile computer is programmed to then instruct the vehicle computer to actuate vehicle components to proceed to the location.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-18T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833946894},{"pair":"US-2017248952-A1 & US-9766626-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.883367065},{"pair":"US-10259457-B2 & US-9766626-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833656838},{"pair":"US-2019012913-A1 & US-10496091-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833570682},{"pair":"US-2019101933-A1 & US-9862364-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833553823},{"pair":"US-2020026279-A1 & US-2017277191-A1","patent_1":"US-2020026279-A1","title_1":"Smart neighborhood routing for autonomous vehicles ","patent_2":"US-2017277191-A1","title_2":"Arranging passenger pickups for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200026279A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170277191A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to arranging a pickup between a driverless vehicle and a passenger. For instance, dispatch instructions dispatching the vehicle to a predetermined pickup area in order to pick up the passenger are received by the vehicle which begins maneuvering to the predetermined pickup area. While doing so, the vehicle receives from the passenger's client computing device the device's location. An indication that the passenger is interested in a fly-by pickup is identified. The fly-by pickup allows the passenger to safely enter the vehicle at a location outside of the predetermined pickup area and prior to the one or more processors have maneuvered the vehicle to the predetermined pickup area. The vehicle determines that the fly-by pickup is appropriate based on at least the location of the client computing device and the indication, and based on the determination, maneuvers itself in order to attempt the fly-by pickup.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-03-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.883265643},{"pair":"US-2018120858-A1 & US-2018011496-A1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8831577133},{"pair":"US-10082796-B2 & US-2018011496-A1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8831577133},{"pair":"US-2017072962-A1 & US-2018011496-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8830624107},{"pair":"US-2019176830-A1 & US-2017341643-A1","patent_1":"US-2019176830-A1","title_1":"Vehicle lane change ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190176830A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a processor. The system includes a memory, the memory storing instructions executable by the processor to identify a relative area within a specified distance from a first vehicle and free of another vehicle, identify a second vehicle within a second specified distance of the relative area, transmit the relative area to the second vehicle, and navigate the first vehicle to the relative area within a specified time.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-12-11T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8830434825},{"pair":"US-2019111922-A1 & US-9594379-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9594379-B1","title_2":"Detecting sensor degradation by actively controlling an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9594379B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Methods and systems are disclosed for determining sensor degradation by actively controlling an autonomous vehicle. Determining sensor degradation may include obtaining sensor readings from a sensor of an autonomous vehicle, and determining baseline state information from the obtained sensor readings. A movement characteristic of the autonomous vehicle, such as speed or position, may then be changed. The sensor may then obtain additional sensor readings, and second state information may be determined from these additional sensor readings. Expected state information may be determined from the baseline state information and the change in the movement characteristic of the autonomous vehicle. A comparison of the expected state information and the second state information may then be performed. Based on this comparison, a determination may be made as to whether the sensor has degraded.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8830047677},{"pair":"US-2018350234-A1 & US-9836052-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-05-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8829079254},{"pair":"US-10282984-B2 & US-9836052-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-05-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8829079254},{"pair":"US-2017248952-A1 & US-9557737-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8826926986},{"pair":"US-2019039616-A1 & US-9766626-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8826868131},{"pair":"US-10259457-B2 & US-9352752-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9352752-B2","title_2":"Engaging and disengaging for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9352752B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate switching between autonomous and manual driving modes. In order to do so, the vehicle's computer may conduct a series of environmental, system, and driver checks to identify certain conditions. The computer may correct some of these conditions and also provide a driver with a checklist of tasks for completion. Once the tasks have been completed and the conditions are changed, the computer may allow the driver to switch from the manual to the autonomous driving mode. The computer may also make a determination, under certain conditions, that it would be detrimental to the driver's safety or comfort to make a switch from the autonomous driving mode to the manual driving mode.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8826244002},{"pair":"US-2018319402-A1 & US-10139829-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2017-05-05T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.882587177},{"pair":"US-2019101933-A1 & US-2017341643-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825867918},{"pair":"US-10589742-B2 & US-9494942-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":null,"abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825253854},{"pair":"US-2017248952-A1 & US-10204278-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825202321},{"pair":"US-2018033309-A1 & US-9669827-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-07-29T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8824065811},{"pair":"US-10267911-B2 & US-2016209844-A1","patent_1":"US-10267911-B2","title_1":"Steering wheel actuation ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10267911B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A computing device in a vehicle can be programmed to determine a time to a collision and a field of safe travel, select one of a first and a second haptic output based on (a) the field of safe travel and (b) a predetermined time threshold. The computing device can deliver the first haptic output via a steering wheel when the time to collision is greater than the predetermined time threshold and deliver the second haptic output via the steering wheel when the time to collision is less than or equal to the predetermined time threshold.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-03-31T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8823434714},{"pair":"US-10289113-B2 & US-9766626-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8823409441},{"pair":"US-2017248951-A1 & US-9766626-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.882292589},{"pair":"US-2019012913-A1 & US-9557736-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821720434},{"pair":"US-2017248953-A1 & US-9766626-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821400463},{"pair":"US-2019111922-A1 & US-10059334-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821086895},{"pair":"US-2018081357-A1 & US-10146223-B1","patent_1":"US-2018081357-A1","title_1":"Geocoded information aided vehicle warning ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180081357A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Methods and apparatus are disclosed for geocoded information aided vehicle warning. An example disclosed vehicle includes range detection sensors and a threat detector. The example threat detector determines a threat level based on a location of the vehicle. Additionally, the example threat detector defines, with the range detection sensors, contours of detection zones around the vehicle based on the threat level. The example threat detector also performs first actions, via a body control module, to secure the vehicle in response to a threat detected in the detection zone.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-09-16T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820938592},{"pair":"US-2017072962-A1 & US-9862364-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820866303},{"pair":"US-2019235520-A1 & US-9373045-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820854591},{"pair":"US-10377376-B2 & US-9862364-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820854139},{"pair":"US-9989963-B2 & US-9766626-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820425157},{"pair":"US-2017206426-A1 & US-9862364-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820187733},{"pair":"US-2019385336-A1 & US-2019311209-A1","patent_1":"US-2019385336-A1","title_1":"Vehicle Localization Using Cameras ","patent_2":"US-2019311209-A1","title_2":"Feature Recognition Assisted Super-resolution Method ","link_1":"https:\/\/patents.google.com\/patent\/US20190385336A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311209A1\/en","abstract_1":"According to one embodiment, a system for determining a position of a vehicle includes an image sensor, a top-down view component, a comparison component, and a location component. The image sensor obtains an image of an environment near a vehicle. The top-down view component is configured to generate a top-down view of a ground surface based on the image of the environment. The comparison component is configured to compare the top-down image with a map, the map comprising a top-down light LIDAR intensity map or a vector-based semantic map. The location component is configured to determine a location of the vehicle on the map based on the comparison.","abstract_2":"A vehicle mounted imaging system tracks and resolves image using an object image regions of interest at a higher resolution than that which can be provided by typical wide-angle optics. The imaging system includes an object identification camera, a sampling camera, and one or more computing devices. The one or more computing devices obtain a full-frame image from the object identification camera and identify at least one region of interest within the full frame image. The one or more computing devices then configure the sampling camera to capture images of a sampling area containing the region of interest, wherein the sampling area consists of some, but not all, of a field of view of the sampling camera. Using a super-image resolution technique, the one or more computing devices create a high-resolution image of the region of interest from a plurality of images captured by the sampling camera.","priority_1":"2017-03-14T00:00:00","priority_2":"2016-12-09T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818920344},{"pair":"US-2017247040-A1 & US-10204278-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818726256},{"pair":"US-2018081357-A1 & US-2018102001-A1","patent_1":"US-2018081357-A1","title_1":"Geocoded information aided vehicle warning ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180081357A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Methods and apparatus are disclosed for geocoded information aided vehicle warning. An example disclosed vehicle includes range detection sensors and a threat detector. The example threat detector determines a threat level based on a location of the vehicle. Additionally, the example threat detector defines, with the range detection sensors, contours of detection zones around the vehicle based on the threat level. The example threat detector also performs first actions, via a body control module, to secure the vehicle in response to a threat detected in the detection zone.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-09-16T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818715473},{"pair":"US-10377383-B2 & US-2017341643-A1","patent_1":"US-10377383-B2","title_1":"Vehicle lane change ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377383B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a processor. The system includes a memory, the memory storing instructions executable by the processor to identify a relative area within a specified distance from a first vehicle and free of another vehicle, identify a second vehicle within a second specified distance of the relative area, transmit the relative area to the second vehicle, and navigate the first vehicle to the relative area within a specified time.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-12-11T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818677858},{"pair":"US-9478137-B1 & US-2018143643-A1","patent_1":"US-9478137-B1","title_1":"Detecting and communicating lane splitting maneuver ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9478137B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle system includes a lane detector programmed to output a boundary signal representing a location of a lane boundary relative to a host vehicle. A processing device is programmed to determine, from the boundary signal, whether the host vehicle is performing a lane splitting maneuver. If so, the processing device is programmed to transmit a lane splitting signal.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-06-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818017665},{"pair":"US-9696721-B1 & US-10156851-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-03-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8817116078},{"pair":"US-2017197615-A1 & US-2018135972-A1","patent_1":"US-2017197615-A1","title_1":"System and method for reverse perpendicular parking a vehicle ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170197615A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A method for parking a vehicle in a parking lot includes generating steering commands for the vehicle while in the lot based on an occupancy grid and plenoptic camera data. The occupancy grid indicates occupied areas and unoccupied areas around the vehicle and is derived from map data defining parking spots relative to a topological feature contained within the lot. The plenoptic camera data defines a plurality of depth maps and corresponding images that include the topological feature captured during movement of the vehicle. The steering command is generated such that the vehicle follows a reverse perpendicular path into one of the spots without entering an occupied area.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-11T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8816968326},{"pair":"US-2019176830-A1 & US-9862364-B2","patent_1":"US-2019176830-A1","title_1":"Vehicle lane change ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190176830A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a processor. The system includes a memory, the memory storing instructions executable by the processor to identify a relative area within a specified distance from a first vehicle and free of another vehicle, identify a second vehicle within a second specified distance of the relative area, transmit the relative area to the second vehicle, and navigate the first vehicle to the relative area within a specified time.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-12-11T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8816959075},{"pair":"US-2018033309-A1 & US-9557736-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-07-29T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8816851936},{"pair":"US-2017072962-A1 & US-10093181-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10093181-B1","title_2":"Occupant facing vehicle display ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10093181B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering an occupant of the vehicle to a destination autonomously as well as providing information about the vehicle and the vehicle's environment for display to the occupant.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8816156299},{"pair":"US-2018099663-A1 & US-9836052-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815801686},{"pair":"US-2017072962-A1 & US-9352752-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9352752-B2","title_2":"Engaging and disengaging for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9352752B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate switching between autonomous and manual driving modes. In order to do so, the vehicle's computer may conduct a series of environmental, system, and driver checks to identify certain conditions. The computer may correct some of these conditions and also provide a driver with a checklist of tasks for completion. Once the tasks have been completed and the conditions are changed, the computer may allow the driver to switch from the manual to the autonomous driving mode. The computer may also make a determination, under certain conditions, that it would be detrimental to the driver's safety or comfort to make a switch from the autonomous driving mode to the manual driving mode.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815688637},{"pair":"US-2019101933-A1 & US-2018143643-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815660593},{"pair":"US-2019101933-A1 & US-9557736-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815099206},{"pair":"US-2018211119-A1 & US-10013773-B1","patent_1":"US-2018211119-A1","title_1":"Sign Recognition for Autonomous Vehicles ","patent_2":"US-10013773-B1","title_2":"Neural networks for object detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180211119A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10013773B1\/en","abstract_1":"An autonomous vehicle includes both a LIDAR sensor and a camera. A point cloud from the LIDAR sensor is processed to remove points corresponding to a ground plane and points having a reflectivity below a reflectivity threshold. The remaining points are grouped into clusters. Clusters having points satisfying a flatness threshold are then converted into 2D pixel positions in the output of the camera. Regions of interest including these 2D pixel positions are then analyzed to detect and interpret any road signs present.","abstract_2":"A neural network system for identifying positions of objects in an input image can include an object detector neural network, a memory interface subsystem, and an external memory. The object detector neural network is configured to, at each time step of multiple successive time steps, (i) receive a first neural network input that represents the input image and a second neural network input that identifies a first set of positions of the input image that have each been classified as showing a respective object of the set of objects, and (ii) process the first and second inputs to generate a set of output scores that each represents a respective likelihood that an object that is not one of the objects shown at any of the positions in the first set of positions is shown at a respective position of the input image that corresponds to the output score.","priority_1":"2017-01-23T00:00:00","priority_2":"2016-12-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815090517},{"pair":"US-2017072962-A1 & US-9766626-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815087978},{"pair":"US-10589742-B2 & US-9690296-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814731551},{"pair":"US-10377376-B2 & US-9836052-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814598587},{"pair":"US-2018350234-A1 & US-9669827-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-05-30T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814434991},{"pair":"US-10282984-B2 & US-9669827-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-05-30T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814434991},{"pair":"US-2019101933-A1 & US-9707966-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814337841},{"pair":"US-2018099663-A1 & US-9557736-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814228747},{"pair":"US-2017139420-A1 & US-2018143643-A1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-07-16T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814142972},{"pair":"US-2019362168-A1 & US-2018143643-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8813301824},{"pair":"US-10259457-B2 & US-2018011496-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8813287159},{"pair":"US-2019377343-A1 & US-10496091-B1","patent_1":"US-2019377343-A1","title_1":"Picking up and dropping off passengers at an airport using an autonomous vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190377343A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A controller of an autonomous vehicle receives a travel itinerary of a passenger and an airport map. The controller then uses the airport map to arrive at a terminal corresponding to the passenger's travel itinerary. Upon arrival at the terminal the controller communicates with parked vehicles (V2V) or infrastructure to identify an unoccupied parking spot and then autonomously parks. When picking up a passenger, the controller determines whether the passenger has checked luggage and adjusts and arrival time accordingly and may account for the storage volume of the luggage. The controller may also loop a circuit at the airport where a wait time has been exceeded. In some embodiments, augmented reality may be used to help the passenger identify the vehicle.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-01-10T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8813000898},{"pair":"US-10345822-B1 & US-2017098129-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812678708},{"pair":"US-2019161085-A1 & US-9440652-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9440652-B1","title_2":"Filtering noisy\/high-intensity regions in laser-based lane marker detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9440652B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"An autonomous vehicle may be configured to receive, using a computer system, a plurality of remission signals from a portion of a lane of travel in an environment in response to at least one sensor of the vehicle sensing the portion of the lane of travel. A given remission signal of the plurality of remission signals may include a remission value indicative of a level of reflectiveness for the portion of the lane of travel. The vehicle may also be configured to compare the plurality of remission signals to a known remission value indicative of a level of reflectiveness for a lane marker in the lane of travel. Based on the comparison, the vehicle may additionally be configured to determine whether the portion of the lane of travel in the environment is indicative of a presence of the lane marker.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-08-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812634858},{"pair":"US-10259457-B2 & US-10093181-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10093181-B1","title_2":"Occupant facing vehicle display ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10093181B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering an occupant of the vehicle to a destination autonomously as well as providing information about the vehicle and the vehicle's environment for display to the occupant.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812604929},{"pair":"US-10423847-B2 & US-2018143643-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812435212},{"pair":"US-10410524-B2 & US-9669827-B1","patent_1":"US-10410524-B2","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10410524B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has traveled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-07-29T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.881185497},{"pair":"US-9989963-B2 & US-10204278-B2","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.881153714},{"pair":"US-10377383-B2 & US-9862364-B2","patent_1":"US-10377383-B2","title_1":"Vehicle lane change ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377383B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a processor. The system includes a memory, the memory storing instructions executable by the processor to identify a relative area within a specified distance from a first vehicle and free of another vehicle, identify a second vehicle within a second specified distance of the relative area, transmit the relative area to the second vehicle, and navigate the first vehicle to the relative area within a specified time.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-12-11T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8809910226},{"pair":"US-2018047293-A1 & US-10146223-B1","patent_1":"US-2018047293-A1","title_1":"Platooning autonomous vehicle navigation sensory exchange ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180047293A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle system includes a communication interface programmed to communicate with a plurality of platooning vehicles, including a rear vehicle, and receive sensor signals transmitted from the rear vehicle. The vehicle system further includes a processor programmed to command the rear vehicle to turn around and programmed to output control signals to the plurality of platooning vehicles. The control signals control at least one of the plurality platooning vehicles to travel in a reverse direction according to the sensor signals received from the rear vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-08-15T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8809660837},{"pair":"US-2020073405-A1 & US-9575490-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8809537022},{"pair":"US-2018120857-A1 & US-10204278-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8809068528},{"pair":"US-2017247040-A1 & US-10059334-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880882991},{"pair":"US-10589742-B2 & US-9594379-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9594379-B1","title_2":"Detecting sensor degradation by actively controlling an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9594379B1\/en","abstract_1":null,"abstract_2":"Methods and systems are disclosed for determining sensor degradation by actively controlling an autonomous vehicle. Determining sensor degradation may include obtaining sensor readings from a sensor of an autonomous vehicle, and determining baseline state information from the obtained sensor readings. A movement characteristic of the autonomous vehicle, such as speed or position, may then be changed. The sensor may then obtain additional sensor readings, and second state information may be determined from these additional sensor readings. Expected state information may be determined from the baseline state information and the change in the movement characteristic of the autonomous vehicle. A comparison of the expected state information and the second state information may then be performed. Based on this comparison, a determination may be made as to whether the sensor has degraded.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8808706791},{"pair":"US-10289113-B2 & US-10204278-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8808623799},{"pair":"US-10259457-B2 & US-9575490-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880854615},{"pair":"US-2016210383-A1 & US-2018143643-A1","patent_1":"US-2016210383-A1","title_1":"Virtual autonomous response testbed ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20160210383A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A computing device includes a processing circuit and a data storage medium, and is programmed to receive a user input representing a vehicle control action associated with operating a virtual vehicle in a virtual environment, virtually navigate the virtual vehicle through the virtual environment according to the vehicle control action, collect virtual sensor data, and process the virtual sensor data collected.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-01-21T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8808493082},{"pair":"US-10423847-B2 & US-2018011496-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8807519006},{"pair":"US-2019111922-A1 & US-9690296-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8807407517},{"pair":"US-2017248953-A1 & US-10204278-B2","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8806664277},{"pair":"US-2019362168-A1 & US-2018011496-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8805694582},{"pair":"US-10410524-B2 & US-9557736-B1","patent_1":"US-10410524-B2","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10410524B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has traveled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-07-29T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8805526415},{"pair":"US-2017248951-A1 & US-10204278-B2","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8805324833},{"pair":"US-2018120857-A1 & US-9534918-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9534918-B2","title_2":"Determining and displaying auto drive lanes in an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9534918B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the present disclosure relate generally to identifying and displaying traffic lanes that are available for autonomous driving. This information may be displayed to a driver of a vehicle having an autonomous driving mode, in order to inform the driver of where he or she can use the autonomous driving mode. In one example, the display may visually distinguishing between lanes that are available for auto-drive from those that are not. The display may also include an indicator of the position of a lane (autodrive or not) currently occupied by the vehicle. In addition, if that lane is an autodrive lane the display may include information indicating how much further the vehicle may continue in the autonomous driving mode in that particular lane. The display may also display information indicating the remaining autodrive distance in other lanes as well as the lane with the greatest remaining autodrive distance.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880501732},{"pair":"US-2018203457-A1 & US-9669827-B1","patent_1":"US-2018203457-A1","title_1":"System and Method for Avoiding Interference with a Bus ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180203457A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A method for avoiding interference with a bus. The method includes detecting a bus and obtaining image data from the bus, such as information displayed on the bus. A deep neural network trained on bus images may process the information to associate the bus with a bus route and stop locations. Map data corresponding to the stop locations may also be obtained and used to initiate a lane change or safety response in response to proximity of the bus to a stop location. A corresponding system and computer program product is also disclosed and claimed herein.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-01-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8803214291},{"pair":"US-2017369057-A1 & US-2018135972-A1","patent_1":"US-2017369057-A1","title_1":"Lane Detection Systems And Methods ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170369057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method receives an image from a front-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicle camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-06-24T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8802929719},{"pair":"US-2019111922-A1 & US-9528850-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9528850-B1","title_2":"Suggesting a route based on desired amount of driver interaction ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9528850B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate generally to generating and providing route options for an autonomous vehicle. For example, a user may identify a destination, and in response the vehicle's computer may provide routing options to the user. The routing options may be based on typical navigating considerations such as the total travel time, travel distance, fuel economy, etc. Each routing option may include not only an estimated total time, but also information regarding whether and which portions of the route may be maneuvered under the control of the vehicle alone (fully autonomous), a combination of the vehicle and the driver (semiautonomous), or the driver alone. The time of the longest stretch of driving associated with the autonomous mode as well as map information indicating portions of the routes associated with the type of maneuvering control may also be provided.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8802438678},{"pair":"US-10259457-B2 & US-9290181-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8802318509},{"pair":"US-2019189008-A1 & US-2018143643-A1","patent_1":"US-2019189008-A1","title_1":"Apparatus and methods for detection and notification of icy conditions using integrated vehicle sensors ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190189008A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Methods and apparatus for detection and notification of icy conditions using integrated vehicle sensors. An example apparatus includes a sensor to detect an icy condition adjacent to a door of a vehicle, a processor to determine if a person is exiting the vehicle, and a human-machine interface to alert the person exiting the vehicle of the icy condition.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-05-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8802140514},{"pair":"US-10336326-B2 & US-2018135972-A1","patent_1":"US-10336326-B2","title_1":"Lane detection systems and methods ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10336326B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method received an image from-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicl camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-06-24T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8801609868},{"pair":"US-2017174261-A1 & US-9682707-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880158036},{"pair":"US-10289113-B2 & US-9557737-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8800961578},{"pair":"US-9696721-B1 & US-9836052-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-03-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8800183387},{"pair":"US-2018120857-A1 & US-2017098129-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8800180226},{"pair":"US-2017248951-A1 & US-9557737-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8799922029},{"pair":"US-9989963-B2 & US-9557737-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8799604033},{"pair":"US-2017248952-A1 & US-10059334-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8799270991},{"pair":"US-2017174261-A1 & US-2018143643-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8798768929},{"pair":"US-10589742-B2 & US-10204278-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879822686},{"pair":"US-10345822-B1 & US-2016231748-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016231748-A1","title_2":"Real-Time Image-Based Vehicle Detection based on a Multi-Stage Classification ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160231748A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The present disclosure is directed to an autonomous vehicle having a vehicle control system. The vehicle control system includes a vehicle detection system. The vehicle detection system includes receiving an image of a field of view of the vehicle and identifying a region-pair in the image with a sliding-window filter. The region-pair is made up of a first region and a second region. Each region is determined based on a color of pixels within the sliding-window filter. The vehicle detection system also determines a potential second vehicle in the image based on the region-pair. In response to determining the potential second vehicle in the image, the vehicle detection system performs a multi-stage classification of the image to determine whether the second vehicle is present in the image. Additionally, the vehicle detection system provides instructions to control the first vehicle based at least on the determined second vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-06-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8797380524},{"pair":"US-2017248952-A1 & US-9679206-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8797316759},{"pair":"US-2019111922-A1 & US-9836895-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9836895-B1","title_2":"Simulating virtual objects ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836895B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"An autonomous vehicle is tested using virtual objects. The autonomous vehicle is maneuvered, by one or more computing devices, the autonomous vehicle in an autonomous driving mode. Sensor data is received corresponding to objects in the autonomous vehicle's environment, and virtual object data is received corresponding to a virtual object in the autonomous vehicle's environment. The virtual object represents a real object that is not in the vehicle's environment. The autonomous vehicle is maneuvered based on both the sensor data and the virtual object data. Information about the maneuvering of the vehicle based on both the sensor data and the virtual object data may be logged and analyzed.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8796931846},{"pair":"US-2020026279-A1 & US-2018135972-A1","patent_1":"US-2020026279-A1","title_1":"Smart neighborhood routing for autonomous vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200026279A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-07-20T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8795727115},{"pair":"US-10259457-B2 & US-9862364-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8795589625},{"pair":"US-2018224859-A1 & US-2018102001-A1","patent_1":"US-2018224859-A1","title_1":"Tornado Detection Systems And Methods ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180224859A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Example tornado detection systems and methods are described. In one implementation, a method receives data from a sensor mounted to a vehicle and analyzes the received data using a deep neural network. The method determines whether a tornado is identified in the received data based on the analysis of the received data. If a tornado is identified in the received data, the method determines a trajectory of the tornado.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-02-08T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8795348},{"pair":"US-10068485-B2 & US-10146223-B1","patent_1":"US-10068485-B2","title_1":"Platooning autonomous vehicle navigation sensory exchange ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068485B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle system includes a communication interface programmed to communicate with a plurality of platooning vehicles, including a rear vehicle, and receive sensor signals transmitted from the rear vehicle. The vehicle system further includes a processor programmed to command the rear vehicle to turn around and programmed to output control signals to the plurality of platooning vehicles. The control signals control at least one of the plurality platooning vehicles to travel in a reverse direction according to the sensor signals received from the rear vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-08-15T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8795084513},{"pair":"US-2018114436-A1 & US-2015310281-A1","patent_1":"US-2018114436-A1","title_1":"Lidar and vision vehicle sensing ","patent_2":"US-2015310281-A1","title_2":"Methods and Systems for Object Detection using Multiple Sensors ","link_1":"https:\/\/patents.google.com\/patent\/US20180114436A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150310281A1\/en","abstract_1":"A computer is programmed to identify a vehicle in an infrared image, determine a body type of the vehicle based on the infrared image, and predict coordinates of one or more vehicle elements based at least on the determined body type. The computer is further programmed to then perform a plurality of LIDAR sensor sweeps and, based on the LIDAR sensor sweeps, determine whether the vehicle elements are at the predicted coordinates.","abstract_2":"Methods and systems for object detection using multiple sensors are described herein. In an example embodiment, a vehicle's computing device may receive sensor data frames indicative of an environment at different rates from multiple sensors. Based on a first frame from a first sensor indicative of the environment at a first time period and a portion of a first frame that corresponds to the first time period from a second sensor, the computing device may estimate parameters of objects in the vehicle's environment. The computing device may modify the parameters in response to receiving subsequent frames or subsequent portions of frame of sensor data from the sensors even if the frames arrive at the computing device out of order. The computing device may provide the parameters of the objects to systems of the vehicle for object detection and obstacle avoidance.","priority_1":"2016-10-20T00:00:00","priority_2":"2014-04-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8794764983},{"pair":"US-2017192429-A1 & US-2018011496-A1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8794647816},{"pair":"US-9921581-B2 & US-2018011496-A1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8794647816},{"pair":"US-2018224859-A1 & US-10156851-B1","patent_1":"US-2018224859-A1","title_1":"Tornado Detection Systems And Methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180224859A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example tornado detection systems and methods are described. In one implementation, a method receives data from a sensor mounted to a vehicle and analyzes the received data using a deep neural network. The method determines whether a tornado is identified in the received data based on the analysis of the received data. If a tornado is identified in the received data, the method determines a trajectory of the tornado.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-02-08T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8794171125},{"pair":"US-10528055-B2 & US-9534918-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9534918-B2","title_2":"Determining and displaying auto drive lanes in an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9534918B2\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate generally to identifying and displaying traffic lanes that are available for autonomous driving. This information may be displayed to a driver of a vehicle having an autonomous driving mode, in order to inform the driver of where he or she can use the autonomous driving mode. In one example, the display may visually distinguishing between lanes that are available for auto-drive from those that are not. The display may also include an indicator of the position of a lane (autodrive or not) currently occupied by the vehicle. In addition, if that lane is an autodrive lane the display may include information indicating how much further the vehicle may continue in the autonomous driving mode in that particular lane. The display may also display information indicating the remaining autodrive distance in other lanes as well as the lane with the greatest remaining autodrive distance.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8794085997},{"pair":"US-10026317-B2 & US-10204278-B2","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793824666},{"pair":"US-9983591-B2 & US-2018011496-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793807397},{"pair":"US-2018120857-A1 & US-9387854-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793661863},{"pair":"US-2017205823-A1 & US-9766626-B1","patent_1":"US-2017205823-A1","title_1":"Method and device for operating a motor vehicle ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170205823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"The disclosure relates to a method and a device for operating a motor vehicle. The vehicle exhibits a first driving mode in which an at least partial automation of the control of the vehicle is obtained. The vehicle also exhibits a second driving mode in which the automation has been at least partly canceled and replaced by a manual control of the vehicle on the part of a driver. The method for operating the motor vehicle comprises the following steps: ascertaining at least one parameter that is characteristic of a current status of the driver, and adapting a transition strategy for the transition between the first driving mode and the second driving mode in a manner depending on the parameter.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-01-18T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793590402},{"pair":"US-2018239361-A1 & US-2018011496-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793433244},{"pair":"US-10026317-B2 & US-9557737-B1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793202281},{"pair":"US-10026317-B2 & US-9766626-B1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792947057},{"pair":"US-2018319402-A1 & US-9862364-B2","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-05-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792830708},{"pair":"US-10160459-B2 & US-9862364-B2","patent_1":"US-10160459-B2","title_1":"Vehicle lane direction detection ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10160459B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A roadway lane direction is identified based on vehicle sensor data of a traffic sign, a direction of a parked vehicle, and a marking on a surface of the roadway lane. A trajectory of a vehicle is determined to differ from the roadway lane direction, and a vehicle component is then actuated.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-03-22T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792766116},{"pair":"US-10082796-B2 & US-10146223-B1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792624981},{"pair":"US-2018120858-A1 & US-10146223-B1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792624981},{"pair":"US-2019189008-A1 & US-2016370194-A1","patent_1":"US-2019189008-A1","title_1":"Apparatus and methods for detection and notification of icy conditions using integrated vehicle sensors ","patent_2":"US-2016370194-A1","title_2":"Determining Pickup and Destination Locations for Autonomous Vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190189008A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370194A1\/en","abstract_1":"Methods and apparatus for detection and notification of icy conditions using integrated vehicle sensors. An example apparatus includes a sensor to detect an icy condition adjacent to a door of a vehicle, a processor to determine if a person is exiting the vehicle, and a human-machine interface to alert the person exiting the vehicle of the icy condition.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-05-17T00:00:00","priority_2":"2015-06-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792442436},{"pair":"US-2017139420-A1 & US-9255805-B1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2014-07-16T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792288496},{"pair":"US-2018081057-A1 & US-9557736-B1","patent_1":"US-2018081057-A1","title_1":"Metal bridge detection systems and methods ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180081057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-09-20T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792268905},{"pair":"US-2020031468-A1 & US-10496091-B1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-12-14T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792153714},{"pair":"US-10528055-B2 & US-10204278-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792022109},{"pair":"US-2017247040-A1 & US-9679206-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8791761538},{"pair":"US-2017205823-A1 & US-10059334-B1","patent_1":"US-2017205823-A1","title_1":"Method and device for operating a motor vehicle ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170205823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"The disclosure relates to a method and a device for operating a motor vehicle. The vehicle exhibits a first driving mode in which an at least partial automation of the control of the vehicle is obtained. The vehicle also exhibits a second driving mode in which the automation has been at least partly canceled and replaced by a manual control of the vehicle on the part of a driver. The method for operating the motor vehicle comprises the following steps: ascertaining at least one parameter that is characteristic of a current status of the driver, and adapting a transition strategy for the transition between the first driving mode and the second driving mode in a manner depending on the parameter.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-01-18T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879160747},{"pair":"US-2018033309-A1 & US-10156851-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-07-29T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8791226784},{"pair":"US-10377376-B2 & US-9557736-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879109342},{"pair":"US-9989963-B2 & US-10059334-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879089813},{"pair":"US-2018281855-A1 & US-2016209844-A1","patent_1":"US-2018281855-A1","title_1":"Vehicle human machine interface control ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20180281855A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A computing device in a vehicle can determine a plurality of lane change maneuvers based on the time to collision. The computing device can determine a field of safe travel to execute the lane change maneuvers without braking to a stop and display the field of safe travel to an occupant.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-03-31T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789918238},{"pair":"US-10345822-B1 & US-10204278-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789533611},{"pair":"US-2017249844-A1 & US-9557737-B1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789367885},{"pair":"US-2017248951-A1 & US-10059334-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789238125},{"pair":"US-10289113-B2 & US-10059334-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789236524},{"pair":"US-2017248953-A1 & US-9557737-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-9557737-B1","title_2":"Distribution decision trees ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557737B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"The present disclosure is directed to autonomous vehicle having a vehicle control system. The vehicle control system includes a processing system that receives input values that indicate attributes of an object within a threshold distance of the autonomous vehicle and variance values indicating uncertainty associated with the input values. The processing system also provides a plurality of outcomes that are associated with combinations of split decisions. A given split decision indicates whether a particular input value is above or below a threshold value associated with the given split decision. The processing system further determines (i) a probability that the particular input value is above a threshold value and (ii) a probability that the particular input is below the threshold value for a given split decision. Additionally, the processing system determines one or more likelihoods associated with a given outcome. Further, the processing system provides instructions to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8788718878},{"pair":"US-2019012913-A1 & US-2018011496-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8788521354},{"pair":"US-2018120857-A1 & US-9193355-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9193355-B2","title_2":"Construction zone sign detection using light detection and ranging ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9193355B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for construction zone sign detection are described. A computing device may be configured to receive a 3D point cloud of a vicinity of a road on which a vehicle is travelling. The 3D point cloud may include points corresponding to light reflected from objects in the vicinity of the road. The computing device may be configured to determine a set of points representing an area at a given height from a surface of the road, and estimate a shape associated with the set of points. Further, the computing device may be configured to determine a likelihood that the set of points represents a construction zone sign, based on the estimated shape. Based on the likelihood, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8787768066},{"pair":"US-2018120857-A1 & US-2015266472-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2015266472-A1","title_2":"Construction Zone Object Detection Using Light Detection and Ranging ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150266472A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for construction zone object detection are described. A computing device may be configured to receive, from a LIDAR, a 3D point cloud of a road on which a vehicle is travelling. The 3D point cloud may comprise points corresponding to light reflected from objects on the road. Also, the computing device may be configured to determine sets of points in the 3D point cloud representing an area within a threshold distance from a surface of the road. Further, the computing device may be configured to identify construction zone objects in the sets of points. Further, the computing device may be configured to determine a likelihood of existence of a construction zone, based on the identification. Based on the likelihood, the computing device may be configured to modify a control strategy of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8787768066},{"pair":"US-2017249844-A1 & US-9766626-B1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8787271808},{"pair":"US-2018120857-A1 & US-2016092755-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2016092755-A1","title_2":"Construction Zone Sign Detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160092755A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for detection of a construction zone sign are described. A computing device, configured to control the vehicle, may be configured to receive, from an image-capture device coupled to the computing device, images of a vicinity of the road on which the vehicle is travelling. Also, the computing device may be configured to determine image portions in the images that may depict sides of the road at a predetermined height range. Further, the computing device may be configured to detect a construction zone sign in the image portions, and determine a type of the construction zone sign. Accordingly, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8787055088},{"pair":"US-2019161085-A1 & US-9555740-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9555740-B1","title_2":"Cross-validating sensors of an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9555740B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems are disclosed for cross-validating a second sensor with a first sensor. Cross-validating the second sensor may include obtaining sensor readings from the first sensor and comparing the sensor readings from the first sensor with sensor readings obtained from the second sensor. In particular, the comparison of the sensor readings may include comparing state information about a vehicle detected by the first sensor and the second sensor. In addition, comparing the sensor readings may include obtaining a first image from the first sensor, obtaining a second image from the second sensor, and then comparing various characteristics of the images. One characteristic that may be compared are object labels applied to the vehicle detected by the first and second sensor. The first and second sensors may be different types of sensors.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8786896514},{"pair":"US-2017248953-A1 & US-10059334-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.878675851},{"pair":"US-2017072962-A1 & US-9575490-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8786554377},{"pair":"US-2019066509-A1 & US-9557736-B1","patent_1":"US-2019066509-A1","title_1":"Vehicular image projection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190066509A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A computer programmed to actuate a light source to project a symbol outwardly from a vehicle. The computer is further programmed to actuate the light source to modify the projection based on a determination that a trajectory of the vehicle is changing.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-08-22T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8786516012},{"pair":"US-2018370532-A1 & US-2018135972-A1","patent_1":"US-2018370532-A1","title_1":"Assessing u-turn feasibility ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180370532A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Methods, devices and apparatuses pertaining to U-turn assistance. The method may include detecting an intention of an operator of a vehicle of rendering a U-turn at a location. A computing device may obtain geographic information associated with the U-turn, and assess feasibility of the U-turn at the location based on the geographic information. Further, the computing device may provide a notification to the operator based on the feasibility of the U-turn to assist the operator to operate the U-turn of the vehicle at the location.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-14T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8785753552},{"pair":"US-2020073405-A1 & US-9684836-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8785332157},{"pair":"US-2019023280-A1 & US-9557736-B1","patent_1":"US-2019023280-A1","title_1":"Method and device for environment-based adaptation of driver assistance functions ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190023280A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A method is disclosed to operate a motor vehicle using a driver assistance system. The driver assistance system includes, for at least one driver assistance system function, at least one criterion relating to a vehicle environment. The at least one criterion is defined for an adaptation of the driver assistance system function, a number of features of the environment of the vehicle are detected, a probability of the occurrence of at least one criterion is estimated on the basis of a combination of the detected features, and the driver assistance system function is adapted on the basis of the estimated probability.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-07-21T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8783994763},{"pair":"US-2019101933-A1 & US-9551992-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8783844102},{"pair":"US-2017249844-A1 & US-10204278-B2","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8783384013},{"pair":"US-2017174261-A1 & US-2016209844-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8783048765},{"pair":"US-10528055-B2 & US-9387854-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8782877237},{"pair":"US-2019066509-A1 & US-10496091-B1","patent_1":"US-2019066509-A1","title_1":"Vehicular image projection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190066509A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A computer programmed to actuate a light source to project a symbol outwardly from a vehicle. The computer is further programmed to actuate the light source to modify the projection based on a determination that a trajectory of the vehicle is changing.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8782800171},{"pair":"US-2017205823-A1 & US-9669827-B1","patent_1":"US-2017205823-A1","title_1":"Method and device for operating a motor vehicle ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170205823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"The disclosure relates to a method and a device for operating a motor vehicle. The vehicle exhibits a first driving mode in which an at least partial automation of the control of the vehicle is obtained. The vehicle also exhibits a second driving mode in which the automation has been at least partly canceled and replaced by a manual control of the vehicle on the part of a driver. The method for operating the motor vehicle comprises the following steps: ascertaining at least one parameter that is characteristic of a current status of the driver, and adapting a transition strategy for the transition between the first driving mode and the second driving mode in a manner depending on the parameter.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-01-18T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8782665955},{"pair":"US-10410524-B2 & US-10156851-B1","patent_1":"US-10410524-B2","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10410524B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has traveled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-07-29T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8782260601},{"pair":"US-10589742-B2 & US-9440652-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9440652-B1","title_2":"Filtering noisy\/high-intensity regions in laser-based lane marker detection ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9440652B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle may be configured to receive, using a computer system, a plurality of remission signals from a portion of a lane of travel in an environment in response to at least one sensor of the vehicle sensing the portion of the lane of travel. A given remission signal of the plurality of remission signals may include a remission value indicative of a level of reflectiveness for the portion of the lane of travel. The vehicle may also be configured to compare the plurality of remission signals to a known remission value indicative of a level of reflectiveness for a lane marker in the lane of travel. Based on the comparison, the vehicle may additionally be configured to determine whether the portion of the lane of travel in the environment is indicative of a presence of the lane marker.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-08-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781936672},{"pair":"US-10528055-B2 & US-2017098129-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781500087},{"pair":"US-2017072962-A1 & US-9669827-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781492849},{"pair":"US-2018120857-A1 & US-9862364-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781304238},{"pair":"US-2019012913-A1 & US-2017098129-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8780656848},{"pair":"US-10026317-B2 & US-9679206-B1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8780431792},{"pair":"US-10408937-B2 & US-9557736-B1","patent_1":"US-10408937-B2","title_1":"Metal bridge detection systems and methods ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10408937B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-09-20T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8779759253},{"pair":"US-10481609-B2 & US-9682707-B1","patent_1":"US-10481609-B2","title_1":"Parking-lot-navigation system and method ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10481609B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-12-09T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8779531637},{"pair":"US-2017247040-A1 & US-9646497-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8779233652},{"pair":"US-10289113-B2 & US-9679206-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8778868356},{"pair":"US-10259457-B2 & US-10139829-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.87784214},{"pair":"US-9478137-B1 & US-9682707-B1","patent_1":"US-9478137-B1","title_1":"Detecting and communicating lane splitting maneuver ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9478137B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle system includes a lane detector programmed to output a boundary signal representing a location of a lane boundary relative to a host vehicle. A processing device is programmed to determine, from the boundary signal, whether the host vehicle is performing a lane splitting maneuver. If so, the processing device is programmed to transmit a lane splitting signal.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-06-17T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8778329579},{"pair":"US-2017072962-A1 & US-9290181-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.877823002},{"pair":"US-2018081057-A1 & US-10156851-B1","patent_1":"US-2018081057-A1","title_1":"Metal bridge detection systems and methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180081057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-09-20T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8778180682},{"pair":"US-2017174261-A1 & US-9836052-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.877786993},{"pair":"US-10528055-B2 & US-2018135972-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8777024404},{"pair":"US-2018273048-A1 & US-9862364-B2","patent_1":"US-2018273048-A1","title_1":"Vehicle lane direction detection ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180273048A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A roadway lane direction is identified based on vehicle sensor data of a traffic sign, a direction of a parked vehicle, and a marking on a surface of the roadway lane. A trajectory of a vehicle is determined to differ from the roadway lane direction, and a vehicle component is then actuated.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-03-22T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8777012032},{"pair":"US-2017270374-A1 & US-9669827-B1","patent_1":"US-2017270374-A1","title_1":"Pedestrian detection and motion prediction with rear-facing camera ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170270374A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving one or more images from a rear-facing camera on a vehicle. The method further includes determining that a pedestrian is present in the one or more images, predicting future motion of the pedestrian, and notifying a driver-assistance or automated driving system when a conflict exists between forward motion of the vehicle and the predicted future motion of the pedestrian.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-03-21T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8776986914},{"pair":"US-10055652-B2 & US-9669827-B1","patent_1":"US-10055652-B2","title_1":"Pedestrian detection and motion prediction with rear-facing camera ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10055652B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving one or more images from a rear-facing camera on a vehicle. The method further includes determining that a pedestrian is present in the one or more images, predicting future motion of the pedestrian, and notifying a driver-assistance or automated driving system when a conflict exists between forward motion of the vehicle and the predicted future motion of the pedestrian.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-03-21T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8776986914},{"pair":"US-10377376-B2 & US-9958869-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9958869-B1","title_2":"Using obstacle clearance to measure precise lateral gap ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9958869B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A system and method is provided for identifying an object along a road, where the object may be represented by a bounding box, and projecting a set of obstacle points within the bounding box corresponding to the identified object. In one aspect, a two-dimensional plane oriented perpendicular to a direction of the movement of the vehicle may be identified. In another aspect, the areas of the plane that may be occupied based on the set of obstacle points may be determined to generate a contour of the identified object. Thereafter, the height profiles of the identified object and the vehicle may be determined and identified, respectively. Based on the height profiles, a minimum clearance may be determined.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8776319547},{"pair":"US-10345822-B1 & US-9494942-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8776019359},{"pair":"US-2017248951-A1 & US-9679206-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8775963388},{"pair":"US-2018164830-A1 & US-9682707-B1","patent_1":"US-2018164830-A1","title_1":"Parking-lot-navigation system and method ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180164830A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-12-09T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8775892798},{"pair":"US-2019064345-A1 & US-9836052-B1","patent_1":"US-2019064345-A1","title_1":"Communication of infrastructure information to a vehicle via ground penetrating radar ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190064345A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Method and apparatus are disclosed for communication of infrastructure information to a vehicle via ground penetrating radar. A vehicle comprising an antenna positioned to broadcast radio waves below the vehicle, a ground penetrating radar system, and an active safety module. The ground penetrating radar system determines types of reflectors and a spatial relationship between the reflectors based on radar cross-sections detected by the antenna, and generates a signature based on the shapes and the spatial relationship. The active safety module determines environmental data based on the signature, and autonomously control the vehicle based on the environmental data.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-08-22T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.877582225},{"pair":"US-2017174261-A1 & US-10204278-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8775257437},{"pair":"US-10345822-B1 & US-9387854-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774993556},{"pair":"US-2019235520-A1 & US-2017098129-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774551274},{"pair":"US-2018099663-A1 & US-9463794-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774429523},{"pair":"US-2019161085-A1 & US-9928431-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9928431-B2","title_2":"Verifying a target object with reverse-parallax analysis ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9928431B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle configured to operate in an autonomous mode may engage in a reverse-parallax analysis that includes a vehicle system detecting an object, capturing via a camera located at a first location a first image of the detected object, retrieving location data specifying (i) a location of a target object, (ii) the first location, and (iii) a direction of the camera, and based on the location data and the position of the detected object in the first image, predicting where in a second image captured from a second location the detected object would appear if the detected object is the target object.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773892182},{"pair":"US-2017249844-A1 & US-9679206-B1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773767099},{"pair":"US-10259457-B2 & US-10059334-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773535515},{"pair":"US-2017072962-A1 & US-10139829-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773515173},{"pair":"US-2017248953-A1 & US-9679206-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773481427},{"pair":"US-2018120857-A1 & US-2018135972-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773449742},{"pair":"US-2018239361-A1 & US-2018143643-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773258311},{"pair":"US-2019039616-A1 & US-9646497-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8772104291},{"pair":"US-9989963-B2 & US-9679206-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8771491027},{"pair":"US-10259457-B2 & US-9669827-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8770471794},{"pair":"US-2018099663-A1 & US-9958869-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9958869-B1","title_2":"Using obstacle clearance to measure precise lateral gap ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9958869B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A system and method is provided for identifying an object along a road, where the object may be represented by a bounding box, and projecting a set of obstacle points within the bounding box corresponding to the identified object. In one aspect, a two-dimensional plane oriented perpendicular to a direction of the movement of the vehicle may be identified. In another aspect, the areas of the plane that may be occupied based on the set of obstacle points may be determined to generate a contour of the identified object. Thereafter, the height profiles of the identified object and the vehicle may be determined and identified, respectively. Based on the height profiles, a minimum clearance may be determined.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.877008465},{"pair":"US-10228696-B2 & US-10156851-B1","patent_1":"US-10228696-B2","title_1":"Wind detection systems and methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10228696B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example wind detection systems and methods are described. In one implementation, a method receives data from a vehicle-mounted sensor and determines whether airborne particles are identified in the received data. If airborne particles are identified in the received data, the method determines a wind speed and a wind direction based on movement of the airborne particles and determines a best action to avoid or mitigate the impact of the wind.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8770006707},{"pair":"US-2018210447-A1 & US-10156851-B1","patent_1":"US-2018210447-A1","title_1":"Wind Detection Systems And Methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180210447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example wind detection systems and methods are described. In one implementation, a method receives data from a vehicle-mounted sensor and determines whether airborne particles are identified in the received data. If airborne particles are identified in the received data, the method determines a wind speed and a wind direction based on movement of the airborne particles and determines a best action to avoid or mitigate the impact of the wind.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8770006707},{"pair":"US-10528055-B2 & US-9193355-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9193355-B2","title_2":"Construction zone sign detection using light detection and ranging ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9193355B2\/en","abstract_1":null,"abstract_2":"Methods and systems for construction zone sign detection are described. A computing device may be configured to receive a 3D point cloud of a vicinity of a road on which a vehicle is travelling. The 3D point cloud may include points corresponding to light reflected from objects in the vicinity of the road. The computing device may be configured to determine a set of points representing an area at a given height from a surface of the road, and estimate a shape associated with the set of points. Further, the computing device may be configured to determine a likelihood that the set of points represents a construction zone sign, based on the estimated shape. Based on the likelihood, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8769866728},{"pair":"US-10528055-B2 & US-2015266472-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2015266472-A1","title_2":"Construction Zone Object Detection Using Light Detection and Ranging ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150266472A1\/en","abstract_1":null,"abstract_2":"Methods and systems for construction zone object detection are described. A computing device may be configured to receive, from a LIDAR, a 3D point cloud of a road on which a vehicle is travelling. The 3D point cloud may comprise points corresponding to light reflected from objects on the road. Also, the computing device may be configured to determine sets of points in the 3D point cloud representing an area within a threshold distance from a surface of the road. Further, the computing device may be configured to identify construction zone objects in the sets of points. Further, the computing device may be configured to determine a likelihood of existence of a construction zone, based on the identification. Based on the likelihood, the computing device may be configured to modify a control strategy of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8769866728},{"pair":"US-10289113-B2 & US-9646497-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8769563851},{"pair":"US-10528055-B2 & US-2016092755-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2016092755-A1","title_2":"Construction Zone Sign Detection ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160092755A1\/en","abstract_1":null,"abstract_2":"Methods and systems for detection of a construction zone sign are described. A computing device, configured to control the vehicle, may be configured to receive, from an image-capture device coupled to the computing device, images of a vicinity of the road on which the vehicle is travelling. Also, the computing device may be configured to determine image portions in the images that may depict sides of the road at a predetermined height range. Further, the computing device may be configured to detect a construction zone sign in the image portions, and determine a type of the construction zone sign. Accordingly, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8769559404},{"pair":"US-2018158334-A1 & US-10146223-B1","patent_1":"US-2018158334-A1","title_1":"Vehicle collision avoidance ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180158334A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A computer, programmed to: receive image data from a vehicle sensor; associate a plurality of geometric shapes with the image data of a target vehicle; monitor the plurality of geometric shapes for a condition indicative of the target vehicle moving to avoid a roadway obstacle; and in response to the condition, provide a steering instruction to avoid the obstacle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-12-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8769267333},{"pair":"US-2018025640-A1 & US-10013773-B1","patent_1":"US-2018025640-A1","title_1":"Using Virtual Data To Test And Train Parking Space Detection Systems ","patent_2":"US-10013773-B1","title_2":"Neural networks for object detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180025640A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10013773B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for using virtual data to test and train parking space detection systems. Aspects of the invention integrate a virtual driving environment with sensor models (e.g., of a radar system) to provide virtual radar data in relatively large quantities in a relatively short amount of time. The sensor models perceive values for relevant parameters of a training data set. Relevant parameters can be randomized in the recorded data to ensure a diverse training data set with minimal bias. Since the driving environment is virtualized, the training data set can be generated alongside ground truth data. The ground truth data is used to annotate true locations, which are used to train a parking space classification algorithms to detect the free space boundaries.","abstract_2":"A neural network system for identifying positions of objects in an input image can include an object detector neural network, a memory interface subsystem, and an external memory. The object detector neural network is configured to, at each time step of multiple successive time steps, (i) receive a first neural network input that represents the input image and a second neural network input that identifies a first set of positions of the input image that have each been classified as showing a respective object of the set of objects, and (ii) process the first and second inputs to generate a set of output scores that each represents a respective likelihood that an object that is not one of the objects shown at any of the positions in the first set of positions is shown at a respective position of the input image that corresponds to the output score.","priority_1":"2016-07-19T00:00:00","priority_2":"2016-12-16T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8768848759},{"pair":"US-2019066510-A1 & US-9557736-B1","patent_1":"US-2019066510-A1","title_1":"Vehicular image projection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190066510A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A computer is programmed to determine a target area to project, along a planned travel path of a vehicle, a symbol based on detecting a target object. The computer is further programmed to actuate a light source to project the symbol moving within the target area.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-08-22T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.876721499},{"pair":"US-9983591-B2 & US-2018143643-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8767112259},{"pair":"US-2019019409-A1 & US-9551992-B1","patent_1":"US-2019019409-A1","title_1":"Automated map anomaly detection and update ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190019409A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A deviation hint is received from a vehicle by a server indicating an anomaly in vehicle sensor data compared to autonomous vehicle data maintained by the vehicle. A cause of the anomaly is identified per a view of the sensor data prior to through after the anomaly is received from the vehicle. Revised autonomous vehicle data is updated per the cause to a plurality of autonomous vehicles including the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-17T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8766687097},{"pair":"US-2019087671-A1 & US-10168712-B1","patent_1":"US-2019087671-A1","title_1":"Color learning ","patent_2":"US-10168712-B1","title_2":"Vison-based object detection using a polar grid ","link_1":"https:\/\/patents.google.com\/patent\/US20190087671A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10168712B1\/en","abstract_1":"A computing device, programmed to: acquire a color image and transform the color image into a color-component map. The computer can be further programmed to process the color-component map to detect a traffic sign by determining spatial coincidence and determining temporal consistency between the color-component map and the traffic sign.","abstract_2":"A computing device of a first vehicle may receive a first image and a second image of a second vehicle having flashing light signals. The computing device may determine, in the first image and the second image, an image region that bounds the second vehicle such that the image region substantially encompasses the second vehicle. The computing device may determine a polar grid that partitions the image region in the first image and the second image into polar bins, and identify portions of image data exhibiting a change in color and a change in brightness between the first image and the second image. The computing device may determine a type of the flashing light signals and a type of the second vehicle; and accordingly provide instructions to control the first vehicle.","priority_1":"2017-09-19T00:00:00","priority_2":"2014-04-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8766458652},{"pair":"US-10552692-B2 & US-10168712-B1","patent_1":"US-10552692-B2","title_1":"Color learning ","patent_2":"US-10168712-B1","title_2":"Vison-based object detection using a polar grid ","link_1":"https:\/\/patents.google.com\/patent\/US10552692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10168712B1\/en","abstract_1":null,"abstract_2":"A computing device of a first vehicle may receive a first image and a second image of a second vehicle having flashing light signals. The computing device may determine, in the first image and the second image, an image region that bounds the second vehicle such that the image region substantially encompasses the second vehicle. The computing device may determine a polar grid that partitions the image region in the first image and the second image into polar bins, and identify portions of image data exhibiting a change in color and a change in brightness between the first image and the second image. The computing device may determine a type of the flashing light signals and a type of the second vehicle; and accordingly provide instructions to control the first vehicle.","priority_1":"2017-09-19T00:00:00","priority_2":"2014-04-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8766458652},{"pair":"US-2017248952-A1 & US-9646497-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8766013937},{"pair":"US-10345822-B1 & US-9804597-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9804597-B1","title_2":"Use of detected objects for image processing ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9804597B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8765928144},{"pair":"US-10068477-B2 & US-10146223-B1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8765531182},{"pair":"US-2017316691-A1 & US-10146223-B1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8765531182},{"pair":"US-2019012913-A1 & US-2017092131-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017092131-A1","title_2":"Reporting Road Event Data and Sharing with Other Vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170092131A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Example systems and methods allow for reporting and sharing of information reports relating to driving conditions within a fleet of autonomous vehicles. One example method includes receiving information reports relating to driving conditions from a plurality of autonomous vehicles within a fleet of autonomous vehicles. The method may also include receiving sensor data from a plurality of autonomous vehicles within the fleet of autonomous vehicles. The method may further include validating some of the information reports based at least in part on the sensor data. The method may additionally include combining validated information reports into a driving information map. The method may also include periodically filtering the driving information map to remove outdated information reports. The method may further include providing portions of the driving information map to autonomous vehicles within the fleet of autonomous vehicles.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-03-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8765395201},{"pair":"US-2018120857-A1 & US-9734417-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9734417-B2","title_2":"Use of relationship between activities of different traffic signals in a network to improve traffic signal state estimation ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734417B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and devices for using a relationship between activities of different traffic signals in a network to improve traffic signal state estimation are disclosed. An example method includes determining that a vehicle is approaching an upcoming traffic signal. The method may further include determining a state of one or more traffic signals other than the upcoming traffic signal. Additionally, the method may also include determining an estimate of a state of the upcoming traffic signal based on a relationship between the state of the one or more traffic signals other than the upcoming traffic signal and the state of the upcoming traffic signal.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8764412218},{"pair":"US-2017316691-A1 & US-2018135972-A1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-04-29T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8764098095},{"pair":"US-10068477-B2 & US-2018135972-A1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-04-29T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8764098095},{"pair":"US-2020031468-A1 & US-2018135972-A1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-12-14T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8763660392},{"pair":"US-2018120857-A1 & US-9836052-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8763611365},{"pair":"US-10026317-B2 & US-10059334-B1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.876315555},{"pair":"US-2017072947-A1 & US-9862364-B2","patent_1":"US-2017072947-A1","title_1":"Park out assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072947A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A method, including: detecting a distance between a vehicle and an object. The method also includes determining, based on the distance between the vehicle and the object, that a path of travel of the vehicle presents a risk of collision between the vehicle and the object. The method also includes causing at least one of a wheel angle, a vehicle drivetrain, and vehicle braking to be changed to reduce the risk of collision.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-09-10T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8763013665},{"pair":"US-10528055-B2 & US-9862364-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.876294648},{"pair":"US-10408937-B2 & US-10156851-B1","patent_1":"US-10408937-B2","title_1":"Metal bridge detection systems and methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10408937B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-09-20T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762893921},{"pair":"US-10269242-B2 & US-10496091-B1","patent_1":"US-10269242-B2","title_1":"Autonomous police vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10269242B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Techniques pertaining to an autonomous police vehicle are described. A method may involve a processor associated with an autonomous vehicle obtaining an indication of violation of one or more traffic laws by a first vehicle. The method may also involve the processor maneuvering the autonomous vehicle to pursue the first vehicle. The method may further involve the processor remotely executing one or more actions with respect to the first vehicle.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-07-12T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762893232},{"pair":"US-2018018869-A1 & US-10496091-B1","patent_1":"US-2018018869-A1","title_1":"Autonomous Police Vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180018869A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Techniques pertaining to an autonomous police vehicle are described. A method may involve a processor associated with an autonomous vehicle obtaining an indication of violation of one or more traffic laws by a first vehicle. The method may also involve the processor maneuvering the autonomous vehicle to pursue the first vehicle. The method may further involve the processor remotely executing one or more actions with respect to the first vehicle.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-07-12T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762893232},{"pair":"US-10377376-B2 & US-9463794-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762513662},{"pair":"US-2017016740-A1 & US-9836052-B1","patent_1":"US-2017016740-A1","title_1":"Method and apparatus for determining a vehicle ego-position ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170016740A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system includes a processor configured to receive image data gathered by a vehicle camera, relating to a fixed environmental feature. The processor is also configured to determine a vehicle position relative to the fixed environmental feature and determine a vehicle lane-level location on a digital map, based on the vehicle position relative to the fixed environmental feature.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-07-16T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762386083},{"pair":"US-2019101933-A1 & US-9740202-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762314974},{"pair":"US-2018281782-A1 & US-9868391-B1","patent_1":"US-2018281782-A1","title_1":"Wrong-way vehicle detection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180281782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762115472},{"pair":"US-10442429-B2 & US-9868391-B1","patent_1":"US-10442429-B2","title_1":"Wrong-way vehicle detection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10442429B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-03-30T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762115472},{"pair":"US-2018120857-A1 & US-9373045-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8761947237},{"pair":"US-2018251136-A1 & US-10012991-B1","patent_1":"US-2018251136-A1","title_1":"Enhanced lane behavior detection ","patent_2":"US-10012991-B1","title_2":"Approach for consolidating observed vehicle trajectories into a single representative trajectory ","link_1":"https:\/\/patents.google.com\/patent\/US20180251136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10012991B1\/en","abstract_1":"A lane behavior detection value that is a measure of wrist movement of a vehicle occupant is determined. A mechanism in a wearable device is actuated when the lane behavior detection value exceeds a threshold.","abstract_2":"A method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a pool of combined trajectories. Subsequently, the autonomous vehicle may select one of the combined trajectories as a representative trajectory. The representative trajectory may be used to change at least one of the speed or direction of the autonomous vehicle.","priority_1":"2015-10-20T00:00:00","priority_2":"2012-03-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.87616054},{"pair":"US-10336326-B2 & US-9463794-B1","patent_1":"US-10336326-B2","title_1":"Lane detection systems and methods ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10336326B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method received an image from-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicl camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-06-24T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8760848867},{"pair":"US-2017210291-A1 & US-10156851-B1","patent_1":"US-2017210291-A1","title_1":"Drive History Parking Barrier Alert ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170210291A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A driving assistance system includes a drive detection component, a presence component, and a notification component. The drive detection component is configured to determine that a vehicle or driver is exiting or preparing to exit a parking location. The presence component is configured to determine, from a drive history database, whether a parking barrier is present in front of or behind the parking location. The notification component is configured to provide an indication that the parking barrier is present to a human driver or an automated driving system of the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-09-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8760766831},{"pair":"US-10150412-B2 & US-10156851-B1","patent_1":"US-10150412-B2","title_1":"Drive history parking barrier alert ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10150412B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A driving assistance system includes a drive detection component, a presence component, and a notification component. The drive detection component is configured to determine that a vehicle or driver is exiting or preparing to exit a parking location. The presence component is configured to determine, from a drive history database, whether a parking barrier is present in front of or behind the parking location. The notification component is configured to provide an indication that the parking barrier is present to a human driver or an automated driving system of the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-09-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8760766831},{"pair":"US-2019111922-A1 & US-9646497-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8760332577},{"pair":"US-10127814-B2 & US-2018135972-A1","patent_1":"US-10127814-B2","title_1":"Advanced V2X event dissemination ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10127814B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Disclosed is a host vehicle including: motor(s), sensors, processor(s) configured to: (i) package sensed data into a first unit; (ii) determine whether a vehicle-to-infrastructure connection is (a) active or (b) inactive; (iii) if (a), append a TRUE flag to the unit and if (b) append a FALSE flag to the unit; (iv) transmit the first appended unit over a vehicle-to-vehicle connection; (v) determine whether a second appended unit, received over a vehicle-to-vehicle connection, includes (c) a TRUE flag or (d) a FALSE flag; (vi) if (d), transmit the second appended unit over the vehicle-to-infrastructure connection; (vii) if (c), not transmit the second appended unit over the vehicle-to-infrastructure connection.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-02-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8760046281},{"pair":"US-2018120857-A1 & US-9932035-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9932035-B1","title_2":"Modifying speed of an autonomous vehicle based on traffic conditions ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9932035B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate generally to speed control in an autonomous vehicle. For example, an autonomous vehicle may include a user interface which allows the driver to input speed preferences. These preferences may include the maximum speed above the speed limit the user would like the autonomous vehicle to drive when other vehicles are present and driving above or below certain speeds. The other vehicles may be in adjacent or the same lane the vehicle, and need not be in front of the vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.876002568},{"pair":"US-2019219697-A1 & US-9804597-B1","patent_1":"US-2019219697-A1","title_1":"Lidar localization ","patent_2":"US-9804597-B1","title_2":"Use of detected objects for image processing ","link_1":"https:\/\/patents.google.com\/patent\/US20190219697A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9804597B1\/en","abstract_1":"A system including a processor and a memory, the memory including instructions to be executed by the processor to determine map data, determine uncalibrated LIDAR data, determine a location of a vehicle in the map data by combining the map data with the uncalibrated LIDAR data, and operate the vehicle based on the location of the vehicle in the map data.","abstract_2":"Methods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.","priority_1":"2018-01-12T00:00:00","priority_2":"2013-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8759755232},{"pair":"US-10528055-B2 & US-9836052-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8758622936},{"pair":"US-2020020117-A1 & US-9804597-B1","patent_1":"US-2020020117-A1","title_1":"Pose estimation ","patent_2":"US-9804597-B1","title_2":"Use of detected objects for image processing ","link_1":"https:\/\/patents.google.com\/patent\/US20200020117A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9804597B1\/en","abstract_1":null,"abstract_2":"Methods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.","priority_1":"2018-07-16T00:00:00","priority_2":"2013-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8758511747},{"pair":"US-10453346-B2 & US-9862364-B2","patent_1":"US-10453346-B2","title_1":"Vehicle light control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10453346B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system including a computer for a vehicle is programmed to identify the vehicle as a lead vehicle in a platoon of three or more vehicles, and to identify one of the vehicles in the platoon as a caboose vehicle. The computer is programmed to deactivate a rear light of the lead vehicle, and to instruct activation of a rear light of the caboose vehicle.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-09-07T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.875837011},{"pair":"US-2018210447-A1 & US-2018102001-A1","patent_1":"US-2018210447-A1","title_1":"Wind Detection Systems And Methods ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180210447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Example wind detection systems and methods are described. In one implementation, a method receives data from a vehicle-mounted sensor and determines whether airborne particles are identified in the received data. If airborne particles are identified in the received data, the method determines a wind speed and a wind direction based on movement of the airborne particles and determines a best action to avoid or mitigate the impact of the wind.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-01-26T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8758261395},{"pair":"US-10228696-B2 & US-2018102001-A1","patent_1":"US-10228696-B2","title_1":"Wind detection systems and methods ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10228696B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Example wind detection systems and methods are described. In one implementation, a method receives data from a vehicle-mounted sensor and determines whether airborne particles are identified in the received data. If airborne particles are identified in the received data, the method determines a wind speed and a wind direction based on movement of the airborne particles and determines a best action to avoid or mitigate the impact of the wind.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-01-26T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8758261395},{"pair":"US-2018319402-A1 & US-2018135972-A1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-05-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8757540349},{"pair":"US-2018113459-A1 & US-9541410-B1","patent_1":"US-2018113459-A1","title_1":"Vehicle virtual map ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180113459A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"A vehicle includes: motor(s), local sensors, processor(s) configured to: generate a virtual map based on the local sensors; receive a plurality of reports from a plurality of external entities, statistically compare the plurality of reports, and identify an outlying report based on the statistical comparison; instruct the external entity responsible for the outlying report to mark future reports; ignore marked reports; generate the virtual map based on unmarked reports; reallocate virtual map processing resources based on unmarked reports.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2016-10-24T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8757512702},{"pair":"US-10152058-B2 & US-9541410-B1","patent_1":"US-10152058-B2","title_1":"Vehicle virtual map ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10152058B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"A vehicle includes: motor(s), local sensors, processor(s) configured to: generate a virtual map based on the local sensors; receive a plurality of reports from a plurality of external entities, statistically compare the plurality of reports, and identify an outlying report based on the statistical comparison; instruct the external entity responsible for the outlying report to mark future reports; ignore marked reports; generate the virtual map based on unmarked reports; reallocate virtual map processing resources based on unmarked reports.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2016-10-24T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8757512702},{"pair":"US-10082796-B2 & US-2018102001-A1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8756471245},{"pair":"US-2018120858-A1 & US-2018102001-A1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8756471245},{"pair":"US-2017206426-A1 & US-10496091-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8756022169},{"pair":"US-2017174215-A1 & US-2018143643-A1","patent_1":"US-2017174215-A1","title_1":"Vehicle mode determination ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174215A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"An operating mode is determined for a vehicle according to respective control states of each of a plurality of vehicle subsystems that include braking, steering, and propulsion. The operating mode is one of manual control, partial manual control, and no manual control. A route for the vehicle is determined based in part on the operating mode.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8755933617},{"pair":"US-9796388-B2 & US-2018143643-A1","patent_1":"US-9796388-B2","title_1":"Vehicle mode determination ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9796388B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"An operating mode is determined for a vehicle according to respective control states of each of a plurality of vehicle subsystems that include braking, steering, and propulsion. The operating mode is one of manual control, partial manual control, and no manual control. A route for the vehicle is determined based in part on the operating mode.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8755933617},{"pair":"US-2018120857-A1 & US-9958869-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9958869-B1","title_2":"Using obstacle clearance to measure precise lateral gap ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9958869B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A system and method is provided for identifying an object along a road, where the object may be represented by a bounding box, and projecting a set of obstacle points within the bounding box corresponding to the identified object. In one aspect, a two-dimensional plane oriented perpendicular to a direction of the movement of the vehicle may be identified. In another aspect, the areas of the plane that may be occupied based on the set of obstacle points may be determined to generate a contour of the identified object. Thereafter, the height profiles of the identified object and the vehicle may be determined and identified, respectively. Based on the height profiles, a minimum clearance may be determined.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8755882941},{"pair":"US-2018120857-A1 & US-9381917-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9381917-B1","title_2":"Predictive reasoning for controlling speed of a vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9381917B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for predictive reasoning for controlling speed of a vehicle are described. A computing device may be configured to identify a first and second vehicle travelling ahead of an autonomous vehicle and in a same lane as the autonomous vehicle. The computing device may also be configured to determine a first buffer distance behind the first vehicle at which the autonomous vehicle will substantially reach a speed of the first vehicle and a second buffer distance behind the second vehicle at which the first vehicle will substantially reach a speed of the second vehicle. The computing device may further be configured to determine a distance at which to adjust a speed of the autonomous vehicle based on the first and second buffer distances and the speed of the autonomous vehicle, and then provide instructions to adjust the speed of the autonomous vehicle based on the distance.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-05-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8755721456},{"pair":"US-2017249844-A1 & US-10059334-B1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8754557271},{"pair":"US-2019385336-A1 & US-10126141-B2","patent_1":"US-2019385336-A1","title_1":"Vehicle Localization Using Cameras ","patent_2":"US-10126141-B2","title_2":"Systems and methods for using real-time imagery in navigation ","link_1":"https:\/\/patents.google.com\/patent\/US20190385336A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10126141B2\/en","abstract_1":"According to one embodiment, a system for determining a position of a vehicle includes an image sensor, a top-down view component, a comparison component, and a location component. The image sensor obtains an image of an environment near a vehicle. The top-down view component is configured to generate a top-down view of a ground surface based on the image of the environment. The comparison component is configured to compare the top-down image with a map, the map comprising a top-down light LIDAR intensity map or a vector-based semantic map. The location component is configured to determine a location of the vehicle on the map based on the comparison.","abstract_2":"To generate navigation directions for a driver of a vehicle, a route for guiding the driver to a destination is obtained, visual landmarks corresponding to prominent physical objects disposed along the route are retrieved, and real-time imagery is collected at the vehicle approximately from a vantage point of the driver during navigation along the route. Using (i) the retrieved visual landmarks and (ii) the imagery collected at the vehicle, a subset of the visual landmarks that are currently visible to the driver is selected. Navigation directions describing the route are provided the driver, the navigation directions referencing the selected subset of the visual landmarks and excluding the remaining visual landmarks.","priority_1":"2017-03-14T00:00:00","priority_2":"2016-05-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8754521618},{"pair":"US-2017016740-A1 & US-9255805-B1","patent_1":"US-2017016740-A1","title_1":"Method and apparatus for determining a vehicle ego-position ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170016740A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system includes a processor configured to receive image data gathered by a vehicle camera, relating to a fixed environmental feature. The processor is also configured to determine a vehicle position relative to the fixed environmental feature and determine a vehicle lane-level location on a digital map, based on the vehicle position relative to the fixed environmental feature.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2015-07-16T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8754066073},{"pair":"US-10220769-B1 & US-10496091-B1","patent_1":"US-10220769-B1","title_1":"Vehicular image projection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10220769B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753969814},{"pair":"US-2019061611-A1 & US-10496091-B1","patent_1":"US-2019061611-A1","title_1":"Vehicular image projection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190061611A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753969814},{"pair":"US-2017174261-A1 & US-9193355-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9193355-B2","title_2":"Construction zone sign detection using light detection and ranging ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9193355B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems for construction zone sign detection are described. A computing device may be configured to receive a 3D point cloud of a vicinity of a road on which a vehicle is travelling. The 3D point cloud may include points corresponding to light reflected from objects in the vicinity of the road. The computing device may be configured to determine a set of points representing an area at a given height from a surface of the road, and estimate a shape associated with the set of points. Further, the computing device may be configured to determine a likelihood that the set of points represents a construction zone sign, based on the estimated shape. Based on the likelihood, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753898275},{"pair":"US-2017174261-A1 & US-2015266472-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2015266472-A1","title_2":"Construction Zone Object Detection Using Light Detection and Ranging ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150266472A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems for construction zone object detection are described. A computing device may be configured to receive, from a LIDAR, a 3D point cloud of a road on which a vehicle is travelling. The 3D point cloud may comprise points corresponding to light reflected from objects on the road. Also, the computing device may be configured to determine sets of points in the 3D point cloud representing an area within a threshold distance from a surface of the road. Further, the computing device may be configured to identify construction zone objects in the sets of points. Further, the computing device may be configured to determine a likelihood of existence of a construction zone, based on the identification. Based on the likelihood, the computing device may be configured to modify a control strategy of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753898275},{"pair":"US-10179590-B2 & US-9862364-B2","patent_1":"US-10179590-B2","title_1":"Park out assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10179590B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A method, including: detecting a distance between a vehicle and an object. The method also includes determining, based on the distance between the vehicle and the object, that a path of travel of the vehicle presents a risk of collision between the vehicle and the object. The method also includes causing at least one of a wheel angle, a vehicle drivetrain, and vehicle braking to be changed to reduce the risk of collision.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-09-10T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753461913},{"pair":"US-2017072962-A1 & US-10059334-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753134448},{"pair":"US-10589742-B2 & US-9555740-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9555740-B1","title_2":"Cross-validating sensors of an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9555740B1\/en","abstract_1":null,"abstract_2":"Methods and systems are disclosed for cross-validating a second sensor with a first sensor. Cross-validating the second sensor may include obtaining sensor readings from the first sensor and comparing the sensor readings from the first sensor with sensor readings obtained from the second sensor. In particular, the comparison of the sensor readings may include comparing state information about a vehicle detected by the first sensor and the second sensor. In addition, comparing the sensor readings may include obtaining a first image from the first sensor, obtaining a second image from the second sensor, and then comparing various characteristics of the images. One characteristic that may be compared are object labels applied to the vehicle detected by the first and second sensor. The first and second sensors may be different types of sensors.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753075957},{"pair":"US-10282984-B2 & US-10156851-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-05-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8752948084},{"pair":"US-2018350234-A1 & US-10156851-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-05-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8752948084},{"pair":"US-2017197615-A1 & US-2016187887-A1","patent_1":"US-2017197615-A1","title_1":"System and method for reverse perpendicular parking a vehicle ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170197615A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A method for parking a vehicle in a parking lot includes generating steering commands for the vehicle while in the lot based on an occupancy grid and plenoptic camera data. The occupancy grid indicates occupied areas and unoccupied areas around the vehicle and is derived from map data defining parking spots relative to a topological feature contained within the lot. The plenoptic camera data defines a plurality of depth maps and corresponding images that include the topological feature captured during movement of the vehicle. The steering command is generated such that the vehicle follows a reverse perpendicular path into one of the spots without entering an occupied area.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-01-11T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8752603424},{"pair":"US-10528055-B2 & US-9958869-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9958869-B1","title_2":"Using obstacle clearance to measure precise lateral gap ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9958869B1\/en","abstract_1":null,"abstract_2":"A system and method is provided for identifying an object along a road, where the object may be represented by a bounding box, and projecting a set of obstacle points within the bounding box corresponding to the identified object. In one aspect, a two-dimensional plane oriented perpendicular to a direction of the movement of the vehicle may be identified. In another aspect, the areas of the plane that may be occupied based on the set of obstacle points may be determined to generate a contour of the identified object. Thereafter, the height profiles of the identified object and the vehicle may be determined and identified, respectively. Based on the height profiles, a minimum clearance may be determined.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8752578285},{"pair":"US-10528055-B2 & US-9932035-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9932035-B1","title_2":"Modifying speed of an autonomous vehicle based on traffic conditions ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9932035B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to speed control in an autonomous vehicle. For example, an autonomous vehicle may include a user interface which allows the driver to input speed preferences. These preferences may include the maximum speed above the speed limit the user would like the autonomous vehicle to drive when other vehicles are present and driving above or below certain speeds. The other vehicles may be in adjacent or the same lane the vehicle, and need not be in front of the vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8752415918},{"pair":"US-2017031362-A1 & US-9646497-B1","patent_1":"US-2017031362-A1","title_1":"Field-based torque steering control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170031362A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system includes a computer programmed to determine, along a nominal path to be traversed by a vehicle, a potential field representing a driving corridor for the vehicle. The computer is further programmed to identify a position of the vehicle relative to the potential field at a current time, and apply a torque to q steering column of the vehicle. The torque is based at least in part on the position. The potential field includes an attractive potential that guides the vehicle to remain within the corridor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-07-31T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8751718836},{"pair":"US-2019039616-A1 & US-9669827-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.875166165},{"pair":"US-2019235520-A1 & US-2018143643-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8751629644},{"pair":"US-10282984-B2 & US-10139829-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2017-05-30T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8751473018},{"pair":"US-2018350234-A1 & US-10139829-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2017-05-30T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8751473018},{"pair":"US-2019009778-A1 & US-2018135972-A1","patent_1":"US-2019009778-A1","title_1":"U-turn assistance based on difficulty in maneuvering ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190009778A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Methods, devices and apparatuses pertaining to U-turn assistance. The method may include obtaining, by a computing device, geographic obtaining of a location designated for an operation of a U-turn. The computing device may further obtain vehicle information of a vehicle performing the U-turn, and collect user information of an operator of the vehicle. Based on the geographic information, the vehicle information and the user information, the computing device may determine a level of difficulty of the U-turn and assist the operator with the operation of the U-turn based on the level of difficulty.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-14T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8750840873},{"pair":"US-2019161085-A1 & US-9381917-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9381917-B1","title_2":"Predictive reasoning for controlling speed of a vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9381917B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems for predictive reasoning for controlling speed of a vehicle are described. A computing device may be configured to identify a first and second vehicle travelling ahead of an autonomous vehicle and in a same lane as the autonomous vehicle. The computing device may also be configured to determine a first buffer distance behind the first vehicle at which the autonomous vehicle will substantially reach a speed of the first vehicle and a second buffer distance behind the second vehicle at which the first vehicle will substantially reach a speed of the second vehicle. The computing device may further be configured to determine a distance at which to adjust a speed of the autonomous vehicle based on the first and second buffer distances and the speed of the autonomous vehicle, and then provide instructions to adjust the speed of the autonomous vehicle based on the distance.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-05-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8749738198},{"pair":"US-2019294164-A1 & US-9669827-B1","patent_1":"US-2019294164-A1","title_1":"Action-conditioned vehicle control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190294164A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A high-level vehicle command is determined based on a location of the vehicle with respect to a route including a start location and a finish location. An image is acquired of the vehicle external environment. Steering, braking, and powertrain commands are determined based on inputting the high-level command and the image into a Deep Neural Network. The vehicle is operated by actuating vehicle components based on the steering, braking and powertrain commands.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-03-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8749514325},{"pair":"US-2019066510-A1 & US-10496091-B1","patent_1":"US-2019066510-A1","title_1":"Vehicular image projection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190066510A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A computer is programmed to determine a target area to project, along a planned travel path of a vehicle, a symbol based on detecting a target object. The computer is further programmed to actuate a light source to project the symbol moving within the target area.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8749028132},{"pair":"US-2017369057-A1 & US-2018152628-A1","patent_1":"US-2017369057-A1","title_1":"Lane Detection Systems And Methods ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170369057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method receives an image from a front-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicle camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-06-24T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748756427},{"pair":"US-10068477-B2 & US-9551992-B1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748533356},{"pair":"US-2017316691-A1 & US-9551992-B1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748533356},{"pair":"US-2019061611-A1 & US-9557736-B1","patent_1":"US-2019061611-A1","title_1":"Vehicular image projection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190061611A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-08-22T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748484686},{"pair":"US-10220769-B1 & US-9557736-B1","patent_1":"US-10220769-B1","title_1":"Vehicular image projection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10220769B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-08-22T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748484686},{"pair":"US-2018059679-A1 & US-10204278-B2","patent_1":"US-2018059679-A1","title_1":"Depth map estimation with stereo images ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180059679A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. While operating in either mode, an array of sensors can be used to pilot the vehicle including stereo cameras and 3D sensors. Stereo camera and 3D sensors can also be employed to assist occupants while piloting vehicles. Deep convolutional neural networks can be employed to determine estimated depth maps from stereo images of scenes in real time for vehicles in autonomous and occupant piloted modes.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-09-01T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748411382},{"pair":"US-2019294164-A1 & US-9494942-B1","patent_1":"US-2019294164-A1","title_1":"Action-conditioned vehicle control ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US20190294164A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":"A high-level vehicle command is determined based on a location of the vehicle with respect to a route including a start location and a finish location. An image is acquired of the vehicle external environment. Steering, braking, and powertrain commands are determined based on inputting the high-level command and the image into a Deep Neural Network. The vehicle is operated by actuating vehicle components based on the steering, braking and powertrain commands.","abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2018-03-26T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8748004623},{"pair":"US-2017174261-A1 & US-2016092755-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2016092755-A1","title_2":"Construction Zone Sign Detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160092755A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems for detection of a construction zone sign are described. A computing device, configured to control the vehicle, may be configured to receive, from an image-capture device coupled to the computing device, images of a vicinity of the road on which the vehicle is travelling. Also, the computing device may be configured to determine image portions in the images that may depict sides of the road at a predetermined height range. Further, the computing device may be configured to detect a construction zone sign in the image portions, and determine a type of the construction zone sign. Accordingly, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8747984248},{"pair":"US-2017369057-A1 & US-9463794-B1","patent_1":"US-2017369057-A1","title_1":"Lane Detection Systems And Methods ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170369057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method receives an image from a front-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicle camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-06-24T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.874762064},{"pair":"US-10423847-B2 & US-2018135972-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8747569719},{"pair":"US-2016210775-A1 & US-2018143643-A1","patent_1":"US-2016210775-A1","title_1":"Virtual sensor testbed ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20160210775A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A computing device comprising a processing circuit and a data storage medium. The computing device is programmed to receive virtual sensor data that represents data collected by a virtual sensor associated with autonomously operating a virtual vehicle in a virtual environment and process the virtual sensor data to identify a limitation of a real-world sensor.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-01-21T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8747035269},{"pair":"US-2019366918-A1 & US-9868391-B1","patent_1":"US-2019366918-A1","title_1":"Display for rear lamp of a vehicle ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190366918A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A vehicle includes a rear lamp display configured to display images as well as perform the usual functions of a rear lamp assembly. The rear lamp display may include a light source and a digital mirror device. Obstacles detected may trigger display of a static or animated representation of the obstacle in the rear lamp display. Detection of a turn may invoke display of a direction of the turn as well as text indicating a target of the turn. Detection of an intervention of a vehicle system to maintain stability, a warning may be displayed that indicates potentially hazardous road conditions. Where opening of a door is detected, a representation of an open or opening door may be displayed. Where a following vehicle is detected, the speed limit or cruising speed of the vehicle may be displayed. Objects left in the vehicle may trigger display of an alert.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-02-09T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8746913211},{"pair":"US-2019294164-A1 & US-2017098129-A1","patent_1":"US-2019294164-A1","title_1":"Action-conditioned vehicle control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190294164A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A high-level vehicle command is determined based on a location of the vehicle with respect to a route including a start location and a finish location. An image is acquired of the vehicle external environment. Steering, braking, and powertrain commands are determined based on inputting the high-level command and the image into a Deep Neural Network. The vehicle is operated by actuating vehicle components based on the steering, braking and powertrain commands.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-03-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8746824962},{"pair":"US-10228696-B2 & US-9862364-B2","patent_1":"US-10228696-B2","title_1":"Wind detection systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10228696B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example wind detection systems and methods are described. In one implementation, a method receives data from a vehicle-mounted sensor and determines whether airborne particles are identified in the received data. If airborne particles are identified in the received data, the method determines a wind speed and a wind direction based on movement of the airborne particles and determines a best action to avoid or mitigate the impact of the wind.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8746162587},{"pair":"US-2018210447-A1 & US-9862364-B2","patent_1":"US-2018210447-A1","title_1":"Wind Detection Systems And Methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180210447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example wind detection systems and methods are described. In one implementation, a method receives data from a vehicle-mounted sensor and determines whether airborne particles are identified in the received data. If airborne particles are identified in the received data, the method determines a wind speed and a wind direction based on movement of the airborne particles and determines a best action to avoid or mitigate the impact of the wind.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8746162587},{"pair":"US-2018319402-A1 & US-9551992-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-05-05T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745911229},{"pair":"US-2018319402-A1 & US-2016370801-A1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2017-05-05T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745903537},{"pair":"US-10345822-B1 & US-2016187887-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745746569},{"pair":"US-2017206426-A1 & US-10059334-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745629898},{"pair":"US-2018120857-A1 & US-2016187887-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745532381},{"pair":"US-10336326-B2 & US-10198643-B1","patent_1":"US-10336326-B2","title_1":"Lane detection systems and methods ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US10336326B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method received an image from-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicl camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2016-06-24T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745428962},{"pair":"US-10528055-B2 & US-9734417-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9734417-B2","title_2":"Use of relationship between activities of different traffic signals in a network to improve traffic signal state estimation ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734417B2\/en","abstract_1":null,"abstract_2":"Methods and devices for using a relationship between activities of different traffic signals in a network to improve traffic signal state estimation are disclosed. An example method includes determining that a vehicle is approaching an upcoming traffic signal. The method may further include determining a state of one or more traffic signals other than the upcoming traffic signal. Additionally, the method may also include determining an estimate of a state of the upcoming traffic signal based on a relationship between the state of the one or more traffic signals other than the upcoming traffic signal and the state of the upcoming traffic signal.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745318632},{"pair":"US-10345822-B1 & US-9707966-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8744893046},{"pair":"US-2019362168-A1 & US-2018135972-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8744781579},{"pair":"US-2017206426-A1 & US-2018143643-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.874459514},{"pair":"US-2019219697-A1 & US-2017098129-A1","patent_1":"US-2019219697-A1","title_1":"Lidar localization ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190219697A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system including a processor and a memory, the memory including instructions to be executed by the processor to determine map data, determine uncalibrated LIDAR data, determine a location of a vehicle in the map data by combining the map data with the uncalibrated LIDAR data, and operate the vehicle based on the location of the vehicle in the map data.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-12T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743866129},{"pair":"US-2017174261-A1 & US-10139829-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743580888},{"pair":"US-2019235520-A1 & US-9862364-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743542045},{"pair":"US-2018120857-A1 & US-9669827-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743050747},{"pair":"US-10423847-B2 & US-9836052-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8742789234},{"pair":"US-10410524-B2 & US-9766626-B1","patent_1":"US-10410524-B2","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10410524B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has traveled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-07-29T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.874262611},{"pair":"US-10259457-B2 & US-9582907-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9582907-B1","title_2":"User interface for displaying internal state of autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9582907B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Autonomous vehicles use various computing systems to transport passengers from one location to another. A control computer sends messages to the various systems of the vehicle in order to maneuver the vehicle safely to the destination. The control computer may display information on an electronic display in order to allow the passenger to understand what actions the vehicle may be taking in the immediate future. Various icons and images may be used to provide this information to the passenger.","priority_1":"2014-05-13T00:00:00","priority_2":"2010-04-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8741840852},{"pair":"US-10336326-B2 & US-2018152628-A1","patent_1":"US-10336326-B2","title_1":"Lane detection systems and methods ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10336326B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method received an image from-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicl camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-06-24T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8740727592},{"pair":"US-10599146-B2 & US-9494942-B1","patent_1":"US-10599146-B2","title_1":"Action-conditioned vehicle control ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US10599146B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":null,"abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2018-03-26T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8740644995},{"pair":"US-10423847-B2 & US-9463794-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8740626621},{"pair":"US-2017205823-A1 & US-9862364-B2","patent_1":"US-2017205823-A1","title_1":"Method and device for operating a motor vehicle ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170205823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"The disclosure relates to a method and a device for operating a motor vehicle. The vehicle exhibits a first driving mode in which an at least partial automation of the control of the vehicle is obtained. The vehicle also exhibits a second driving mode in which the automation has been at least partly canceled and replaced by a manual control of the vehicle on the part of a driver. The method for operating the motor vehicle comprises the following steps: ascertaining at least one parameter that is characteristic of a current status of the driver, and adapting a transition strategy for the transition between the first driving mode and the second driving mode in a manner depending on the parameter.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-01-18T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873996164},{"pair":"US-9989963-B2 & US-9646497-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8739519545},{"pair":"US-2018164830-A1 & US-9669827-B1","patent_1":"US-2018164830-A1","title_1":"Parking-lot-navigation system and method ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180164830A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-12-09T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873926971},{"pair":"US-2018350234-A1 & US-9862364-B2","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-05-30T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8739187776},{"pair":"US-10282984-B2 & US-9862364-B2","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-05-30T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8739187776},{"pair":"US-10599146-B2 & US-2017098129-A1","patent_1":"US-10599146-B2","title_1":"Action-conditioned vehicle control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10599146B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-03-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8739091191},{"pair":"US-10528055-B2 & US-9381917-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9381917-B1","title_2":"Predictive reasoning for controlling speed of a vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9381917B1\/en","abstract_1":null,"abstract_2":"Methods and systems for predictive reasoning for controlling speed of a vehicle are described. A computing device may be configured to identify a first and second vehicle travelling ahead of an autonomous vehicle and in a same lane as the autonomous vehicle. The computing device may also be configured to determine a first buffer distance behind the first vehicle at which the autonomous vehicle will substantially reach a speed of the first vehicle and a second buffer distance behind the second vehicle at which the first vehicle will substantially reach a speed of the second vehicle. The computing device may further be configured to determine a distance at which to adjust a speed of the autonomous vehicle based on the first and second buffer distances and the speed of the autonomous vehicle, and then provide instructions to adjust the speed of the autonomous vehicle based on the distance.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-05-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8739045261},{"pair":"US-2017369057-A1 & US-10198643-B1","patent_1":"US-2017369057-A1","title_1":"Lane Detection Systems And Methods ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US20170369057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"Example lane detection systems and methods are described. In one implementation, a method receives an image from a front-facing vehicle camera and applies a geometric transformation to the image to create a birds-eye view of the image. The method analyzes the birds-eye view of the image using a neural network, which was previously trained using side-facing vehicle camera images, to determine a lane position associated with the birds-eye view of the image.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2016-06-24T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8738905801},{"pair":"US-2017016740-A1 & US-2018135972-A1","patent_1":"US-2017016740-A1","title_1":"Method and apparatus for determining a vehicle ego-position ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170016740A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a processor configured to receive image data gathered by a vehicle camera, relating to a fixed environmental feature. The processor is also configured to determine a vehicle position relative to the fixed environmental feature and determine a vehicle lane-level location on a digital map, based on the vehicle position relative to the fixed environmental feature.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-07-16T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8738808633},{"pair":"US-2020026279-A1 & US-10436597-B1","patent_1":"US-2020026279-A1","title_1":"Smart neighborhood routing for autonomous vehicles ","patent_2":"US-10436597-B1","title_2":"Systems and methods for suggesting mode of transport in a geographic application ","link_1":"https:\/\/patents.google.com\/patent\/US20200026279A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10436597B1\/en","abstract_1":null,"abstract_2":"A request for directions for traveling to a destination is received via a user interface of a user device, where a mode of transport is not selected via the user interface. A current geographic context of the user device is determined, and suggested mode of transport for travelling to the destination is determined based on the current geographic context. Directions for travelling to the destination using the suggested mode of transport are obtained and provided via the user interface of the user device.","priority_1":"2018-07-20T00:00:00","priority_2":"2014-08-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873860345},{"pair":"US-10259457-B2 & US-9690296-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873849535},{"pair":"US-10528055-B2 & US-2016187887-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737824685},{"pair":"US-2018033309-A1 & US-9766626-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-07-29T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737560003},{"pair":"US-2019012913-A1 & US-9669827-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737558608},{"pair":"US-10481609-B2 & US-9669827-B1","patent_1":"US-10481609-B2","title_1":"Parking-lot-navigation system and method ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10481609B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-12-09T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737094763},{"pair":"US-2016325779-A1 & US-9868391-B1","patent_1":"US-2016325779-A1","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20160325779A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2015-05-05T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736995146},{"pair":"US-2017139420-A1 & US-2017341643-A1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-07-16T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736866335},{"pair":"US-9921581-B2 & US-2018143643-A1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736795862},{"pair":"US-2017192429-A1 & US-2018143643-A1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736795862},{"pair":"US-2019039616-A1 & US-10146223-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736756657},{"pair":"US-2019101933-A1 & US-10496091-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736401526},{"pair":"US-2019235520-A1 & US-2017341643-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8735905944},{"pair":"US-2018319402-A1 & US-2016209844-A1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-05-05T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8735463741},{"pair":"US-10430968-B2 & US-10126141-B2","patent_1":"US-10430968-B2","title_1":"Vehicle localization using cameras ","patent_2":"US-10126141-B2","title_2":"Systems and methods for using real-time imagery in navigation ","link_1":"https:\/\/patents.google.com\/patent\/US10430968B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10126141B2\/en","abstract_1":"According to one embodiment, a system for determining a position of a vehicle includes an image sensor, a top-down view component, a comparison component, and a location component. The image sensor obtains an image of an environment near a vehicle. The top-down view component is configured to generate a top-down view of a ground surface based on the image of the environment. The comparison component is configured to compare the top-down image with a map, the map comprising a top-down light LIDAR intensity map or a vector-based semantic map. The location component is configured to determine a location of the vehicle on the map based on the comparison.","abstract_2":"To generate navigation directions for a driver of a vehicle, a route for guiding the driver to a destination is obtained, visual landmarks corresponding to prominent physical objects disposed along the route are retrieved, and real-time imagery is collected at the vehicle approximately from a vantage point of the driver during navigation along the route. Using (i) the retrieved visual landmarks and (ii) the imagery collected at the vehicle, a subset of the visual landmarks that are currently visible to the driver is selected. Navigation directions describing the route are provided the driver, the navigation directions referencing the selected subset of the visual landmarks and excluding the remaining visual landmarks.","priority_1":"2017-03-14T00:00:00","priority_2":"2016-05-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873494004},{"pair":"US-9983591-B2 & US-9836052-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734881605},{"pair":"US-2017248953-A1 & US-9646497-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734845402},{"pair":"US-10282984-B2 & US-9557736-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-05-30T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734838825},{"pair":"US-2018350234-A1 & US-9557736-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-05-30T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734838825},{"pair":"US-2017174261-A1 & US-10146223-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734753486},{"pair":"US-10589742-B2 & US-9928431-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9928431-B2","title_2":"Verifying a target object with reverse-parallax analysis ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9928431B2\/en","abstract_1":null,"abstract_2":"A vehicle configured to operate in an autonomous mode may engage in a reverse-parallax analysis that includes a vehicle system detecting an object, capturing via a camera located at a first location a first image of the detected object, retrieving location data specifying (i) a location of a target object, (ii) the first location, and (iii) a direction of the camera, and based on the location data and the position of the detected object in the first image, predicting where in a second image captured from a second location the detected object would appear if the detected object is the target object.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734692196},{"pair":"US-10528055-B2 & US-9373045-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":null,"abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734577142},{"pair":"US-10488863-B2 & US-2016187887-A1","patent_1":"US-10488863-B2","title_1":"Autonomous vehicle post-fault operation ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10488863B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. Vehicles can be equipped with hardware and software to determine a driving-acceptable region defined by lateral and longitudinal coordinates relative to a first vehicle, wherein the lateral and longitudinal coordinates are based on the locations and sizes of one or more second vehicles and the location and size of a roadway. Upon determining a vehicle fault, a computing device in the vehicle can pilot the vehicle to a stop within the driving-acceptable region.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-12-13T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734203653},{"pair":"US-10488863-B2 & US-9684836-B1","patent_1":"US-10488863-B2","title_1":"Autonomous vehicle post-fault operation ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10488863B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. Vehicles can be equipped with hardware and software to determine a driving-acceptable region defined by lateral and longitudinal coordinates relative to a first vehicle, wherein the lateral and longitudinal coordinates are based on the locations and sizes of one or more second vehicles and the location and size of a roadway. Upon determining a vehicle fault, a computing device in the vehicle can pilot the vehicle to a stop within the driving-acceptable region.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-12-13T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734188126},{"pair":"US-2017334440-A1 & US-2018011496-A1","patent_1":"US-2017334440-A1","title_1":"Accident attenuation systems and methods ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170334440A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Example accident attenuation systems and methods are described. In one implementation, a method determines a speed of a second vehicle approaching from behind a first vehicle and determines a distance between the first and second vehicles. The method also determines whether the second vehicle can stop before colliding with the first vehicle. If the second vehicle cannot stop before colliding with the first vehicle, the method takes action to attenuate the potential collision by applying full brake force, tightening seat belts, and\/or turning the front wheels of the first vehicle to direct the first vehicle away from oncoming traffic.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-05-23T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734125381},{"pair":"US-10086830-B2 & US-2018011496-A1","patent_1":"US-10086830-B2","title_1":"Accident attenuation systems and methods ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10086830B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Example accident attenuation systems and methods are described. In one implementation, a method determines a speed of a second vehicle approaching from behind a first vehicle and determines a distance between the first and second vehicles. The method also determines whether the second vehicle can stop before colliding with the first vehicle. If the second vehicle cannot stop before colliding with the first vehicle, the method takes action to attenuate the potential collision by applying full brake force, tightening seat belts, and\/or turning the front wheels of the first vehicle to direct the first vehicle away from oncoming traffic.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-05-23T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734125381},{"pair":"US-2017248951-A1 & US-9646497-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734050194},{"pair":"US-2019362168-A1 & US-9836052-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8733719879},{"pair":"US-2019019409-A1 & US-9740202-B2","patent_1":"US-2019019409-A1","title_1":"Automated map anomaly detection and update ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190019409A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A deviation hint is received from a vehicle by a server indicating an anomaly in vehicle sensor data compared to autonomous vehicle data maintained by the vehicle. A cause of the anomaly is identified per a view of the sensor data prior to through after the anomaly is received from the vehicle. Revised autonomous vehicle data is updated per the cause to a plurality of autonomous vehicles including the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-17T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873360131},{"pair":"US-2017072962-A1 & US-9557736-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8733592323},{"pair":"US-10345822-B1 & US-10168712-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10168712-B1","title_2":"Vison-based object detection using a polar grid ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10168712B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A computing device of a first vehicle may receive a first image and a second image of a second vehicle having flashing light signals. The computing device may determine, in the first image and the second image, an image region that bounds the second vehicle such that the image region substantially encompasses the second vehicle. The computing device may determine a polar grid that partitions the image region in the first image and the second image into polar bins, and identify portions of image data exhibiting a change in color and a change in brightness between the first image and the second image. The computing device may determine a type of the flashing light signals and a type of the second vehicle; and accordingly provide instructions to control the first vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-04-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.87330265},{"pair":"US-10259457-B2 & US-9541410-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8732326652},{"pair":"US-10599146-B2 & US-9669827-B1","patent_1":"US-10599146-B2","title_1":"Action-conditioned vehicle control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10599146B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-03-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8731917205},{"pair":"US-2019073909-A1 & US-9862364-B2","patent_1":"US-2019073909-A1","title_1":"Vehicle light control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190073909A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system including a computer for a vehicle is programmed to identify the vehicle as a lead vehicle in a platoon of three or more vehicles, and to identify one of the vehicles in the platoon as a caboose vehicle. The computer is programmed to deactivate a rear light of the lead vehicle, and to instruct activation of a rear light of the caboose vehicle.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-09-07T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8730773311},{"pair":"US-10068477-B2 & US-9740202-B2","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8730572881},{"pair":"US-2017316691-A1 & US-9740202-B2","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8730572881},{"pair":"US-10259457-B2 & US-2018152628-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729763675},{"pair":"US-2017364072-A1 & US-9682707-B1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-06-15T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729571146},{"pair":"US-10037033-B2 & US-9682707-B1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-06-15T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729571146},{"pair":"US-2020020117-A1 & US-2015310281-A1","patent_1":"US-2020020117-A1","title_1":"Pose estimation ","patent_2":"US-2015310281-A1","title_2":"Methods and Systems for Object Detection using Multiple Sensors ","link_1":"https:\/\/patents.google.com\/patent\/US20200020117A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150310281A1\/en","abstract_1":null,"abstract_2":"Methods and systems for object detection using multiple sensors are described herein. In an example embodiment, a vehicle's computing device may receive sensor data frames indicative of an environment at different rates from multiple sensors. Based on a first frame from a first sensor indicative of the environment at a first time period and a portion of a first frame that corresponds to the first time period from a second sensor, the computing device may estimate parameters of objects in the vehicle's environment. The computing device may modify the parameters in response to receiving subsequent frames or subsequent portions of frame of sensor data from the sensors even if the frames arrive at the computing device out of order. The computing device may provide the parameters of the objects to systems of the vehicle for object detection and obstacle avoidance.","priority_1":"2018-07-16T00:00:00","priority_2":"2014-04-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729427991},{"pair":"US-10121367-B2 & US-2017341643-A1","patent_1":"US-10121367-B2","title_1":"Vehicle lane map estimation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10121367B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A computer can receive, from a vehicle sensor, data about a plurality of second vehicles, define two or more vehicle clusters based on location data of second vehicles, each cluster including two or more of the second vehicles determined to be traveling in a same lane, identify two or more lane boundaries according to clusters, and use lane boundaries to generate a lane map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-04-29T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729259375},{"pair":"US-2017316684-A1 & US-2017341643-A1","patent_1":"US-2017316684-A1","title_1":"Vehicle lane map estimation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316684A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-04-29T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729259375},{"pair":"US-2019235520-A1 & US-10204278-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728583245},{"pair":"US-10466714-B2 & US-10204278-B2","patent_1":"US-10466714-B2","title_1":"Depth map estimation with stereo images ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10466714B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. While operating in either mode, an array of sensors can be used to pilot the vehicle including stereo cameras and 3D sensors. Stereo camera and 3D sensors can also be employed to assist occupants while piloting vehicles. Deep convolutional neural networks can be employed to determine estimated depth maps from stereo images of scenes in real time for vehicles in autonomous and occupant piloted modes.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-09-01T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728528197},{"pair":"US-2017206426-A1 & US-9766626-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872825313},{"pair":"US-2017316684-A1 & US-9862364-B2","patent_1":"US-2017316684-A1","title_1":"Vehicle lane map estimation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316684A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-04-29T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728146725},{"pair":"US-10121367-B2 & US-9862364-B2","patent_1":"US-10121367-B2","title_1":"Vehicle lane map estimation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10121367B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A computer can receive, from a vehicle sensor, data about a plurality of second vehicles, define two or more vehicle clusters based on location data of second vehicles, each cluster including two or more of the second vehicles determined to be traveling in a same lane, identify two or more lane boundaries according to clusters, and use lane boundaries to generate a lane map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-04-29T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728146725},{"pair":"US-9618938-B2 & US-9646497-B1","patent_1":"US-9618938-B2","title_1":"Field-based torque steering control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US9618938B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system includes a computer programmed to determine, along a nominal path to be traversed by a vehicle, a potential field representing a driving corridor for the vehicle. The computer is further programmed to identify a position of the vehicle relative to the potential field at a current time, and apply a torque to q steering column of the vehicle. The torque is based at least in part on the position. The potential field includes an attractive potential that guides the vehicle to remain within the corridor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-07-31T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728087976},{"pair":"US-9612596-B2 & US-9868391-B1","patent_1":"US-9612596-B2","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9612596B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2015-05-05T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727566227},{"pair":"US-2017072962-A1 & US-9690296-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727479944},{"pair":"US-2017072962-A1 & US-10198643-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727235517},{"pair":"US-2019210593-A1 & US-9360556-B2","patent_1":"US-2019210593-A1","title_1":"Vehicle vision ","patent_2":"US-9360556-B2","title_2":"Methods and systems for detecting weather conditions including fog using vehicle onboard sensors ","link_1":"https:\/\/patents.google.com\/patent\/US20190210593A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9360556B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to detect water on a ground surface, actuate a vehicle exterior light to illuminate a grid pattern on the ground surface, detect a depression at a location of the detected water based on received reflections of the grid pattern, and move a vehicle based on the detected depression.","abstract_2":"Methods and systems for detecting weather conditions including fog using vehicle onboard sensors are provided. An example method includes receiving laser data collected from scans of an environment of a vehicle, and associating, by a computing device, laser data points of with one or more objects in the environment. The method also includes comparing laser data points that are unassociated with the one or more objects in the environment with stored laser data points representative of a pattern due to fog, and based on the comparison, identifying by the computing device an indication that a weather condition of the environment of the vehicle includes fog.","priority_1":"2018-01-09T00:00:00","priority_2":"2013-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727196335},{"pair":"US-10556584-B2 & US-9360556-B2","patent_1":"US-10556584-B2","title_1":"Vehicle vision ","patent_2":"US-9360556-B2","title_2":"Methods and systems for detecting weather conditions including fog using vehicle onboard sensors ","link_1":"https:\/\/patents.google.com\/patent\/US10556584B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9360556B2\/en","abstract_1":null,"abstract_2":"Methods and systems for detecting weather conditions including fog using vehicle onboard sensors are provided. An example method includes receiving laser data collected from scans of an environment of a vehicle, and associating, by a computing device, laser data points of with one or more objects in the environment. The method also includes comparing laser data points that are unassociated with the one or more objects in the environment with stored laser data points representative of a pattern due to fog, and based on the comparison, identifying by the computing device an indication that a weather condition of the environment of the vehicle includes fog.","priority_1":"2018-01-09T00:00:00","priority_2":"2013-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727196335},{"pair":"US-10220769-B1 & US-2018135972-A1","patent_1":"US-10220769-B1","title_1":"Vehicular image projection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10220769B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-08-22T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727149345},{"pair":"US-2019061611-A1 & US-2018135972-A1","patent_1":"US-2019061611-A1","title_1":"Vehicular image projection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190061611A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-08-22T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727149345},{"pair":"US-10528055-B2 & US-9261379-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9261379-B1","title_2":"Intersection completer ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9261379B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to generating roadgraphs for use by autonomous vehicles. A computer may receive input defining aspects of a roadway including an intersection with another roadway, one or more traffic control features, and one or more locations at which a vehicle is required to observe at least one traffic signal before entering the intersection. A user may identify the intersection, for example, by tracing a perimeter around the intersection. In response, for each particular location of the one or more locations, the computer may identifying a route through the intersection from the particular location and determine, based on the boundary of the intersection and the particular location, a set of the one or more traffic control features must be observed by the vehicle before entering the intersection. This information may then be used to generate a roadgraph.","priority_1":"2016-11-03T00:00:00","priority_2":"2011-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727108537},{"pair":"US-2020073405-A1 & US-2018143643-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727016823},{"pair":"US-2019362168-A1 & US-9463794-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872697555},{"pair":"US-2018120857-A1 & US-9261379-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9261379-B1","title_2":"Intersection completer ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9261379B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate generally to generating roadgraphs for use by autonomous vehicles. A computer may receive input defining aspects of a roadway including an intersection with another roadway, one or more traffic control features, and one or more locations at which a vehicle is required to observe at least one traffic signal before entering the intersection. A user may identify the intersection, for example, by tracing a perimeter around the intersection. In response, for each particular location of the one or more locations, the computer may identifying a route through the intersection from the particular location and determine, based on the boundary of the intersection and the particular location, a set of the one or more traffic control features must be observed by the vehicle before entering the intersection. This information may then be used to generate a roadgraph.","priority_1":"2016-11-03T00:00:00","priority_2":"2011-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8725889232},{"pair":"US-2018011954-A1 & US-9836895-B1","patent_1":"US-2018011954-A1","title_1":"Virtual Sensor-Data-Generation System and Method Supporting Development of Algorithms Facilitating Navigation of Railway Crossings in Varying Weather Conditions ","patent_2":"US-9836895-B1","title_2":"Simulating virtual objects ","link_1":"https:\/\/patents.google.com\/patent\/US20180011954A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836895B1\/en","abstract_1":"A method for generating training data is disclosed. The method may include executing a simulation process. The simulation process may include traversing a virtual, forward-looking sensor over a virtual road surface defining at least one virtual railroad crossing. During the traversing, the virtual sensor may be moved with respect to the virtual road surface as dictated by a vehicle-motion model modeling motion of a vehicle driving on the virtual road surface while carrying the virtual sensor. Virtual sensor data characterizing the virtual road surface may be recorded. The virtual sensor data may correspond to what a real sensor would have output had it sensed the road surface in the real world.","abstract_2":"An autonomous vehicle is tested using virtual objects. The autonomous vehicle is maneuvered, by one or more computing devices, the autonomous vehicle in an autonomous driving mode. Sensor data is received corresponding to objects in the autonomous vehicle's environment, and virtual object data is received corresponding to a virtual object in the autonomous vehicle's environment. The virtual object represents a real object that is not in the vehicle's environment. The autonomous vehicle is maneuvered based on both the sensor data and the virtual object data. Information about the maneuvering of the vehicle based on both the sensor data and the virtual object data may be logged and analyzed.","priority_1":"2016-07-07T00:00:00","priority_2":"2015-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8725557435},{"pair":"US-2018120858-A1 & US-9740202-B2","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8725295564},{"pair":"US-10082796-B2 & US-9740202-B2","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8725295564},{"pair":"US-2019176830-A1 & US-10156851-B1","patent_1":"US-2019176830-A1","title_1":"Vehicle lane change ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190176830A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a processor. The system includes a memory, the memory storing instructions executable by the processor to identify a relative area within a specified distance from a first vehicle and free of another vehicle, identify a second vehicle within a second specified distance of the relative area, transmit the relative area to the second vehicle, and navigate the first vehicle to the relative area within a specified time.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-12-11T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8725010214},{"pair":"US-2017247040-A1 & US-9690296-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872468399},{"pair":"US-2017364072-A1 & US-2017277191-A1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-2017277191-A1","title_2":"Arranging passenger pickups for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170277191A1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure relate to arranging a pickup between a driverless vehicle and a passenger. For instance, dispatch instructions dispatching the vehicle to a predetermined pickup area in order to pick up the passenger are received by the vehicle which begins maneuvering to the predetermined pickup area. While doing so, the vehicle receives from the passenger's client computing device the device's location. An indication that the passenger is interested in a fly-by pickup is identified. The fly-by pickup allows the passenger to safely enter the vehicle at a location outside of the predetermined pickup area and prior to the one or more processors have maneuvered the vehicle to the predetermined pickup area. The vehicle determines that the fly-by pickup is appropriate based on at least the location of the client computing device and the indication, and based on the determination, maneuvers itself in order to attempt the fly-by pickup.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-03-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8724520824},{"pair":"US-10037033-B2 & US-2017277191-A1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-2017277191-A1","title_2":"Arranging passenger pickups for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170277191A1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure relate to arranging a pickup between a driverless vehicle and a passenger. For instance, dispatch instructions dispatching the vehicle to a predetermined pickup area in order to pick up the passenger are received by the vehicle which begins maneuvering to the predetermined pickup area. While doing so, the vehicle receives from the passenger's client computing device the device's location. An indication that the passenger is interested in a fly-by pickup is identified. The fly-by pickup allows the passenger to safely enter the vehicle at a location outside of the predetermined pickup area and prior to the one or more processors have maneuvered the vehicle to the predetermined pickup area. The vehicle determines that the fly-by pickup is appropriate based on at least the location of the client computing device and the indication, and based on the determination, maneuvers itself in order to attempt the fly-by pickup.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-03-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8724520824},{"pair":"US-2018239361-A1 & US-9836052-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8724421057},{"pair":"US-2016325779-A1 & US-10580291-B1","patent_1":"US-2016325779-A1","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-10580291-B1","title_2":"Vehicle location assistance using audible signals ","link_1":"https:\/\/patents.google.com\/patent\/US20160325779A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10580291B1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the present disclosure relate to using audible cues to guide a passenger to a vehicle having an autonomous driving mode. For instance, one or more processors of the vehicle may receive, from a server computing device, instructions to pick up the passenger at a pickup location. The one or more processors may maneuver the vehicle towards the pickup location in the autonomous driving mode. The one or more processors may receive a signal indicating that the passenger requests assistance locating the vehicle. The one or more processors may use the signal to generate the audible cues. The audible cues may be played by the one or more processors through a speaker of the vehicle in order to guide the passenger towards the vehicle.","priority_1":"2015-05-05T00:00:00","priority_2":"2017-09-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.87237798},{"pair":"US-2018281782-A1 & US-10156851-B1","patent_1":"US-2018281782-A1","title_1":"Wrong-way vehicle detection ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180281782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-03-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8723767543},{"pair":"US-10442429-B2 & US-10156851-B1","patent_1":"US-10442429-B2","title_1":"Wrong-way vehicle detection ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10442429B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Disclosed herein is a system including a computer programmed to determine that a vehicle is traveling in a wrong-way direction. Upon such determination, the computer is programmed to actuate a light of the vehicle to provide a user-detectable pattern external to the vehicle.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-03-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8723767543},{"pair":"US-2018164823-A1 & US-9684836-B1","patent_1":"US-2018164823-A1","title_1":"Autonomous vehicle post-fault operation ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180164823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. Vehicles can be equipped with hardware and software to determine a driving-acceptable region defined by lateral and longitudinal coordinates relative to a first vehicle, wherein the lateral and longitudinal coordinates are based on the locations and sizes of one or more second vehicles and the location and size of a roadway. Upon determining a vehicle fault, a computing device in the vehicle can pilot the vehicle to a stop within the driving-acceptable region.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-12-13T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8723726318},{"pair":"US-2018319402-A1 & US-9740202-B2","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-05-05T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8723712918},{"pair":"US-10488863-B2 & US-2017098129-A1","patent_1":"US-10488863-B2","title_1":"Autonomous vehicle post-fault operation ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10488863B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. Vehicles can be equipped with hardware and software to determine a driving-acceptable region defined by lateral and longitudinal coordinates relative to a first vehicle, wherein the lateral and longitudinal coordinates are based on the locations and sizes of one or more second vehicles and the location and size of a roadway. Upon determining a vehicle fault, a computing device in the vehicle can pilot the vehicle to a stop within the driving-acceptable region.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-12-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8723329875},{"pair":"US-9696721-B1 & US-10139829-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-10139829-B1","title_2":"User interface for displaying object-based indications in an autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10139829B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"A vehicle has a plurality of control apparatuses, a user input, a geographic position component, an object detection apparatus, memory, and a display. A processor is also included and is programmed to receive the destination information, identify a route, and determine the current geographic location of the vehicle. The processor is also programmed to identify an object and object type based on object information received from the object detection apparatus and to determine at least one warning characteristic of the identified object based on at least one of: the object type, a detected proximity of the detected object to the vehicle, the location of the detected object relative to predetermined peripheral areas of the vehicle, the current geographic location of the vehicle, and the route. The processor is also configured to select and display on the display an object warning image based on the at least one warning characteristic.","priority_1":"2016-03-21T00:00:00","priority_2":"2013-03-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722992973},{"pair":"US-10528055-B2 & US-9669827-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722808697},{"pair":"US-9921581-B2 & US-9868391-B1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.87227986},{"pair":"US-2017192429-A1 & US-9868391-B1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.87227986},{"pair":"US-2018120857-A1 & US-9707966-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722723272},{"pair":"US-10345822-B1 & US-2018135972-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722596656},{"pair":"US-2018319402-A1 & US-9679206-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2017-05-05T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722511584},{"pair":"US-2017174261-A1 & US-9373045-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872223729},{"pair":"US-2020026279-A1 & US-2017193627-A1","patent_1":"US-2020026279-A1","title_1":"Smart neighborhood routing for autonomous vehicles ","patent_2":"US-2017193627-A1","title_2":"Autonomous vehicle services ","link_1":"https:\/\/patents.google.com\/patent\/US20200026279A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170193627A1\/en","abstract_1":null,"abstract_2":"The technology relates to facilitating transportation services between a user and a vehicle having an autonomous driving mode. For instance, one or more server computing devices having one or more processors may information identifying the current location of the vehicle. The one or more server computing devices may determine that the user is likely to want to take a trip to a particular destination based on prior location history for the user. The one or more server computing devices may dispatch the vehicle to cause the vehicle to travel in the autonomous driving mode towards a location of the user. In addition, after dispatching, the one or more server computing devices sending a notification to a client computing device associated with the user indicating that the vehicle is currently available to take the passenger to the particular destination.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8721888819},{"pair":"US-2019389456-A1 & US-2018102001-A1","patent_1":"US-2019389456-A1","title_1":"Transportation infrastructure communication and control ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190389456A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"In a computer mounted to a stationary support structure a vehicle and an object proximate to the support structure can be detected from data from a sensor mounted to the support structure. A risk condition can be identified based on the detected vehicle and object.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2018-06-26T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8721419625},{"pair":"US-2018251155-A1 & US-10496091-B1","patent_1":"US-2018251155-A1","title_1":"Assisting Drivers With Roadway Lane Changes ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180251155A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for assisting drivers with roadway lane changes. In general, aspects of the invention are used in motorized vehicles to guide a driver to a more efficiently operating lane of a multi-lane roadway. A lane recommendation can be based on sensed and\/or communicated aspects of surrounding vehicles (e.g., speed, acceleration, etc.). Lane recommendations can be communicated to a driver with audio and\/or visual cues. In one aspect, images of surrounding roadway are augmented with additional data to highlight lanes, lane change locations, other vehicles, etc. Lane recommendations can be revised in (essentially) real-time in response to changing conditions in a roadway environment (e.g., a vehicle in a neighboring lane has changed speed).","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-03-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8721360319},{"pair":"US-2017327037-A1 & US-9551992-B1","patent_1":"US-2017327037-A1","title_1":"Adaptive rear view display ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170327037A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"System and methods to provide an adaptive rear view display are disclosed. An example disclosed first vehicle includes a rear view camera and an adaptive display controller. The example adaptive display controller is to determine, with range detection sensors, a following-time of a second vehicle behind the first vehicle. The example adaptive display controller is also to determine a workload estimate associated with the first vehicle. Additionally, when the first vehicle is moving forward, the adaptive display controller is to selectively display video from the rear view camera based on the following-time, the workload estimate, and a user request.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-05-10T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8721180004},{"pair":"US-10082796-B2 & US-9679206-B1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-10-27T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872115379},{"pair":"US-2018120858-A1 & US-9679206-B1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-10-27T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872115379},{"pair":"US-2018225970-A1 & US-2018135972-A1","patent_1":"US-2018225970-A1","title_1":"Advanced v2x event dissemination ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180225970A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Disclosed is a host vehicle including: motor(s), sensors, processor(s) configured to: (i) package sensed data into a first unit; (ii) determine whether a vehicle-to-infrastructure connection is (a) active or (b) inactive; (iii) if (a), append a TRUE flag to the unit and if (b) append a FALSE flag to the unit; (iv) transmit the first appended unit over a vehicle-to-vehicle connection; (v) determine whether a second appended unit, received over a vehicle-to-vehicle connection, includes (c) a TRUE flag or (d) a FALSE flag; (vi) if (d), transmit the second appended unit over the vehicle-to-infrastructure connection; (vii) if (c), not transmit the second appended unit over the vehicle-to-infrastructure connection.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-02-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8721067095},{"pair":"US-10345822-B1 & US-2018143643-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720964776},{"pair":"US-2017072962-A1 & US-2018152628-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.872089394},{"pair":"US-2020064850-A1 & US-2018011496-A1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2018-08-22T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720630535},{"pair":"US-2017174261-A1 & US-9720412-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9720412-B1","title_2":"Modifying the behavior of an autonomous vehicle using context based parameter switching ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9720412B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle configured to operate in an autonomous mode may operate a sensor to determine an environment of the vehicle. The sensor may be configured to obtain sensor data of a sensed portion of the environment. The sensed portion may be defined by a sensor parameter. Based on the environment of the vehicle, the vehicle may select at least one parameter value for the at least one sensor parameter such that the sensed portion of the environment corresponds to a region of interest. The vehicle may operate the sensor, using the selected at least one parameter value for the at least one sensor parameter, to obtain sensor data of the region of interest, and control the vehicle in the autonomous mode based on the sensor data of the region of interest.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720428625},{"pair":"US-2017197615-A1 & US-10204278-B2","patent_1":"US-2017197615-A1","title_1":"System and method for reverse perpendicular parking a vehicle ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170197615A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A method for parking a vehicle in a parking lot includes generating steering commands for the vehicle while in the lot based on an occupancy grid and plenoptic camera data. The occupancy grid indicates occupied areas and unoccupied areas around the vehicle and is derived from map data defining parking spots relative to a topological feature contained within the lot. The plenoptic camera data defines a plurality of depth maps and corresponding images that include the topological feature captured during movement of the vehicle. The steering command is generated such that the vehicle follows a reverse perpendicular path into one of the spots without entering an occupied area.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-01-11T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720427676},{"pair":"US-10082796-B2 & US-2018135972-A1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-10-27T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720076604},{"pair":"US-2018120858-A1 & US-2018135972-A1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-10-27T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720076604},{"pair":"US-2020031468-A1 & US-2018143643-A1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-12-14T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8719889863},{"pair":"US-2019235520-A1 & US-2018135972-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8719880115},{"pair":"US-2018164823-A1 & US-2017098129-A1","patent_1":"US-2018164823-A1","title_1":"Autonomous vehicle post-fault operation ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180164823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. Vehicles can be equipped with hardware and software to determine a driving-acceptable region defined by lateral and longitudinal coordinates relative to a first vehicle, wherein the lateral and longitudinal coordinates are based on the locations and sizes of one or more second vehicles and the location and size of a roadway. Upon determining a vehicle fault, a computing device in the vehicle can pilot the vehicle to a stop within the driving-acceptable region.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-12-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871971872},{"pair":"US-2018203457-A1 & US-10496091-B1","patent_1":"US-2018203457-A1","title_1":"System and Method for Avoiding Interference with a Bus ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180203457A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A method for avoiding interference with a bus. The method includes detecting a bus and obtaining image data from the bus, such as information displayed on the bus. A deep neural network trained on bus images may process the information to associate the bus with a bus route and stop locations. Map data corresponding to the stop locations may also be obtained and used to initiate a lane change or safety response in response to proximity of the bus to a stop location. A corresponding system and computer program product is also disclosed and claimed herein.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-01-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8719464833},{"pair":"US-2019235520-A1 & US-9804597-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9804597-B1","title_2":"Use of detected objects for image processing ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9804597B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8719441469},{"pair":"US-10589742-B2 & US-9381917-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9381917-B1","title_2":"Predictive reasoning for controlling speed of a vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9381917B1\/en","abstract_1":null,"abstract_2":"Methods and systems for predictive reasoning for controlling speed of a vehicle are described. A computing device may be configured to identify a first and second vehicle travelling ahead of an autonomous vehicle and in a same lane as the autonomous vehicle. The computing device may also be configured to determine a first buffer distance behind the first vehicle at which the autonomous vehicle will substantially reach a speed of the first vehicle and a second buffer distance behind the second vehicle at which the first vehicle will substantially reach a speed of the second vehicle. The computing device may further be configured to determine a distance at which to adjust a speed of the autonomous vehicle based on the first and second buffer distances and the speed of the autonomous vehicle, and then provide instructions to adjust the speed of the autonomous vehicle based on the distance.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-05-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8718890241},{"pair":"US-2017072962-A1 & US-9541410-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9541410-B1","title_2":"Augmented trajectories for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9541410B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"An autonomous vehicle may include a stuck condition detection component and a communications component. The stuck-detection component may be configured to detect a condition in which the autonomous vehicle is impeded from navigating according to a first trajectory. The communications component may send an assistance signal to an assistance center and receive a response to the assistance signal. The assistance signal may include sensor information from the autonomous vehicle. The assistance center may include a communications component and a trajectory specification component. The communications component may receive the assistance signal and send a corresponding response. The trajectory specification component may specify a second trajectory for the autonomous vehicle and generate the corresponding response that includes a representation of the second trajectory. The second trajectory may be based on the first trajectory and may ignore an object that obstructs the first trajectory.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8718530289},{"pair":"US-2017364072-A1 & US-9368026-B1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9368026-B1","title_2":"Fallback requests for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9368026B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the present disclosure relate to a system having a memory, a plurality of self-driving systems for controlling a vehicle, and one or more processors. The processors are configured to receive at least one fallback task in association with a request for a primary task and at least one trigger of each fallback task. Each trigger is a set of conditions that, when satisfied, indicate when a vehicle requires attention for proper operation. The processors are also configured to send instructions to the self-driving systems to execute the primary task and receive status updates from the self-driving systems. The processors are configured to determine that a set of conditions of a trigger is satisfied based on the status updates and send further instructions based on the associated fallback task to the self-driving systems.","priority_1":"2016-06-15T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8718466313},{"pair":"US-10037033-B2 & US-9368026-B1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9368026-B1","title_2":"Fallback requests for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9368026B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the present disclosure relate to a system having a memory, a plurality of self-driving systems for controlling a vehicle, and one or more processors. The processors are configured to receive at least one fallback task in association with a request for a primary task and at least one trigger of each fallback task. Each trigger is a set of conditions that, when satisfied, indicate when a vehicle requires attention for proper operation. The processors are also configured to send instructions to the self-driving systems to execute the primary task and receive status updates from the self-driving systems. The processors are configured to determine that a set of conditions of a trigger is satisfied based on the status updates and send further instructions based on the associated fallback task to the self-driving systems.","priority_1":"2016-06-15T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8718466313},{"pair":"US-2016325779-A1 & US-2018102001-A1","patent_1":"US-2016325779-A1","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20160325779A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-05-05T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.871824168},{"pair":"US-2019235520-A1 & US-9387854-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8718079397},{"pair":"US-10082796-B2 & US-9551992-B1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871807436},{"pair":"US-2018120858-A1 & US-9551992-B1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871807436},{"pair":"US-2019161085-A1 & US-9387854-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8718024562},{"pair":"US-2019235520-A1 & US-9494942-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8717561463},{"pair":"US-10328973-B2 & US-10496091-B1","patent_1":"US-10328973-B2","title_1":"Assisting drivers with roadway lane changes ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10328973B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for assisting drivers with roadway lane changes. In general, aspects of the invention are used in motorized vehicles to guide a driver to a more efficiently operating lane of a multi-lane roadway. A lane recommendation can be based on sensed and\/or communicated aspects of surrounding vehicles (e.g., speed, acceleration, etc.). Lane recommendations can be communicated to a driver with audio and\/or visual cues. In one aspect, images of surrounding roadway are augmented with additional data to highlight lanes, lane change locations, other vehicles, etc. Lane recommendations can be revised in (essentially) real-time in response to changing conditions in a roadway environment (e.g., a vehicle in a neighboring lane has changed speed).","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-03-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8717406436},{"pair":"US-10026317-B2 & US-9646497-B1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8717228839},{"pair":"US-2018239361-A1 & US-10204278-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8717209971},{"pair":"US-2020064850-A1 & US-2018143643-A1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-08-22T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871689143},{"pair":"US-10551836-B2 & US-9862364-B2","patent_1":"US-10551836-B2","title_1":"Driver assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10551836B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-06-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8716290596},{"pair":"US-2019111922-A1 & US-9555740-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9555740-B1","title_2":"Cross-validating sensors of an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9555740B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Methods and systems are disclosed for cross-validating a second sensor with a first sensor. Cross-validating the second sensor may include obtaining sensor readings from the first sensor and comparing the sensor readings from the first sensor with sensor readings obtained from the second sensor. In particular, the comparison of the sensor readings may include comparing state information about a vehicle detected by the first sensor and the second sensor. In addition, comparing the sensor readings may include obtaining a first image from the first sensor, obtaining a second image from the second sensor, and then comparing various characteristics of the images. One characteristic that may be compared are object labels applied to the vehicle detected by the first and second sensor. The first and second sensors may be different types of sensors.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8715885849},{"pair":"US-10262540-B2 & US-9862364-B2","patent_1":"US-10262540-B2","title_1":"Bollard receiver identification ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10262540B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"The disclosure relates generally to methods, systems, and apparatuses for automated or assisted driving and more particularly relates to identification, localization, and navigation with respect to bollard receivers. A method for detecting bollard receivers includes receiving perception data from one or more perception sensors of a vehicle. The method includes determining, based on the perception data, a location of one or more bollard receivers in relation to a body of the vehicle. The method also includes providing an indication of the location of the one or more bollard receivers to one or more of a driver and component or system that makes driving maneuver decisions.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-01-29T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8714908646},{"pair":"US-9983591-B2 & US-10204278-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8714582386},{"pair":"US-10259457-B2 & US-10198643-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.871421744},{"pair":"US-2017072962-A1 & US-9582907-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9582907-B1","title_2":"User interface for displaying internal state of autonomous driving system ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9582907B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Autonomous vehicles use various computing systems to transport passengers from one location to another. A control computer sends messages to the various systems of the vehicle in order to maneuver the vehicle safely to the destination. The control computer may display information on an electronic display in order to allow the passenger to understand what actions the vehicle may be taking in the immediate future. Various icons and images may be used to provide this information to the passenger.","priority_1":"2014-05-13T00:00:00","priority_2":"2010-04-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8714062561},{"pair":"US-2020064850-A1 & US-10496091-B1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-08-22T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8713972031},{"pair":"US-2017206426-A1 & US-9193355-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9193355-B2","title_2":"Construction zone sign detection using light detection and ranging ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9193355B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Methods and systems for construction zone sign detection are described. A computing device may be configured to receive a 3D point cloud of a vicinity of a road on which a vehicle is travelling. The 3D point cloud may include points corresponding to light reflected from objects in the vicinity of the road. The computing device may be configured to determine a set of points representing an area at a given height from a surface of the road, and estimate a shape associated with the set of points. Further, the computing device may be configured to determine a likelihood that the set of points represents a construction zone sign, based on the estimated shape. Based on the likelihood, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871379356},{"pair":"US-2017206426-A1 & US-2015266472-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2015266472-A1","title_2":"Construction Zone Object Detection Using Light Detection and Ranging ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150266472A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Methods and systems for construction zone object detection are described. A computing device may be configured to receive, from a LIDAR, a 3D point cloud of a road on which a vehicle is travelling. The 3D point cloud may comprise points corresponding to light reflected from objects on the road. Also, the computing device may be configured to determine sets of points in the 3D point cloud representing an area within a threshold distance from a surface of the road. Further, the computing device may be configured to identify construction zone objects in the sets of points. Further, the computing device may be configured to determine a likelihood of existence of a construction zone, based on the identification. Based on the likelihood, the computing device may be configured to modify a control strategy of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871379356},{"pair":"US-10377383-B2 & US-10156851-B1","patent_1":"US-10377383-B2","title_1":"Vehicle lane change ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377383B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a processor. The system includes a memory, the memory storing instructions executable by the processor to identify a relative area within a specified distance from a first vehicle and free of another vehicle, identify a second vehicle within a second specified distance of the relative area, transmit the relative area to the second vehicle, and navigate the first vehicle to the relative area within a specified time.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-12-11T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8713770802},{"pair":"US-9478137-B1 & US-10146223-B1","patent_1":"US-9478137-B1","title_1":"Detecting and communicating lane splitting maneuver ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9478137B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle system includes a lane detector programmed to output a boundary signal representing a location of a lane boundary relative to a host vehicle. A processing device is programmed to determine, from the boundary signal, whether the host vehicle is performing a lane splitting maneuver. If so, the processing device is programmed to transmit a lane splitting signal.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-06-17T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8713451291},{"pair":"US-10345822-B1 & US-9734417-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9734417-B2","title_2":"Use of relationship between activities of different traffic signals in a network to improve traffic signal state estimation ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734417B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and devices for using a relationship between activities of different traffic signals in a network to improve traffic signal state estimation are disclosed. An example method includes determining that a vehicle is approaching an upcoming traffic signal. The method may further include determining a state of one or more traffic signals other than the upcoming traffic signal. Additionally, the method may also include determining an estimate of a state of the upcoming traffic signal based on a relationship between the state of the one or more traffic signals other than the upcoming traffic signal and the state of the upcoming traffic signal.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.871338107},{"pair":"US-2017206426-A1 & US-2016092755-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2016092755-A1","title_2":"Construction Zone Sign Detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160092755A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Methods and systems for detection of a construction zone sign are described. A computing device, configured to control the vehicle, may be configured to receive, from an image-capture device coupled to the computing device, images of a vicinity of the road on which the vehicle is travelling. Also, the computing device may be configured to determine image portions in the images that may depict sides of the road at a predetermined height range. Further, the computing device may be configured to detect a construction zone sign in the image portions, and determine a type of the construction zone sign. Accordingly, the computing device may be configured to modify a control strategy associated with a driving behavior of the vehicle; and control the vehicle based on the modified control strategy.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-09-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8713242994},{"pair":"US-2018017799-A1 & US-2018102001-A1","patent_1":"US-2018017799-A1","title_1":"Heads Up Display For Observing Vehicle Perception Activity ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180017799A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for a heads up display for observing vehicle perception activity. As a vehicle is operating, an occupant can see objects outside of the vehicle through the windshield. Vehicle sensors also sense the objects outside the vehicle. A vehicle projection system can project a heads up display for the sensed objects onto the windshield. The heads up display can be aligned with a driver's point of view so that graphical elements projected on a windshield overlap with their corresponding objects as seen through the windshield. As such, a driver (e.g., a test engineer) is able to view algorithm output (e.g., perception algorithm output) without having to look away from the road while driving. Accordingly, testing driver assist and autonomous driving features is both safer and more efficient. The heads up display can also be used as a driver assist.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-07-13T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8713026378},{"pair":"US-2017248951-A1 & US-9690296-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712919112},{"pair":"US-2017139420-A1 & US-9534918-B2","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9534918-B2","title_2":"Determining and displaying auto drive lanes in an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9534918B2\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Aspects of the present disclosure relate generally to identifying and displaying traffic lanes that are available for autonomous driving. This information may be displayed to a driver of a vehicle having an autonomous driving mode, in order to inform the driver of where he or she can use the autonomous driving mode. In one example, the display may visually distinguishing between lanes that are available for auto-drive from those that are not. The display may also include an indicator of the position of a lane (autodrive or not) currently occupied by the vehicle. In addition, if that lane is an autodrive lane the display may include information indicating how much further the vehicle may continue in the autonomous driving mode in that particular lane. The display may also display information indicating the remaining autodrive distance in other lanes as well as the lane with the greatest remaining autodrive distance.","priority_1":"2014-07-16T00:00:00","priority_2":"2012-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712733269},{"pair":"US-9970615-B1 & US-9868391-B1","patent_1":"US-9970615-B1","title_1":"Light-based vehicle-device communications ","patent_2":"US-9868391-B1","title_2":"Scenario based audible warnings for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9970615B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9868391B1\/en","abstract_1":"A system for light-based vehicle-device communication includes a computer programmed to generate a first light pattern based on a received identifier, actuate a vehicle light according to the first light pattern, and then identify, from received image data, a second light pattern emitted from outside of the vehicle. The system may further include a mobile computing device programmed to generate the second light pattern based on a received vehicle identifier, and actuate a mobile device light according to the second light pattern. The mobile computing device may be programmed to identify, from received image data, the first light pattern.","abstract_2":"Aspects of the disclosure relate to providing audible indications to objects located externally to a vehicle having an autonomous driving mode. For instance, a vehicle is controlled in the autonomous driving mode along a particular path. Information identifying a characteristic and a location of an object is received. When vehicle is determined to be prevented from proceeding along the particular path because of the location of the object, a scenario is identified using the characteristic. The scenario is associated with a predetermined period of time and a type of audible indication used to identify an audible indication. After the waiting the predetermined period, when the object is determined to still be preventing the vehicle from proceeding along the particular path, the audible indication is played through a speaker of the vehicle to encourage the object to take an action to allow the vehicle to proceed along the particular path.","priority_1":"2017-05-23T00:00:00","priority_2":"2016-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712730299},{"pair":"US-2017327035-A1 & US-10496091-B1","patent_1":"US-2017327035-A1","title_1":"Methods and systems for beyond-the-horizon threat indication for vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170327035A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Methods and systems for Beyond-the-Horizon Threat Indication (BHTI) for vehicles are described. A system and a method may involve receiving motion information of a first vehicle. The system and the method may also involve receiving vicinity data corresponding to a vicinity of the first vehicle. The system and the method may also involve determining whether the first vehicle is subject to a potential hazard within the vicinity based on the motion information and the vicinity data. The system and the method may further involves alerting the first vehicle about the potential hazard in response to the determining of the potential hazard.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-05-10T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712724419},{"pair":"US-2018164823-A1 & US-2016187887-A1","patent_1":"US-2018164823-A1","title_1":"Autonomous vehicle post-fault operation ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20180164823A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. Vehicles can be equipped with hardware and software to determine a driving-acceptable region defined by lateral and longitudinal coordinates relative to a first vehicle, wherein the lateral and longitudinal coordinates are based on the locations and sizes of one or more second vehicles and the location and size of a roadway. Upon determining a vehicle fault, a computing device in the vehicle can pilot the vehicle to a stop within the driving-acceptable region.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-12-13T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712432765},{"pair":"US-2017174261-A1 & US-2017098129-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712362066},{"pair":"US-2017139420-A1 & US-9528850-B1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9528850-B1","title_2":"Suggesting a route based on desired amount of driver interaction ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9528850B1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Aspects of the disclosure relate generally to generating and providing route options for an autonomous vehicle. For example, a user may identify a destination, and in response the vehicle's computer may provide routing options to the user. The routing options may be based on typical navigating considerations such as the total travel time, travel distance, fuel economy, etc. Each routing option may include not only an estimated total time, but also information regarding whether and which portions of the route may be maneuvered under the control of the vehicle alone (fully autonomous), a combination of the vehicle and the driver (semiautonomous), or the driver alone. The time of the longest stretch of driving associated with the autonomous mode as well as map information indicating portions of the routes associated with the type of maneuvering control may also be provided.","priority_1":"2014-07-16T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8711887712},{"pair":"US-2017197615-A1 & US-2017098129-A1","patent_1":"US-2017197615-A1","title_1":"System and method for reverse perpendicular parking a vehicle ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170197615A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A method for parking a vehicle in a parking lot includes generating steering commands for the vehicle while in the lot based on an occupancy grid and plenoptic camera data. The occupancy grid indicates occupied areas and unoccupied areas around the vehicle and is derived from map data defining parking spots relative to a topological feature contained within the lot. The plenoptic camera data defines a plurality of depth maps and corresponding images that include the topological feature captured during movement of the vehicle. The steering command is generated such that the vehicle follows a reverse perpendicular path into one of the spots without entering an occupied area.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-01-11T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8711779624},{"pair":"US-10037033-B2 & US-9463794-B1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-06-15T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8710679641},{"pair":"US-2017364072-A1 & US-9463794-B1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-06-15T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8710679641},{"pair":"US-10259457-B2 & US-9557736-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8710385688},{"pair":"US-2020064850-A1 & US-2018135972-A1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-08-22T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8710277675},{"pair":"US-2017248952-A1 & US-9690296-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8709717904},{"pair":"US-2017248953-A1 & US-9690296-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8708561143},{"pair":"US-2019161085-A1 & US-9932035-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9932035-B1","title_2":"Modifying speed of an autonomous vehicle based on traffic conditions ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9932035B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate generally to speed control in an autonomous vehicle. For example, an autonomous vehicle may include a user interface which allows the driver to input speed preferences. These preferences may include the maximum speed above the speed limit the user would like the autonomous vehicle to drive when other vehicles are present and driving above or below certain speeds. The other vehicles may be in adjacent or the same lane the vehicle, and need not be in front of the vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.870810526},{"pair":"US-2017174261-A1 & US-9707966-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8708003008},{"pair":"US-2018224859-A1 & US-2018152628-A1","patent_1":"US-2018224859-A1","title_1":"Tornado Detection Systems And Methods ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20180224859A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Example tornado detection systems and methods are described. In one implementation, a method receives data from a sensor mounted to a vehicle and analyzes the received data using a deep neural network. The method determines whether a tornado is identified in the received data based on the analysis of the received data. If a tornado is identified in the received data, the method determines a trajectory of the tornado.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-02-08T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707865664},{"pair":"US-10345822-B1 & US-9862364-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707709104},{"pair":"US-10345822-B1 & US-9796386-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9796386-B2","title_2":"Robust method for detecting traffic signals and their associated states ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9796386B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and devices for detecting traffic signals and their associated states are disclosed. In one embodiment, an example method includes a scanning a target area using one or more sensors of a vehicle to obtain target area information. The vehicle may be configured to operate in an autonomous mode, and the target area may be a type of area where traffic signals are typically located. The method may also include detecting a traffic signal in the target area information, determining a location of the traffic signal, and determining a state of the traffic signal. Also, a confidence in the traffic signal may be determined. For example, the location of the traffic signal may be compared to known locations of traffic signals. Based on the state of the traffic signal and the confidence in the traffic signal, the vehicle may be controlled in the autonomous mode.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-03-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707570377},{"pair":"US-2020065978-A1 & US-2016187887-A1","patent_1":"US-2020065978-A1","title_1":"Foreground detection ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20200065978A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-08-24T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707273759},{"pair":"US-2019235520-A1 & US-2016231748-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016231748-A1","title_2":"Real-Time Image-Based Vehicle Detection based on a Multi-Stage Classification ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160231748A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The present disclosure is directed to an autonomous vehicle having a vehicle control system. The vehicle control system includes a vehicle detection system. The vehicle detection system includes receiving an image of a field of view of the vehicle and identifying a region-pair in the image with a sliding-window filter. The region-pair is made up of a first region and a second region. Each region is determined based on a color of pixels within the sliding-window filter. The vehicle detection system also determines a potential second vehicle in the image based on the region-pair. In response to determining the potential second vehicle in the image, the vehicle detection system performs a multi-stage classification of the image to determine whether the second vehicle is present in the image. Additionally, the vehicle detection system provides instructions to control the first vehicle based at least on the determined second vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-06-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707026136},{"pair":"US-2020031468-A1 & US-10204278-B2","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-12-14T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8706720437},{"pair":"US-10366541-B2 & US-9682707-B1","patent_1":"US-10366541-B2","title_1":"Vehicle backup safety mapping ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10366541B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Method and apparatus are disclosed for vehicle backup safety mapping. An example vehicle includes a display, a rear-view camera, and a processor. The processor generates a three-dimensional model of space behind the vehicle based on images from the rear-view camera The processor also generates an overlay based on the three-dimensional model. The overlay includes representation of objects not in the field of view of the rear-view camera. Additionally, the processor displays, on the display, the images from the rear-view camera and the overlay.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-07-21T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.870632362},{"pair":"US-2017247040-A1 & US-10192442-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8706182743},{"pair":"US-2018120857-A1 & US-9804597-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9804597-B1","title_2":"Use of detected objects for image processing ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9804597B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705829096},{"pair":"US-2018081057-A1 & US-9862364-B2","patent_1":"US-2018081057-A1","title_1":"Metal bridge detection systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180081057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-09-20T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705751184},{"pair":"US-10055652-B2 & US-9862364-B2","patent_1":"US-10055652-B2","title_1":"Pedestrian detection and motion prediction with rear-facing camera ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10055652B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving one or more images from a rear-facing camera on a vehicle. The method further includes determining that a pedestrian is present in the one or more images, predicting future motion of the pedestrian, and notifying a driver-assistance or automated driving system when a conflict exists between forward motion of the vehicle and the predicted future motion of the pedestrian.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-03-21T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705657022},{"pair":"US-2017270374-A1 & US-9862364-B2","patent_1":"US-2017270374-A1","title_1":"Pedestrian detection and motion prediction with rear-facing camera ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170270374A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving one or more images from a rear-facing camera on a vehicle. The method further includes determining that a pedestrian is present in the one or more images, predicting future motion of the pedestrian, and notifying a driver-assistance or automated driving system when a conflict exists between forward motion of the vehicle and the predicted future motion of the pedestrian.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-03-21T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705657022},{"pair":"US-10345822-B1 & US-2017341643-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705624707},{"pair":"US-2020073405-A1 & US-2018135972-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.870558404},{"pair":"US-2018319402-A1 & US-9557736-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-05-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705318653},{"pair":"US-2017206426-A1 & US-2018135972-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705256316},{"pair":"US-2019161085-A1 & US-9783172-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9783172-B2","title_2":"Methods and systems for steering-based oscillatory vehicle braking ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9783172B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems for steering-based oscillatory braking are described herein. A method may involve making a determination, by a computing device, to reduce a speed of a vehicle. The vehicle may include a pair of wheels. The method may further involve providing instructions to turn the pair of wheels of the vehicle in an oscillatory manner, such that each wheel of the pair of wheels is turned in substantially the same direction and turning of the pair of wheels oscillates each wheel of the pair of wheels between given directions about a direction of travel of the vehicle so as to reduce the speed of the vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8704595922},{"pair":"US-2017249844-A1 & US-9646497-B1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.870348336},{"pair":"US-10423847-B2 & US-10204278-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8702783994},{"pair":"US-2019012913-A1 & US-10093181-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10093181-B1","title_2":"Occupant facing vehicle display ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10093181B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering an occupant of the vehicle to a destination autonomously as well as providing information about the vehicle and the vehicle's environment for display to the occupant.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-09-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8702619719},{"pair":"US-2018120858-A1 & US-10059334-B1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-10-27T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8702372457},{"pair":"US-10082796-B2 & US-10059334-B1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-10-27T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8702372457},{"pair":"US-10040390-B2 & US-9551992-B1","patent_1":"US-10040390-B2","title_1":"Vehicle light diagnostic ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10040390B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A first vehicle includes a light and a controller in communication with the light. The controller is programmed to detect a second vehicle positioned to sense the light, transmit a first message to the second vehicle requesting observation of the light, actuate the light to change state in response to a second message from the second vehicle, and receive a third message from the second vehicle specifying a state of the light.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-11T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8701273377},{"pair":"US-2018099606-A1 & US-9551992-B1","patent_1":"US-2018099606-A1","title_1":"Vehicle light diagnostic ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099606A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A first vehicle includes a light and a controller in communication with the light. The controller is programmed to detect a second vehicle positioned to sense the light, transmit a first message to the second vehicle requesting observation of the light, actuate the light to change state in response to a second message from the second vehicle, and receive a third message from the second vehicle specifying a state of the light.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-11T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8701273377},{"pair":"US-9618938-B2 & US-10012991-B1","patent_1":"US-9618938-B2","title_1":"Field-based torque steering control ","patent_2":"US-10012991-B1","title_2":"Approach for consolidating observed vehicle trajectories into a single representative trajectory ","link_1":"https:\/\/patents.google.com\/patent\/US9618938B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10012991B1\/en","abstract_1":"A system includes a computer programmed to determine, along a nominal path to be traversed by a vehicle, a potential field representing a driving corridor for the vehicle. The computer is further programmed to identify a position of the vehicle relative to the potential field at a current time, and apply a torque to q steering column of the vehicle. The torque is based at least in part on the position. The potential field includes an attractive potential that guides the vehicle to remain within the corridor.","abstract_2":"A method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a pool of combined trajectories. Subsequently, the autonomous vehicle may select one of the combined trajectories as a representative trajectory. The representative trajectory may be used to change at least one of the speed or direction of the autonomous vehicle.","priority_1":"2015-07-31T00:00:00","priority_2":"2012-03-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8701114512},{"pair":"US-2016210382-A1 & US-9575490-B2","patent_1":"US-2016210382-A1","title_1":"Autonomous driving refined in virtual environments ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20160210382A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"A computing device includes a processing circuit and a data storage medium. The computing device is programmed to receive a user input selecting at least one testing parameter associated with autonomously operating a virtual vehicle in a virtual environment, simulate the virtual environment incorporating the at least one testing parameter, virtually navigate the virtual vehicle through the virtual environment, collect virtual sensor data, and processing the collected virtual sensor data.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2015-01-21T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8701031682},{"pair":"US-2017016740-A1 & US-2018143643-A1","patent_1":"US-2017016740-A1","title_1":"Method and apparatus for determining a vehicle ego-position ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170016740A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a processor configured to receive image data gathered by a vehicle camera, relating to a fixed environmental feature. The processor is also configured to determine a vehicle position relative to the fixed environmental feature and determine a vehicle lane-level location on a digital map, based on the vehicle position relative to the fixed environmental feature.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-07-16T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8700942955},{"pair":"US-10406917-B2 & US-2018152628-A1","patent_1":"US-10406917-B2","title_1":"Systems and methods for vehicle cruise control smoothness adaptation ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10406917B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Methods and systems are disclosed for vehicle cruise control smoothness adaptation. An example vehicle includes a GPS receiver for receiving expected road incline data, a camera for determining a half lane width position, and a radar for determining two respective leading vehicle angles of arrival. The vehicle also includes a processor for determining an actual road incline by filtering the expected road incline, half lane width position, and leading vehicle angles of arrival. And the processor is further for modifying a cruise control system based on the actual road incline.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-08-28T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8700859739},{"pair":"US-2015241226-A1 & US-2018143643-A1","patent_1":"US-2015241226-A1","title_1":"Autonomous driving sensing system and method ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20150241226A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"First and second sets of data are collected in a vehicle from respective data sources. Each of the first and second sets of data are provided for determinations respectively selected from first and second categories of autonomous vehicle operations. A determination is made to take an autonomous action selected from the first category of autonomous vehicle operations. Data is used from each of the first and second data sets relating respectively to the first and second categories of autonomous vehicle operations to determine the autonomous action.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-02-24T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8700723191},{"pair":"US-2020026279-A1 & US-10580291-B1","patent_1":"US-2020026279-A1","title_1":"Smart neighborhood routing for autonomous vehicles ","patent_2":"US-10580291-B1","title_2":"Vehicle location assistance using audible signals ","link_1":"https:\/\/patents.google.com\/patent\/US20200026279A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10580291B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using audible cues to guide a passenger to a vehicle having an autonomous driving mode. For instance, one or more processors of the vehicle may receive, from a server computing device, instructions to pick up the passenger at a pickup location. The one or more processors may maneuver the vehicle towards the pickup location in the autonomous driving mode. The one or more processors may receive a signal indicating that the passenger requests assistance locating the vehicle. The one or more processors may use the signal to generate the audible cues. The audible cues may be played by the one or more processors through a speaker of the vehicle in order to guide the passenger towards the vehicle.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8700556175},{"pair":"US-2019346860-A1 & US-2019285754-A1","patent_1":"US-2019346860-A1","title_1":"Autonomous Vehicle Localization Using 5G Infrastructure ","patent_2":"US-2019285754-A1","title_2":"Methods and Systems for Location Determination ","link_1":"https:\/\/patents.google.com\/patent\/US20190346860A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190285754A1\/en","abstract_1":"A method for autonomous vehicle localization. The method may include receiving, by an autonomous vehicle, millimeter-wave signals from at least two 5G transmission points. Bearing measurements may be calculated relative to each of the 5G transmission points based on the signals. A vehicle velocity may be determined by observing characteristics of the signals. Sensory data, including the bearing measurements and the vehicle velocity, may then be fused to localize the autonomous vehicle. A corresponding system and computer program product are also disclosed and claimed herein.","abstract_2":"Methods and systems for location determination are described herein. An example implementation may involve receiving signals from a set of satellites to determine a general location of a receiver. After receiving a signal from a satellite, the receiver may-determine an angle of reception that indicates an orientation of the satellite relative to the receiver. The receiver may further obtain topography information for the general location that indicates the positions and elevations of features (e.g., buildings) at the general location. For instance, the receiver may use elevation maps or sensors to determine the topography information. Using the topography information and determined angles of receptions, the receiver may identify any signals that reflected off a feature prior to reaching the receiver. As a result, the receiver may determine and use the reflected path traveled by a reflected signal to refine the general location of the receiver.","priority_1":"2018-05-14T00:00:00","priority_2":"2016-12-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8700383882},{"pair":"US-2019197901-A1 & US-9862364-B2","patent_1":"US-2019197901-A1","title_1":"Bollard Receiver Identification ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190197901A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"The disclosure relates generally to methods, systems, and apparatuses for automated or assisted driving and more particularly relates to identification, localization, and navigation with respect to bollard receivers. A method for detecting bollard receivers includes receiving perception data from one or more perception sensors of a vehicle. The method includes determining, based on the perception data, a location of one or more bollard receivers in relation to a body of the vehicle. The method also includes providing an indication of the location of the one or more bollard receivers to one or more of a driver and component or system that makes driving maneuver decisions.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-01-29T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8700246546},{"pair":"US-10408937-B2 & US-9290181-B1","patent_1":"US-10408937-B2","title_1":"Metal bridge detection systems and methods ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US10408937B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2016-09-20T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699954768},{"pair":"US-10068477-B2 & US-10496091-B1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699925509},{"pair":"US-2017316691-A1 & US-10496091-B1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699925509},{"pair":"US-2017139420-A1 & US-9928431-B2","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9928431-B2","title_2":"Verifying a target object with reverse-parallax analysis ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9928431B2\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"A vehicle configured to operate in an autonomous mode may engage in a reverse-parallax analysis that includes a vehicle system detecting an object, capturing via a camera located at a first location a first image of the detected object, retrieving location data specifying (i) a location of a target object, (ii) the first location, and (iii) a direction of the camera, and based on the location data and the position of the detected object in the first image, predicting where in a second image captured from a second location the detected object would appear if the detected object is the target object.","priority_1":"2014-07-16T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699895011},{"pair":"US-10259457-B2 & US-9261379-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9261379-B1","title_2":"Intersection completer ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9261379B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate generally to generating roadgraphs for use by autonomous vehicles. A computer may receive input defining aspects of a roadway including an intersection with another roadway, one or more traffic control features, and one or more locations at which a vehicle is required to observe at least one traffic signal before entering the intersection. A user may identify the intersection, for example, by tracing a perimeter around the intersection. In response, for each particular location of the one or more locations, the computer may identifying a route through the intersection from the particular location and determine, based on the boundary of the intersection and the particular location, a set of the one or more traffic control features must be observed by the vehicle before entering the intersection. This information may then be used to generate a roadgraph.","priority_1":"2014-05-13T00:00:00","priority_2":"2011-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699715496},{"pair":"US-10259457-B2 & US-9646497-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699661979},{"pair":"US-2017248952-A1 & US-10192442-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699172861},{"pair":"US-10422649-B2 & US-2018143643-A1","patent_1":"US-10422649-B2","title_1":"Autonomous driving sensing system and method ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10422649B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"First and second sets of data are collected in a vehicle from respective data sources. Each of the first and second sets of data are provided for determinations respectively selected from first and second categories of autonomous vehicle operations. A determination is made to take an autonomous action selected from the first category of autonomous vehicle operations. Data is used from each of the first and second data sets relating respectively to the first and second categories of autonomous vehicle operations to determine the autonomous action.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-02-24T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8698679978},{"pair":"US-2019061527-A1 & US-2018152628-A1","patent_1":"US-2019061527-A1","title_1":"Systems and methods for vehicle cruise control smoothness adaptation ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190061527A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Methods and systems are disclosed for vehicle cruise control smoothness adaptation. An example vehicle includes a GPS receiver for receiving expected road incline data, a camera for determining a half lane width position, and a radar for determining two respective leading vehicle angles of arrival. The vehicle also includes a processor for determining an actual road incline by filtering the expected road incline, half lane width position, and leading vehicle angles of arrival. And the processor is further for modifying a cruise control system based on the actual road incline.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-08-28T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8698589079},{"pair":"US-2017072962-A1 & US-9767370-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9767370-B1","title_2":"Construction object detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9767370B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to identifying construction objects. As an example, an image captured by a camera associated with a vehicle as the vehicle is driven along a roadway may be received. This image may be converted into a first channel corresponding to an average brightness contribution from red, blue and green channels of the image. The image may also be converted into a second channel corresponding to a contribution of a color from the red and the green channels of the image. A template may then be used to identify a region of the image corresponding to a potential construction object from the first channel and the second channel.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-09-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8698425554},{"pair":"US-2017139420-A1 & US-10192442-B2","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2014-07-16T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8697747003},{"pair":"US-10399106-B2 & US-2018143643-A1","patent_1":"US-10399106-B2","title_1":"Camera and washer spray diagnostic ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10399106B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system including a computer programmed to actuate a spray device on a first vehicle and to receive an image, from a second vehicle, of the actuated spray device. The computer determines whether a spray device fault exists based at least on the image of the actuated spray device, and transmits the spray device fault via a first vehicle communications network.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-01-19T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8697741909},{"pair":"US-10345822-B1 & US-9928431-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9928431-B2","title_2":"Verifying a target object with reverse-parallax analysis ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9928431B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle configured to operate in an autonomous mode may engage in a reverse-parallax analysis that includes a vehicle system detecting an object, capturing via a camera located at a first location a first image of the detected object, retrieving location data specifying (i) a location of a target object, (ii) the first location, and (iii) a direction of the camera, and based on the location data and the position of the detected object in the first image, predicting where in a second image captured from a second location the detected object would appear if the detected object is the target object.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.869736842},{"pair":"US-2019235520-A1 & US-9707966-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696965462},{"pair":"US-2017174261-A1 & US-9290181-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696695562},{"pair":"US-2018300620-A1 & US-9862364-B2","patent_1":"US-2018300620-A1","title_1":"Foliage Detection Training Systems And Methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180300620A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example foliage detection training systems and methods are described. In one implementation, a method receives data associated with a plurality of vehicle-mounted sensors and defines multiple regions of interest (ROIs) based on the received data. The method applies a label to each ROI, where the label classifies a type of foliage associated with the ROI. A foliage detection training system trains a machine learning algorithm based on the ROIs and associated labels.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-04-12T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696602806},{"pair":"US-10528055-B2 & US-9707966-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":null,"abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696600389},{"pair":"US-9478137-B1 & US-10496091-B1","patent_1":"US-9478137-B1","title_1":"Detecting and communicating lane splitting maneuver ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9478137B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle system includes a lane detector programmed to output a boundary signal representing a location of a lane boundary relative to a host vehicle. A processing device is programmed to determine, from the boundary signal, whether the host vehicle is performing a lane splitting maneuver. If so, the processing device is programmed to transmit a lane splitting signal.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-06-17T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.869640278},{"pair":"US-2018033309-A1 & US-10059334-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-07-29T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696383776},{"pair":"US-2017261990-A1 & US-2018135972-A1","patent_1":"US-2017261990-A1","title_1":"Systems and methods for driving risk index estimation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170261990A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle implements driving risk estimation. The vehicle includes a processor and a program stored in memory. The vehicle calculates a first risk estimation based on first vehicle dynamics data, and second vehicle dynamics data and a second risk estimation received from a second proximate vehicle. The vehicle also, in response to the first risk estimation satisfying a risk threshold, determines a risk reduction action, and automatically instructs a vehicle control unit to implement the risk reduction action.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-03-10T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.869633156},{"pair":"US-9791864-B2 & US-2018135972-A1","patent_1":"US-9791864-B2","title_1":"Systems and methods for driving risk index estimation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US9791864B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle implements driving risk estimation. The vehicle includes a processor and a program stored in memory. The vehicle calculates a first risk estimation based on first vehicle dynamics data, and second vehicle dynamics data and a second risk estimation received from a second proximate vehicle. The vehicle also, in response to the first risk estimation satisfying a risk threshold, determines a risk reduction action, and automatically instructs a vehicle control unit to implement the risk reduction action.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-03-10T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.869633156},{"pair":"US-2018237012-A1 & US-2016209844-A1","patent_1":"US-2018237012-A1","title_1":"Autonomous vehicle towing ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20180237012A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A computer that includes a processor and memory that stores instructions executable by the processor, so that the computer is programmed to: instruct a host vehicle to follow a leader vehicle; monitor driving behavior of the leader vehicle; and instruct the host vehicle to cease following the leader vehicle based on an abnormal driving action of the leader vehicle.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-02-22T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8695725831},{"pair":"US-2019389456-A1 & US-2018143643-A1","patent_1":"US-2019389456-A1","title_1":"Transportation infrastructure communication and control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190389456A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"In a computer mounted to a stationary support structure a vehicle and an object proximate to the support structure can be detected from data from a sensor mounted to the support structure. A risk condition can be identified based on the detected vehicle and object.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-06-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8695304027},{"pair":"US-2016210382-A1 & US-2018135972-A1","patent_1":"US-2016210382-A1","title_1":"Autonomous driving refined in virtual environments ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20160210382A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computing device includes a processing circuit and a data storage medium. The computing device is programmed to receive a user input selecting at least one testing parameter associated with autonomously operating a virtual vehicle in a virtual environment, simulate the virtual environment incorporating the at least one testing parameter, virtually navigate the virtual vehicle through the virtual environment, collect virtual sensor data, and processing the collected virtual sensor data.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-01-21T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8695093597},{"pair":"US-2018081057-A1 & US-9290181-B1","patent_1":"US-2018081057-A1","title_1":"Metal bridge detection systems and methods ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US20180081057A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2016-09-20T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694917658},{"pair":"US-10410524-B2 & US-10059334-B1","patent_1":"US-10410524-B2","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10410524B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has traveled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-07-29T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694734207},{"pair":"US-2019225210-A1 & US-10146223-B1","patent_1":"US-2019225210-A1","title_1":"Inter-vehicle cooperation for vehicle self height estimation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190225210A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Method and apparatus are disclosed for inter-vehicle cooperation for vehicle self height estimation. An example vehicle includes an inter-vehicle communication module and a body control module. The body control module broadcasts a request for images via the inter-vehicle communication module. The body control module also performs semantic segmentation on the images, generates a composite image of the vehicle based on the segmented images, and generates a three dimensional representation of the vehicle based on the composite image. Using the three dimensional representation, the body control module determines a height of the vehicle, and based on the height, controls the vehicle to avoid obstacles.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-01-24T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694722724},{"pair":"US-2020064850-A1 & US-9575490-B2","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2018-08-22T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694671809},{"pair":"US-2018099606-A1 & US-9740202-B2","patent_1":"US-2018099606-A1","title_1":"Vehicle light diagnostic ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099606A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A first vehicle includes a light and a controller in communication with the light. The controller is programmed to detect a second vehicle positioned to sense the light, transmit a first message to the second vehicle requesting observation of the light, actuate the light to change state in response to a second message from the second vehicle, and receive a third message from the second vehicle specifying a state of the light.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-11T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694455561},{"pair":"US-10040390-B2 & US-9740202-B2","patent_1":"US-10040390-B2","title_1":"Vehicle light diagnostic ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10040390B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A first vehicle includes a light and a controller in communication with the light. The controller is programmed to detect a second vehicle positioned to sense the light, transmit a first message to the second vehicle requesting observation of the light, actuate the light to change state in response to a second message from the second vehicle, and receive a third message from the second vehicle specifying a state of the light.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-11T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694455561},{"pair":"US-10481609-B2 & US-9862364-B2","patent_1":"US-10481609-B2","title_1":"Parking-lot-navigation system and method ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10481609B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-12-09T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8694069581},{"pair":"US-9921581-B2 & US-10496091-B1","patent_1":"US-9921581-B2","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9921581B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693503124},{"pair":"US-2017192429-A1 & US-10496091-B1","patent_1":"US-2017192429-A1","title_1":"Autonomous vehicle emergency operating mode ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170192429A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle computing device has a data storage medium and a processing device programmed to execute instructions stored on the data storage medium. The instructions include detecting an emergency vehicle near an autonomous host vehicle, receiving operational data from nearby vehicles, and transmitting the operational data to the emergency vehicle. The operational data indicates whether one or more of the nearby vehicles is operating in an autonomous mode.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-01-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693503124},{"pair":"US-2019362168-A1 & US-10204278-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693475807},{"pair":"US-2018099663-A1 & US-9707966-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693408355},{"pair":"US-2019101933-A1 & US-2018135972-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693043874},{"pair":"US-2019026947-A1 & US-9682707-B1","patent_1":"US-2019026947-A1","title_1":"Vehicle backup safety mapping ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190026947A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Method and apparatus are disclosed for vehicle backup safety mapping. An example vehicle includes a display, a rear-view camera, and a processor. The processor generates a three-dimensional model of space behind the vehicle based on images from the rear-view camera The processor also generates an overlay based on the three-dimensional model. The overlay includes representation of objects not in the field of view of the rear-view camera. Additionally, the processor displays, on the display, the images from the rear-view camera and the overlay.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-07-21T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.869283019},{"pair":"US-2020066155-A1 & US-2018143643-A1","patent_1":"US-2020066155-A1","title_1":"Parking management systems and methods ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200066155A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-08-22T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8692820775},{"pair":"US-2018164830-A1 & US-9862364-B2","patent_1":"US-2018164830-A1","title_1":"Parking-lot-navigation system and method ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180164830A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-12-09T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8692652031},{"pair":"US-2019066510-A1 & US-2018135972-A1","patent_1":"US-2019066510-A1","title_1":"Vehicular image projection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190066510A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computer is programmed to determine a target area to project, along a planned travel path of a vehicle, a symbol based on detecting a target object. The computer is further programmed to actuate a light source to project the symbol moving within the target area.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-08-22T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8692379518},{"pair":"US-9970615-B1 & US-10496091-B1","patent_1":"US-9970615-B1","title_1":"Light-based vehicle-device communications ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9970615B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system for light-based vehicle-device communication includes a computer programmed to generate a first light pattern based on a received identifier, actuate a vehicle light according to the first light pattern, and then identify, from received image data, a second light pattern emitted from outside of the vehicle. The system may further include a mobile computing device programmed to generate the second light pattern based on a received vehicle identifier, and actuate a mobile device light according to the second light pattern. The mobile computing device may be programmed to identify, from received image data, the first light pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-05-23T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8692286482},{"pair":"US-2017247040-A1 & US-2016370801-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8691662137},{"pair":"US-10345822-B1 & US-9381917-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9381917-B1","title_2":"Predictive reasoning for controlling speed of a vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9381917B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for predictive reasoning for controlling speed of a vehicle are described. A computing device may be configured to identify a first and second vehicle travelling ahead of an autonomous vehicle and in a same lane as the autonomous vehicle. The computing device may also be configured to determine a first buffer distance behind the first vehicle at which the autonomous vehicle will substantially reach a speed of the first vehicle and a second buffer distance behind the second vehicle at which the first vehicle will substantially reach a speed of the second vehicle. The computing device may further be configured to determine a distance at which to adjust a speed of the autonomous vehicle based on the first and second buffer distances and the speed of the autonomous vehicle, and then provide instructions to adjust the speed of the autonomous vehicle based on the distance.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-05-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8691620554},{"pair":"US-2020026279-A1 & US-2018143643-A1","patent_1":"US-2020026279-A1","title_1":"Smart neighborhood routing for autonomous vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200026279A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8691561427},{"pair":"US-2020065978-A1 & US-2018135972-A1","patent_1":"US-2020065978-A1","title_1":"Foreground detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200065978A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-08-24T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8691404081},{"pair":"US-2018059679-A1 & US-2017098129-A1","patent_1":"US-2018059679-A1","title_1":"Depth map estimation with stereo images ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180059679A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. While operating in either mode, an array of sensors can be used to pilot the vehicle including stereo cameras and 3D sensors. Stereo camera and 3D sensors can also be employed to assist occupants while piloting vehicles. Deep convolutional neural networks can be employed to determine estimated depth maps from stereo images of scenes in real time for vehicles in autonomous and occupant piloted modes.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-09-01T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8691367217},{"pair":"US-2017174261-A1 & US-9646497-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690996241},{"pair":"US-2017248952-A1 & US-2016370801-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690925319},{"pair":"US-2017174261-A1 & US-2018135972-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690881293},{"pair":"US-10408937-B2 & US-9862364-B2","patent_1":"US-10408937-B2","title_1":"Metal bridge detection systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10408937B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example metal bridge detection systems and methods are described. In one implementation, a method receives LIDAR data from a LIDAR system mounted to a vehicle and receives camera data from a camera system mounted to the vehicle. The method analyzes the received LIDAR data and the camera data to identify a metal bridge proximate the vehicle. If a metal bridge is identified, the method adjusts vehicle operations to improve vehicle control as it drives across the metal bridge.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-09-20T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690813057},{"pair":"US-2020055515-A1 & US-2016187887-A1","patent_1":"US-2020055515-A1","title_1":"Vehicle path planning ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20200055515A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-08-17T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690759744},{"pair":"US-2019377339-A1 & US-9862364-B2","patent_1":"US-2019377339-A1","title_1":"Driver assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190377339A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A computing system can determine a probability of precipitation based on Bayesian inference conditioned on probabilities associated with vehicle wiper status, vehicle jerk, vehicle sway, and vehicle lateral offset. The computing system can disable a vehicle lane assist system based on the probability of precipitation and operate a vehicle with the disabled vehicle lane assist system.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-06-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.869072061},{"pair":"US-2017174261-A1 & US-2016187887-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690402181},{"pair":"US-2018120857-A1 & US-10156851-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690372641},{"pair":"US-2018319402-A1 & US-10496091-B1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-05-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690213268},{"pair":"US-2020064850-A1 & US-2018102001-A1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2018-08-22T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8689732406},{"pair":"US-2017248952-A1 & US-2016155452-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016155452-A1","title_2":"Method for Siren Detection Based on Audio Samples ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160155452A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The present disclosure provides methods and apparatuses that enable an apparatus to identify sounds from short samples of audio. The apparatus may capture an audio sample and create several audio signals of different lengths, each containing audio from the captured audio sample. The apparatus my process the several audio signals in an attempt to identify features of the audio signal that indicate an identification of the captured sound. Because shorter audio samples can be analyzed more quickly, the system may first process the shortest audio samples in order to quickly identify features of the audio signal. Because longer audio samples contain more information, the system may be able to more accurately identify features in the audio signal in longer audio samples. However, analyzing longer audio signals takes more buffered audio than identifying features in shorter signals. Therefore, the present system attempts to identify features in the shortest audio signals first.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8689563828},{"pair":"US-2019161063-A1 & US-9740202-B2","patent_1":"US-2019161063-A1","title_1":"Automotive control ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161063A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"A system includes a switch biased to a neutral position, a camera, and a computer communicatively coupled to the switch and the camera. The computer is programmed to activate a vehicle brake upon receiving data from the switch that the switch is in the neutral position and to activate the vehicle brake upon determining that an operator of the switch is in an inattentive state based on data received from the camera.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-11-29T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8689166454},{"pair":"US-2019026947-A1 & US-2018152628-A1","patent_1":"US-2019026947-A1","title_1":"Vehicle backup safety mapping ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190026947A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Method and apparatus are disclosed for vehicle backup safety mapping. An example vehicle includes a display, a rear-view camera, and a processor. The processor generates a three-dimensional model of space behind the vehicle based on images from the rear-view camera The processor also generates an overlay based on the three-dimensional model. The overlay includes representation of objects not in the field of view of the rear-view camera. Additionally, the processor displays, on the display, the images from the rear-view camera and the overlay.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-07-21T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868908139},{"pair":"US-2019039616-A1 & US-2018135972-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-09T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8689068811},{"pair":"US-2016210775-A1 & US-10198643-B1","patent_1":"US-2016210775-A1","title_1":"Virtual sensor testbed ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US20160210775A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"A computing device comprising a processing circuit and a data storage medium. The computing device is programmed to receive virtual sensor data that represents data collected by a virtual sensor associated with autonomously operating a virtual vehicle in a virtual environment and process the virtual sensor data to identify a limitation of a real-world sensor.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2015-01-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8688890817},{"pair":"US-2017139420-A1 & US-2018152628-A1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2014-07-16T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.86887673},{"pair":"US-10082796-B2 & US-9766626-B1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-10-27T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868857933},{"pair":"US-2018120858-A1 & US-9766626-B1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-10-27T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868857933},{"pair":"US-9612596-B2 & US-10580291-B1","patent_1":"US-9612596-B2","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-10580291-B1","title_2":"Vehicle location assistance using audible signals ","link_1":"https:\/\/patents.google.com\/patent\/US9612596B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10580291B1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the present disclosure relate to using audible cues to guide a passenger to a vehicle having an autonomous driving mode. For instance, one or more processors of the vehicle may receive, from a server computing device, instructions to pick up the passenger at a pickup location. The one or more processors may maneuver the vehicle towards the pickup location in the autonomous driving mode. The one or more processors may receive a signal indicating that the passenger requests assistance locating the vehicle. The one or more processors may use the signal to generate the audible cues. The audible cues may be played by the one or more processors through a speaker of the vehicle in order to guide the passenger towards the vehicle.","priority_1":"2015-05-05T00:00:00","priority_2":"2017-09-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8688525502},{"pair":"US-9989963-B2 & US-9690296-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8688397533},{"pair":"US-2019377343-A1 & US-10146223-B1","patent_1":"US-2019377343-A1","title_1":"Picking up and dropping off passengers at an airport using an autonomous vehicle ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190377343A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A controller of an autonomous vehicle receives a travel itinerary of a passenger and an airport map. The controller then uses the airport map to arrive at a terminal corresponding to the passenger's travel itinerary. Upon arrival at the terminal the controller communicates with parked vehicles (V2V) or infrastructure to identify an unoccupied parking spot and then autonomously parks. When picking up a passenger, the controller determines whether the passenger has checked luggage and adjusts and arrival time accordingly and may account for the storage volume of the luggage. The controller may also loop a circuit at the airport where a wait time has been exceeded. In some embodiments, augmented reality may be used to help the passenger identify the vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-01-10T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8688332776},{"pair":"US-10289113-B2 & US-10192442-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8688151715},{"pair":"US-2017139420-A1 & US-9811091-B2","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9811091-B2","title_2":"Modifying behavior of autonomous vehicles based on sensor blind spots and limitations ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9811091B2\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"Models can be generated of a vehicle's view of its environment and used to maneuver the vehicle. This view need not include what objects or features the vehicle is actually seeing, but rather those areas that the vehicle is able to observe using its sensors if the sensors were completely un-occluded. For example, for each of a plurality of sensors of the object detection component, a computer may generate an individual 3D model of that sensor's field of view. Weather information is received and used to adjust one or more of the models. After this adjusting, the models may be aggregated into a comprehensive 3D model. The comprehensive model may be combined with detailed map information indicating the probability of detecting objects at different locations. The model of the vehicle's environment may be computed based on the combined comprehensive 3D model and detailed map information.","priority_1":"2014-07-16T00:00:00","priority_2":"2013-01-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8688090086},{"pair":"US-2019161063-A1 & US-9551992-B1","patent_1":"US-2019161063-A1","title_1":"Automotive control ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161063A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a switch biased to a neutral position, a camera, and a computer communicatively coupled to the switch and the camera. The computer is programmed to activate a vehicle brake upon receiving data from the switch that the switch is in the neutral position and to activate the vehicle brake upon determining that an operator of the switch is in an inattentive state based on data received from the camera.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-11-29T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687672276},{"pair":"US-2017247040-A1 & US-2016155452-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2016155452-A1","title_2":"Method for Siren Detection Based on Audio Samples ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160155452A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"The present disclosure provides methods and apparatuses that enable an apparatus to identify sounds from short samples of audio. The apparatus may capture an audio sample and create several audio signals of different lengths, each containing audio from the captured audio sample. The apparatus my process the several audio signals in an attempt to identify features of the audio signal that indicate an identification of the captured sound. Because shorter audio samples can be analyzed more quickly, the system may first process the shortest audio samples in order to quickly identify features of the audio signal. Because longer audio samples contain more information, the system may be able to more accurately identify features in the audio signal in longer audio samples. However, analyzing longer audio signals takes more buffered audio than identifying features in shorter signals. Therefore, the present system attempts to identify features in the shortest audio signals first.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687501066},{"pair":"US-2019061527-A1 & US-2017341643-A1","patent_1":"US-2019061527-A1","title_1":"Systems and methods for vehicle cruise control smoothness adaptation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190061527A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Methods and systems are disclosed for vehicle cruise control smoothness adaptation. An example vehicle includes a GPS receiver for receiving expected road incline data, a camera for determining a half lane width position, and a radar for determining two respective leading vehicle angles of arrival. The vehicle also includes a processor for determining an actual road incline by filtering the expected road incline, half lane width position, and leading vehicle angles of arrival. And the processor is further for modifying a cruise control system based on the actual road incline.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-08-28T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687352992},{"pair":"US-2017248952-A1 & US-9684836-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687331552},{"pair":"US-10423847-B2 & US-9290181-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687188594},{"pair":"US-9983591-B2 & US-9779621-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687146316},{"pair":"US-10160459-B2 & US-9682707-B1","patent_1":"US-10160459-B2","title_1":"Vehicle lane direction detection ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10160459B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A roadway lane direction is identified based on vehicle sensor data of a traffic sign, a direction of a parked vehicle, and a marking on a surface of the roadway lane. A trajectory of a vehicle is determined to differ from the roadway lane direction, and a vehicle component is then actuated.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-03-22T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687070296},{"pair":"US-10328973-B2 & US-2018135972-A1","patent_1":"US-10328973-B2","title_1":"Assisting drivers with roadway lane changes ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10328973B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for assisting drivers with roadway lane changes. In general, aspects of the invention are used in motorized vehicles to guide a driver to a more efficiently operating lane of a multi-lane roadway. A lane recommendation can be based on sensed and\/or communicated aspects of surrounding vehicles (e.g., speed, acceleration, etc.). Lane recommendations can be communicated to a driver with audio and\/or visual cues. In one aspect, images of surrounding roadway are augmented with additional data to highlight lanes, lane change locations, other vehicles, etc. Lane recommendations can be revised in (essentially) real-time in response to changing conditions in a roadway environment (e.g., a vehicle in a neighboring lane has changed speed).","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-03-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687066716},{"pair":"US-2017327037-A1 & US-9740202-B2","patent_1":"US-2017327037-A1","title_1":"Adaptive rear view display ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170327037A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"System and methods to provide an adaptive rear view display are disclosed. An example disclosed first vehicle includes a rear view camera and an adaptive display controller. The example adaptive display controller is to determine, with range detection sensors, a following-time of a second vehicle behind the first vehicle. The example adaptive display controller is also to determine a workload estimate associated with the first vehicle. Additionally, when the first vehicle is moving forward, the adaptive display controller is to selectively display video from the rear view camera based on the following-time, the workload estimate, and a user request.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-05-10T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687053446},{"pair":"US-2019066509-A1 & US-2018135972-A1","patent_1":"US-2019066509-A1","title_1":"Vehicular image projection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190066509A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computer programmed to actuate a light source to project a symbol outwardly from a vehicle. The computer is further programmed to actuate the light source to modify the projection based on a determination that a trajectory of the vehicle is changing.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-08-22T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686908058},{"pair":"US-2018251155-A1 & US-2018135972-A1","patent_1":"US-2018251155-A1","title_1":"Assisting Drivers With Roadway Lane Changes ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180251155A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for assisting drivers with roadway lane changes. In general, aspects of the invention are used in motorized vehicles to guide a driver to a more efficiently operating lane of a multi-lane roadway. A lane recommendation can be based on sensed and\/or communicated aspects of surrounding vehicles (e.g., speed, acceleration, etc.). Lane recommendations can be communicated to a driver with audio and\/or visual cues. In one aspect, images of surrounding roadway are augmented with additional data to highlight lanes, lane change locations, other vehicles, etc. Lane recommendations can be revised in (essentially) real-time in response to changing conditions in a roadway environment (e.g., a vehicle in a neighboring lane has changed speed).","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-03-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686895928},{"pair":"US-2019101933-A1 & US-2016187887-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686890301},{"pair":"US-2019161085-A1 & US-9796386-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9796386-B2","title_2":"Robust method for detecting traffic signals and their associated states ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9796386B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and devices for detecting traffic signals and their associated states are disclosed. In one embodiment, an example method includes a scanning a target area using one or more sensors of a vehicle to obtain target area information. The vehicle may be configured to operate in an autonomous mode, and the target area may be a type of area where traffic signals are typically located. The method may also include detecting a traffic signal in the target area information, determining a location of the traffic signal, and determining a state of the traffic signal. Also, a confidence in the traffic signal may be determined. For example, the location of the traffic signal may be compared to known locations of traffic signals. Based on the state of the traffic signal and the confidence in the traffic signal, the vehicle may be controlled in the autonomous mode.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-03-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686707428},{"pair":"US-2019111922-A1 & US-9682707-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686680791},{"pair":"US-2020073405-A1 & US-2017098129-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686505199},{"pair":"US-2019235520-A1 & US-9734417-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9734417-B2","title_2":"Use of relationship between activities of different traffic signals in a network to improve traffic signal state estimation ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734417B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and devices for using a relationship between activities of different traffic signals in a network to improve traffic signal state estimation are disclosed. An example method includes determining that a vehicle is approaching an upcoming traffic signal. The method may further include determining a state of one or more traffic signals other than the upcoming traffic signal. Additionally, the method may also include determining an estimate of a state of the upcoming traffic signal based on a relationship between the state of the one or more traffic signals other than the upcoming traffic signal and the state of the upcoming traffic signal.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-09-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686328524},{"pair":"US-2018370532-A1 & US-2017341643-A1","patent_1":"US-2018370532-A1","title_1":"Assessing u-turn feasibility ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180370532A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Methods, devices and apparatuses pertaining to U-turn assistance. The method may include detecting an intention of an operator of a vehicle of rendering a U-turn at a location. A computing device may obtain geographic information associated with the U-turn, and assess feasibility of the U-turn at the location based on the geographic information. Further, the computing device may provide a notification to the operator based on the feasibility of the U-turn to assist the operator to operate the U-turn of the vehicle at the location.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-01-14T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868614126},{"pair":"US-10394237-B2 & US-10146223-B1","patent_1":"US-10394237-B2","title_1":"Perceiving roadway conditions from fused sensor data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10394237B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for perceiving roadway conditions from fused sensor data. Aspects of the invention use a combination of different types of cameras mounted to a vehicle to achieve visual perception for autonomous driving of the vehicle. Each camera in the combination of cameras generates sensor data by sensing at least part of the environment around the vehicle. The sensor data form each camera is fused together into a view of the environment around the vehicle. Sensor data from each camera (and, when appropriate, each other type of sensor) is fed into a central sensor perception chip. The central sensor perception chip uses a sensor fusion algorithm to fuse the sensor data into a view of the environment around the vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-09-08T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8685964907},{"pair":"US-2017217434-A1 & US-2018135972-A1","patent_1":"US-2017217434-A1","title_1":"Tracking Objects Within A Dynamic Environment For Improved Localization ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170217434A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for tracking objects within a dynamic environment for improved localization. Sensing devices are utilized to gather data about a vehicle's environment. In cases where the sensor data has become degraded, such as data indicating that lane lines have become degraded, obscured, or nonexistent, the vehicle computer system uses previously detected sensor data to estimate the speed and direction of travel of moving objects. The computer system then estimates the location of the moving objects after a specified period of time based on the estimated speed and direction of the moving object. The computer system utilizes this information to localize the vehicle within the dynamic environment and to control the configuration of the vehicle.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-29T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8685600206},{"pair":"US-10077054-B2 & US-2018135972-A1","patent_1":"US-10077054-B2","title_1":"Tracking objects within a dynamic environment for improved localization ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10077054B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for tracking objects within a dynamic environment for improved localization. Sensing devices are utilized to gather data about a vehicle's environment. In cases where the sensor data has become degraded, such as data indicating that lane lines have become degraded, obscured, or nonexistent, the vehicle computer system uses previously detected sensor data to estimate the speed and direction of travel of moving objects. The computer system then estimates the location of the moving objects after a specified period of time based on the estimated speed and direction of the moving object. The computer system utilizes this information to localize the vehicle within the dynamic environment and to control the configuration of the vehicle.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-29T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8685600206},{"pair":"US-2019043278-A1 & US-9836895-B1","patent_1":"US-2019043278-A1","title_1":"Test drive scenario system for virtual test drive scenarios ","patent_2":"US-9836895-B1","title_2":"Simulating virtual objects ","link_1":"https:\/\/patents.google.com\/patent\/US20190043278A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836895B1\/en","abstract_1":"A test drive scenario database system for highly realistic, virtual test drive scenarios comprises at least one device that generates a virtual scene, a database memory and a control device. The control device has at least one data receiving unit with one or more data receiving interfaces, a configuration unit with at least one user interface and a data output unit with at least one data output interface. The device that generates a virtual scene is configured to display real, test drive scenario data in a virtual scenario, in which one or more parameters of the output test drive scenario data can be changed.","abstract_2":"An autonomous vehicle is tested using virtual objects. The autonomous vehicle is maneuvered, by one or more computing devices, the autonomous vehicle in an autonomous driving mode. Sensor data is received corresponding to objects in the autonomous vehicle's environment, and virtual object data is received corresponding to a virtual object in the autonomous vehicle's environment. The virtual object represents a real object that is not in the vehicle's environment. The autonomous vehicle is maneuvered based on both the sensor data and the virtual object data. Information about the maneuvering of the vehicle based on both the sensor data and the virtual object data may be logged and analyzed.","priority_1":"2017-08-01T00:00:00","priority_2":"2015-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8685490044},{"pair":"US-2017247040-A1 & US-9684836-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8685219093},{"pair":"US-2019111922-A1 & US-10156851-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684796536},{"pair":"US-10259457-B2 & US-9368026-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9368026-B1","title_2":"Fallback requests for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9368026B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to a system having a memory, a plurality of self-driving systems for controlling a vehicle, and one or more processors. The processors are configured to receive at least one fallback task in association with a request for a primary task and at least one trigger of each fallback task. Each trigger is a set of conditions that, when satisfied, indicate when a vehicle requires attention for proper operation. The processors are also configured to send instructions to the self-driving systems to execute the primary task and receive status updates from the self-driving systems. The processors are configured to determine that a set of conditions of a trigger is satisfied based on the status updates and send further instructions based on the associated fallback task to the self-driving systems.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684705942},{"pair":"US-2019219697-A1 & US-2016187887-A1","patent_1":"US-2019219697-A1","title_1":"Lidar localization ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190219697A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system including a processor and a memory, the memory including instructions to be executed by the processor to determine map data, determine uncalibrated LIDAR data, determine a location of a vehicle in the map data by combining the map data with the uncalibrated LIDAR data, and operate the vehicle based on the location of the vehicle in the map data.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-01-12T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684669275},{"pair":"US-10037033-B2 & US-9599477-B1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9599477-B1","title_2":"Specifying unavailable locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9599477B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering a passenger to a destination autonomously. The vehicle includes one or more computing devices that receive a request for a vehicle from a client computing device. The request identifies a first location. The one or more computing devices also determine whether the first location is within a threshold outside of a service area of the vehicle. When the location is within the threshold distance outside of the service area of the vehicle, the one or more computing devices identify a second location within the service area of the vehicle where the vehicle is able to stop for a passenger and based on the first location. The one or more computing devices then provide a map and a marker identifying the position of the second location on the map for display on the client computing device.","priority_1":"2016-06-15T00:00:00","priority_2":"2014-05-23T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684636319},{"pair":"US-2017364072-A1 & US-9599477-B1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-9599477-B1","title_2":"Specifying unavailable locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9599477B1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering a passenger to a destination autonomously. The vehicle includes one or more computing devices that receive a request for a vehicle from a client computing device. The request identifies a first location. The one or more computing devices also determine whether the first location is within a threshold outside of a service area of the vehicle. When the location is within the threshold distance outside of the service area of the vehicle, the one or more computing devices identify a second location within the service area of the vehicle where the vehicle is able to stop for a passenger and based on the first location. The one or more computing devices then provide a map and a marker identifying the position of the second location on the map for display on the client computing device.","priority_1":"2016-06-15T00:00:00","priority_2":"2014-05-23T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684636319},{"pair":"US-2018251155-A1 & US-2018011496-A1","patent_1":"US-2018251155-A1","title_1":"Assisting Drivers With Roadway Lane Changes ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180251155A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for assisting drivers with roadway lane changes. In general, aspects of the invention are used in motorized vehicles to guide a driver to a more efficiently operating lane of a multi-lane roadway. A lane recommendation can be based on sensed and\/or communicated aspects of surrounding vehicles (e.g., speed, acceleration, etc.). Lane recommendations can be communicated to a driver with audio and\/or visual cues. In one aspect, images of surrounding roadway are augmented with additional data to highlight lanes, lane change locations, other vehicles, etc. Lane recommendations can be revised in (essentially) real-time in response to changing conditions in a roadway environment (e.g., a vehicle in a neighboring lane has changed speed).","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-03-06T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684570902},{"pair":"US-10289113-B2 & US-9690296-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684480099},{"pair":"US-2019012913-A1 & US-2016209844-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684453486},{"pair":"US-2017072962-A1 & US-9368026-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9368026-B1","title_2":"Fallback requests for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9368026B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to a system having a memory, a plurality of self-driving systems for controlling a vehicle, and one or more processors. The processors are configured to receive at least one fallback task in association with a request for a primary task and at least one trigger of each fallback task. Each trigger is a set of conditions that, when satisfied, indicate when a vehicle requires attention for proper operation. The processors are also configured to send instructions to the self-driving systems to execute the primary task and receive status updates from the self-driving systems. The processors are configured to determine that a set of conditions of a trigger is satisfied based on the status updates and send further instructions based on the associated fallback task to the self-driving systems.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684413088},{"pair":"US-2017174261-A1 & US-9767370-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9767370-B1","title_2":"Construction object detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9767370B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to identifying construction objects. As an example, an image captured by a camera associated with a vehicle as the vehicle is driven along a roadway may be received. This image may be converted into a first channel corresponding to an average brightness contribution from red, blue and green channels of the image. The image may also be converted into a second channel corresponding to a contribution of a color from the red and the green channels of the image. A template may then be used to identify a region of the image corresponding to a potential construction object from the first channel and the second channel.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-09-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684170354},{"pair":"US-10528055-B2 & US-9804597-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9804597-B1","title_2":"Use of detected objects for image processing ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9804597B1\/en","abstract_1":null,"abstract_2":"Methods and systems for the use of detected objects for image processing are described. A computing device autonomously controlling a vehicle may receive images of the environment surrounding the vehicle from an image-capture device coupled to the vehicle. In order to process the images, the computing device may receive information indicating characteristics of objects in the images from one or more sources coupled to the vehicle. Examples of sources may include RADAR, LIDAR, a map, sensors, a global positioning system (GPS), or other cameras. The computing device may use the information indicating characteristics of the objects to process received images, including determining the approximate locations of objects within the images. Further, while processing the image, the computing device may use information from sources to determine portions of the image to focus upon that may allow the computing device to determine a control strategy based on portions of the image.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8683949834},{"pair":"US-2018239361-A1 & US-9779621-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8683863836},{"pair":"US-2019374151-A1 & US-2018135972-A1","patent_1":"US-2019374151-A1","title_1":"Focus-Based Tagging Of Sensor Data ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190374151A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Data from sensors of a vehicle is captured along with data tracking a driver's gaze. The route traveled by the vehicle may also be captured. The driver's gaze is evaluated with respect to the sensor data to determine a feature the driver was focused on. A focus record is created for the feature. Focus records for many drivers may be aggregated to determine a frequency of observation of the feature. A machine learning model may be trained using the focus records to identify a region of interest for a given scenario in order to more quickly identify relevant hazards.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-06-08T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8683464509},{"pair":"US-10207560-B2 & US-2017341643-A1","patent_1":"US-10207560-B2","title_1":"Roadway-crossing-anomaly detection system and method ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10207560B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868336373},{"pair":"US-2018105009-A1 & US-2017341643-A1","patent_1":"US-2018105009-A1","title_1":"Roadway-Crossing-Anomaly Detection System and Method ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180105009A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868336373},{"pair":"US-2017197615-A1 & US-9387854-B1","patent_1":"US-2017197615-A1","title_1":"System and method for reverse perpendicular parking a vehicle ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170197615A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":"A method for parking a vehicle in a parking lot includes generating steering commands for the vehicle while in the lot based on an occupancy grid and plenoptic camera data. The occupancy grid indicates occupied areas and unoccupied areas around the vehicle and is derived from map data defining parking spots relative to a topological feature contained within the lot. The plenoptic camera data defines a plurality of depth maps and corresponding images that include the topological feature captured during movement of the vehicle. The steering command is generated such that the vehicle follows a reverse perpendicular path into one of the spots without entering an occupied area.","abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2016-01-11T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8683301858},{"pair":"US-2019362168-A1 & US-9290181-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868308872},{"pair":"US-2019012913-A1 & US-2016187887-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868302755},{"pair":"US-10366541-B2 & US-2018152628-A1","patent_1":"US-10366541-B2","title_1":"Vehicle backup safety mapping ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10366541B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Method and apparatus are disclosed for vehicle backup safety mapping. An example vehicle includes a display, a rear-view camera, and a processor. The processor generates a three-dimensional model of space behind the vehicle based on images from the rear-view camera The processor also generates an overlay based on the three-dimensional model. The overlay includes representation of objects not in the field of view of the rear-view camera. Additionally, the processor displays, on the display, the images from the rear-view camera and the overlay.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-07-21T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8682741254},{"pair":"US-2018025640-A1 & US-10318827-B2","patent_1":"US-2018025640-A1","title_1":"Using Virtual Data To Test And Train Parking Space Detection Systems ","patent_2":"US-10318827-B2","title_2":"Object detection neural networks ","link_1":"https:\/\/patents.google.com\/patent\/US20180025640A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10318827B2\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for using virtual data to test and train parking space detection systems. Aspects of the invention integrate a virtual driving environment with sensor models (e.g., of a radar system) to provide virtual radar data in relatively large quantities in a relatively short amount of time. The sensor models perceive values for relevant parameters of a training data set. Relevant parameters can be randomized in the recorded data to ensure a diverse training data set with minimal bias. Since the driving environment is virtualized, the training data set can be generated alongside ground truth data. The ground truth data is used to annotate true locations, which are used to train a parking space classification algorithms to detect the free space boundaries.","abstract_2":"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating object detection predictions from a neural network. In some implementations, an input characterizing a first region of an environment is obtained. The input includes a projected laser image generated from a three-dimensional laser sensor reading of the first region, a camera image patch generated from a camera image of the first region, and a feature vector of features characterizing the first region. The input is processed using a high precision object detection neural network to generate a respective object score for each object category in a first set of one or more object categories. Each object score represents a respective likelihood that an object belonging to the object category is located in the first region of the environment.","priority_1":"2016-07-19T00:00:00","priority_2":"2016-12-19T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8682496694},{"pair":"US-10160459-B2 & US-9669827-B1","patent_1":"US-10160459-B2","title_1":"Vehicle lane direction detection ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10160459B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A roadway lane direction is identified based on vehicle sensor data of a traffic sign, a direction of a parked vehicle, and a marking on a surface of the roadway lane. A trajectory of a vehicle is determined to differ from the roadway lane direction, and a vehicle component is then actuated.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-03-22T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8682377099},{"pair":"US-10589742-B2 & US-9783172-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9783172-B2","title_2":"Methods and systems for steering-based oscillatory vehicle braking ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9783172B2\/en","abstract_1":null,"abstract_2":"Methods and systems for steering-based oscillatory braking are described herein. A method may involve making a determination, by a computing device, to reduce a speed of a vehicle. The vehicle may include a pair of wheels. The method may further involve providing instructions to turn the pair of wheels of the vehicle in an oscillatory manner, such that each wheel of the pair of wheels is turned in substantially the same direction and turning of the pair of wheels oscillates each wheel of the pair of wheels between given directions about a direction of travel of the vehicle so as to reduce the speed of the vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8682083842},{"pair":"US-2018105009-A1 & US-9862364-B2","patent_1":"US-2018105009-A1","title_1":"Roadway-Crossing-Anomaly Detection System and Method ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180105009A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8682063512},{"pair":"US-10207560-B2 & US-9862364-B2","patent_1":"US-10207560-B2","title_1":"Roadway-crossing-anomaly detection system and method ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10207560B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8682063512},{"pair":"US-10259457-B2 & US-9767370-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9767370-B1","title_2":"Construction object detection ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9767370B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to identifying construction objects. As an example, an image captured by a camera associated with a vehicle as the vehicle is driven along a roadway may be received. This image may be converted into a first channel corresponding to an average brightness contribution from red, blue and green channels of the image. The image may also be converted into a second channel corresponding to a contribution of a color from the red and the green channels of the image. A template may then be used to identify a region of the image corresponding to a potential construction object from the first channel and the second channel.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-09-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.868203087},{"pair":"US-2020073405-A1 & US-9811091-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9811091-B2","title_2":"Modifying behavior of autonomous vehicles based on sensor blind spots and limitations ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9811091B2\/en","abstract_1":null,"abstract_2":"Models can be generated of a vehicle's view of its environment and used to maneuver the vehicle. This view need not include what objects or features the vehicle is actually seeing, but rather those areas that the vehicle is able to observe using its sensors if the sensors were completely un-occluded. For example, for each of a plurality of sensors of the object detection component, a computer may generate an individual 3D model of that sensor's field of view. Weather information is received and used to adjust one or more of the models. After this adjusting, the models may be aggregated into a comprehensive 3D model. The comprehensive model may be combined with detailed map information indicating the probability of detecting objects at different locations. The model of the vehicle's environment may be computed based on the combined comprehensive 3D model and detailed map information.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-01-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8681840675},{"pair":"US-9796388-B2 & US-9528850-B1","patent_1":"US-9796388-B2","title_1":"Vehicle mode determination ","patent_2":"US-9528850-B1","title_2":"Suggesting a route based on desired amount of driver interaction ","link_1":"https:\/\/patents.google.com\/patent\/US9796388B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9528850B1\/en","abstract_1":"An operating mode is determined for a vehicle according to respective control states of each of a plurality of vehicle subsystems that include braking, steering, and propulsion. The operating mode is one of manual control, partial manual control, and no manual control. A route for the vehicle is determined based in part on the operating mode.","abstract_2":"Aspects of the disclosure relate generally to generating and providing route options for an autonomous vehicle. For example, a user may identify a destination, and in response the vehicle's computer may provide routing options to the user. The routing options may be based on typical navigating considerations such as the total travel time, travel distance, fuel economy, etc. Each routing option may include not only an estimated total time, but also information regarding whether and which portions of the route may be maneuvered under the control of the vehicle alone (fully autonomous), a combination of the vehicle and the driver (semiautonomous), or the driver alone. The time of the longest stretch of driving associated with the autonomous mode as well as map information indicating portions of the routes associated with the type of maneuvering control may also be provided.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8681616393},{"pair":"US-2017174215-A1 & US-9528850-B1","patent_1":"US-2017174215-A1","title_1":"Vehicle mode determination ","patent_2":"US-9528850-B1","title_2":"Suggesting a route based on desired amount of driver interaction ","link_1":"https:\/\/patents.google.com\/patent\/US20170174215A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9528850B1\/en","abstract_1":"An operating mode is determined for a vehicle according to respective control states of each of a plurality of vehicle subsystems that include braking, steering, and propulsion. The operating mode is one of manual control, partial manual control, and no manual control. A route for the vehicle is determined based in part on the operating mode.","abstract_2":"Aspects of the disclosure relate generally to generating and providing route options for an autonomous vehicle. For example, a user may identify a destination, and in response the vehicle's computer may provide routing options to the user. The routing options may be based on typical navigating considerations such as the total travel time, travel distance, fuel economy, etc. Each routing option may include not only an estimated total time, but also information regarding whether and which portions of the route may be maneuvered under the control of the vehicle alone (fully autonomous), a combination of the vehicle and the driver (semiautonomous), or the driver alone. The time of the longest stretch of driving associated with the autonomous mode as well as map information indicating portions of the routes associated with the type of maneuvering control may also be provided.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8681616393},{"pair":"US-2019362168-A1 & US-2018105174-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018105174-A1","title_2":"Planning stopping locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180105174A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to generating a speed plan for an autonomous vehicle. As an example, the vehicle is maneuvered in an autonomous driving mode along a route using pre-stored map information. This information identifies a plurality of keep clear regions where the vehicle should not stop but can drive through in the autonomous driving mode. Each keep clear region of the plurality of keep clear regions is associated with a priority value. A subset of the plurality of keep clear regions is identified based on the route. A speed plan for stopping the vehicle is generated based on the priority values associated with the keep clear regions of the subset. The speed plan identifies a location for stopping the vehicle. The speed plan is used to stop the vehicle in the location.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8681306454},{"pair":"US-2018120858-A1 & US-2018143643-A1","patent_1":"US-2018120858-A1","title_1":"Pedestrian face detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120858A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8681162838},{"pair":"US-10082796-B2 & US-2018143643-A1","patent_1":"US-10082796-B2","title_1":"Pedestrian face detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10082796B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A controller for a vehicle is programmed to detect a pedestrian in an image received from a camera, determine whether a face of the pedestrian is present in the image, and cause the vehicle to change lanes based on the absence of the face.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8681162838},{"pair":"US-2019294164-A1 & US-2018143643-A1","patent_1":"US-2019294164-A1","title_1":"Action-conditioned vehicle control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190294164A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A high-level vehicle command is determined based on a location of the vehicle with respect to a route including a start location and a finish location. An image is acquired of the vehicle external environment. Steering, braking, and powertrain commands are determined based on inputting the high-level command and the image into a Deep Neural Network. The vehicle is operated by actuating vehicle components based on the steering, braking and powertrain commands.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-03-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868081759},{"pair":"US-10037033-B2 & US-2018143643-A1","patent_1":"US-10037033-B2","title_1":"Vehicle exterior surface object detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10037033B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680631429},{"pair":"US-2017364072-A1 & US-2018143643-A1","patent_1":"US-2017364072-A1","title_1":"Vehicle exterior surface object detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170364072A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle system includes at least one autonomous driving sensor programmed to output environment signals representing an environment around an autonomous vehicle and object detection signals representing an object or person on an exterior surface of the autonomous vehicle. The vehicle system further includes an autonomous mode controller programmed to autonomously control the autonomous vehicle in accordance with the environment signals output by the autonomous driving sensor, detect the object or person on the exterior surface of the autonomous vehicle in accordance with the object detection signals, and limit autonomous operation of the autonomous vehicle in response to detecting the object or person on the exterior surface of the autonomous vehicle.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-06-15T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680631429},{"pair":"US-2019385336-A1 & US-2018135972-A1","patent_1":"US-2019385336-A1","title_1":"Vehicle Localization Using Cameras ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190385336A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"According to one embodiment, a system for determining a position of a vehicle includes an image sensor, a top-down view component, a comparison component, and a location component. The image sensor obtains an image of an environment near a vehicle. The top-down view component is configured to generate a top-down view of a ground surface based on the image of the environment. The comparison component is configured to compare the top-down image with a map, the map comprising a top-down light LIDAR intensity map or a vector-based semantic map. The location component is configured to determine a location of the vehicle on the map based on the comparison.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-03-14T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868063073},{"pair":"US-2019235520-A1 & US-9669827-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680490539},{"pair":"US-2017031362-A1 & US-10012991-B1","patent_1":"US-2017031362-A1","title_1":"Field-based torque steering control ","patent_2":"US-10012991-B1","title_2":"Approach for consolidating observed vehicle trajectories into a single representative trajectory ","link_1":"https:\/\/patents.google.com\/patent\/US20170031362A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10012991B1\/en","abstract_1":"A system includes a computer programmed to determine, along a nominal path to be traversed by a vehicle, a potential field representing a driving corridor for the vehicle. The computer is further programmed to identify a position of the vehicle relative to the potential field at a current time, and apply a torque to q steering column of the vehicle. The torque is based at least in part on the position. The potential field includes an attractive potential that guides the vehicle to remain within the corridor.","abstract_2":"A method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a pool of combined trajectories. Subsequently, the autonomous vehicle may select one of the combined trajectories as a representative trajectory. The representative trajectory may be used to change at least one of the speed or direction of the autonomous vehicle.","priority_1":"2015-07-31T00:00:00","priority_2":"2012-03-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680452481},{"pair":"US-2020073405-A1 & US-9932035-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9932035-B1","title_2":"Modifying speed of an autonomous vehicle based on traffic conditions ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9932035B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to speed control in an autonomous vehicle. For example, an autonomous vehicle may include a user interface which allows the driver to input speed preferences. These preferences may include the maximum speed above the speed limit the user would like the autonomous vehicle to drive when other vehicles are present and driving above or below certain speeds. The other vehicles may be in adjacent or the same lane the vehicle, and need not be in front of the vehicle.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-09-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680313016},{"pair":"US-10377376-B2 & US-9707966-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680225332},{"pair":"US-2018312165-A1 & US-2018102001-A1","patent_1":"US-2018312165-A1","title_1":"Road water detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180312165A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle computer includes a memory and a processor programmed to execute instructions stored in the memory. The instructions include receiving a first tire pressure measurement at a first time, receiving a second tire pressure measurement at a second time, comparing the first tire pressure measurement to the second tire pressure measurement, and determining that a road is flooded based on a difference of the first tire pressure measurement and the second tire pressure measurement.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-04-27T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680121844},{"pair":"US-10026317-B2 & US-2016370801-A1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680109157},{"pair":"US-10580300-B1 & US-2018143643-A1","patent_1":"US-10580300-B1","title_1":"Parking management systems and methods ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10580300B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-08-22T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679981008},{"pair":"US-10328973-B2 & US-2018011496-A1","patent_1":"US-10328973-B2","title_1":"Assisting drivers with roadway lane changes ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10328973B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for assisting drivers with roadway lane changes. In general, aspects of the invention are used in motorized vehicles to guide a driver to a more efficiently operating lane of a multi-lane roadway. A lane recommendation can be based on sensed and\/or communicated aspects of surrounding vehicles (e.g., speed, acceleration, etc.). Lane recommendations can be communicated to a driver with audio and\/or visual cues. In one aspect, images of surrounding roadway are augmented with additional data to highlight lanes, lane change locations, other vehicles, etc. Lane recommendations can be revised in (essentially) real-time in response to changing conditions in a roadway environment (e.g., a vehicle in a neighboring lane has changed speed).","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-03-06T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679817478},{"pair":"US-2017248951-A1 & US-10192442-B2","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679785735},{"pair":"US-2018120857-A1 & US-2015310281-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2015310281-A1","title_2":"Methods and Systems for Object Detection using Multiple Sensors ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150310281A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for object detection using multiple sensors are described herein. In an example embodiment, a vehicle's computing device may receive sensor data frames indicative of an environment at different rates from multiple sensors. Based on a first frame from a first sensor indicative of the environment at a first time period and a portion of a first frame that corresponds to the first time period from a second sensor, the computing device may estimate parameters of objects in the vehicle's environment. The computing device may modify the parameters in response to receiving subsequent frames or subsequent portions of frame of sensor data from the sensors even if the frames arrive at the computing device out of order. The computing device may provide the parameters of the objects to systems of the vehicle for object detection and obstacle avoidance.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-04-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679525475},{"pair":"US-2016325779-A1 & US-2018135972-A1","patent_1":"US-2016325779-A1","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20160325779A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-05-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679327398},{"pair":"US-2020064850-A1 & US-9594379-B1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-9594379-B1","title_2":"Detecting sensor degradation by actively controlling an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9594379B1\/en","abstract_1":null,"abstract_2":"Methods and systems are disclosed for determining sensor degradation by actively controlling an autonomous vehicle. Determining sensor degradation may include obtaining sensor readings from a sensor of an autonomous vehicle, and determining baseline state information from the obtained sensor readings. A movement characteristic of the autonomous vehicle, such as speed or position, may then be changed. The sensor may then obtain additional sensor readings, and second state information may be determined from these additional sensor readings. Expected state information may be determined from the baseline state information and the change in the movement characteristic of the autonomous vehicle. A comparison of the expected state information and the second state information may then be performed. Based on this comparison, a determination may be made as to whether the sensor has degraded.","priority_1":"2018-08-22T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679194027},{"pair":"US-2019219697-A1 & US-9255805-B1","patent_1":"US-2019219697-A1","title_1":"Lidar localization ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190219697A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system including a processor and a memory, the memory including instructions to be executed by the processor to determine map data, determine uncalibrated LIDAR data, determine a location of a vehicle in the map data by combining the map data with the uncalibrated LIDAR data, and operate the vehicle based on the location of the vehicle in the map data.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2018-01-12T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679144612},{"pair":"US-2018067487-A1 & US-10146223-B1","patent_1":"US-2018067487-A1","title_1":"Perceiving Roadway Conditions from Fused Sensor Data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180067487A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for perceiving roadway conditions from fused sensor data. Aspects of the invention use a combination of different types of cameras mounted to a vehicle to achieve visual perception for autonomous driving of the vehicle. Each camera in the combination of cameras generates sensor data by sensing at least part of the environment around the vehicle. The sensor data form each camera is fused together into a view of the environment around the vehicle. Sensor data from each camera (and, when appropriate, each other type of sensor) is fed into a central sensor perception chip. The central sensor perception chip uses a sensor fusion algorithm to fuse the sensor data into a view of the environment around the vehicle.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-09-08T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8679033962},{"pair":"US-9696721-B1 & US-2018143643-A1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-03-21T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8678789137},{"pair":"US-2020073405-A1 & US-9255805-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8678498887},{"pair":"US-2020073405-A1 & US-9290181-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9290181-B1","title_2":"Detecting and responding to tailgaters ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9290181B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle detects a tailgating vehicle and uses various response mechanisms. A vehicle is identified as a tailgater based on whether its characteristics meet a variable threshold. When the autonomous vehicle is traveling at slower speeds, the threshold is defined in distance. When the autonomous vehicle is traveling at faster speeds, the threshold is defined in time. The autonomous vehicle responds to the tailgater by modifying its driving behavior. In one example, the autonomous vehicle adjusts a headway buffer (defined in time) from another vehicle in front of the autonomous vehicle. In this regard, if the tailgater is T seconds too close to the autonomous vehicle, the autonomous vehicle increases the headway buffer to the vehicle in front of it by some amount relative to T.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8678014049},{"pair":"US-10423847-B2 & US-2018105174-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018105174-A1","title_2":"Planning stopping locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180105174A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to generating a speed plan for an autonomous vehicle. As an example, the vehicle is maneuvered in an autonomous driving mode along a route using pre-stored map information. This information identifies a plurality of keep clear regions where the vehicle should not stop but can drive through in the autonomous driving mode. Each keep clear region of the plurality of keep clear regions is associated with a priority value. A subset of the plurality of keep clear regions is identified based on the route. A speed plan for stopping the vehicle is generated based on the priority values associated with the keep clear regions of the subset. The speed plan identifies a location for stopping the vehicle. The speed plan is used to stop the vehicle in the location.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.867791386},{"pair":"US-2019039616-A1 & US-10059334-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677840059},{"pair":"US-10289113-B2 & US-9684836-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677579493},{"pair":"US-2020088881-A1 & US-9796386-B2","patent_1":"US-2020088881-A1","title_1":"Sensor field of view mapping ","patent_2":"US-9796386-B2","title_2":"Robust method for detecting traffic signals and their associated states ","link_1":"https:\/\/patents.google.com\/patent\/US20200088881A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9796386B2\/en","abstract_1":null,"abstract_2":"Methods and devices for detecting traffic signals and their associated states are disclosed. In one embodiment, an example method includes a scanning a target area using one or more sensors of a vehicle to obtain target area information. The vehicle may be configured to operate in an autonomous mode, and the target area may be a type of area where traffic signals are typically located. The method may also include detecting a traffic signal in the target area information, determining a location of the traffic signal, and determining a state of the traffic signal. Also, a confidence in the traffic signal may be determined. For example, the location of the traffic signal may be compared to known locations of traffic signals. Based on the state of the traffic signal and the confidence in the traffic signal, the vehicle may be controlled in the autonomous mode.","priority_1":"2018-09-19T00:00:00","priority_2":"2012-03-26T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677435068},{"pair":"US-2017197615-A1 & US-9494942-B1","patent_1":"US-2017197615-A1","title_1":"System and method for reverse perpendicular parking a vehicle ","patent_2":"US-9494942-B1","title_2":"Enhancing basic roadway-intersection models using high intensity image data ","link_1":"https:\/\/patents.google.com\/patent\/US20170197615A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9494942B1\/en","abstract_1":"A method for parking a vehicle in a parking lot includes generating steering commands for the vehicle while in the lot based on an occupancy grid and plenoptic camera data. The occupancy grid indicates occupied areas and unoccupied areas around the vehicle and is derived from map data defining parking spots relative to a topological feature contained within the lot. The plenoptic camera data defines a plurality of depth maps and corresponding images that include the topological feature captured during movement of the vehicle. The steering command is generated such that the vehicle follows a reverse perpendicular path into one of the spots without entering an occupied area.","abstract_2":"Systems and methods are provided that may optimize basic models of an intersection in a roadway with high intensity image data of the intersection of the roadway. More specifically, parameters that define the basic model of the intersection in the roadway may be adjusted to more accurately define the intersection. For example, by comparing a shape of the intersection predicted by the basic model with extracted curbs and lane boundaries from elevation and intensity maps, the intersection parameters can be optimized to match real intersection-features in the environment. Once the optimal intersection parameters have been found, roadgraph features describing the intersection may be extracted.","priority_1":"2016-01-11T00:00:00","priority_2":"2014-01-22T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677389063},{"pair":"US-2018120857-A1 & US-2017341643-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677226295},{"pair":"US-2019294164-A1 & US-2016187887-A1","patent_1":"US-2019294164-A1","title_1":"Action-conditioned vehicle control ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190294164A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A high-level vehicle command is determined based on a location of the vehicle with respect to a route including a start location and a finish location. An image is acquired of the vehicle external environment. Steering, braking, and powertrain commands are determined based on inputting the high-level command and the image into a Deep Neural Network. The vehicle is operated by actuating vehicle components based on the steering, braking and powertrain commands.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-03-26T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677139762},{"pair":"US-2020031468-A1 & US-9463794-B1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-12-14T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.867702929},{"pair":"US-10077054-B2 & US-9779621-B1","patent_1":"US-10077054-B2","title_1":"Tracking objects within a dynamic environment for improved localization ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10077054B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for tracking objects within a dynamic environment for improved localization. Sensing devices are utilized to gather data about a vehicle's environment. In cases where the sensor data has become degraded, such as data indicating that lane lines have become degraded, obscured, or nonexistent, the vehicle computer system uses previously detected sensor data to estimate the speed and direction of travel of moving objects. The computer system then estimates the location of the moving objects after a specified period of time based on the estimated speed and direction of the moving object. The computer system utilizes this information to localize the vehicle within the dynamic environment and to control the configuration of the vehicle.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2016-01-29T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.867687523},{"pair":"US-2017217434-A1 & US-9779621-B1","patent_1":"US-2017217434-A1","title_1":"Tracking Objects Within A Dynamic Environment For Improved Localization ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20170217434A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for tracking objects within a dynamic environment for improved localization. Sensing devices are utilized to gather data about a vehicle's environment. In cases where the sensor data has become degraded, such as data indicating that lane lines have become degraded, obscured, or nonexistent, the vehicle computer system uses previously detected sensor data to estimate the speed and direction of travel of moving objects. The computer system then estimates the location of the moving objects after a specified period of time based on the estimated speed and direction of the moving object. The computer system utilizes this information to localize the vehicle within the dynamic environment and to control the configuration of the vehicle.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2016-01-29T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.867687523},{"pair":"US-9612596-B2 & US-2018011496-A1","patent_1":"US-9612596-B2","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9612596B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-05-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676820166},{"pair":"US-2018137756-A1 & US-2018011496-A1","patent_1":"US-2018137756-A1","title_1":"Detecting and responding to emergency vehicles in a roadway ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180137756A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"The present invention extends to methods, systems, and computer program products for detecting and responding to emergency vehicles in a roadway. Aspects of the invention can be used to detect emergency vehicles and properly yield to emergency vehicles depending on roadway configuration. A vehicle includes a plurality of sensors. The vehicle also includes vehicle to vehicle (V2V) communication capabilities and has access to map data. Sensor data from the plurality of sensors along with map data is provided as input to a neural network (either in the vehicle or in the cloud). Based on sensor data, the neural network detects when one or more emergency vehicles are approaching the vehicle. From a roadway configuration, a vehicle can use the plurality of sensors to automatically (and safely) yield to detected emergency vehicle(s). Automatically yielding can include one or more of: slowing down, changing lanes, stopping, etc.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-11-17T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676754672},{"pair":"US-2019012913-A1 & US-10204278-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676701014},{"pair":"US-2020073405-A1 & US-9594379-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9594379-B1","title_2":"Detecting sensor degradation by actively controlling an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9594379B1\/en","abstract_1":null,"abstract_2":"Methods and systems are disclosed for determining sensor degradation by actively controlling an autonomous vehicle. Determining sensor degradation may include obtaining sensor readings from a sensor of an autonomous vehicle, and determining baseline state information from the obtained sensor readings. A movement characteristic of the autonomous vehicle, such as speed or position, may then be changed. The sensor may then obtain additional sensor readings, and second state information may be determined from these additional sensor readings. Expected state information may be determined from the baseline state information and the change in the movement characteristic of the autonomous vehicle. A comparison of the expected state information and the second state information may then be performed. Based on this comparison, a determination may be made as to whether the sensor has degraded.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676604954},{"pair":"US-10423847-B2 & US-9575490-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676445381},{"pair":"US-2020031468-A1 & US-10156851-B1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-12-14T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676323271},{"pair":"US-2018029607-A1 & US-9551992-B1","patent_1":"US-2018029607-A1","title_1":"Vehicle user-communication system and method ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180029607A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A controller includes a processor and a memory storing processor-executable instructions. The processor is programmed to control steering and at least one of propulsion and braking of a vehicle while following a route segment and, during the route segment, to activate a user interface at a frequency based on at least one of an elapsed duration of the route segment, an age of a user, a time of day, and a route-segment topology.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-07-28T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676314273},{"pair":"US-10528055-B2 & US-10156851-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676259847},{"pair":"US-2017072962-A1 & US-9261379-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9261379-B1","title_2":"Intersection completer ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9261379B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate generally to generating roadgraphs for use by autonomous vehicles. A computer may receive input defining aspects of a roadway including an intersection with another roadway, one or more traffic control features, and one or more locations at which a vehicle is required to observe at least one traffic signal before entering the intersection. A user may identify the intersection, for example, by tracing a perimeter around the intersection. In response, for each particular location of the one or more locations, the computer may identifying a route through the intersection from the particular location and determine, based on the boundary of the intersection and the particular location, a set of the one or more traffic control features must be observed by the vehicle before entering the intersection. This information may then be used to generate a roadgraph.","priority_1":"2014-05-13T00:00:00","priority_2":"2011-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676230835},{"pair":"US-2018273048-A1 & US-9669827-B1","patent_1":"US-2018273048-A1","title_1":"Vehicle lane direction detection ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180273048A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A roadway lane direction is identified based on vehicle sensor data of a traffic sign, a direction of a parked vehicle, and a marking on a surface of the roadway lane. A trajectory of a vehicle is determined to differ from the roadway lane direction, and a vehicle component is then actuated.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-03-22T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676130344},{"pair":"US-9989963-B2 & US-9684836-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8675722054},{"pair":"US-2018273048-A1 & US-9682707-B1","patent_1":"US-2018273048-A1","title_1":"Vehicle lane direction detection ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180273048A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A roadway lane direction is identified based on vehicle sensor data of a traffic sign, a direction of a parked vehicle, and a marking on a surface of the roadway lane. A trajectory of a vehicle is determined to differ from the roadway lane direction, and a vehicle component is then actuated.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-03-22T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8675696502},{"pair":"US-10267911-B2 & US-10156851-B1","patent_1":"US-10267911-B2","title_1":"Steering wheel actuation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10267911B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A computing device in a vehicle can be programmed to determine a time to a collision and a field of safe travel, select one of a first and a second haptic output based on (a) the field of safe travel and (b) a predetermined time threshold. The computing device can deliver the first haptic output via a steering wheel when the time to collision is greater than the predetermined time threshold and deliver the second haptic output via the steering wheel when the time to collision is less than or equal to the predetermined time threshold.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-03-31T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8675400165},{"pair":"US-2018208190-A1 & US-2018011496-A1","patent_1":"US-2018208190-A1","title_1":"Collision Avoidance Systems And Methods ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180208190A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Example collision avoidance systems and methods are described. In one implementation, a method receives data from multiple sensors mounted to a first vehicle. A collision avoidance system determines a likelihood that a second vehicle will collide with the back of the first vehicle based on the received data. If a collision is likely, the method identifies open space near the first vehicle and determines a best action to avoid or mitigate the likely collision based on the identified open space.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-01-25T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8675202285},{"pair":"US-10259455-B2 & US-2018011496-A1","patent_1":"US-10259455-B2","title_1":"Collision avoidance systems and methods ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259455B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Example collision avoidance systems and methods are described. In one implementation, a method receives data from multiple sensors mounted to a first vehicle. A collision avoidance system determines a likelihood that a second vehicle will collide with the back of the first vehicle based on the received data. If a collision is likely, the method identifies open space near the first vehicle and determines a best action to avoid or mitigate the likely collision based on the identified open space.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-01-25T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8675202285},{"pair":"US-2019374151-A1 & US-2018143643-A1","patent_1":"US-2019374151-A1","title_1":"Focus-Based Tagging Of Sensor Data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190374151A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Data from sensors of a vehicle is captured along with data tracking a driver's gaze. The route traveled by the vehicle may also be captured. The driver's gaze is evaluated with respect to the sensor data to determine a feature the driver was focused on. A focus record is created for the feature. Focus records for many drivers may be aggregated to determine a frequency of observation of the feature. A machine learning model may be trained using the focus records to identify a region of interest for a given scenario in order to more quickly identify relevant hazards.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-06-08T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8675025857},{"pair":"US-10289113-B2 & US-2016155452-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016155452-A1","title_2":"Method for Siren Detection Based on Audio Samples ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160155452A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The present disclosure provides methods and apparatuses that enable an apparatus to identify sounds from short samples of audio. The apparatus may capture an audio sample and create several audio signals of different lengths, each containing audio from the captured audio sample. The apparatus my process the several audio signals in an attempt to identify features of the audio signal that indicate an identification of the captured sound. Because shorter audio samples can be analyzed more quickly, the system may first process the shortest audio samples in order to quickly identify features of the audio signal. Because longer audio samples contain more information, the system may be able to more accurately identify features in the audio signal in longer audio samples. However, analyzing longer audio signals takes more buffered audio than identifying features in shorter signals. Therefore, the present system attempts to identify features in the shortest audio signals first.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674961501},{"pair":"US-10589742-B2 & US-9387854-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674741398},{"pair":"US-2017232961-A1 & US-9551992-B1","patent_1":"US-2017232961-A1","title_1":"System and method for automatic activation of autonomous parking ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170232961A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system for parking a vehicle is disclosed. In various embodiments, the system includes a vehicle including a motor, sensors, a steering system, a processor, and a memory; an autopark program operatively connected to the vehicle's steering system; a navigation program operatively connected to the vehicle and configured to determine the vehicle's speed and lane with the sensors, to evaluate the data, and in response to the evaluation, to automatically execute the autopark program.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-12T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674651544},{"pair":"US-9878709-B2 & US-9551992-B1","patent_1":"US-9878709-B2","title_1":"System and method for automatic activation of autonomous parking ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9878709B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system for parking a vehicle is disclosed. In various embodiments, the system includes a vehicle including a motor, sensors, a steering system, a processor, and a memory; an autopark program operatively connected to the vehicle's steering system; a navigation program operatively connected to the vehicle and configured to determine the vehicle's speed and lane with the sensors, to evaluate the data, and in response to the evaluation, to automatically execute the autopark program.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-12T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674651544},{"pair":"US-2017249844-A1 & US-2016370801-A1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674480283},{"pair":"US-2018215374-A1 & US-10146223-B1","patent_1":"US-2018215374-A1","title_1":"Self-parking vehicle ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180215374A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A computer is programmed to, upon determining that a user has departed a vehicle, identify available parking spaces based at least in part on one of stored parking restrictions and vehicle sensor data. The computer is programmed to select one of the parking spaces based at least in part on a distance to a respective parking space and an environmental condition. The computer navigates the vehicle to park at the selected parking space.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.867447983},{"pair":"US-2020064850-A1 & US-2017341643-A1","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-08-22T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674455201},{"pair":"US-2017139420-A1 & US-9658620-B1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-9658620-B1","title_2":"System and method of providing recommendations to users of vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9658620B1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"A system and method is provided of providing recommendations to a user of a vehicle. In one aspect, the vehicle navigates autonomously and the sensors provide information that is based on the location of the vehicle and output from sensors directed to the environment surrounding the vehicle. In further aspects, both current and previous sensor data is used to make the recommendation, as well as data based on the sensors of other vehicles.","priority_1":"2014-07-16T00:00:00","priority_2":"2010-10-05T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674449609},{"pair":"US-2018319402-A1 & US-2018143643-A1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-05-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674275468},{"pair":"US-2017206426-A1 & US-10126141-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10126141-B2","title_2":"Systems and methods for using real-time imagery in navigation ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10126141B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"To generate navigation directions for a driver of a vehicle, a route for guiding the driver to a destination is obtained, visual landmarks corresponding to prominent physical objects disposed along the route are retrieved, and real-time imagery is collected at the vehicle approximately from a vantage point of the driver during navigation along the route. Using (i) the retrieved visual landmarks and (ii) the imagery collected at the vehicle, a subset of the visual landmarks that are currently visible to the driver is selected. Navigation directions describing the route are provided the driver, the navigation directions referencing the selected subset of the visual landmarks and excluding the remaining visual landmarks.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-05-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674235506},{"pair":"US-2020065980-A1 & US-9690296-B1","patent_1":"US-2020065980-A1","title_1":"Eccentricity maps ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200065980A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2018-08-22T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674203825},{"pair":"US-2017072962-A1 & US-9646497-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674126888},{"pair":"US-2016055749-A1 & US-2018135972-A1","patent_1":"US-2016055749-A1","title_1":"Method and system for vehicle parking ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20160055749A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A request to identify a parking spot is received. A response to the request, including an identification of at least one available parking spot, is provided. A parking spot selected from the response is identified. Data relating to the selected spot are collected. A user profile based on the collected data is updated.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-08-21T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674109469},{"pair":"US-9989963-B2 & US-10192442-B2","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674075689},{"pair":"US-2019325238-A1 & US-9682707-B1","patent_1":"US-2019325238-A1","title_1":"Advanced warnings for drivers of vehicles for upcoming signs ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190325238A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Method and apparatus are disclosed for advanced warnings to drivers of vehicles for upcoming signs. An example vehicle includes a GPS receiver to determine a vehicle location. The example vehicle also includes a condition identifier to determine a familiarity level of a driver for the vehicle location and detect an upcoming sign. The example vehicle also includes a warning determiner to compare the familiarity level to a threshold level and provide, in response to the familiarity level being less than the threshold level, an advanced warning to the driver for the upcoming sign.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-12-21T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674063316},{"pair":"US-2018099663-A1 & US-9373045-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674028889},{"pair":"US-2020031468-A1 & US-9551992-B1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-12-14T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674005475},{"pair":"US-9612596-B2 & US-2018135972-A1","patent_1":"US-9612596-B2","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US9612596B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-05-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8673906845},{"pair":"US-10127814-B2 & US-10146223-B1","patent_1":"US-10127814-B2","title_1":"Advanced V2X event dissemination ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10127814B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Disclosed is a host vehicle including: motor(s), sensors, processor(s) configured to: (i) package sensed data into a first unit; (ii) determine whether a vehicle-to-infrastructure connection is (a) active or (b) inactive; (iii) if (a), append a TRUE flag to the unit and if (b) append a FALSE flag to the unit; (iv) transmit the first appended unit over a vehicle-to-vehicle connection; (v) determine whether a second appended unit, received over a vehicle-to-vehicle connection, includes (c) a TRUE flag or (d) a FALSE flag; (vi) if (d), transmit the second appended unit over the vehicle-to-infrastructure connection; (vii) if (c), not transmit the second appended unit over the vehicle-to-infrastructure connection.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-02-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8673846274},{"pair":"US-2019251371-A1 & US-10146223-B1","patent_1":"US-2019251371-A1","title_1":"Methods and apparatus to facilitate environmental visibility determination ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190251371A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Methods and apparatus are disclosed to facilitate environmental visibility determination. An example vehicle comprises a sensor and a processor and memory. The sensor is to generate road image information. The processor and memory are in communication with the sensor and are configured to: detect vanishing points of lane markings in the road image information, convert an average pixel row value of the vanishing points to a distance value, and if the distance value is below a threshold, stop execution of at least one road condition monitoring feature.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-02-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.867384434},{"pair":"US-2019235520-A1 & US-2016187887-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8673698241},{"pair":"US-2019212743-A1 & US-9551992-B1","patent_1":"US-2019212743-A1","title_1":"Methods and apparatus to monitor and control mobility vehicles ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190212743A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Methods, apparatus, systems and articles of manufacture to provide an improved mobility vehicle are disclosed. An example vehicle includes a sensor positioned with respect to a seat to detect pressure by a user with respect to the sensor and to generate a signal corresponding to the pressure; and a processor to convert the signal into a control command for a powertrain to move the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-09-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8672684473},{"pair":"US-10409286-B2 & US-9862364-B2","patent_1":"US-10409286-B2","title_1":"Highway detection systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10409286B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example highway detection systems and methods are described. In one implementation, a method receives data from a vehicle data bus in a first vehicle and detects a speed of the first vehicle based on the received data. The method also determines a speed of an oncoming vehicle and a lateral distance between the first vehicle and the oncoming vehicle based on the received data. One or more processors determine whether the first vehicle is driving on a highway based on the speed of the first vehicle, the speed of the oncoming vehicle, and the lateral distance between the first vehicle and the oncoming vehicle.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-07-21T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8672476813},{"pair":"US-10345822-B1 & US-9255805-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8672469777},{"pair":"US-2018059679-A1 & US-9255805-B1","patent_1":"US-2018059679-A1","title_1":"Depth map estimation with stereo images ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20180059679A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Vehicles can be equipped to operate in both autonomous and occupant piloted mode. While operating in either mode, an array of sensors can be used to pilot the vehicle including stereo cameras and 3D sensors. Stereo camera and 3D sensors can also be employed to assist occupants while piloting vehicles. Deep convolutional neural networks can be employed to determine estimated depth maps from stereo images of scenes in real time for vehicles in autonomous and occupant piloted modes.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-09-01T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8672197049},{"pair":"US-9696721-B1 & US-9682707-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-03-21T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8672066548},{"pair":"US-9989963-B2 & US-2016082953-A1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-2016082953-A1","title_2":"Consideration of Risks in Active Sensing for an Autonomous Vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160082953A1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"An autonomous vehicle configured for active sensing may also be configured to weigh expected information gains from active-sensing actions against risk costs associated with the active-sensing actions. An example method involves: (a) receiving information from one or more sensors of an autonomous vehicle, (b) determining a risk-cost framework that indicates risk costs across a range of degrees to which an active-sensing action can be performed, wherein the active-sensing action comprises an action that is performable by the autonomous vehicle to potentially improve the information upon which at least one of the control processes for the autonomous vehicle is based, (c) determining an information-improvement expectation framework across the range of degrees to which the active-sensing action can be performed, and (d) applying the risk-cost framework and the information-improvement expectation framework to determine a degree to which the active-sensing action should be performed.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-05-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671760968},{"pair":"US-9989963-B2 & US-2016155452-A1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-2016155452-A1","title_2":"Method for Siren Detection Based on Audio Samples ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160155452A1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"The present disclosure provides methods and apparatuses that enable an apparatus to identify sounds from short samples of audio. The apparatus may capture an audio sample and create several audio signals of different lengths, each containing audio from the captured audio sample. The apparatus my process the several audio signals in an attempt to identify features of the audio signal that indicate an identification of the captured sound. Because shorter audio samples can be analyzed more quickly, the system may first process the shortest audio samples in order to quickly identify features of the audio signal. Because longer audio samples contain more information, the system may be able to more accurately identify features in the audio signal in longer audio samples. However, analyzing longer audio signals takes more buffered audio than identifying features in shorter signals. Therefore, the present system attempts to identify features in the shortest audio signals first.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671658505},{"pair":"US-10068477-B2 & US-2018105174-A1","patent_1":"US-10068477-B2","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-2018105174-A1","title_2":"Planning stopping locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10068477B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180105174A1\/en","abstract_1":"Systems and methods for detecting and communicating slipping of non-connected vehicles are disclosed. An example disclosed vehicle includes a wireless communication module and a vehicle marker. The example wireless communication module is configured to determine whether a second vehicle in the vicinity of the vehicle is wireless communication enabled. The example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, when the second vehicle is not wireless communication enabled, broadcast an alert including a location of the second vehicle. Additionally, the example vehicle marker is configured to, in response to detecting that the second vehicle is slipping, display a visual cue visible behind the vehicle.","abstract_2":"Aspects of the disclosure relate to generating a speed plan for an autonomous vehicle. As an example, the vehicle is maneuvered in an autonomous driving mode along a route using pre-stored map information. This information identifies a plurality of keep clear regions where the vehicle should not stop but can drive through in the autonomous driving mode. Each keep clear region of the plurality of keep clear regions is associated with a priority value. A subset of the plurality of keep clear regions is identified based on the route. A speed plan for stopping the vehicle is generated based on the priority values associated with the keep clear regions of the subset. The speed plan identifies a location for stopping the vehicle. The speed plan is used to stop the vehicle in the location.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-10-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671561737},{"pair":"US-2017316691-A1 & US-2018105174-A1","patent_1":"US-2017316691-A1","title_1":"System and method for detecting and communicating slipping of non-connected vehicles ","patent_2":"US-2018105174-A1","title_2":"Planning stopping locations for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170316691A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180105174A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to generating a speed plan for an autonomous vehicle. As an example, the vehicle is maneuvered in an autonomous driving mode along a route using pre-stored map information. This information identifies a plurality of keep clear regions where the vehicle should not stop but can drive through in the autonomous driving mode. Each keep clear region of the plurality of keep clear regions is associated with a priority value. A subset of the plurality of keep clear regions is identified based on the route. A speed plan for stopping the vehicle is generated based on the priority values associated with the keep clear regions of the subset. The speed plan identifies a location for stopping the vehicle. The speed plan is used to stop the vehicle in the location.","priority_1":"2016-04-29T00:00:00","priority_2":"2016-10-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671561737},{"pair":"US-2020073405-A1 & US-2017341643-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671301766},{"pair":"US-10232856-B2 & US-9551992-B1","patent_1":"US-10232856-B2","title_1":"Vehicle user-communication system and method ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10232856B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A controller includes a processor and a memory storing processor-executable instructions. The processor is programmed to control steering and at least one of propulsion and braking of a vehicle while following a route segment and, during the route segment, to activate a user interface at a frequency based on at least one of an elapsed duration of the route segment, an age of a user, a time of day, and a route-segment topology.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-07-28T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.867118549},{"pair":"US-2018370532-A1 & US-9669827-B1","patent_1":"US-2018370532-A1","title_1":"Assessing u-turn feasibility ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180370532A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Methods, devices and apparatuses pertaining to U-turn assistance. The method may include detecting an intention of an operator of a vehicle of rendering a U-turn at a location. A computing device may obtain geographic information associated with the U-turn, and assess feasibility of the U-turn at the location based on the geographic information. Further, the computing device may provide a notification to the operator based on the feasibility of the U-turn to assist the operator to operate the U-turn of the vehicle at the location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-01-14T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671074466},{"pair":"US-10289113-B2 & US-2016370801-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670964171},{"pair":"US-2017327037-A1 & US-2018135972-A1","patent_1":"US-2017327037-A1","title_1":"Adaptive rear view display ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170327037A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"System and methods to provide an adaptive rear view display are disclosed. An example disclosed first vehicle includes a rear view camera and an adaptive display controller. The example adaptive display controller is to determine, with range detection sensors, a following-time of a second vehicle behind the first vehicle. The example adaptive display controller is also to determine a workload estimate associated with the first vehicle. Additionally, when the first vehicle is moving forward, the adaptive display controller is to selectively display video from the rear view camera based on the following-time, the workload estimate, and a user request.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-05-10T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670793586},{"pair":"US-2017248953-A1 & US-10192442-B2","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-10192442-B2","title_2":"Determining changes in a driving environment based on vehicle behavior ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10192442B2\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"A method and apparatus are provided for determining whether a driving environment has changed relative to previously stored information about the driving environment. The apparatus may include an autonomous driving computer system configured to detect one or more vehicles in the driving environment, and determine corresponding trajectories for those detected vehicles. The autonomous driving computer system may then compare the determined trajectories to an expected trajectory of a hypothetical vehicle in the driving environment. Based on the comparison, the autonomous driving computer system may determine whether the driving environment has changed and\/or a probability that the driving environment has changed, relative to the previously stored information about the driving environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670547917},{"pair":"US-2017249844-A1 & US-9690296-B1","patent_1":"US-2017249844-A1","title_1":"Autonomous probability control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170249844A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670543879},{"pair":"US-10220769-B1 & US-10093181-B1","patent_1":"US-10220769-B1","title_1":"Vehicular image projection ","patent_2":"US-10093181-B1","title_2":"Occupant facing vehicle display ","link_1":"https:\/\/patents.google.com\/patent\/US10220769B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10093181B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering an occupant of the vehicle to a destination autonomously as well as providing information about the vehicle and the vehicle's environment for display to the occupant.","priority_1":"2017-08-22T00:00:00","priority_2":"2015-09-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670332503},{"pair":"US-2019061611-A1 & US-10093181-B1","patent_1":"US-2019061611-A1","title_1":"Vehicular image projection ","patent_2":"US-10093181-B1","title_2":"Occupant facing vehicle display ","link_1":"https:\/\/patents.google.com\/patent\/US20190061611A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10093181B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"Aspects of the present disclosure relate to a vehicle for maneuvering an occupant of the vehicle to a destination autonomously as well as providing information about the vehicle and the vehicle's environment for display to the occupant.","priority_1":"2017-08-22T00:00:00","priority_2":"2015-09-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670332503},{"pair":"US-2017334440-A1 & US-9862364-B2","patent_1":"US-2017334440-A1","title_1":"Accident attenuation systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170334440A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example accident attenuation systems and methods are described. In one implementation, a method determines a speed of a second vehicle approaching from behind a first vehicle and determines a distance between the first and second vehicles. The method also determines whether the second vehicle can stop before colliding with the first vehicle. If the second vehicle cannot stop before colliding with the first vehicle, the method takes action to attenuate the potential collision by applying full brake force, tightening seat belts, and\/or turning the front wheels of the first vehicle to direct the first vehicle away from oncoming traffic.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-05-23T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670318639},{"pair":"US-10086830-B2 & US-9862364-B2","patent_1":"US-10086830-B2","title_1":"Accident attenuation systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10086830B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example accident attenuation systems and methods are described. In one implementation, a method determines a speed of a second vehicle approaching from behind a first vehicle and determines a distance between the first and second vehicles. The method also determines whether the second vehicle can stop before colliding with the first vehicle. If the second vehicle cannot stop before colliding with the first vehicle, the method takes action to attenuate the potential collision by applying full brake force, tightening seat belts, and\/or turning the front wheels of the first vehicle to direct the first vehicle away from oncoming traffic.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-05-23T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670318639},{"pair":"US-10569785-B2 & US-2018102001-A1","patent_1":"US-10569785-B2","title_1":"Road water detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10569785B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-04-27T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670315182},{"pair":"US-10345822-B1 & US-9669827-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670280564},{"pair":"US-2019325238-A1 & US-10156851-B1","patent_1":"US-2019325238-A1","title_1":"Advanced warnings for drivers of vehicles for upcoming signs ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190325238A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Method and apparatus are disclosed for advanced warnings to drivers of vehicles for upcoming signs. An example vehicle includes a GPS receiver to determine a vehicle location. The example vehicle also includes a condition identifier to determine a familiarity level of a driver for the vehicle location and detect an upcoming sign. The example vehicle also includes a warning determiner to compare the familiarity level to a threshold level and provide, in response to the familiarity level being less than the threshold level, an advanced warning to the driver for the upcoming sign.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-12-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670230991},{"pair":"US-2019156132-A1 & US-9862364-B2","patent_1":"US-2019156132-A1","title_1":"Brake Light Detection ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190156132A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for detecting brake lights are disclosed herein. A system includes a mode component, a vehicle region component, and a classification component. The mode component is configured to select a night mode or day mode based on a pixel brightness in an image frame. The vehicle region component is configured to detect a region corresponding to a vehicle based on data from a range sensor when in a night mode or based on camera image data when in the day mode. The classification component is configured to classify a brake light of the vehicle as on or off based on image data in the region corresponding to the vehicle.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-22T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.866975544},{"pair":"US-2020064850-A1 & US-10204278-B2","patent_1":"US-2020064850-A1","title_1":"Predicting movement intent of objects ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20200064850A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-08-22T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8669741306},{"pair":"US-9666074-B2 & US-2018135972-A1","patent_1":"US-9666074-B2","title_1":"Method and system for vehicle parking ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US9666074B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A request to identify a parking spot is received. A response to the request, including an identification of at least one available parking spot, is provided. A parking spot selected from the response is identified. Data relating to the selected spot are collected. A user profile based on the collected data is updated.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-08-21T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8669395072},{"pair":"US-2018200745-A1 & US-2018143643-A1","patent_1":"US-2018200745-A1","title_1":"Camera and washer spray diagnostic ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180200745A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system including a computer programmed to actuate a spray device on a first vehicle and to receive an image, from a second vehicle, of the actuated spray device. The computer determines whether a spray device fault exists based at least on the image of the actuated spray device, and transmits the spray device fault via a first vehicle communications network.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-01-19T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.866917866},{"pair":"US-2019084427-A1 & US-2017098129-A1","patent_1":"US-2019084427-A1","title_1":"Solar vehicle charging ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190084427A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system includes processor. The system includes a memory, the memory storing instructions executable by the processor to identify, in a vehicle at a first location, a second location receiving reflected light. The memory stores instructions executable by the processor to navigate the vehicle from the first location to the second location receiving the reflected light.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-09-18T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8669177583},{"pair":"US-2017031362-A1 & US-9836052-B1","patent_1":"US-2017031362-A1","title_1":"Field-based torque steering control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170031362A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system includes a computer programmed to determine, along a nominal path to be traversed by a vehicle, a potential field representing a driving corridor for the vehicle. The computer is further programmed to identify a position of the vehicle relative to the potential field at a current time, and apply a torque to q steering column of the vehicle. The torque is based at least in part on the position. The potential field includes an attractive potential that guides the vehicle to remain within the corridor.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-07-31T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8669130489},{"pair":"US-2019161085-A1 & US-9255805-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8669007094},{"pair":"US-2018237012-A1 & US-2018143643-A1","patent_1":"US-2018237012-A1","title_1":"Autonomous vehicle towing ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180237012A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A computer that includes a processor and memory that stores instructions executable by the processor, so that the computer is programmed to: instruct a host vehicle to follow a leader vehicle; monitor driving behavior of the leader vehicle; and instruct the host vehicle to cease following the leader vehicle based on an abnormal driving action of the leader vehicle.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-02-22T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668847356},{"pair":"US-9612596-B2 & US-2018102001-A1","patent_1":"US-9612596-B2","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US9612596B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-05-05T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668706824},{"pair":"US-2019061611-A1 & US-10146223-B1","patent_1":"US-2019061611-A1","title_1":"Vehicular image projection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190061611A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668686431},{"pair":"US-10220769-B1 & US-10146223-B1","patent_1":"US-10220769-B1","title_1":"Vehicular image projection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10220769B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A computer is programmed to receive data indicating a state of a traffic signal. The computer is further programmed to activate a light source in a first vehicle to project a traffic signal symbol representing the state of the traffic signal.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-08-22T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668686431},{"pair":"US-2018300620-A1 & US-2018102001-A1","patent_1":"US-2018300620-A1","title_1":"Foliage Detection Training Systems And Methods ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180300620A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Example foliage detection training systems and methods are described. In one implementation, a method receives data associated with a plurality of vehicle-mounted sensors and defines multiple regions of interest (ROIs) based on the received data. The method applies a label to each ROI, where the label classifies a type of foliage associated with the ROI. A foliage detection training system trains a machine learning algorithm based on the ROIs and associated labels.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-04-12T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668505517},{"pair":"US-10406917-B2 & US-2017341643-A1","patent_1":"US-10406917-B2","title_1":"Systems and methods for vehicle cruise control smoothness adaptation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10406917B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Methods and systems are disclosed for vehicle cruise control smoothness adaptation. An example vehicle includes a GPS receiver for receiving expected road incline data, a camera for determining a half lane width position, and a radar for determining two respective leading vehicle angles of arrival. The vehicle also includes a processor for determining an actual road incline by filtering the expected road incline, half lane width position, and leading vehicle angles of arrival. And the processor is further for modifying a cruise control system based on the actual road incline.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-08-28T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668211341},{"pair":"US-10377376-B2 & US-9373045-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668198454},{"pair":"US-2020031468-A1 & US-9862364-B2","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-12-14T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668186379},{"pair":"US-9983591-B2 & US-9682707-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668094149},{"pair":"US-2019212743-A1 & US-9740202-B2","patent_1":"US-2019212743-A1","title_1":"Methods and apparatus to monitor and control mobility vehicles ","patent_2":"US-9740202-B2","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190212743A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9740202B2\/en","abstract_1":"Methods, apparatus, systems and articles of manufacture to provide an improved mobility vehicle are disclosed. An example vehicle includes a sensor positioned with respect to a seat to detect pressure by a user with respect to the sensor and to generate a signal corresponding to the pressure; and a processor to convert the signal into a control command for a powertrain to move the vehicle.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-09-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8667909621},{"pair":"US-9696721-B1 & US-10198643-B1","patent_1":"US-9696721-B1","title_1":"Inductive loop detection systems and methods ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US9696721B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2016-03-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.86677569},{"pair":"US-2015268338-A1 & US-2018102001-A1","patent_1":"US-2015268338-A1","title_1":"Tracking from a vehicle ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20150268338A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Data related to a person outside of a vehicle can be collected by a computer in the vehicle. The collected data is used to generate a virtual map of one or more targets, including at least the person, proximate to the vehicle. A display is provided based on the virtual map that includes information about a location of the person.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2014-03-22T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8667586701},{"pair":"US-2018120857-A1 & US-10019805-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10019805-B1","title_2":"Detecting vehicle movement through wheel movement ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10019805B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting vehicle movement. For example, one or more computing devices may receive first image data representative of a vehicle's wheel and second image data representative of the wheel captured subsequent to the capture of the first image data. The one or more computing devices may determine a first location of a first portion of the wheel based on the first image data, and a second location of the first portion of the wheel based on the second image data. The one or more computing devices may calculate a value based on the angular distance between the first location and the second location of the first portion, and based on the value, determine whether the vehicle is in motion. Upon determining the vehicle is in motion the one or more computing devices may provide a signal that the vehicle is in motion.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8667428753},{"pair":"US-2017248953-A1 & US-2016370801-A1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8667142069},{"pair":"US-2017248951-A1 & US-2016155452-A1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-2016155452-A1","title_2":"Method for Siren Detection Based on Audio Samples ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160155452A1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"The present disclosure provides methods and apparatuses that enable an apparatus to identify sounds from short samples of audio. The apparatus may capture an audio sample and create several audio signals of different lengths, each containing audio from the captured audio sample. The apparatus my process the several audio signals in an attempt to identify features of the audio signal that indicate an identification of the captured sound. Because shorter audio samples can be analyzed more quickly, the system may first process the shortest audio samples in order to quickly identify features of the audio signal. Because longer audio samples contain more information, the system may be able to more accurately identify features in the audio signal in longer audio samples. However, analyzing longer audio signals takes more buffered audio than identifying features in shorter signals. Therefore, the present system attempts to identify features in the shortest audio signals first.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666831364},{"pair":"US-2016210382-A1 & US-10198643-B1","patent_1":"US-2016210382-A1","title_1":"Autonomous driving refined in virtual environments ","patent_2":"US-10198643-B1","title_2":"Plane estimation for contextual awareness ","link_1":"https:\/\/patents.google.com\/patent\/US20160210382A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10198643B1\/en","abstract_1":"A computing device includes a processing circuit and a data storage medium. The computing device is programmed to receive a user input selecting at least one testing parameter associated with autonomously operating a virtual vehicle in a virtual environment, simulate the virtual environment incorporating the at least one testing parameter, virtually navigate the virtual vehicle through the virtual environment, collect virtual sensor data, and processing the collected virtual sensor data.","abstract_2":"Aspects of the disclosure relate to classifying the status of objects. For examples, one or more computing devices detect an object from an image of a vehicle's environment. The object is associated with a location. The one or more computing devices receive data corresponding to the surfaces of objects in the vehicle's environment and identifying data within a region around the location of the object. The one or more computing devices also determine whether the data within the region corresponds to a planar surface extending away from an edge of the object. Based on this determination, the one or more computing devices classify the status of the object.","priority_1":"2015-01-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666725179},{"pair":"US-10282984-B2 & US-9400183-B1","patent_1":"US-10282984-B2","title_1":"Inductive loop detection systems and methods ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US10282984B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2017-05-30T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666613727},{"pair":"US-2018350234-A1 & US-9400183-B1","patent_1":"US-2018350234-A1","title_1":"Inductive Loop Detection Systems And Methods ","patent_2":"US-9400183-B1","title_2":"Method and apparatus to transition between levels using warp zones ","link_1":"https:\/\/patents.google.com\/patent\/US20180350234A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9400183B1\/en","abstract_1":"Example inductive loop detection systems and methods are described. In one implementation, a method receives image data from a camera of a vehicle and determines a geographic position of the vehicle. Based on the image data and the geographic position of the vehicle, the method determines a location of an inductive loop in a roadway proximate the vehicle. The data associated with the location of the inductive loop is stored in a storage device within the vehicle. For a vehicle, a detectable zone may be determined based on actual or simulated outputs an inductive loop system at various locations relative to the vehicle. While driving, the vehicle is controlled to cause the detectable zone to pass over or stop over a known location of the inductive loop.","abstract_2":"An autonomous vehicle may access portions of a map to maneuver a roadway. The map may be split into one or more levels that represent different regions in space. For example, an overpass may be represented by one level while the road below the overpass may be on a separate level. A vehicle traveling on a particular level may use map data that is associated with that level. Furthermore, if the vehicle travels through a warp zone, it may transition from the current level to a destination level and thus begin to use map data associated with the destination level.","priority_1":"2017-05-30T00:00:00","priority_2":"2011-11-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666613727},{"pair":"US-2016325779-A1 & US-2018011496-A1","patent_1":"US-2016325779-A1","title_1":"Hands-off steering wheel governed by pedestrian detection ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20160325779A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle may be steered without a driver's hands being on a vehicle steering control mechanism. A presence of an object within a predetermined distance of the vehicle may be detected using data from at least one object detection sensor that provides data to at least one of a passive safety system, a lane control system, a speed control system, and a brake control system. A steering control mechanism hands-on mode can then be enabled based at least in part on the presence of the object.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-05-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666557062},{"pair":"US-2016210775-A1 & US-2018135972-A1","patent_1":"US-2016210775-A1","title_1":"Virtual sensor testbed ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20160210775A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A computing device comprising a processing circuit and a data storage medium. The computing device is programmed to receive virtual sensor data that represents data collected by a virtual sensor associated with autonomously operating a virtual vehicle in a virtual environment and process the virtual sensor data to identify a limitation of a real-world sensor.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-01-21T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666380091},{"pair":"US-10259455-B2 & US-9862364-B2","patent_1":"US-10259455-B2","title_1":"Collision avoidance systems and methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259455B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example collision avoidance systems and methods are described. In one implementation, a method receives data from multiple sensors mounted to a first vehicle. A collision avoidance system determines a likelihood that a second vehicle will collide with the back of the first vehicle based on the received data. If a collision is likely, the method identifies open space near the first vehicle and determines a best action to avoid or mitigate the likely collision based on the identified open space.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-01-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666255068},{"pair":"US-2018208190-A1 & US-9862364-B2","patent_1":"US-2018208190-A1","title_1":"Collision Avoidance Systems And Methods ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180208190A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Example collision avoidance systems and methods are described. In one implementation, a method receives data from multiple sensors mounted to a first vehicle. A collision avoidance system determines a likelihood that a second vehicle will collide with the back of the first vehicle based on the received data. If a collision is likely, the method identifies open space near the first vehicle and determines a best action to avoid or mitigate the likely collision based on the identified open space.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-01-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666255068},{"pair":"US-10453346-B2 & US-10496091-B1","patent_1":"US-10453346-B2","title_1":"Vehicle light control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10453346B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system including a computer for a vehicle is programmed to identify the vehicle as a lead vehicle in a platoon of three or more vehicles, and to identify one of the vehicles in the platoon as a caboose vehicle. The computer is programmed to deactivate a rear light of the lead vehicle, and to instruct activation of a rear light of the caboose vehicle.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-09-07T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8666042937},{"pair":"US-2016210382-A1 & US-9836052-B1","patent_1":"US-2016210382-A1","title_1":"Autonomous driving refined in virtual environments ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20160210382A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A computing device includes a processing circuit and a data storage medium. The computing device is programmed to receive a user input selecting at least one testing parameter associated with autonomously operating a virtual vehicle in a virtual environment, simulate the virtual environment incorporating the at least one testing parameter, virtually navigate the virtual vehicle through the virtual environment, collect virtual sensor data, and processing the collected virtual sensor data.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-01-21T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665962694},{"pair":"US-2017248951-A1 & US-2016082953-A1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-2016082953-A1","title_2":"Consideration of Risks in Active Sensing for an Autonomous Vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160082953A1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"An autonomous vehicle configured for active sensing may also be configured to weigh expected information gains from active-sensing actions against risk costs associated with the active-sensing actions. An example method involves: (a) receiving information from one or more sensors of an autonomous vehicle, (b) determining a risk-cost framework that indicates risk costs across a range of degrees to which an active-sensing action can be performed, wherein the active-sensing action comprises an action that is performable by the autonomous vehicle to potentially improve the information upon which at least one of the control processes for the autonomous vehicle is based, (c) determining an information-improvement expectation framework across the range of degrees to which the active-sensing action can be performed, and (d) applying the risk-cost framework and the information-improvement expectation framework to determine a degree to which the active-sensing action should be performed.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-05-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665827373},{"pair":"US-2019374151-A1 & US-9669827-B1","patent_1":"US-2019374151-A1","title_1":"Focus-Based Tagging Of Sensor Data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190374151A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Data from sensors of a vehicle is captured along with data tracking a driver's gaze. The route traveled by the vehicle may also be captured. The driver's gaze is evaluated with respect to the sensor data to determine a feature the driver was focused on. A focus record is created for the feature. Focus records for many drivers may be aggregated to determine a frequency of observation of the feature. A machine learning model may be trained using the focus records to identify a region of interest for a given scenario in order to more quickly identify relevant hazards.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-06-08T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665785923},{"pair":"US-2018105009-A1 & US-9836052-B1","patent_1":"US-2018105009-A1","title_1":"Roadway-Crossing-Anomaly Detection System and Method ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180105009A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665449991},{"pair":"US-10207560-B2 & US-9836052-B1","patent_1":"US-10207560-B2","title_1":"Roadway-crossing-anomaly detection system and method ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10207560B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A method for improving the safety and comfort of a vehicle driving over a railroad track, cattle guard, or the like. The method may include receiving, by a computer system, one or more inputs corresponding to one or more forward looking sensors. The computer system may also receive data characterizing a motion of the vehicle. The computer system may estimate, based on the one or more inputs and the data, a motion of a vehicle with respect to a railroad track, cattle guard, or the like extending across a road ahead of the vehicle. Accordingly, the computer system may change a suspension setting, steering setting, or the like of the vehicle to more safely or comfortably drive over the railroad track, cattle guard, or the like.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665449991},{"pair":"US-2018203457-A1 & US-10126141-B2","patent_1":"US-2018203457-A1","title_1":"System and Method for Avoiding Interference with a Bus ","patent_2":"US-10126141-B2","title_2":"Systems and methods for using real-time imagery in navigation ","link_1":"https:\/\/patents.google.com\/patent\/US20180203457A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10126141B2\/en","abstract_1":"A method for avoiding interference with a bus. The method includes detecting a bus and obtaining image data from the bus, such as information displayed on the bus. A deep neural network trained on bus images may process the information to associate the bus with a bus route and stop locations. Map data corresponding to the stop locations may also be obtained and used to initiate a lane change or safety response in response to proximity of the bus to a stop location. A corresponding system and computer program product is also disclosed and claimed herein.","abstract_2":"To generate navigation directions for a driver of a vehicle, a route for guiding the driver to a destination is obtained, visual landmarks corresponding to prominent physical objects disposed along the route are retrieved, and real-time imagery is collected at the vehicle approximately from a vantage point of the driver during navigation along the route. Using (i) the retrieved visual landmarks and (ii) the imagery collected at the vehicle, a subset of the visual landmarks that are currently visible to the driver is selected. Navigation directions describing the route are provided the driver, the navigation directions referencing the selected subset of the visual landmarks and excluding the remaining visual landmarks.","priority_1":"2017-01-13T00:00:00","priority_2":"2016-05-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665350299},{"pair":"US-2018120857-A1 & US-9646497-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665278588},{"pair":"US-2017248953-A1 & US-2016155452-A1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-2016155452-A1","title_2":"Method for Siren Detection Based on Audio Samples ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160155452A1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"The present disclosure provides methods and apparatuses that enable an apparatus to identify sounds from short samples of audio. The apparatus may capture an audio sample and create several audio signals of different lengths, each containing audio from the captured audio sample. The apparatus my process the several audio signals in an attempt to identify features of the audio signal that indicate an identification of the captured sound. Because shorter audio samples can be analyzed more quickly, the system may first process the shortest audio samples in order to quickly identify features of the audio signal. Because longer audio samples contain more information, the system may be able to more accurately identify features in the audio signal in longer audio samples. However, analyzing longer audio signals takes more buffered audio than identifying features in shorter signals. Therefore, the present system attempts to identify features in the shortest audio signals first.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665263543},{"pair":"US-2017248951-A1 & US-2016370801-A1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665197617},{"pair":"US-2019161085-A1 & US-9599989-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9599989-B1","title_2":"Use of motion data in the processing of automotive radar image processing ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9599989B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"In an example method, a vehicle configured to operate in an autonomous mode could have a radar system used to aid in vehicle guidance. The method could include a plurality of antennas configured to transmit and receive electromagnetic signals. The method may also include a one or more sensors configured to measure a movement of the vehicle. A portion of the method may be performed by a processor configured to: i) determine adjustments based on the movement of the vehicle; ii) calculate distance and direction information for received electromagnetic signals; and iii) recover distance and direction information for received electromagnetic signals with the adjustments applied. The processor may be further configured to adjust the movement of the autonomous vehicle based on the distance and direction information with adjustments applied.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-09-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665150259},{"pair":"US-10481609-B2 & US-2018143643-A1","patent_1":"US-10481609-B2","title_1":"Parking-lot-navigation system and method ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10481609B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system and method for assisted or autonomous parking of a vehicle is disclosed. The method may begin when the vehicle approaches a feeder lane within a parking lot. At that point, a computer system may decide whether the vehicle should enter the feeder lane. The computer system may use at least one of machine learning, computer vision, and range measurements to determining whether a condition precedent for entering the feeder lane exists. The condition precedent may include an in-bound arrow on the feeder lane or parking lines and\/or a parked vehicle adjacent the feeder lane defining a departure angle less than or equal to ninety degrees. If the condition precedent exists, the vehicle may enter the feeder lane. If the condition precedent does not exist, the vehicle may move on to another feeder lane.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-12-09T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665091581},{"pair":"US-2018319402-A1 & US-2017341643-A1","patent_1":"US-2018319402-A1","title_1":"System and method for automatic activation of driver assistance feature ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180319402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Embodiments include a vehicle system comprising a display capable of displaying a message indicating automatic activation of a driver assistance feature; at least one electronic control unit configured to determine whether preset driving conditions are met; and a processor configured to cause the display to display the message upon receiving a notification indicating satisfaction of the conditions, initiate a countdown, and automatically activate the driver assistance feature upon completion of the countdown. Embodiments also include a method of activating a driver assistance feature in a vehicle. The method includes receiving, at a processor, a notification indicating satisfaction of preset driving conditions; in response, displaying, on a display, a message indicating automatic activation of the driver assistance feature; initiating a countdown, using the processor; and automatically activating the driver assistance feature, using the processor, upon completion of the countdown.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-05-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665043925},{"pair":"US-2017248952-A1 & US-2016082953-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016082953-A1","title_2":"Consideration of Risks in Active Sensing for an Autonomous Vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160082953A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"An autonomous vehicle configured for active sensing may also be configured to weigh expected information gains from active-sensing actions against risk costs associated with the active-sensing actions. An example method involves: (a) receiving information from one or more sensors of an autonomous vehicle, (b) determining a risk-cost framework that indicates risk costs across a range of degrees to which an active-sensing action can be performed, wherein the active-sensing action comprises an action that is performable by the autonomous vehicle to potentially improve the information upon which at least one of the control processes for the autonomous vehicle is based, (c) determining an information-improvement expectation framework across the range of degrees to which the active-sensing action can be performed, and (d) applying the risk-cost framework and the information-improvement expectation framework to determine a degree to which the active-sensing action should be performed.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-05-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664984062},{"pair":"US-2017316684-A1 & US-9255805-B1","patent_1":"US-2017316684-A1","title_1":"Vehicle lane map estimation ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170316684A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-04-29T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664911097},{"pair":"US-10121367-B2 & US-9255805-B1","patent_1":"US-10121367-B2","title_1":"Vehicle lane map estimation ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10121367B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A computer can receive, from a vehicle sensor, data about a plurality of second vehicles, define two or more vehicle clusters based on location data of second vehicles, each cluster including two or more of the second vehicles determined to be traveling in a same lane, identify two or more lane boundaries according to clusters, and use lane boundaries to generate a lane map.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-04-29T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664911097},{"pair":"US-2017072962-A1 & US-9779621-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9779621-B1","title_2":"Intersection phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9779621B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Methods and apparatus are disclosed for providing information about road features. A server can receive reports from information sources associated with a road feature that can include a road intersection. Each report can include source data obtained at a respective time. The source data from the reports can be stored at the server. The server can construct a phase map, where the phase map is configured to represent a status of the road feature at one or more times. The server can receive an information request related to the road feature at a specified time. In response to the information request, the server can generate an information response including a prediction of a status related to the road feature at the specified time. The prediction can be provided by the phase map and is based on information request. The information response can be sent from the server.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-03-15T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664893733},{"pair":"US-2019111922-A1 & US-9836052-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664722019},{"pair":"US-2018033309-A1 & US-9463794-B1","patent_1":"US-2018033309-A1","title_1":"Systems and methods of an overtaking lane control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180033309A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"An overtaking lane control system in a vehicle comprises a lane determination unit to recognize road configuration; an obstacle monitoring unit to detect approaching vehicles in adjacent lanes; and an overtaking lane control unit to issue a first alert to a driver to warn the driver to return to a normal lane when the overtaking lane control unit determines that the vehicle has travelled in an overtaking lane for a first predetermined time and it is safe to change to the normal lane.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-07-29T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664718457},{"pair":"US-10026317-B2 & US-9684836-B1","patent_1":"US-10026317-B2","title_1":"Autonomous probability control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10026317B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"An action probability factor is developed based at least in part on a plurality of probability arrays predicting one or more probabilities of a deviation from at least one of a planned vehicle direction, position, speed, and acceleration. Levels of autonomous control are transitioned based at least in part on the action probability factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664715873},{"pair":"US-2019362168-A1 & US-9575490-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9575490-B2","title_2":"Mapping active and inactive construction zones for autonomous driving ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9575490B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the present disclosure relate to differentiating between active and inactive construction zones. In one example, this may include identifying a construction object associated with a construction zone. The identified construction object may be used to map the area of the construction zone. Detailed map information may then be used to classify the activity of the construction zone. The area of the construction zone and the classification may be added to the detailed map information. Subsequent to adding the construction zone and the classification to the detailed map information, the construction object (or another construction object) may be identified. The location of the construction object may be used to identify the construction zone and classification from the detailed map information. The classification of the classification may be used to operate a vehicle having an autonomous mode.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-04-10T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664682602},{"pair":"US-2017248953-A1 & US-9440652-B1","patent_1":"US-2017248953-A1","title_1":"Autonomous peril control ","patent_2":"US-9440652-B1","title_2":"Filtering noisy\/high-intensity regions in laser-based lane marker detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248953A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9440652B1\/en","abstract_1":"At least one object having a risk of collision with the vehicle is detected. Levels of autonomous control are transitioned in response to detection of a potential collision based at least in part on an autonomous peril factor which includes a probability of collision and a magnitude of possible damage in the event of a collision.","abstract_2":"An autonomous vehicle may be configured to receive, using a computer system, a plurality of remission signals from a portion of a lane of travel in an environment in response to at least one sensor of the vehicle sensing the portion of the lane of travel. A given remission signal of the plurality of remission signals may include a remission value indicative of a level of reflectiveness for the portion of the lane of travel. The vehicle may also be configured to compare the plurality of remission signals to a known remission value indicative of a level of reflectiveness for a lane marker in the lane of travel. Based on the comparison, the vehicle may additionally be configured to determine whether the portion of the lane of travel in the environment is indicative of a presence of the lane marker.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-08-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664483867},{"pair":"US-2019347498-A1 & US-2018135972-A1","patent_1":"US-2019347498-A1","title_1":"Systems and methods for automated detection of trailer properties ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190347498A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Methods and apparatus are disclosed for automated detection of trailer properties. An example vehicle includes an inter-vehicle communication module and an infotainment head unit. The infotainment head unit is configured to detect presence of an attached trailer. The infotainment head unit is also configured to, in response to a determination that the attached trailer is an unrecognized trailer broadcast a request for images via the inter-vehicle communication module, perform semantic segmentation on the images, generate a three dimensional point cloud using the segmented images, and estimate a property of the attached trailer based on the three dimensional point cloud","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-05-09T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664457357},{"pair":"US-2017139420-A1 & US-10146223-B1","patent_1":"US-2017139420-A1","title_1":"Automotive drone deployment system ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170139420A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"This disclosure generally relates to an automotive drone deployment system that includes at least a vehicle and a deployable drone that is configured to attach and detach from the vehicle. More specifically, the disclosure describes the vehicle and drone remaining in communication with each other to exchange information while the vehicle is being operated in an autonomous driving mode so that the vehicle's performance under the autonomous driving mode is enhanced.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-07-16T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664355579},{"pair":"US-2017248951-A1 & US-9684836-B1","patent_1":"US-2017248951-A1","title_1":"Autonomous confidence control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664302514},{"pair":"US-2019012913-A1 & US-2016370801-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2016370801-A1","title_2":"Remote Assistance for an Autonomous Vehicle in Low Confidence Situations ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160370801A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664221398},{"pair":"US-2020031468-A1 & US-9387854-B1","patent_1":"US-2020031468-A1","title_1":"Drone-based vehicle illumination ","patent_2":"US-9387854-B1","title_2":"Use of environmental information to aid image processing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200031468A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9387854B1\/en","abstract_1":null,"abstract_2":"An autonomous vehicle may be configured to use environmental information for image processing. The vehicle may be configured to operate in an autonomous mode in an environment and may be operating substantially in a lane of travel of the environment. The vehicle may include a sensor configured to receive image data indicative of the environment. The vehicle may also include a computer system configured to compare environmental information indicative of the lane of travel to the image data so as to determine a portion of the image data that corresponds to the lane of travel of the environment. Based on the portion of the image data that corresponds to the lane of travel of the environment and by disregarding a remaining portion of the image data, the vehicle may determine whether an object is present in the lane, and based on the determination, provide instructions to control the vehicle in the autonomous mode in the environment.","priority_1":"2016-12-14T00:00:00","priority_2":"2013-06-24T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664023996},{"pair":"US-9989963-B2 & US-9440652-B1","patent_1":"US-9989963-B2","title_1":"Autonomous confidence control ","patent_2":"US-9440652-B1","title_2":"Filtering noisy\/high-intensity regions in laser-based lane marker detection ","link_1":"https:\/\/patents.google.com\/patent\/US9989963B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9440652B1\/en","abstract_1":"Signals are from a plurality of sources representing aspects of the vehicle and an environment surrounding the vehicle. An autonomous confidence factor is developed based on component confidence levels for at least one of the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the autonomous confidence factor.","abstract_2":"An autonomous vehicle may be configured to receive, using a computer system, a plurality of remission signals from a portion of a lane of travel in an environment in response to at least one sensor of the vehicle sensing the portion of the lane of travel. A given remission signal of the plurality of remission signals may include a remission value indicative of a level of reflectiveness for the portion of the lane of travel. The vehicle may also be configured to compare the plurality of remission signals to a known remission value indicative of a level of reflectiveness for a lane marker in the lane of travel. Based on the comparison, the vehicle may additionally be configured to determine whether the portion of the lane of travel in the environment is indicative of a presence of the lane marker.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-08-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664022197},{"pair":"US-2019111922-A1 & US-9373045-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663924961},{"pair":"US-2017248952-A1 & US-9440652-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9440652-B1","title_2":"Filtering noisy\/high-intensity regions in laser-based lane marker detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9440652B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"An autonomous vehicle may be configured to receive, using a computer system, a plurality of remission signals from a portion of a lane of travel in an environment in response to at least one sensor of the vehicle sensing the portion of the lane of travel. A given remission signal of the plurality of remission signals may include a remission value indicative of a level of reflectiveness for the portion of the lane of travel. The vehicle may also be configured to compare the plurality of remission signals to a known remission value indicative of a level of reflectiveness for a lane marker in the lane of travel. Based on the comparison, the vehicle may additionally be configured to determine whether the portion of the lane of travel in the environment is indicative of a presence of the lane marker.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-08-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663693002},{"pair":"US-2019219697-A1 & US-9697606-B2","patent_1":"US-2019219697-A1","title_1":"Lidar localization ","patent_2":"US-9697606-B2","title_2":"Methods and systems for object detection using laser point clouds ","link_1":"https:\/\/patents.google.com\/patent\/US20190219697A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9697606B2\/en","abstract_1":"A system including a processor and a memory, the memory including instructions to be executed by the processor to determine map data, determine uncalibrated LIDAR data, determine a location of a vehicle in the map data by combining the map data with the uncalibrated LIDAR data, and operate the vehicle based on the location of the vehicle in the map data.","abstract_2":"Methods and systems for object detection using laser point clouds are described herein. In an example implementation, a computing device may receive laser data indicative of a vehicle's environment from a sensor and generate a two dimensional (2D) range image that includes pixels indicative of respective positions of objects in the environment based on the laser data. The computing device may modify the 2D range image to provide values to given pixels that map to portions of objects in the environment lacking laser data, which may involve providing values to the given pixels based on the average value of neighboring pixels positioned by the given pixels. Additionally, the computing device may determine normal vectors of sets of pixels that correspond to surfaces of objects in the environment based on the modified 2D range image and may use the normal vectors to provide object recognition information to systems of the vehicle.","priority_1":"2018-01-12T00:00:00","priority_2":"2014-04-25T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.866348434},{"pair":"US-10599146-B2 & US-2018143643-A1","patent_1":"US-10599146-B2","title_1":"Action-conditioned vehicle control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10599146B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-03-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663478575},{"pair":"US-2019111922-A1 & US-2018135972-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-10-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663344954},{"pair":"US-2017016740-A1 & US-2017341643-A1","patent_1":"US-2017016740-A1","title_1":"Method and apparatus for determining a vehicle ego-position ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170016740A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a processor configured to receive image data gathered by a vehicle camera, relating to a fixed environmental feature. The processor is also configured to determine a vehicle position relative to the fixed environmental feature and determine a vehicle lane-level location on a digital map, based on the vehicle position relative to the fixed environmental feature.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-07-16T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663326367}]