[{"pair":"US-2017174261-A1 & US-9862364-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9276694351},{"pair":"US-2017174261-A1 & US-9669827-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9217148966},{"pair":"US-9983591-B2 & US-9862364-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9216816239},{"pair":"US-2018239361-A1 & US-9862364-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9213681379},{"pair":"US-9983591-B2 & US-9669827-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9197477237},{"pair":"US-2018239361-A1 & US-9669827-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.919133933},{"pair":"US-10423847-B2 & US-9669827-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.912842262},{"pair":"US-2019362168-A1 & US-9669827-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9116023301},{"pair":"US-2017174261-A1 & US-10156851-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9110571537},{"pair":"US-2017174261-A1 & US-9557736-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9100298006},{"pair":"US-10259457-B2 & US-2018135972-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9089838515},{"pair":"US-10259457-B2 & US-2018143643-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9081384283},{"pair":"US-2017072962-A1 & US-2018135972-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9075835017},{"pair":"US-2017072962-A1 & US-2018143643-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9073475957},{"pair":"US-9983591-B2 & US-9557736-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9069205254},{"pair":"US-2018239361-A1 & US-9557736-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9066577968},{"pair":"US-2019012913-A1 & US-9551992-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9053828388},{"pair":"US-2017072962-A1 & US-10146223-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9043884488},{"pair":"US-10259457-B2 & US-9836052-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9037379899},{"pair":"US-2017072962-A1 & US-9836052-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9035610312},{"pair":"US-2017072962-A1 & US-10156851-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9034867935},{"pair":"US-10259457-B2 & US-10146223-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9034376542},{"pair":"US-2017206426-A1 & US-9669827-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9025774049},{"pair":"US-9983591-B2 & US-2017341643-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9023633922},{"pair":"US-10259457-B2 & US-10156851-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9017713633},{"pair":"US-2018239361-A1 & US-2017341643-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9015565836},{"pair":"US-2017072962-A1 & US-9551992-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9015358642},{"pair":"US-10423847-B2 & US-9862364-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9012034256},{"pair":"US-2017174261-A1 & US-9766626-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9007570433},{"pair":"US-10259457-B2 & US-9551992-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9007348658},{"pair":"US-2019362168-A1 & US-9862364-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9005685584},{"pair":"US-2017072962-A1 & US-2017341643-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8997478407},{"pair":"US-2019039616-A1 & US-10156851-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.898858619},{"pair":"US-10259457-B2 & US-2017341643-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8988200025},{"pair":"US-10423847-B2 & US-9557736-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8987238466},{"pair":"US-2019039616-A1 & US-2017341643-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8986813494},{"pair":"US-2019012913-A1 & US-10156851-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8985569939},{"pair":"US-2019362168-A1 & US-9557736-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8978750027},{"pair":"US-2018239361-A1 & US-10059334-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8976513433},{"pair":"US-2017174261-A1 & US-2017341643-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8974798172},{"pair":"US-9983591-B2 & US-10156851-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8971555682},{"pair":"US-2017174261-A1 & US-10059334-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.896910873},{"pair":"US-2018239361-A1 & US-10156851-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8966606291},{"pair":"US-2017072962-A1 & US-9463794-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8964661297},{"pair":"US-9983591-B2 & US-10059334-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8964259213},{"pair":"US-2019101933-A1 & US-10156851-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8958901094},{"pair":"US-2019111922-A1 & US-2017341643-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8957594557},{"pair":"US-2019012913-A1 & US-2018143643-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8956437137},{"pair":"US-9983591-B2 & US-10496091-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8934203329},{"pair":"US-10259457-B2 & US-9463794-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.893266385},{"pair":"US-2019012913-A1 & US-2018135972-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8931942036},{"pair":"US-2018239361-A1 & US-10496091-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8931447929},{"pair":"US-2019039616-A1 & US-9551992-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8928250783},{"pair":"US-2018239361-A1 & US-9766626-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8926922022},{"pair":"US-2019039616-A1 & US-9862364-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8926683953},{"pair":"US-2017072962-A1 & US-10496091-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8925005431},{"pair":"US-2017174261-A1 & US-9463794-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8924800795},{"pair":"US-10423847-B2 & US-10496091-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.891406076},{"pair":"US-2019161085-A1 & US-2017098129-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8913594468},{"pair":"US-10423847-B2 & US-2017341643-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912700633},{"pair":"US-9983591-B2 & US-9766626-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912060845},{"pair":"US-2019111922-A1 & US-9862364-B2","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8910740177},{"pair":"US-2019362168-A1 & US-10496091-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8909782322},{"pair":"US-2019362168-A1 & US-2017341643-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8908743056},{"pair":"US-2018120857-A1 & US-9463794-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8902571424},{"pair":"US-10259457-B2 & US-10496091-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8898149297},{"pair":"US-10528055-B2 & US-9463794-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8893496131},{"pair":"US-10423847-B2 & US-9766626-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8877407963},{"pair":"US-10423847-B2 & US-10059334-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8874086566},{"pair":"US-10423847-B2 & US-10156851-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8873212463},{"pair":"US-2018099663-A1 & US-9669827-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8872065781},{"pair":"US-9983591-B2 & US-9463794-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8868826096},{"pair":"US-2019362168-A1 & US-10156851-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867934134},{"pair":"US-2018099663-A1 & US-2017341643-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867246271},{"pair":"US-10589742-B2 & US-2017098129-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8866139637},{"pair":"US-2017174261-A1 & US-10496091-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.886075253},{"pair":"US-2018239361-A1 & US-9463794-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8859512805},{"pair":"US-2019362168-A1 & US-10059334-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8859060165},{"pair":"US-10377376-B2 & US-9669827-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8856725154},{"pair":"US-10377376-B2 & US-2017341643-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855436649},{"pair":"US-2019362168-A1 & US-9766626-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8853473968},{"pair":"US-2019012913-A1 & US-2017341643-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8851730787},{"pair":"US-2018120857-A1 & US-2018143643-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.885050048},{"pair":"US-2019012913-A1 & US-9862364-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8846464417},{"pair":"US-2019012913-A1 & US-10146223-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845377034},{"pair":"US-10528055-B2 & US-2018143643-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845368785},{"pair":"US-2017247040-A1 & US-9766626-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845065977},{"pair":"US-2019111922-A1 & US-9766626-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8844196098},{"pair":"US-2018239361-A1 & US-10146223-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8843374501},{"pair":"US-9983591-B2 & US-10146223-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841261491},{"pair":"US-2019362168-A1 & US-10146223-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8837252185},{"pair":"US-2019161085-A1 & US-10204278-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8836129197},{"pair":"US-2018099663-A1 & US-9862364-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835688565},{"pair":"US-10423847-B2 & US-10146223-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835307773},{"pair":"US-2017248952-A1 & US-9766626-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.883367065},{"pair":"US-10259457-B2 & US-9766626-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833656838},{"pair":"US-2019012913-A1 & US-10496091-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833570682},{"pair":"US-2019101933-A1 & US-9862364-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833553823},{"pair":"US-2017072962-A1 & US-2018011496-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8830624107},{"pair":"US-2019039616-A1 & US-9766626-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8826868131},{"pair":"US-2019101933-A1 & US-2017341643-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825867918},{"pair":"US-2017248952-A1 & US-10204278-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825202321},{"pair":"US-10289113-B2 & US-9766626-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8823409441},{"pair":"US-2019012913-A1 & US-9557736-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821720434},{"pair":"US-2019111922-A1 & US-10059334-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821086895},{"pair":"US-2017072962-A1 & US-9862364-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820866303},{"pair":"US-10377376-B2 & US-9862364-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820854139},{"pair":"US-2017206426-A1 & US-9862364-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820187733},{"pair":"US-2017247040-A1 & US-10204278-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818726256},{"pair":"US-2018099663-A1 & US-9836052-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815801686},{"pair":"US-2019101933-A1 & US-2018143643-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815660593},{"pair":"US-2019101933-A1 & US-9557736-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815099206},{"pair":"US-2017072962-A1 & US-9766626-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815087978},{"pair":"US-10377376-B2 & US-9836052-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814598587},{"pair":"US-2018099663-A1 & US-9557736-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814228747},{"pair":"US-2019362168-A1 & US-2018143643-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8813301824},{"pair":"US-10259457-B2 & US-2018011496-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8813287159},{"pair":"US-10345822-B1 & US-2017098129-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812678708},{"pair":"US-10423847-B2 & US-2018143643-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812435212},{"pair":"US-2018120857-A1 & US-10204278-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8809068528},{"pair":"US-2017247040-A1 & US-10059334-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880882991},{"pair":"US-10289113-B2 & US-10204278-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8808623799},{"pair":"US-10423847-B2 & US-2018011496-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8807519006},{"pair":"US-2019362168-A1 & US-2018011496-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8805694582},{"pair":"US-2018120857-A1 & US-2017098129-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8800180226},{"pair":"US-2017248952-A1 & US-10059334-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8799270991},{"pair":"US-2017174261-A1 & US-2018143643-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8798768929},{"pair":"US-10589742-B2 & US-10204278-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879822686},{"pair":"US-10259457-B2 & US-9862364-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8795589625},{"pair":"US-9983591-B2 & US-2018011496-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793807397},{"pair":"US-2018239361-A1 & US-2018011496-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8793433244},{"pair":"US-10528055-B2 & US-10204278-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792022109},{"pair":"US-10377376-B2 & US-9557736-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879109342},{"pair":"US-10345822-B1 & US-10204278-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789533611},{"pair":"US-10289113-B2 & US-10059334-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789236524},{"pair":"US-2019012913-A1 & US-2018011496-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8788521354},{"pair":"US-2019101933-A1 & US-9551992-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8783844102},{"pair":"US-10528055-B2 & US-2017098129-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781500087},{"pair":"US-2017072962-A1 & US-9669827-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781492849},{"pair":"US-2018120857-A1 & US-9862364-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781304238},{"pair":"US-2019012913-A1 & US-2017098129-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8780656848},{"pair":"US-2017174261-A1 & US-9836052-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.877786993},{"pair":"US-10528055-B2 & US-2018135972-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8777024404},{"pair":"US-2017174261-A1 & US-10204278-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8775257437},{"pair":"US-2019235520-A1 & US-2017098129-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774551274},{"pair":"US-2018099663-A1 & US-9463794-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774429523},{"pair":"US-10259457-B2 & US-10059334-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773535515},{"pair":"US-2018120857-A1 & US-2018135972-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773449742},{"pair":"US-2018239361-A1 & US-2018143643-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773258311},{"pair":"US-10259457-B2 & US-9669827-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8770471794},{"pair":"US-9983591-B2 & US-2018143643-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8767112259},{"pair":"US-2018120857-A1 & US-9836052-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8763611365},{"pair":"US-10528055-B2 & US-9862364-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.876294648},{"pair":"US-10377376-B2 & US-9463794-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762513662},{"pair":"US-10528055-B2 & US-9836052-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8758622936},{"pair":"US-2017206426-A1 & US-10496091-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8756022169},{"pair":"US-2017072962-A1 & US-10059334-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753134448},{"pair":"US-2019039616-A1 & US-9669827-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.875166165},{"pair":"US-2019235520-A1 & US-2018143643-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8751629644},{"pair":"US-10423847-B2 & US-2018135972-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8747569719},{"pair":"US-2017206426-A1 & US-10059334-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745629898},{"pair":"US-2019362168-A1 & US-2018135972-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8744781579},{"pair":"US-2017206426-A1 & US-2018143643-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.874459514},{"pair":"US-2019235520-A1 & US-9862364-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743542045},{"pair":"US-2018120857-A1 & US-9669827-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743050747},{"pair":"US-10423847-B2 & US-9836052-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8742789234},{"pair":"US-10423847-B2 & US-9463794-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8740626621},{"pair":"US-2019012913-A1 & US-9669827-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737558608},{"pair":"US-2019039616-A1 & US-10146223-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736756657},{"pair":"US-2019101933-A1 & US-10496091-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736401526},{"pair":"US-2019235520-A1 & US-2017341643-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8735905944},{"pair":"US-9983591-B2 & US-9836052-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734881605},{"pair":"US-2017174261-A1 & US-10146223-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734753486},{"pair":"US-2019362168-A1 & US-9836052-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8733719879},{"pair":"US-2017072962-A1 & US-9557736-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8733592323},{"pair":"US-10259457-B2 & US-2018152628-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8729763675},{"pair":"US-2019235520-A1 & US-10204278-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728583245},{"pair":"US-2017206426-A1 & US-9766626-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872825313},{"pair":"US-2020073405-A1 & US-2018143643-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727016823},{"pair":"US-2019362168-A1 & US-9463794-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872697555},{"pair":"US-2018239361-A1 & US-9836052-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8724421057},{"pair":"US-10528055-B2 & US-9669827-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722808697},{"pair":"US-10345822-B1 & US-2018135972-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722596656},{"pair":"US-10345822-B1 & US-2018143643-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720964776},{"pair":"US-2017072962-A1 & US-2018152628-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.872089394},{"pair":"US-2019235520-A1 & US-2018135972-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8719880115},{"pair":"US-2018239361-A1 & US-10204278-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8717209971},{"pair":"US-9983591-B2 & US-10204278-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8714582386},{"pair":"US-2017174261-A1 & US-2017098129-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712362066},{"pair":"US-10259457-B2 & US-9557736-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8710385688},{"pair":"US-10345822-B1 & US-9862364-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707709104},{"pair":"US-10345822-B1 & US-2017341643-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705624707},{"pair":"US-2020073405-A1 & US-2018135972-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.870558404},{"pair":"US-2017206426-A1 & US-2018135972-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705256316},{"pair":"US-10423847-B2 & US-10204278-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8702783994},{"pair":"US-2019362168-A1 & US-10204278-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693475807},{"pair":"US-2019101933-A1 & US-2018135972-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693043874},{"pair":"US-2017174261-A1 & US-2018135972-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690881293},{"pair":"US-2018120857-A1 & US-10156851-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690372641},{"pair":"US-2019039616-A1 & US-2018135972-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-09T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8689068811},{"pair":"US-2020073405-A1 & US-2017098129-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686505199},{"pair":"US-2019111922-A1 & US-10156851-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684796536},{"pair":"US-2019235520-A1 & US-9669827-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680490539},{"pair":"US-2019039616-A1 & US-10059334-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677840059},{"pair":"US-2018120857-A1 & US-2017341643-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677226295},{"pair":"US-2019012913-A1 & US-10204278-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676701014},{"pair":"US-10528055-B2 & US-10156851-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676259847},{"pair":"US-2020073405-A1 & US-2017341643-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671301766},{"pair":"US-10345822-B1 & US-9669827-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670280564},{"pair":"US-2019111922-A1 & US-9836052-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664722019},{"pair":"US-2019111922-A1 & US-2018135972-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-10-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663344954},{"pair":"US-10528055-B2 & US-2017341643-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663231553},{"pair":"US-2019012913-A1 & US-9463794-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8662512809},{"pair":"US-2020073405-A1 & US-9836052-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8660172566},{"pair":"US-2019111922-A1 & US-9669827-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8659150755},{"pair":"US-2019012913-A1 & US-9836052-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8654868883},{"pair":"US-2019101933-A1 & US-2018011496-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8646655723},{"pair":"US-10528055-B2 & US-2018152628-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8646554144},{"pair":"US-2018120857-A1 & US-2018152628-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8642497363},{"pair":"US-2018099663-A1 & US-10156851-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8641547867},{"pair":"US-2019101933-A1 & US-10146223-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8638076951},{"pair":"US-2019235520-A1 & US-10146223-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8636867787},{"pair":"US-2019111922-A1 & US-2018143643-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8636415548},{"pair":"US-10259457-B2 & US-2018102001-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8635425296},{"pair":"US-2019161085-A1 & US-2017341643-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8634278632},{"pair":"US-2019101933-A1 & US-9669827-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8633259342},{"pair":"US-2017206426-A1 & US-9463794-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8631165114},{"pair":"US-2019111922-A1 & US-10204278-B2","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8627928775},{"pair":"US-2017072962-A1 & US-2018102001-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8627806431},{"pair":"US-2019111922-A1 & US-9463794-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8626232908},{"pair":"US-10377376-B2 & US-10156851-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8625169297},{"pair":"US-2018239361-A1 & US-2018135972-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.862392493},{"pair":"US-2018120857-A1 & US-9766626-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8623913339},{"pair":"US-9983591-B2 & US-2018135972-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8622403126},{"pair":"US-2019235520-A1 & US-10496091-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8618503261},{"pair":"US-2018099663-A1 & US-10204278-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8617053547},{"pair":"US-2019039616-A1 & US-10496091-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8616271657},{"pair":"US-2019111922-A1 & US-9557736-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8615113465},{"pair":"US-2020073405-A1 & US-9862364-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8614145872},{"pair":"US-2019101933-A1 & US-10059334-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.861108439},{"pair":"US-10345822-B1 & US-10146223-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8609571826},{"pair":"US-2019161085-A1 & US-9766626-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8608407672},{"pair":"US-2019012913-A1 & US-2018152628-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8607297824},{"pair":"US-2017206426-A1 & US-10204278-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8606490469},{"pair":"US-10377376-B2 & US-10204278-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8606432728},{"pair":"US-10589742-B2 & US-2017341643-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8600728404},{"pair":"US-2019039616-A1 & US-9463794-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8599676331},{"pair":"US-2019161085-A1 & US-9862364-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8599327309},{"pair":"US-10345822-B1 & US-10496091-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8597187661},{"pair":"US-2019101933-A1 & US-9463794-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8596055746},{"pair":"US-10528055-B2 & US-9766626-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8594991946},{"pair":"US-2017174261-A1 & US-2018011496-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8590569624},{"pair":"US-2018099663-A1 & US-2017098129-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8586201546},{"pair":"US-2017247040-A1 & US-2017098129-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858559196},{"pair":"US-2017206426-A1 & US-10146223-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8584695863},{"pair":"US-10377376-B2 & US-2017098129-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8583902513},{"pair":"US-2017206426-A1 & US-9557736-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858224632},{"pair":"US-10589742-B2 & US-9766626-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8581992024},{"pair":"US-2017248952-A1 & US-2017098129-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8581806191},{"pair":"US-2019161085-A1 & US-10059334-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858098803},{"pair":"US-2019039616-A1 & US-9836052-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8579493546},{"pair":"US-2017247040-A1 & US-9862364-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8578894849},{"pair":"US-2019012913-A1 & US-9766626-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8576665116},{"pair":"US-10289113-B2 & US-9862364-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8574395959},{"pair":"US-2017206426-A1 & US-9836052-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8573393957},{"pair":"US-2018120857-A1 & US-2018102001-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8573246858},{"pair":"US-10528055-B2 & US-2018102001-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8572226676},{"pair":"US-2019101933-A1 & US-2017098129-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8571517771},{"pair":"US-2019235520-A1 & US-2018011496-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8571042071},{"pair":"US-2017248952-A1 & US-9862364-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570570983},{"pair":"US-2020073405-A1 & US-10059334-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":null,"abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570127934},{"pair":"US-2019111922-A1 & US-10146223-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.856945766},{"pair":"US-2019012913-A1 & US-10059334-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8567286055},{"pair":"US-2018099663-A1 & US-2018135972-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8567276254},{"pair":"US-2019101933-A1 & US-10204278-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8567226079},{"pair":"US-2019039616-A1 & US-9557736-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8566545569},{"pair":"US-2019039616-A1 & US-2018011496-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8566223471},{"pair":"US-10589742-B2 & US-9862364-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8565137897},{"pair":"US-10289113-B2 & US-2017098129-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8564306177},{"pair":"US-2020073405-A1 & US-10156851-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8559019577},{"pair":"US-10345822-B1 & US-9766626-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8558960958},{"pair":"US-10377376-B2 & US-2018135972-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8558116187},{"pair":"US-10423847-B2 & US-2017098129-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8555687863},{"pair":"US-2019362168-A1 & US-2017098129-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8553318788},{"pair":"US-10589742-B2 & US-10059334-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":null,"abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8553266391},{"pair":"US-2019039616-A1 & US-2018152628-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8551198182},{"pair":"US-2019235520-A1 & US-9766626-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8547697114},{"pair":"US-2020073405-A1 & US-9766626-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8544923028},{"pair":"US-2019111922-A1 & US-2017098129-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8540161435},{"pair":"US-2019111922-A1 & US-10496091-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8539040092},{"pair":"US-2019101933-A1 & US-9766626-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8534378109},{"pair":"US-2020073405-A1 & US-10204278-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8533573762},{"pair":"US-2017206426-A1 & US-10156851-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8532784055},{"pair":"US-2017247040-A1 & US-9669827-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8531531387},{"pair":"US-2017247040-A1 & US-2017341643-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8530691922},{"pair":"US-10289113-B2 & US-2017341643-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8526984031},{"pair":"US-10289113-B2 & US-9669827-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8523869296},{"pair":"US-2017248952-A1 & US-9669827-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8523595219},{"pair":"US-2017248952-A1 & US-2017341643-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8523016735},{"pair":"US-2020073405-A1 & US-10146223-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8521843664},{"pair":"US-2019161085-A1 & US-2018143643-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8520081708},{"pair":"US-10528055-B2 & US-10146223-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8519530639},{"pair":"US-2018120857-A1 & US-10146223-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8519200778},{"pair":"US-9983591-B2 & US-2017098129-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8518245302},{"pair":"US-2018239361-A1 & US-2017098129-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8516649631},{"pair":"US-2019101933-A1 & US-9836052-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8506577012},{"pair":"US-2019039616-A1 & US-2018143643-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8506336296},{"pair":"US-10259457-B2 & US-10204278-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8503500271},{"pair":"US-2017072962-A1 & US-10204278-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8503016316},{"pair":"US-2018099663-A1 & US-2018143643-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8500363019},{"pair":"US-2019161085-A1 & US-10156851-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.850002801},{"pair":"US-2017206426-A1 & US-2017341643-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8497873277},{"pair":"US-2019039616-A1 & US-2017098129-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8495886695},{"pair":"US-2018120857-A1 & US-10496091-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8494842314},{"pair":"US-2018099663-A1 & US-10146223-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8494408623},{"pair":"US-2019111922-A1 & US-2018011496-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8493583445},{"pair":"US-2018120857-A1 & US-9557736-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8490479186},{"pair":"US-10377376-B2 & US-2018143643-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8488127971},{"pair":"US-2019161085-A1 & US-9557736-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8487768874},{"pair":"US-10528055-B2 & US-10496091-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8483113528},{"pair":"US-10589742-B2 & US-2018143643-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8480955087},{"pair":"US-2018099663-A1 & US-10496091-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8480601237},{"pair":"US-10528055-B2 & US-9557736-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8479157055},{"pair":"US-2019235520-A1 & US-10059334-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8478018831},{"pair":"US-10377376-B2 & US-10146223-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8476856785},{"pair":"US-2017206426-A1 & US-2017098129-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8469029775},{"pair":"US-2018120857-A1 & US-10059334-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8467336548},{"pair":"US-2019012913-A1 & US-2018102001-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8465365509},{"pair":"US-10345822-B1 & US-2018011496-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8465205306},{"pair":"US-10345822-B1 & US-9463794-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8461803083},{"pair":"US-10589742-B2 & US-9557736-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.846055609},{"pair":"US-10345822-B1 & US-10059334-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8460387945},{"pair":"US-2019111922-A1 & US-9551992-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8460314814},{"pair":"US-2020073405-A1 & US-2018152628-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8457579703},{"pair":"US-2019039616-A1 & US-10204278-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8457453527},{"pair":"US-10589742-B2 & US-10156851-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8456636087},{"pair":"US-10377376-B2 & US-10496091-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8453964981},{"pair":"US-10259457-B2 & US-2017098129-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8447676646},{"pair":"US-2019111922-A1 & US-2018102001-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8447214629},{"pair":"US-2017072962-A1 & US-2017098129-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.844355531},{"pair":"US-10528055-B2 & US-10059334-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":null,"abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8440885512},{"pair":"US-10345822-B1 & US-9836052-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8439552829},{"pair":"US-2019235520-A1 & US-9463794-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.843378522},{"pair":"US-2017206426-A1 & US-2018011496-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.843134663},{"pair":"US-2017206426-A1 & US-2018152628-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8430004166},{"pair":"US-10423847-B2 & US-2018152628-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8429212534},{"pair":"US-2020073405-A1 & US-9463794-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8425995389},{"pair":"US-2019362168-A1 & US-2018152628-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8423217874},{"pair":"US-2019235520-A1 & US-10156851-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8422683908},{"pair":"US-2019235520-A1 & US-9836052-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8417097485},{"pair":"US-10345822-B1 & US-2018152628-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8417041422},{"pair":"US-2020073405-A1 & US-2018011496-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8412680199},{"pair":"US-10528055-B2 & US-2018011496-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8411357958},{"pair":"US-2018120857-A1 & US-2018011496-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8411350675},{"pair":"US-2020073405-A1 & US-2018102001-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8408672531},{"pair":"US-2019235520-A1 & US-9557736-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8400398478},{"pair":"US-10345822-B1 & US-10156851-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8399360443},{"pair":"US-2020073405-A1 & US-9669827-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8397050014},{"pair":"US-10345822-B1 & US-9557736-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.839099524},{"pair":"US-2019362168-A1 & US-2018102001-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8390382847},{"pair":"US-2019161085-A1 & US-9836052-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8390368656},{"pair":"US-2019111922-A1 & US-2018152628-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8388901007},{"pair":"US-10423847-B2 & US-2018102001-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.838121983},{"pair":"US-2019235520-A1 & US-2018152628-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8380985558},{"pair":"US-2017248952-A1 & US-2018102001-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8380322006},{"pair":"US-10289113-B2 & US-2018102001-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8379490916},{"pair":"US-2019161085-A1 & US-2018135972-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8375358605},{"pair":"US-2017248952-A1 & US-2018152628-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8371125924},{"pair":"US-2017174261-A1 & US-2018152628-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8370483618},{"pair":"US-10289113-B2 & US-2018152628-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.836993396},{"pair":"US-2017247040-A1 & US-2018102001-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8369361664},{"pair":"US-2017247040-A1 & US-2018152628-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.836753888},{"pair":"US-2018239361-A1 & US-2018102001-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8362811511},{"pair":"US-9983591-B2 & US-2018152628-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.836156618},{"pair":"US-9983591-B2 & US-2018102001-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8359681458},{"pair":"US-2018239361-A1 & US-2018152628-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.835814871},{"pair":"US-10589742-B2 & US-9836052-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8351551103},{"pair":"US-2020073405-A1 & US-10496091-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8349848556},{"pair":"US-10528055-B2 & US-9551992-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8349744835},{"pair":"US-2018120857-A1 & US-9551992-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8347242281},{"pair":"US-2020073405-A1 & US-9557736-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8344741834},{"pair":"US-2019039616-A1 & US-2018102001-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8338099709},{"pair":"US-2018239361-A1 & US-9551992-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8337122634},{"pair":"US-2018099663-A1 & US-9766626-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8336402445},{"pair":"US-9983591-B2 & US-9551992-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8334294824},{"pair":"US-2020073405-A1 & US-9551992-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8328374515},{"pair":"US-10377376-B2 & US-9766626-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8326953508},{"pair":"US-2017248952-A1 & US-2018135972-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8326492322},{"pair":"US-2017247040-A1 & US-2018135972-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8323204836},{"pair":"US-10589742-B2 & US-2018135972-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8318661528},{"pair":"US-2019161085-A1 & US-10146223-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8318420049},{"pair":"US-2017174261-A1 & US-9551992-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8317515991},{"pair":"US-2019161085-A1 & US-9463794-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8316579011},{"pair":"US-2019362168-A1 & US-9551992-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8311902607},{"pair":"US-10423847-B2 & US-9551992-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8310484822},{"pair":"US-10377376-B2 & US-2018152628-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8302522884},{"pair":"US-2017206426-A1 & US-2018102001-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8301276433},{"pair":"US-10289113-B2 & US-2018135972-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8300708337},{"pair":"US-2018099663-A1 & US-2018152628-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8295140958},{"pair":"US-10302744-B1 & US-2016368419-A1","patent_1":"US-10302744-B1","title_1":"Sensor assembly ","patent_2":"US-2016368419-A1","title_2":"Removable side view mirror for vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10302744B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160368419A1\/en","abstract_1":"A vehicle includes a roof and a housing having a bottom surface sealed to the roof. The vehicle includes a base in the housing and having a first surface sealed to the roof, a second surface opposite the first surface, and a duct extending from the first surface to the second surface. The vehicle includes a navigation sensor supported by the second surface. The vehicle includes a wire in electrical communication with the navigation sensor and extending through the duct.","abstract_2":"A side view mirror assembly includes a retention mechanism, a securing mechanism, and a reflective surface. The retention mechanism may be configured to engage at least a portion of a windowsill of a vehicle. The securing mechanism may be connected to the retention mechanism and configured to removably secure the mirror assembly to a surface of the vehicle. The reflective surface may be connected to the retention mechanism.","priority_1":"2018-02-23T00:00:00","priority_2":"2015-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8287147741},{"pair":"US-2019101933-A1 & US-2018152628-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8279463306},{"pair":"US-10589742-B2 & US-9463794-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8275556608},{"pair":"US-2018099663-A1 & US-10059334-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8274256106},{"pair":"US-2017174261-A1 & US-2018102001-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8268495086},{"pair":"US-10589742-B2 & US-10146223-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8267437905},{"pair":"US-10377376-B2 & US-10059334-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8263191907},{"pair":"US-2017248952-A1 & US-10156851-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8237606394},{"pair":"US-2017247040-A1 & US-10156851-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.823567645},{"pair":"US-2019235520-A1 & US-2018102001-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8233630016},{"pair":"US-10289113-B2 & US-10156851-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8230124005},{"pair":"US-2017247040-A1 & US-9836052-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8220199032},{"pair":"US-10345822-B1 & US-2018102001-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.821768751},{"pair":"US-10289113-B2 & US-9836052-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8217244307},{"pair":"US-2017248952-A1 & US-9836052-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8211641821},{"pair":"US-2017247040-A1 & US-9551992-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8210463845},{"pair":"US-2017248952-A1 & US-9551992-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8208379554},{"pair":"US-2017248952-A1 & US-2018011496-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8202142277},{"pair":"US-2017247040-A1 & US-2018011496-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8201079876},{"pair":"US-2017247040-A1 & US-2018143643-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.819454141},{"pair":"US-2017247040-A1 & US-10496091-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8192569291},{"pair":"US-2019161085-A1 & US-9669827-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8191230436},{"pair":"US-10289113-B2 & US-9551992-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8184635695},{"pair":"US-2017248952-A1 & US-10496091-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8184033134},{"pair":"US-2019161085-A1 & US-10496091-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8182046614},{"pair":"US-2017248952-A1 & US-2018143643-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8178763566},{"pair":"US-2017247040-A1 & US-9463794-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8177671923},{"pair":"US-10289113-B2 & US-9463794-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8175653312},{"pair":"US-2018099663-A1 & US-2018011496-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8171027425},{"pair":"US-10289113-B2 & US-2018011496-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8170264599},{"pair":"US-2017248952-A1 & US-9463794-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8168541553},{"pair":"US-10289113-B2 & US-10496091-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8165442121},{"pair":"US-10289113-B2 & US-2018143643-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8164669309},{"pair":"US-10589742-B2 & US-9669827-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8163204618},{"pair":"US-10589742-B2 & US-10496091-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8154067342},{"pair":"US-2019235520-A1 & US-9551992-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8151354758},{"pair":"US-10377376-B2 & US-2018011496-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8139339921},{"pair":"US-2019161085-A1 & US-2018011496-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8132679892},{"pair":"US-10345822-B1 & US-9551992-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.810074359},{"pair":"US-10589742-B2 & US-2018011496-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018011496-A1","title_2":"Testing predictions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180011496A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to testing predictions of an autonomous vehicle relating to another vehicle or object in a roadway. For instance, one or more processors may plan to maneuver the autonomous vehicle to complete an action and predict that the other vehicle will take a responsive action. The autonomous vehicle is then maneuvered towards completing the action in a way that would allow the autonomous vehicle to cancel completing the action without causing a collision between the first vehicle and the second vehicle, and in order to indicate to the second vehicle or a driver of the second vehicle that the first vehicle is attempting to complete the action. Thereafter, when the first vehicle is determined to be able to take the action, the action is completed by controlling the first vehicle autonomously using the determination of whether the second vehicle begins to take the particular responsive action.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8083734711},{"pair":"US-2017248952-A1 & US-9557736-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8079100604},{"pair":"US-2019101933-A1 & US-2018102001-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8075831342},{"pair":"US-2017247040-A1 & US-9557736-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8074559997},{"pair":"US-10289113-B2 & US-9557736-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8067030162},{"pair":"US-2019161085-A1 & US-2018152628-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8048852211},{"pair":"US-2019161085-A1 & US-2018102001-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8007544343},{"pair":"US-2017247040-A1 & US-10146223-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.7978994079},{"pair":"US-2017248952-A1 & US-10146223-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.797768184},{"pair":"US-10589742-B2 & US-2018152628-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018152628-A1","title_2":"Camera peek into turn ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180152628A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to adjusting a virtual camera's orientation when a vehicle is making a turn. One or more computing devices may receive the vehicle's original heading prior to making the turn and the vehicle's current heading. Based on the vehicle's original heading and the vehicle's current heading, the one or more computing devices may determine an angle of a turn the vehicle is performing and The one or more computing devices may determine a camera rotation angle and adjust the virtual camera's orientation relative to the vehicle to an updated orientation by rotating the virtual camera by the camera rotation angle and generate a video corresponding to the virtual camera's updated orientation. The video may be displayed on the display by the one or more computing devices.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-30T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.7976935605},{"pair":"US-2019161085-A1 & US-9551992-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.7976284481},{"pair":"US-10289113-B2 & US-10146223-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.7958986404},{"pair":"US-2017206426-A1 & US-9551992-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.795442562},{"pair":"US-10589742-B2 & US-2018102001-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.7949840337},{"pair":"US-10589742-B2 & US-9551992-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.7914424038},{"pair":"US-2018099663-A1 & US-2018102001-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.7846649857},{"pair":"US-10377376-B2 & US-2018102001-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018102001-A1","title_2":"Unexpected impulse change collision detector ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180102001A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting vehicle collisions. In one example, one or more computing devices may receive acceleration data of a vehicle and the expected acceleration data of the vehicle over a period of time. The one or more computing devices may determine a change in the vehicle's acceleration over the period of time, where the change in the vehicle's acceleration over the period of time is the difference between the expected acceleration data and the acceleration data. The one or more computing devices may detect an occurrence when the change in the vehicle's acceleration is greater than a threshold value and assign the occurrence into a collision category. Based on the assigned collision category, the one or more computing devices may perform a responsive action.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-10-07T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.784379778},{"pair":"US-2018099663-A1 & US-9551992-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.782722708},{"pair":"US-10377376-B2 & US-9551992-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9551992-B1","title_2":"Fall back trajectory systems for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551992B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure provide systems and methods for providing suggested locations for pick up and destination locations. Pick up locations may include locations where an autonomous vehicle can pick up a passenger, while destination locations may include locations where the vehicle can wait for an additional passenger, stop and wait for a passenger to perform some task and return to the vehicle, or for the vehicle to drop off a passenger. As such, a request for a vehicle may be received from a client computing device. The request may identify a first location. A set of one or more suggested locations may be selected by comparing the predetermined locations to the first location. The set may be provided to the client computing device.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-01-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.7799926714}]