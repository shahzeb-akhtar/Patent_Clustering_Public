[{"pair":"US-2017174261-A1 & US-9862364-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9276694351},{"pair":"US-2017174261-A1 & US-9669827-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9217148966},{"pair":"US-9983591-B2 & US-9862364-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9216816239},{"pair":"US-2018239361-A1 & US-9862364-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9213681379},{"pair":"US-9983591-B2 & US-9669827-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9197477237},{"pair":"US-2018239361-A1 & US-9669827-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.919133933},{"pair":"US-10423847-B2 & US-9669827-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.912842262},{"pair":"US-2019362168-A1 & US-9669827-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9116023301},{"pair":"US-2017174261-A1 & US-10156851-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9110571537},{"pair":"US-2017174261-A1 & US-9557736-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9100298006},{"pair":"US-10259457-B2 & US-2018135972-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9089838515},{"pair":"US-10259457-B2 & US-2018143643-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9081384283},{"pair":"US-2017072962-A1 & US-2018135972-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9075835017},{"pair":"US-2017072962-A1 & US-2018143643-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9073475957},{"pair":"US-9983591-B2 & US-9557736-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9069205254},{"pair":"US-2018239361-A1 & US-9557736-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9066577968},{"pair":"US-2017072962-A1 & US-10146223-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9043884488},{"pair":"US-10259457-B2 & US-9836052-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9037379899},{"pair":"US-2017072962-A1 & US-9836052-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9035610312},{"pair":"US-2017072962-A1 & US-10156851-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9034867935},{"pair":"US-10259457-B2 & US-10146223-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9034376542},{"pair":"US-2017206426-A1 & US-9669827-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9025774049},{"pair":"US-9983591-B2 & US-2017341643-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9023633922},{"pair":"US-10259457-B2 & US-10156851-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9017713633},{"pair":"US-2018239361-A1 & US-2017341643-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9015565836},{"pair":"US-10423847-B2 & US-9862364-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9012034256},{"pair":"US-2017174261-A1 & US-9766626-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.9007570433},{"pair":"US-2019362168-A1 & US-9862364-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.9005685584},{"pair":"US-2017072962-A1 & US-2017341643-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8997478407},{"pair":"US-2019039616-A1 & US-10156851-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.898858619},{"pair":"US-10259457-B2 & US-2017341643-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8988200025},{"pair":"US-10423847-B2 & US-9557736-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8987238466},{"pair":"US-2019039616-A1 & US-2017341643-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8986813494},{"pair":"US-2019012913-A1 & US-10156851-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8985569939},{"pair":"US-2019362168-A1 & US-9557736-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8978750027},{"pair":"US-2018239361-A1 & US-10059334-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8976513433},{"pair":"US-2017174261-A1 & US-2017341643-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8974798172},{"pair":"US-9983591-B2 & US-10156851-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8971555682},{"pair":"US-2017174261-A1 & US-10059334-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.896910873},{"pair":"US-2018239361-A1 & US-10156851-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8966606291},{"pair":"US-2019161085-A1 & US-9373045-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.896532188},{"pair":"US-2017072962-A1 & US-9463794-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8964661297},{"pair":"US-9983591-B2 & US-10059334-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8964259213},{"pair":"US-2019101933-A1 & US-10156851-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8958901094},{"pair":"US-2019111922-A1 & US-2017341643-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8957594557},{"pair":"US-2019012913-A1 & US-2018143643-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8956437137},{"pair":"US-2019161085-A1 & US-2016187887-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8944877245},{"pair":"US-2018120857-A1 & US-9682707-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8944793557},{"pair":"US-9983591-B2 & US-10496091-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8934203329},{"pair":"US-10259457-B2 & US-9463794-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.893266385},{"pair":"US-2019012913-A1 & US-2018135972-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-07-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8931942036},{"pair":"US-2018239361-A1 & US-10496091-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8931447929},{"pair":"US-10528055-B2 & US-9682707-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8930302864},{"pair":"US-10589742-B2 & US-9373045-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":null,"abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.892730577},{"pair":"US-2018239361-A1 & US-9766626-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8926922022},{"pair":"US-2019039616-A1 & US-9862364-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8926683953},{"pair":"US-2017072962-A1 & US-10496091-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8925005431},{"pair":"US-2017174261-A1 & US-9463794-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8924800795},{"pair":"US-2019161085-A1 & US-9707966-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8923424677},{"pair":"US-2018120857-A1 & US-9255805-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8917364271},{"pair":"US-2019161085-A1 & US-9684836-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8916366937},{"pair":"US-10423847-B2 & US-10496091-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.891406076},{"pair":"US-2019161085-A1 & US-2017098129-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8913594468},{"pair":"US-10423847-B2 & US-2017341643-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912700633},{"pair":"US-9983591-B2 & US-9766626-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8912060845},{"pair":"US-2019111922-A1 & US-9862364-B2","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8910740177},{"pair":"US-2017072962-A1 & US-9255805-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8910045746},{"pair":"US-2019362168-A1 & US-10496091-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8909782322},{"pair":"US-2019362168-A1 & US-2017341643-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8908743056},{"pair":"US-10589742-B2 & US-9707966-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":null,"abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8906092518},{"pair":"US-2017072962-A1 & US-9682707-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8903713965},{"pair":"US-10528055-B2 & US-9255805-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8903487112},{"pair":"US-2018120857-A1 & US-9463794-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8902571424},{"pair":"US-10259457-B2 & US-9255805-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8901883749},{"pair":"US-10589742-B2 & US-2016187887-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8898500923},{"pair":"US-10259457-B2 & US-10496091-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8898149297},{"pair":"US-10528055-B2 & US-9463794-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8893496131},{"pair":"US-2019039616-A1 & US-9679206-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8892077606},{"pair":"US-2018120857-A1 & US-9690296-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8884130258},{"pair":"US-10589742-B2 & US-9684836-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8882853715},{"pair":"US-10259457-B2 & US-9682707-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8877669357},{"pair":"US-10423847-B2 & US-9766626-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8877407963},{"pair":"US-2019039616-A1 & US-2016209844-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8876018661},{"pair":"US-10423847-B2 & US-10059334-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8874086566},{"pair":"US-10423847-B2 & US-10156851-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8873212463},{"pair":"US-2018099663-A1 & US-9669827-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8872065781},{"pair":"US-10528055-B2 & US-9690296-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8871337883},{"pair":"US-2019111922-A1 & US-9255805-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.887014754},{"pair":"US-9983591-B2 & US-9463794-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8868826096},{"pair":"US-2019362168-A1 & US-10156851-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867934134},{"pair":"US-10345822-B1 & US-9373045-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867764863},{"pair":"US-2019161085-A1 & US-9690296-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867688957},{"pair":"US-2018099663-A1 & US-2017341643-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8867246271},{"pair":"US-10589742-B2 & US-2017098129-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8866139637},{"pair":"US-2017174261-A1 & US-10496091-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.886075253},{"pair":"US-2018239361-A1 & US-9463794-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8859512805},{"pair":"US-2019362168-A1 & US-10059334-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8859060165},{"pair":"US-10377376-B2 & US-9669827-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8856725154},{"pair":"US-10377376-B2 & US-2017341643-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8855436649},{"pair":"US-2019362168-A1 & US-9766626-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8853473968},{"pair":"US-2019012913-A1 & US-2017341643-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8851730787},{"pair":"US-2018120857-A1 & US-2018143643-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.885050048},{"pair":"US-2019012913-A1 & US-9862364-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8846464417},{"pair":"US-2019012913-A1 & US-10146223-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845377034},{"pair":"US-10528055-B2 & US-2018143643-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845368785},{"pair":"US-2017247040-A1 & US-9766626-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8845065977},{"pair":"US-2019111922-A1 & US-9766626-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8844196098},{"pair":"US-2018239361-A1 & US-10146223-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8843374501},{"pair":"US-9983591-B2 & US-10146223-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8841261491},{"pair":"US-2019362168-A1 & US-10146223-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8837252185},{"pair":"US-2019161085-A1 & US-10204278-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8836129197},{"pair":"US-2018099663-A1 & US-9862364-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835688565},{"pair":"US-10423847-B2 & US-10146223-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8835307773},{"pair":"US-2017248952-A1 & US-9766626-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.883367065},{"pair":"US-10259457-B2 & US-9766626-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833656838},{"pair":"US-2019012913-A1 & US-10496091-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-07-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833570682},{"pair":"US-2019101933-A1 & US-9862364-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8833553823},{"pair":"US-2019039616-A1 & US-9766626-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8826868131},{"pair":"US-2019101933-A1 & US-2017341643-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825867918},{"pair":"US-2017248952-A1 & US-10204278-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8825202321},{"pair":"US-10289113-B2 & US-9766626-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8823409441},{"pair":"US-2019012913-A1 & US-9557736-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821720434},{"pair":"US-2019111922-A1 & US-10059334-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8821086895},{"pair":"US-2017072962-A1 & US-9862364-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820866303},{"pair":"US-2019235520-A1 & US-9373045-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820854591},{"pair":"US-10377376-B2 & US-9862364-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820854139},{"pair":"US-2017206426-A1 & US-9862364-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8820187733},{"pair":"US-2017247040-A1 & US-10204278-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8818726256},{"pair":"US-2018099663-A1 & US-9836052-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815801686},{"pair":"US-2019101933-A1 & US-2018143643-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815660593},{"pair":"US-2019101933-A1 & US-9557736-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815099206},{"pair":"US-2017072962-A1 & US-9766626-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8815087978},{"pair":"US-10589742-B2 & US-9690296-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814731551},{"pair":"US-10377376-B2 & US-9836052-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814598587},{"pair":"US-2019101933-A1 & US-9707966-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814337841},{"pair":"US-2018099663-A1 & US-9557736-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8814228747},{"pair":"US-2019362168-A1 & US-2018143643-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8813301824},{"pair":"US-10345822-B1 & US-2017098129-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812678708},{"pair":"US-10423847-B2 & US-2018143643-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8812435212},{"pair":"US-2018120857-A1 & US-10204278-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8809068528},{"pair":"US-2017247040-A1 & US-10059334-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880882991},{"pair":"US-10289113-B2 & US-10204278-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8808623799},{"pair":"US-2019111922-A1 & US-9690296-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8807407517},{"pair":"US-2017174261-A1 & US-9682707-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.880158036},{"pair":"US-2018120857-A1 & US-2017098129-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8800180226},{"pair":"US-2017248952-A1 & US-10059334-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8799270991},{"pair":"US-2017174261-A1 & US-2018143643-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8798768929},{"pair":"US-10589742-B2 & US-10204278-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879822686},{"pair":"US-2017248952-A1 & US-9679206-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8797316759},{"pair":"US-10259457-B2 & US-9862364-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8795589625},{"pair":"US-10528055-B2 & US-10204278-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8792022109},{"pair":"US-2017247040-A1 & US-9679206-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8791761538},{"pair":"US-10377376-B2 & US-9557736-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.879109342},{"pair":"US-10345822-B1 & US-10204278-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789533611},{"pair":"US-10289113-B2 & US-10059334-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8789236524},{"pair":"US-2020073405-A1 & US-9684836-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8785332157},{"pair":"US-2017174261-A1 & US-2016209844-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8783048765},{"pair":"US-10528055-B2 & US-2017098129-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781500087},{"pair":"US-2017072962-A1 & US-9669827-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781492849},{"pair":"US-2018120857-A1 & US-9862364-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8781304238},{"pair":"US-2019012913-A1 & US-2017098129-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8780656848},{"pair":"US-2017247040-A1 & US-9646497-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8779233652},{"pair":"US-10289113-B2 & US-9679206-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8778868356},{"pair":"US-2017174261-A1 & US-9836052-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.877786993},{"pair":"US-10528055-B2 & US-2018135972-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8777024404},{"pair":"US-2017174261-A1 & US-10204278-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8775257437},{"pair":"US-2019235520-A1 & US-2017098129-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774551274},{"pair":"US-2018099663-A1 & US-9463794-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8774429523},{"pair":"US-10259457-B2 & US-10059334-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773535515},{"pair":"US-2018120857-A1 & US-2018135972-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-11-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773449742},{"pair":"US-2018239361-A1 & US-2018143643-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8773258311},{"pair":"US-2019039616-A1 & US-9646497-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8772104291},{"pair":"US-10259457-B2 & US-9669827-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8770471794},{"pair":"US-10289113-B2 & US-9646497-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8769563851},{"pair":"US-9983591-B2 & US-2018143643-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8767112259},{"pair":"US-2017248952-A1 & US-9646497-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8766013937},{"pair":"US-2018120857-A1 & US-9836052-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8763611365},{"pair":"US-10528055-B2 & US-9862364-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.876294648},{"pair":"US-10377376-B2 & US-9463794-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8762513662},{"pair":"US-2018120857-A1 & US-9373045-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8761947237},{"pair":"US-2019111922-A1 & US-9646497-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8760332577},{"pair":"US-10528055-B2 & US-9836052-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8758622936},{"pair":"US-2017206426-A1 & US-10496091-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8756022169},{"pair":"US-2017072962-A1 & US-10059334-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8753134448},{"pair":"US-2019039616-A1 & US-9669827-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.875166165},{"pair":"US-2019235520-A1 & US-2018143643-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8751629644},{"pair":"US-10423847-B2 & US-2018135972-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8747569719},{"pair":"US-10345822-B1 & US-2016187887-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745746569},{"pair":"US-2017206426-A1 & US-10059334-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745629898},{"pair":"US-2018120857-A1 & US-2016187887-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8745532381},{"pair":"US-10345822-B1 & US-9707966-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8744893046},{"pair":"US-2019362168-A1 & US-2018135972-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8744781579},{"pair":"US-2017206426-A1 & US-2018143643-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.874459514},{"pair":"US-2019235520-A1 & US-9862364-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743542045},{"pair":"US-2018120857-A1 & US-9669827-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8743050747},{"pair":"US-10423847-B2 & US-9836052-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8742789234},{"pair":"US-10423847-B2 & US-9463794-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8740626621},{"pair":"US-10259457-B2 & US-9690296-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.873849535},{"pair":"US-10528055-B2 & US-2016187887-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737824685},{"pair":"US-2019012913-A1 & US-9669827-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8737558608},{"pair":"US-2019039616-A1 & US-10146223-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736756657},{"pair":"US-2019101933-A1 & US-10496091-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8736401526},{"pair":"US-2019235520-A1 & US-2017341643-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8735905944},{"pair":"US-9983591-B2 & US-9836052-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734881605},{"pair":"US-2017174261-A1 & US-10146223-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2015-12-17T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734753486},{"pair":"US-10528055-B2 & US-9373045-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":null,"abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8734577142},{"pair":"US-2019362168-A1 & US-9836052-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8733719879},{"pair":"US-2017072962-A1 & US-9557736-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8733592323},{"pair":"US-2019235520-A1 & US-10204278-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8728583245},{"pair":"US-2017206426-A1 & US-9766626-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872825313},{"pair":"US-2017072962-A1 & US-9690296-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727479944},{"pair":"US-2020073405-A1 & US-2018143643-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8727016823},{"pair":"US-2019362168-A1 & US-9463794-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872697555},{"pair":"US-2017247040-A1 & US-9690296-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872468399},{"pair":"US-2018239361-A1 & US-9836052-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8724421057},{"pair":"US-10528055-B2 & US-9669827-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722808697},{"pair":"US-2018120857-A1 & US-9707966-B2","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722723272},{"pair":"US-10345822-B1 & US-2018135972-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8722596656},{"pair":"US-2017174261-A1 & US-9373045-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2015-12-17T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.872223729},{"pair":"US-10345822-B1 & US-2018143643-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8720964776},{"pair":"US-2019235520-A1 & US-2018135972-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-01-26T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8719880115},{"pair":"US-2018239361-A1 & US-10204278-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8717209971},{"pair":"US-9983591-B2 & US-10204278-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8714582386},{"pair":"US-2017174261-A1 & US-2017098129-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8712362066},{"pair":"US-10259457-B2 & US-9557736-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2014-05-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8710385688},{"pair":"US-2017248952-A1 & US-9690296-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8709717904},{"pair":"US-2017174261-A1 & US-9707966-B2","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8708003008},{"pair":"US-10345822-B1 & US-9862364-B2","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8707709104},{"pair":"US-10345822-B1 & US-2017341643-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705624707},{"pair":"US-2020073405-A1 & US-2018135972-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2018-09-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.870558404},{"pair":"US-2017206426-A1 & US-2018135972-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-01-15T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8705256316},{"pair":"US-10423847-B2 & US-10204278-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8702783994},{"pair":"US-10259457-B2 & US-9646497-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8699661979},{"pair":"US-2019235520-A1 & US-9707966-B2","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696965462},{"pair":"US-10528055-B2 & US-9707966-B2","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":null,"abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8696600389},{"pair":"US-2019362168-A1 & US-10204278-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693475807},{"pair":"US-2018099663-A1 & US-9707966-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693408355},{"pair":"US-2019101933-A1 & US-2018135972-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-10-03T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8693043874},{"pair":"US-2017174261-A1 & US-9646497-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690996241},{"pair":"US-2017174261-A1 & US-2018135972-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-12-17T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690881293},{"pair":"US-2017174261-A1 & US-2016187887-A1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690402181},{"pair":"US-2018120857-A1 & US-10156851-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8690372641},{"pair":"US-2019039616-A1 & US-2018135972-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-09T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8689068811},{"pair":"US-2017248952-A1 & US-9684836-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8687331552},{"pair":"US-2019101933-A1 & US-2016187887-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686890301},{"pair":"US-2019111922-A1 & US-9682707-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686680791},{"pair":"US-2020073405-A1 & US-2017098129-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8686505199},{"pair":"US-2017247040-A1 & US-9684836-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8685219093},{"pair":"US-2019111922-A1 & US-10156851-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684796536},{"pair":"US-10289113-B2 & US-9690296-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684480099},{"pair":"US-2019012913-A1 & US-2016209844-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8684453486},{"pair":"US-2019012913-A1 & US-2016187887-A1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.868302755},{"pair":"US-2019235520-A1 & US-9669827-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680490539},{"pair":"US-10377376-B2 & US-9707966-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8680225332},{"pair":"US-2020073405-A1 & US-9255805-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8678498887},{"pair":"US-2019039616-A1 & US-10059334-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677840059},{"pair":"US-10289113-B2 & US-9684836-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677579493},{"pair":"US-2018120857-A1 & US-2017341643-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8677226295},{"pair":"US-2019012913-A1 & US-10204278-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676701014},{"pair":"US-10528055-B2 & US-10156851-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8676259847},{"pair":"US-2017072962-A1 & US-9646497-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674126888},{"pair":"US-2018099663-A1 & US-9373045-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8674028889},{"pair":"US-2019235520-A1 & US-2016187887-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8673698241},{"pair":"US-10345822-B1 & US-9255805-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8672469777},{"pair":"US-2020073405-A1 & US-2017341643-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8671301766},{"pair":"US-10345822-B1 & US-9669827-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8670280564},{"pair":"US-2019161085-A1 & US-9255805-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8669007094},{"pair":"US-10377376-B2 & US-9373045-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668198454},{"pair":"US-9983591-B2 & US-9682707-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8668094149},{"pair":"US-2018120857-A1 & US-9646497-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8665278588},{"pair":"US-2019111922-A1 & US-9836052-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8664722019},{"pair":"US-2019111922-A1 & US-9373045-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663924961},{"pair":"US-2019111922-A1 & US-2018135972-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-10-13T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663344954},{"pair":"US-10528055-B2 & US-2017341643-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-11-03T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8663231553},{"pair":"US-2020073405-A1 & US-9690296-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8662696053},{"pair":"US-2019012913-A1 & US-9463794-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8662512809},{"pair":"US-2020073405-A1 & US-9836052-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8660172566},{"pair":"US-2019111922-A1 & US-9669827-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-10-13T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8659150755},{"pair":"US-2018239361-A1 & US-9682707-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8656565241},{"pair":"US-2019012913-A1 & US-9836052-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8654868883},{"pair":"US-2017248952-A1 & US-2016209844-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8654013139},{"pair":"US-10345822-B1 & US-9690296-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8653114335},{"pair":"US-2019012913-A1 & US-9679206-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8650645316},{"pair":"US-2020073405-A1 & US-2016209844-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":null,"abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8648146254},{"pair":"US-10528055-B2 & US-9646497-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.86476657},{"pair":"US-2017247040-A1 & US-2016209844-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8644071154},{"pair":"US-2018099663-A1 & US-10156851-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8641547867},{"pair":"US-2019235520-A1 & US-9255805-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8638493479},{"pair":"US-2019101933-A1 & US-10146223-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8638076951},{"pair":"US-2017174261-A1 & US-9679206-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8637299958},{"pair":"US-2019235520-A1 & US-10146223-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8636867787},{"pair":"US-2019111922-A1 & US-2018143643-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8636415548},{"pair":"US-10589742-B2 & US-9255805-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":null,"abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8635293311},{"pair":"US-2019161085-A1 & US-2017341643-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8634278632},{"pair":"US-2019101933-A1 & US-9669827-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8633259342},{"pair":"US-10423847-B2 & US-9690296-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8632571563},{"pair":"US-2019101933-A1 & US-9682707-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8631503881},{"pair":"US-2017206426-A1 & US-9463794-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8631165114},{"pair":"US-2017174261-A1 & US-9690296-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2015-12-17T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8628740122},{"pair":"US-2019111922-A1 & US-10204278-B2","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8627928775},{"pair":"US-2019101933-A1 & US-9684836-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8627653584},{"pair":"US-2019111922-A1 & US-2016209844-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-10-13T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8627419063},{"pair":"US-2019111922-A1 & US-9463794-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8626232908},{"pair":"US-10345822-B1 & US-9682707-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8625897619},{"pair":"US-9983591-B2 & US-2016209844-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8625856728},{"pair":"US-10377376-B2 & US-10156851-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8625169297},{"pair":"US-2017248952-A1 & US-9373045-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8624700187},{"pair":"US-2018239361-A1 & US-2016209844-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8624014938},{"pair":"US-2018239361-A1 & US-2018135972-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.862392493},{"pair":"US-2018120857-A1 & US-9766626-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8623913339},{"pair":"US-9983591-B2 & US-2018135972-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2015-11-05T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8622403126},{"pair":"US-2018099663-A1 & US-9682707-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.862202437},{"pair":"US-2019235520-A1 & US-9690296-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8621471361},{"pair":"US-2019362168-A1 & US-9690296-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8619743059},{"pair":"US-2017247040-A1 & US-9373045-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8618877893},{"pair":"US-2019235520-A1 & US-10496091-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8618503261},{"pair":"US-2018099663-A1 & US-10204278-B2","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8617053547},{"pair":"US-10289113-B2 & US-2016209844-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8616467765},{"pair":"US-2019039616-A1 & US-10496091-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8616271657},{"pair":"US-2019111922-A1 & US-9557736-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-10-13T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8615113465},{"pair":"US-10423847-B2 & US-9255805-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8614571118},{"pair":"US-2020073405-A1 & US-9862364-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8614145872},{"pair":"US-10423847-B2 & US-9682707-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8611232573},{"pair":"US-2019101933-A1 & US-10059334-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.861108439},{"pair":"US-2019111922-A1 & US-9684836-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8610631578},{"pair":"US-10289113-B2 & US-9373045-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8609992742},{"pair":"US-10377376-B2 & US-9682707-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8609698775},{"pair":"US-10345822-B1 & US-10146223-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8609571826},{"pair":"US-2019111922-A1 & US-9679206-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8609186627},{"pair":"US-2018239361-A1 & US-9679206-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8608961853},{"pair":"US-2019161085-A1 & US-9766626-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8608407672},{"pair":"US-2019362168-A1 & US-9255805-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8608278978},{"pair":"US-9983591-B2 & US-9679206-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8607644776},{"pair":"US-2017206426-A1 & US-10204278-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8606490469},{"pair":"US-10377376-B2 & US-10204278-B2","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8606432728},{"pair":"US-2019362168-A1 & US-9682707-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8605206155},{"pair":"US-10589742-B2 & US-2017341643-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8600728404},{"pair":"US-2019039616-A1 & US-9463794-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8599676331},{"pair":"US-2019161085-A1 & US-9862364-B2","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8599327309},{"pair":"US-10345822-B1 & US-10496091-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-01-26T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8597187661},{"pair":"US-2019101933-A1 & US-9463794-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8596055746},{"pair":"US-2019101933-A1 & US-2016209844-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8595971059},{"pair":"US-10259457-B2 & US-9679206-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8595914053},{"pair":"US-2018239361-A1 & US-9690296-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8595694286},{"pair":"US-10528055-B2 & US-9766626-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8594991946},{"pair":"US-2019235520-A1 & US-9682707-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8593930444},{"pair":"US-2018120857-A1 & US-9684836-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8593852735},{"pair":"US-9983591-B2 & US-9255805-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8589941395},{"pair":"US-9983591-B2 & US-9690296-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2015-11-05T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8588731932},{"pair":"US-10345822-B1 & US-9684836-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858653895},{"pair":"US-2018099663-A1 & US-2017098129-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8586201546},{"pair":"US-2019362168-A1 & US-2016187887-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8585822975},{"pair":"US-2017247040-A1 & US-2017098129-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858559196},{"pair":"US-2019039616-A1 & US-9682707-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8584880669},{"pair":"US-2017206426-A1 & US-10146223-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-01-15T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8584695863},{"pair":"US-10377376-B2 & US-2017098129-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8583902513},{"pair":"US-2017206426-A1 & US-9557736-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858224632},{"pair":"US-2020073405-A1 & US-2016187887-A1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":null,"abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8582132057},{"pair":"US-2017072962-A1 & US-9679206-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858204572},{"pair":"US-10589742-B2 & US-9766626-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8581992024},{"pair":"US-2017248952-A1 & US-2017098129-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8581806191},{"pair":"US-2018239361-A1 & US-9255805-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8581699464},{"pair":"US-10423847-B2 & US-2016187887-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8581056068},{"pair":"US-2019161085-A1 & US-10059334-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.858098803},{"pair":"US-2019039616-A1 & US-9836052-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8579493546},{"pair":"US-2018239361-A1 & US-9373045-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8579385919},{"pair":"US-2017247040-A1 & US-9862364-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8578894849},{"pair":"US-2019012913-A1 & US-9766626-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8576665116},{"pair":"US-9983591-B2 & US-2016187887-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8575082377},{"pair":"US-10289113-B2 & US-9862364-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8574395959},{"pair":"US-2017206426-A1 & US-9836052-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8573393957},{"pair":"US-2018239361-A1 & US-2016187887-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8572328859},{"pair":"US-10423847-B2 & US-9646497-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8572159724},{"pair":"US-2019101933-A1 & US-2017098129-A1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8571517771},{"pair":"US-9983591-B2 & US-9373045-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2015-11-05T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570954838},{"pair":"US-10528055-B2 & US-9684836-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.857081212},{"pair":"US-2017248952-A1 & US-9862364-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570570983},{"pair":"US-2019111922-A1 & US-9707966-B2","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.857032429},{"pair":"US-2019012913-A1 & US-9684836-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570222987},{"pair":"US-2020073405-A1 & US-10059334-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":null,"abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570127934},{"pair":"US-2017174261-A1 & US-9684836-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8570004479},{"pair":"US-10377376-B2 & US-9646497-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8569478206},{"pair":"US-2019111922-A1 & US-10146223-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.856945766},{"pair":"US-2017174261-A1 & US-9255805-B1","patent_1":"US-2017174261-A1","title_1":"Vehicle Turn Signal Detection ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170174261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Systems, methods, and devices for detecting a vehicle's turn signal status for collision avoidance during lane-switching maneuvers or otherwise. A method includes detecting, at a first vehicle, a presence of a second vehicle in an adjacent lane. The method includes identifying, in an image of the second vehicle, a sub-portion containing a turn signal indicator of the second vehicle. The method includes processing the sub-portion of the image to determine a state of the turn signal indicator. The method also includes notifying a driver or performing a driving maneuver, at the first vehicle, based on the state of the turn signal indicator.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2015-12-17T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8569430272},{"pair":"US-2019012913-A1 & US-10059334-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8567286055},{"pair":"US-2018099663-A1 & US-2018135972-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8567276254},{"pair":"US-2019101933-A1 & US-10204278-B2","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8567226079},{"pair":"US-2019101933-A1 & US-9373045-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8566857241},{"pair":"US-2019039616-A1 & US-9557736-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-09T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8566545569},{"pair":"US-2018239361-A1 & US-9646497-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8566244741},{"pair":"US-10589742-B2 & US-9862364-B2","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9862364-B2","title_2":"Collision mitigated braking for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9862364B2\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure involve a collision mitigated braking system employed in vehicles operating in a self-driving (autonomous) mode. Collision mitigated braking provides redundancy to the vehicle's main driving system in emergency situations. The collision mitigated braking system is configured to cause the vehicle to come to a stop when an imminent collision is perceived and the main driving system has not initiated a braking maneuver. A perception component employs information received from vehicle sensors, analyzing the sensor data to identify nearby objects of interest that are determined to be in the vehicle's path or that could otherwise collide with the vehicle. A control component evaluates the objects of interest to determine whether immediate braking is required. If this is the case and the main driving system has not begun to brake, the control component causes the vehicle to perform immediate braking to avoid a possible collision.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8565137897},{"pair":"US-2018239361-A1 & US-9707966-B2","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8565047705},{"pair":"US-10289113-B2 & US-2017098129-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8564306177},{"pair":"US-2018099663-A1 & US-9646497-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8563083424},{"pair":"US-10423847-B2 & US-9679206-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8562879488},{"pair":"US-2019101933-A1 & US-9679206-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.856162544},{"pair":"US-9983591-B2 & US-9707966-B2","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8559236208},{"pair":"US-2020073405-A1 & US-10156851-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8559019577},{"pair":"US-10345822-B1 & US-9766626-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8558960958},{"pair":"US-10377376-B2 & US-2018135972-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8558116187},{"pair":"US-9983591-B2 & US-9646497-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8557950324},{"pair":"US-2019362168-A1 & US-9646497-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8557545434},{"pair":"US-10423847-B2 & US-2017098129-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8555687863},{"pair":"US-2019362168-A1 & US-9679206-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8555540422},{"pair":"US-2019362168-A1 & US-2017098129-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8553318788},{"pair":"US-10589742-B2 & US-10059334-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":null,"abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8553266391},{"pair":"US-2019235520-A1 & US-9766626-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8547697114},{"pair":"US-2019235520-A1 & US-9684836-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8546132378},{"pair":"US-2018099663-A1 & US-2016187887-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8545536926},{"pair":"US-2020073405-A1 & US-9766626-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2018-09-05T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8544923028},{"pair":"US-2018120857-A1 & US-9679206-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8541784341},{"pair":"US-2019111922-A1 & US-2017098129-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8540161435},{"pair":"US-2017206426-A1 & US-9255805-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8539426863},{"pair":"US-2019111922-A1 & US-10496091-B1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-10-13T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8539040092},{"pair":"US-2019235520-A1 & US-2016209844-A1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.853889114},{"pair":"US-2017247040-A1 & US-2016187887-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8537975921},{"pair":"US-2017248952-A1 & US-2016187887-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8537624919},{"pair":"US-2019111922-A1 & US-2016187887-A1","patent_1":"US-2019111922-A1","title_1":"In-vehicle traffic assist ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190111922A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A system, comprising a processor and a memory, the memory including instructions to be executed by the processor to pilot a vehicle based on determining first and second lane markers, where lane markers are mathematical descriptions of roadway lane markers applied to a roadway to mark traffic lanes, determine a missing first or second lane marker, and pilot the vehicle for a determined period of time based on a remaining first or second lane marker.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2017-10-13T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.853618181},{"pair":"US-10377376-B2 & US-2016187887-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8535695339},{"pair":"US-2019101933-A1 & US-9766626-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8534378109},{"pair":"US-10528055-B2 & US-9679206-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":null,"abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-11-03T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8533590799},{"pair":"US-2020073405-A1 & US-10204278-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":null,"abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8533573762},{"pair":"US-2017206426-A1 & US-10156851-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8532784055},{"pair":"US-2017206426-A1 & US-9682707-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8532287378},{"pair":"US-2017247040-A1 & US-9669827-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8531531387},{"pair":"US-2017247040-A1 & US-2017341643-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8530691922},{"pair":"US-10423847-B2 & US-9373045-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8529858006},{"pair":"US-10289113-B2 & US-2016187887-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.852744562},{"pair":"US-10345822-B1 & US-2016209844-A1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8527207891},{"pair":"US-10289113-B2 & US-2017341643-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8526984031},{"pair":"US-2019161085-A1 & US-2016209844-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8525393113},{"pair":"US-10289113-B2 & US-9669827-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8523869296},{"pair":"US-2017248952-A1 & US-9669827-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8523595219},{"pair":"US-2017248952-A1 & US-2017341643-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8523016735},{"pair":"US-2020073405-A1 & US-10146223-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8521843664},{"pair":"US-2019161085-A1 & US-2018143643-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8520081708},{"pair":"US-10528055-B2 & US-10146223-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8519530639},{"pair":"US-2018120857-A1 & US-10146223-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8519200778},{"pair":"US-9983591-B2 & US-2017098129-A1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8518245302},{"pair":"US-2019039616-A1 & US-2016187887-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8517486759},{"pair":"US-2019362168-A1 & US-9373045-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2015-11-04T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8517484824},{"pair":"US-2018239361-A1 & US-2017098129-A1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8516649631},{"pair":"US-2020073405-A1 & US-9707966-B2","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":null,"abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8513187352},{"pair":"US-2020073405-A1 & US-9373045-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":null,"abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.851154403},{"pair":"US-2020073405-A1 & US-9646497-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8507631535},{"pair":"US-2018239361-A1 & US-9684836-B1","patent_1":"US-2018239361-A1","title_1":"Autonomous Driving At Intersections Based On Perception Data ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180239361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8506916733},{"pair":"US-10259457-B2 & US-9707966-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8506691102},{"pair":"US-2019101933-A1 & US-9836052-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8506577012},{"pair":"US-2019039616-A1 & US-2018143643-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-09T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8506336296},{"pair":"US-2017206426-A1 & US-9373045-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8505445905},{"pair":"US-10259457-B2 & US-10204278-B2","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8503500271},{"pair":"US-9983591-B2 & US-9684836-B1","patent_1":"US-9983591-B2","title_1":"Autonomous driving at intersections based on perception data ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US9983591B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Systems, methods, and devices for predicting a driver's intention and future movements of a proximal vehicle, whether an automated vehicle or a human driven vehicle, are disclosed herein. A system for predicting future movements of a vehicle includes an intersection component, a camera system, a boundary component, and a prediction component. The intersection component is configured to determine that a parent vehicle is near an intersection. The camera system is configured to capture an image of the proximal vehicle. The boundary component is configured to identify a sub-portion of the image containing a turn signal indicator on the proximal vehicle. The prediction component is configured to predict future movement of the proximal vehicle through the intersection based on a state of the turn signal indicator.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2015-11-05T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8503486584},{"pair":"US-2017072962-A1 & US-10204278-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8503016316},{"pair":"US-2018099663-A1 & US-2018143643-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8500363019},{"pair":"US-2019161085-A1 & US-10156851-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.850002801},{"pair":"US-2017206426-A1 & US-2017341643-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2017341643-A1","title_2":"Traffic signal response for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170341643A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate to determining whether a vehicle should continue through an intersection. For example, the one or more of the vehicle's computers may identify a time when the traffic signal light will turn from yellow to red. The one or more computers may also estimate a location of a vehicle at the time when the traffic signal light will turn from yellow to red. A starting point of the intersection may be identified. Based on whether the estimated location of the vehicle is at least a threshold distance past the starting point at the time when the traffic signal light will turn from yellow to red, the computers can determine whether the vehicle should continue through the intersection.","priority_1":"2016-01-15T00:00:00","priority_2":"2014-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8497873277},{"pair":"US-2017072962-A1 & US-2016187887-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8497533429},{"pair":"US-10259457-B2 & US-2016187887-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8496070527},{"pair":"US-2019039616-A1 & US-2017098129-A1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8495886695},{"pair":"US-2018120857-A1 & US-10496091-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8494842314},{"pair":"US-2018099663-A1 & US-10146223-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8494408623},{"pair":"US-2018120857-A1 & US-9557736-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8490479186},{"pair":"US-2017072962-A1 & US-9707966-B2","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8488919569},{"pair":"US-2019012913-A1 & US-9682707-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-07-06T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8488589689},{"pair":"US-10377376-B2 & US-2018143643-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8488127971},{"pair":"US-2019161085-A1 & US-9557736-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8487768874},{"pair":"US-2019039616-A1 & US-9684836-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8487768479},{"pair":"US-2019161085-A1 & US-9646497-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8486122338},{"pair":"US-2019012913-A1 & US-9707966-B2","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8483735095},{"pair":"US-10528055-B2 & US-10496091-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-11-03T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8483113528},{"pair":"US-10589742-B2 & US-2018143643-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":null,"abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8480955087},{"pair":"US-2018099663-A1 & US-10496091-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8480601237},{"pair":"US-10528055-B2 & US-9557736-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-11-03T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8479157055},{"pair":"US-2019235520-A1 & US-10059334-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8478018831},{"pair":"US-2017206426-A1 & US-9646497-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8477569343},{"pair":"US-2020073405-A1 & US-9679206-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":null,"abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2018-09-05T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8477220109},{"pair":"US-10377376-B2 & US-10146223-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8476856785},{"pair":"US-10423847-B2 & US-9707966-B2","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8475639606},{"pair":"US-2019362168-A1 & US-2016209844-A1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.847465319},{"pair":"US-10377376-B2 & US-9255805-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8471713606},{"pair":"US-10589742-B2 & US-2016209844-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":null,"abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8471240657},{"pair":"US-10423847-B2 & US-2016209844-A1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2015-11-04T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8470912424},{"pair":"US-2019362168-A1 & US-9707966-B2","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8470029755},{"pair":"US-2017206426-A1 & US-2017098129-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8469029775},{"pair":"US-2018120857-A1 & US-10059334-B1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8467336548},{"pair":"US-10345822-B1 & US-9463794-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8461803083},{"pair":"US-2018099663-A1 & US-9255805-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8461259689},{"pair":"US-10589742-B2 & US-9557736-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.846055609},{"pair":"US-10345822-B1 & US-10059334-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2018-01-26T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8460387945},{"pair":"US-2017247040-A1 & US-9255805-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.845963203},{"pair":"US-2018099663-A1 & US-2016209844-A1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8457483427},{"pair":"US-2019039616-A1 & US-10204278-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-10204278-B2","title_2":"Static obstacle detection ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10204278B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"A vehicle is provided that may distinguish between dynamic obstacles and static obstacles. Given a detector for a class of static obstacles or objects, the vehicle may receive sensor data indicative of an environment of the vehicle. When a possible object is detected in a single frame, a location of the object and a time of observation of the object may be compared to previous observations. Based on the object being observed a threshold number of times, in substantially the same location, and within some window of time, the vehicle may accurately detect the presence of the object and reduce any false detections.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8457453527},{"pair":"US-10589742-B2 & US-10156851-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8456636087},{"pair":"US-10377376-B2 & US-10496091-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-10-06T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8453964981},{"pair":"US-10289113-B2 & US-9255805-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8453279789},{"pair":"US-10377376-B2 & US-2016209844-A1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8450580329},{"pair":"US-10259457-B2 & US-2017098129-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8447676646},{"pair":"US-10589742-B2 & US-9646497-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":null,"abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8445866217},{"pair":"US-10345822-B1 & US-9679206-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8445592762},{"pair":"US-2017248952-A1 & US-9255805-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8444117824},{"pair":"US-2017072962-A1 & US-2017098129-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2017098129-A1","title_2":"3D Position Estimation of Objects from a Monocular Camera using a Set of Known 3D Points on an Underlying Surface ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170098129A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Disclosed herein are methods and systems for determining a location of an object within an environment. An example method may include determining a three-dimensional (3D) location of a plurality of reference points in an environment, receiving a two-dimensional (2D) image of a portion of the environment that contains an object, selecting certain reference points from the plurality of reference points that form a polygon when projected into the 2D image that contains at least a portion of the object, determining an intersection point of a ray directed toward the object and a 3D polygon formed by the selected reference points, and based on the intersection point of the ray directed toward the object and the 3D polygon formed by the selected reference points, determining a 3D location of the object in the environment.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.844355531},{"pair":"US-10528055-B2 & US-10059334-B1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":null,"abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8440885512},{"pair":"US-10345822-B1 & US-9836052-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8439552829},{"pair":"US-2018120857-A1 & US-2016209844-A1","patent_1":"US-2018120857-A1","title_1":"Road sign recognition ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20180120857A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Vehicles can be equipped with computing devices, networks, sensors and controllers to determine, modify, and\/or augment a digital map of the surrounding real world. Computing devices included in a vehicle can determine road sign locations in LIDAR data. The computing devices can identify road signs in one or more video images based on the road sign locations and include the road sign in a digital map based on the road sign identity and the road sign location.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8436170006},{"pair":"US-10423847-B2 & US-9684836-B1","patent_1":"US-10423847-B2","title_1":"Predicting vehicle movements based on driver body language ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10423847B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8435727971},{"pair":"US-2019235520-A1 & US-9679206-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8435682601},{"pair":"US-2019362168-A1 & US-9684836-B1","patent_1":"US-2019362168-A1","title_1":"Predicting Vehicle Movements Based on Driver Body Language ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190362168A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Systems, methods, and devices for predicting driver intent and future movements of a human driven vehicles are disclosed herein. A computer implemented method includes receiving an image of a proximal vehicle in a region near a vehicle. The method includes determining a region of the image that contains a driver of the proximal vehicle, wherein determining the region comprises determining based on a location of one or more windows of the proximal vehicle. The method includes processing image data only in the region of the image that contains the driver of the proximal vehicle to detect a driver's body language.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2015-11-04T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.843414345},{"pair":"US-2019235520-A1 & US-9463794-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.843378522},{"pair":"US-2019012913-A1 & US-9373045-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2017-07-06T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8432262412},{"pair":"US-2017072962-A1 & US-2016209844-A1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8430360214},{"pair":"US-2018099663-A1 & US-9684836-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8426177128},{"pair":"US-2020073405-A1 & US-9463794-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8425995389},{"pair":"US-2019235520-A1 & US-10156851-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8422683908},{"pair":"US-10377376-B2 & US-9684836-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8417613088},{"pair":"US-10528055-B2 & US-2016209844-A1","patent_1":"US-10528055-B2","title_1":"Road sign recognition ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10528055B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":null,"abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-11-03T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8417595212},{"pair":"US-2019235520-A1 & US-9836052-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8417097485},{"pair":"US-10259457-B2 & US-2016209844-A1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2014-05-13T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8416494678},{"pair":"US-2019101933-A1 & US-9690296-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8411937378},{"pair":"US-2019039616-A1 & US-9707966-B2","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8410044006},{"pair":"US-10345822-B1 & US-9646497-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8409609823},{"pair":"US-2017206426-A1 & US-2016187887-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2016187887-A1","title_2":"Use of Prior Maps for Estimation of Lane Boundaries ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160187887A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Disclosed herein are methods and systems for using prior maps for estimation of lane boundaries or other features within an environment. An example method may include receiving a location of a plurality of detected points on a roadway in an environment of an autonomous vehicle, determining, from a prior map of the roadway, a location of a plurality of reference points from a boundary marker on the roadway that correspond to the detected points on the roadway, determining distances between the detected points and the corresponding reference points based on the location of the detected points in the environment and the location of the reference points from the prior map of the roadway, determining a confidence buffer representing a threshold amount of variation associated with the prior map based at least in part on the distances between the detected points and the corresponding reference points, selecting one or more of the detected points such that the distance between a selected detected point and a corresponding reference point is less than the confidence buffer, and using the selected points to direct the autonomous vehicle along the roadway.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-11-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.840424031},{"pair":"US-2019012913-A1 & US-9255805-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8401682136},{"pair":"US-2019235520-A1 & US-9557736-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8400398478},{"pair":"US-10345822-B1 & US-10156851-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2018-01-26T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8399360443},{"pair":"US-2019039616-A1 & US-9690296-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-02-09T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8399241283},{"pair":"US-2020073405-A1 & US-9669827-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2018-09-05T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8397050014},{"pair":"US-10345822-B1 & US-9557736-B1","patent_1":"US-10345822-B1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10345822B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2018-01-26T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.839099524},{"pair":"US-2019161085-A1 & US-9679206-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8390722123},{"pair":"US-2019161085-A1 & US-9836052-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8390368656},{"pair":"US-2017206426-A1 & US-9679206-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8389680863},{"pair":"US-2019039616-A1 & US-9373045-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2016-02-09T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8379483801},{"pair":"US-2019161085-A1 & US-2018135972-A1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8375358605},{"pair":"US-10259457-B2 & US-9684836-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8374552021},{"pair":"US-2019039616-A1 & US-9255805-B1","patent_1":"US-2019039616-A1","title_1":"Apparatus and method for an autonomous vehicle to follow an object ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190039616A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A vehicle processor, in response to a follow request from a mobile device, senses a location of an object associated with the mobile device relative to the vehicle and execute a series of autonomous drive commands based on the relative location such that the vehicle tracks movements of the object to follow the object along a route traveled by the object.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2016-02-09T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8370390826},{"pair":"US-2017206426-A1 & US-9690296-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8364025957},{"pair":"US-2017072962-A1 & US-9684836-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2014-05-13T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8360523865},{"pair":"US-10589742-B2 & US-9836052-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8351551103},{"pair":"US-2020073405-A1 & US-10496091-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2018-09-05T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8349848556},{"pair":"US-2018099663-A1 & US-9679206-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.834626884},{"pair":"US-2020073405-A1 & US-9557736-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8344741834},{"pair":"US-10589742-B2 & US-9679206-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":null,"abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2017-11-30T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8340920979},{"pair":"US-2017206426-A1 & US-9707966-B2","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.833690439},{"pair":"US-2018099663-A1 & US-9766626-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8336402445},{"pair":"US-10377376-B2 & US-9679206-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9679206-B1","title_2":"Assisted perception for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9679206B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Disclosed herein are systems and methods for providing supplemental identification abilities to an autonomous vehicle system. The sensor unit of the vehicle may be configured to receive data indicating an environment of the vehicle, while the control system may be configured to operate the vehicle. The vehicle may also include a processing unit configured to analyze the data indicating the environment to determine at least one object having a detection confidence below a threshold. Based on the at least one object having a detection confidence below a threshold, the processor may communicate at least a subset of the data indicating the environment for further processing. The vehicle is also configured to receive an indication of an object confirmation of the subset of the data. Based on the object confirmation of the subset of the data, the processor may alter the control of the vehicle by the control system.","priority_1":"2016-10-06T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8334958196},{"pair":"US-2019012913-A1 & US-9646497-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2017-07-06T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.833254557},{"pair":"US-10377376-B2 & US-9766626-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9766626-B1","title_2":"System and method for predicting behaviors of detected objects through environment representation ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9766626B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by performing a behavior analysis on mobile objects in the vicinity of an autonomous vehicle. Specifically, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine how the detected vehicles and pedestrians perceive their surroundings. The autonomous vehicle may then use this information to safely maneuver around all nearby objects.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8326953508},{"pair":"US-2019235520-A1 & US-9646497-B1","patent_1":"US-2019235520-A1","title_1":"Cognitive mapping for vehicles ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190235520A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system, comprising a processor, and a memory, the memory including instructions to be executed by the processor to acquire the images of the vehicle environment, determine a cognitive map, which includes a top-down view of the vehicle environment, based on the image, and operate the vehicle based on the cognitive map.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2018-01-26T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8326690991},{"pair":"US-2017248952-A1 & US-2018135972-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8326492322},{"pair":"US-2017247040-A1 & US-2018135972-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8323204836},{"pair":"US-10589742-B2 & US-2018135972-A1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":null,"abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2017-11-30T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8318661528},{"pair":"US-2019161085-A1 & US-10146223-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8318420049},{"pair":"US-2019161085-A1 & US-9463794-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8316579011},{"pair":"US-2017206426-A1 & US-2016209844-A1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-2016209844-A1","title_2":"Inferring State of Traffic Signal and Other Aspects of a Vehicle's Environment Based on Surrogate Data ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160209844A1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A vehicle configured to operate in an autonomous mode can obtain sensor data from one or more sensors observing one or more aspects of an environment of the vehicle. At least one aspect of the environment of the vehicle that is not observed by the one or more sensors could be inferred based on the sensor data. The vehicle could be controlled in the autonomous mode based on the at least one inferred aspect of the environment of the vehicle.","priority_1":"2016-01-15T00:00:00","priority_2":"2012-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8315574011},{"pair":"US-2019012913-A1 & US-9690296-B1","patent_1":"US-2019012913-A1","title_1":"Navigation of impaired vehicle ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190012913A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A system includes a computer programmed to receive first data from a first source that is a vehicle. The first data identifies a fault of the vehicle. The computer is programmed to receive second data from a second source outside the vehicle describing an area around the vehicle. The computer is programmed to determine, based on the first and second data, a navigational plan. The computer is programmed to transmit an instruction to the vehicle to actuate the vehicle according to the navigational plan.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2017-07-06T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8313914207},{"pair":"US-10259457-B2 & US-9373045-B1","patent_1":"US-10259457-B2","title_1":"Traffic light anticipation ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10259457B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8311701172},{"pair":"US-2019101933-A1 & US-9255805-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9255805-B1","title_2":"Pose estimation using long range features ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9255805B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the present disclosure relate to using an object detected at long range to increase the accuracy of a location and heading estimate based on near range information. For example, an autonomous vehicle may use data points collected from a sensor such as a laser to generate an environmental map of environmental features. The environmental map is then compared to pre-stored map data to determine the vehicle's geographic location and heading. A second sensor, such as a laser or camera, having a longer range than the first sensor may detect an object outside of the range and field of view of the first sensor. For example, the object may have retroreflective properties which make it identifiable in a camera image or from laser data points. The location of the object is then compared to the pre-stored map data and used to refine the vehicle's estimated location and heading.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8309572518},{"pair":"US-2017247040-A1 & US-9707966-B2","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8309458133},{"pair":"US-2017248952-A1 & US-9707966-B2","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8308021814},{"pair":"US-10289113-B2 & US-2018135972-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018135972-A1","title_2":"Using map information to smooth objects generated from sensor data ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180135972A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to generating a representation of an object detected by a perception system of a vehicle. For instance, a set of data points corresponding to an object is received from the perception system. Map information identifying shapes and locations of lanes as well as locations of center points for the lanes is retrieved. A representative point of the center points is selected based on the set of data points. A first position is determined based on the location of the representative point. A second position is determined based on the set of data points. The first and second positions are used to determine a third position for a representation of the object based on a distance the first position and the second position. The he representation of the object is generated using the third position. The representation of the object is displayed on a display of the vehicle","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8300708337},{"pair":"US-2019161085-A1 & US-9682707-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.829617094},{"pair":"US-2017206426-A1 & US-9684836-B1","patent_1":"US-2017206426-A1","title_1":"Pedestrian Detection With Saliency Maps ","patent_2":"US-9684836-B1","title_2":"Combining multiple estimates of an environment into a consolidated estimate for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170206426A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9684836B1\/en","abstract_1":"Systems, methods, and devices for pedestrian detection are disclosed herein. A method includes receiving an image of a region near a vehicle. The method further includes processing the image using a first neural network to determine one or more locations where pedestrians are likely located within the image. The method also includes processing the one or more locations of the image using a second neural network to determine that a pedestrian is present and notifying a driving assistance system or automated driving system that the pedestrian is present.","abstract_2":"A vehicle is provided that may combine multiple estimates of an environment into a consolidated estimate. The vehicle may receive first data indicative of the region of interest in an environment from a sensor of the vehicle. The first data may include a first accuracy value and a first estimate of the region of interest. The vehicle may also receive second data indicative of the region of interest in the environment, and the second data may include a second accuracy value and a second estimate of the region of interest. Based on the first data and the second data, the vehicle may combine the first estimate of the region of interest and the second estimate of the region of interest.","priority_1":"2016-01-15T00:00:00","priority_2":"2013-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8293931031},{"pair":"US-10289113-B2 & US-9707966-B2","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9707966-B2","title_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9707966B2\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Methods and systems for determining instructions for pulling over an autonomous vehicle are described. An example method may involve identifying a region of a road ahead of the autonomous vehicle based on lane boundaries of the road, one or more road boundaries indicating an edge of the road, and a size of the autonomous vehicle. The method may also involve determining a braking profile for reducing the speed of the autonomous vehicle based on the region and a speed of the autonomous vehicle. The method may also involve determining, based on the braking profile, a trajectory such that the autonomous vehicle will travel within the region while reducing the speed of the autonomous vehicle. The method may further involve determining instructions for pulling over and stopping the autonomous vehicle in the region in accordance with the determined trajectory and storing the instructions in a memory accessible by a computing device.","priority_1":"2016-02-25T00:00:00","priority_2":"2013-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8289360753},{"pair":"US-2017072962-A1 & US-9373045-B1","patent_1":"US-2017072962-A1","title_1":"Traffic light anticipation ","patent_2":"US-9373045-B1","title_2":"Bus detection for an autonomous vehicle ","link_1":"https:\/\/patents.google.com\/patent\/US20170072962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9373045B1\/en","abstract_1":"A vehicle includes at least one autonomous driving sensor configured to detect a traffic flow pattern relative to an intersection. An autonomous mode controller is configured to determine the state of the traffic control device. The autonomous mode controller may estimate when the state of the traffic control device is likely to change based on the traffic flow pattern.","abstract_2":"Methods and systems are provided that may allow an autonomous vehicle to discern a school bus from image data. An example method may include receiving image data indicative of a vehicles operating in an environment. The image data may depict sizes of the vehicles. The method may also include, based on relative sizes of the vehicles, determining a vehicle that is larger in size as compared the other vehicles. The method may additionally include comparing a size of the determined vehicle to a size of a school bus and based on the size of vehicle being within a threshold size of the school bus, comparing a color of the vehicle to a color of the school bus. The method may further include based on the vehicle being substantially the same color as the school bus, determining that the vehicle is representative of the school bus.","priority_1":"2014-05-13T00:00:00","priority_2":"2014-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8286848741},{"pair":"US-10589742-B2 & US-9463794-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8275556608},{"pair":"US-2018099663-A1 & US-10059334-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8274256106},{"pair":"US-10589742-B2 & US-10146223-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":null,"abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8267437905},{"pair":"US-10377376-B2 & US-10059334-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-10059334-B1","title_2":"Automated system and method for modeling the behavior of vehicles and other agents ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10059334B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"A method and apparatus are provided for determining one or more behavior models used by an autonomous vehicle to predict the behavior of detected objects. The autonomous vehicle may collect and record object behavior using one or more sensors. The autonomous vehicle may then communicate the recorded object behavior to a server operative to determine the behavior models. The server may determine the behavior models according to a given object classification, actions of interest performed by the object, and the object's perceived surroundings.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-04-13T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8263191907},{"pair":"US-10589742-B2 & US-9682707-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2017-11-30T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8258281368},{"pair":"US-10377376-B2 & US-9690296-B1","patent_1":"US-10377376-B2","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10377376B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8240765128},{"pair":"US-2018099663-A1 & US-9690296-B1","patent_1":"US-2018099663-A1","title_1":"Vehicle with environmental context analysis ","patent_2":"US-9690296-B1","title_2":"Avoiding blind spots of other vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20180099663A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9690296B1\/en","abstract_1":"A host vehicle may include: motor(s), brakes, sensors, processor(s) configured to: (a) predict a target path of a target vehicle based on lane boundaries of a virtual map; (b) compare the target path to a predicted host path of the host vehicle; (c) apply the brakes based on the comparison; (d) predict the target path and the host path as shapes, each having a two-dimensional surface area; (e) determine whether the shapes intersect, and based on the determination, (f) calculate a first timespan where the target vehicle reaches the intersection, and (g) a second timespan where the host vehicle reaches the intersection.","abstract_2":"Aspects of the disclosure relate generally to detecting and avoiding blind spots of other vehicles when maneuvering an autonomous vehicle. Blind spots may include both areas adjacent to another vehicle in which the driver of that vehicle would be unable to identify another object as well as areas that a second driver in a second vehicle may be uncomfortable driving. In one example, a computer of the autonomous vehicle may identify objects that may be relevant for blind spot detecting and may determine the blind spots for these other vehicles. The computer may predict the future locations of the autonomous vehicle and the identified vehicles to determine whether the autonomous vehicle would drive in any of the determined blind spots. If so, the autonomous driving system may adjust its speed to avoid or limit the autonomous vehicle's time in any of the blind spots.","priority_1":"2016-10-06T00:00:00","priority_2":"2012-06-20T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8239475802},{"pair":"US-2017248952-A1 & US-10156851-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8237606394},{"pair":"US-2017247040-A1 & US-10156851-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.823567645},{"pair":"US-2017247040-A1 & US-9682707-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8230143381},{"pair":"US-10289113-B2 & US-10156851-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10156851-B1","title_2":"Determining the stationary state of detected vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10156851B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detect other nearby vehicles and designate stationary vehicles as being in one of a short-term stationary state or a long-term stationary state. This determination may be made based on various indicia, including visible indicia displayed by the detected vehicle and traffic control factors relating to the detected vehicle. For example, the autonomous vehicle may identify a detected vehicle as being in a long-term stationary state based on detection of hazard lights being displayed by the detected vehicle, as well as the absence of brake lights being displayed by the detected vehicle. The autonomous vehicle may then base its control strategy on the stationary state of the detected vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8230124005},{"pair":"US-2019101933-A1 & US-9646497-B1","patent_1":"US-2019101933-A1","title_1":"Vehicle light platoon ","patent_2":"US-9646497-B1","title_2":"System and method for determining position and distance of objects using road fiducials ","link_1":"https:\/\/patents.google.com\/patent\/US20190101933A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9646497B1\/en","abstract_1":"A system includes a processor and a memory. The memory stores instructions executable by the processor to actuate a first vehicle to form a platoon including a second vehicle upon determining that an external light of the first vehicle is in a fault state.","abstract_2":"Aspects of the invention relate generally to autonomous vehicles. The features described improve the safety, use, driver experience, and performance of these vehicles by using ground markers to determine the position of the surrounding objects. In particular, the autonomous vehicle is capable of detecting nearby objects, such as vehicles and pedestrians, and is able to determine the position of these objects based on whether they have passed over ground markers.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-01-16T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8227428122},{"pair":"US-2017248952-A1 & US-9682707-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8225208485},{"pair":"US-2017247040-A1 & US-9836052-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8220199032},{"pair":"US-10289113-B2 & US-9836052-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8217244307},{"pair":"US-10289113-B2 & US-9682707-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8213225529},{"pair":"US-2017248952-A1 & US-9836052-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9836052-B1","title_2":"Change detection using curve alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9836052B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to determining whether a feature of map information. For example, data identifying an object detected in a vehicle's environment and including location coordinates is received. This information is used to identify a corresponding feature from pre-stored map information based on a map location of the corresponding feature. The corresponding feature is defined as a curve and associated with a tag identifying a type of the corresponding feature. A tolerance constraint is identified based on the tag. The curve is divided into two or more line segments. Each line segment has a first position. The first position of a line segment is changed in order to determine a second position based on the location coordinates and the tolerance constraint. A value is determined based on a comparison of the first position to the second position. This value indicates a likelihood that the corresponding feature has changed.","priority_1":"2016-02-25T00:00:00","priority_2":"2014-08-29T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8211641821},{"pair":"US-2020073405-A1 & US-9682707-B1","patent_1":"US-2020073405-A1","title_1":"Vehicle navigation and control ","patent_2":"US-9682707-B1","title_2":"Detecting and responding to parking behaviors in autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20200073405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9682707B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate controlling autonomous vehicles or vehicles having an autonomous driving mode. More particularly, these vehicles may identify and respond to other vehicles engaged in a parallel parking maneuver by receiving sensor data corresponding to objects in an autonomous vehicle's environment and including location information for the objects over time. An object corresponding to another vehicle in a lane in front of the first vehicle may be identified from the sensor data. A pattern of actions of the other vehicle identified form the sensor data is used to determine that the second vehicle is engaged in a parallel parking maneuver based on a pattern of actions exhibited by the other vehicle identified from the sensor data. The determination is then used to control the autonomous vehicle.","priority_1":"2018-09-05T00:00:00","priority_2":"2015-08-27T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8197583502},{"pair":"US-2017247040-A1 & US-2018143643-A1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.819454141},{"pair":"US-2017247040-A1 & US-10496091-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8192569291},{"pair":"US-2019161085-A1 & US-9669827-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8191230436},{"pair":"US-2017248952-A1 & US-10496091-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8184033134},{"pair":"US-2019161085-A1 & US-10496091-B1","patent_1":"US-2019161085-A1","title_1":"Vehicle snow level response ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20190161085A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"A system, including a processor and a memory, the memory including instructions to be executed by the processor to determine a best-fit snow boundary in an image including a reference object, determine a snow level based on comparing the best-fit snow boundary to the image of the reference object, and operate a vehicle by actuating vehicle components based on the determined snow level.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8182046614},{"pair":"US-2017248952-A1 & US-2018143643-A1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8178763566},{"pair":"US-2017247040-A1 & US-9463794-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8177671923},{"pair":"US-10289113-B2 & US-9463794-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8175653312},{"pair":"US-2017248952-A1 & US-9463794-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9463794-B1","title_2":"Stop sign detection and response ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9463794B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to detecting and responding to stop signs. An object detected in a vehicle's environment having location coordinates may be identified as a stop sign and, it may be determined whether the location coordinates of the identified stop sign correspond to a location of a stop sign in detailed map information. Then, whether the identified stop sign applies to the vehicle may be determined based on the detailed map information or on a number of factors. Then, if the identified stop sign is determined to apply to the vehicle, responses of the vehicle to the stop sign may be determined, and, the vehicle may be controlled based on the determined responses.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-09-04T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8168541553},{"pair":"US-10289113-B2 & US-10496091-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8165442121},{"pair":"US-10289113-B2 & US-2018143643-A1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-2018143643-A1","title_2":"Dynamic routing for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180143643A1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"A route for a trip to a destination is generated using map information. A set of no-go roadway segments, where the vehicle is not able to drive in an autonomous mode, relevant to the route from the plurality of no-go roadway segments is identified from the map information. A local region around a current location of the vehicle is determined. A local map region including roadway segments of the map information that correspond to locations within the local region is determined. The set of the plurality of no-go roadway segments is filtered from the roadway segments of the local map region. A cost value is assigned to each roadway segment of the filtered roadway segments of the local map region. Any assigned cost values are used to determining a plan for maneuvering the vehicle for a predetermined period into the future. The vehicle is maneuvered according to the plan.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-11-18T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.8164669309},{"pair":"US-10589742-B2 & US-9669827-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-9669827-B1","title_2":"Predicting trajectories of objects based on contextual information ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9669827B1\/en","abstract_1":null,"abstract_2":"Aspects of the disclosure relate to detecting and responding to objects in a vehicle's environment. For example, an object may be identified in a vehicle's environment, the object having a heading and location. A set of possible actions for the object may be generated using map information describing the vehicle's environment and the heading and location of the object. A set of possible future trajectories of the object may be generated based on the set of possible actions. A likelihood value of each trajectory of the set of possible future trajectories may be determined based on contextual information including a status of the detected object. A final future trajectory is determined based on the determined likelihood value for each trajectory of the set of possible future trajectories. The vehicle is then maneuvered in order to avoid the final future trajectory and the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2014-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8163204618},{"pair":"US-10589742-B2 & US-10496091-B1","patent_1":"US-10589742-B2","title_1":"Vehicle snow level response ","patent_2":"US-10496091-B1","title_2":"Behavior and intent estimations of road users for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10589742B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10496091B1\/en","abstract_1":null,"abstract_2":"As an example, data identifying characteristics of a road user as well as contextual information about the vehicle's environment is received from the vehicle's perception system. A prediction of the intent of the object including an action of a predetermined list of actions to be initiated by the road user and a point in time for initiation of the action is generated using the data. A prediction of the behavior of the road user for a predetermined period of time into the future indicating that the road user is not going to initiate the action during the predetermined period of time is generated using the data. When the prediction of the behavior indicates that the road user is not going to initiate the action during the predetermined period of time, the vehicle is maneuvered according to the prediction of the intent prior to the vehicle passing the object.","priority_1":"2017-11-30T00:00:00","priority_2":"2016-08-17T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8154067342},{"pair":"US-2017248952-A1 & US-9557736-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8079100604},{"pair":"US-2017247040-A1 & US-9557736-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8074559997},{"pair":"US-10289113-B2 & US-9557736-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-9557736-B1","title_2":"Detecting street parked vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9557736B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"Aspects of the disclosure relate to an autonomous vehicle that may detected other nearby vehicles and identify them as parked or unparked. This identification may be based on visual indicia displayed by the detected vehicles as well as traffic control factors relating to the detected vehicles. Detected vehicles that are in a known parking spot may automatically be identified as parked. In addition, detected vehicles that satisfy conditions that are indications of being parked may also be identified as parked. The autonomous vehicle may then base its control strategy on whether or not a vehicle has been identified as parked or not.","priority_1":"2016-02-25T00:00:00","priority_2":"2015-04-08T00:00:00","earlier_priority":"Google","assignee_1":"Ford","assignee_2":"Google","similarity":0.8067030162},{"pair":"US-2017247040-A1 & US-10146223-B1","patent_1":"US-2017247040-A1","title_1":"Autonomous vehicle control transitioning ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170247040A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Signals are received from a plurality of sources, representing operating characteristics of a vehicle and an environment surrounding the vehicle. A plurality of operational factors are developed based on the signals. The vehicle is controlled according to one of at least three levels of control, including an autonomous, a semi-autonomous, and a manual level of control, based on the operational factors.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.7978994079},{"pair":"US-2017248952-A1 & US-10146223-B1","patent_1":"US-2017248952-A1","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US20170248952A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.797768184},{"pair":"US-10289113-B2 & US-10146223-B1","patent_1":"US-10289113-B2","title_1":"Autonomous occupant attention-based control ","patent_2":"US-10146223-B1","title_2":"Handling sensor occlusions for autonomous vehicles ","link_1":"https:\/\/patents.google.com\/patent\/US10289113B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146223B1\/en","abstract_1":"Signals are received from a plurality of sources, representing aspects of the vehicle, a vehicle operator, and an environment surrounding the vehicle. An alertness factor and a readiness factor are developed based at least in part on the signals. Control of the vehicle is transitioned between levels of autonomous control based at least in part on the alertness factor and the readiness factor.","abstract_2":"The technology relates to identifying sensor occlusions due to the limits of the ranges of a vehicle's sensors and using this information to maneuver the vehicle. As an example, the vehicle is maneuvered along a route that includes traveling on a first roadway and crossing over a lane of a second roadway. A trajectory is identified from the lane that will cross with the route during the crossing at a first point. A second point beyond a range of the vehicle's sensors is selected. The second point corresponds to a hypothetical vehicle moving towards the route along the lane. A distance between the first point and the second point is determined. An amount of time that it would take the hypothetical vehicle to travel the distance is determined and compared to a threshold amount of time. The vehicle is maneuvered based on the comparison to complete the crossing.","priority_1":"2016-02-25T00:00:00","priority_2":"2016-10-21T00:00:00","earlier_priority":"Ford","assignee_1":"Ford","assignee_2":"Google","similarity":0.7958986404}]