[{"pair":"US-2019313087-A1 & US-2019271844-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9270114741},{"pair":"US-2019313087-A1 & US-9851565-B1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-04-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9234032067},{"pair":"US-2019313087-A1 & US-2020041798-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9209473667},{"pair":"US-10529117-B2 & US-2018061119-A1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.918013488},{"pair":"US-2019318528-A1 & US-2018061119-A1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9178391753},{"pair":"US-2018239145-A1 & US-10241329-B2","patent_1":"US-2018239145-A1","title_1":"Focus adjusting multiplanar head mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20180239145A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A multiplanar head mounted display (HMD) includes two or more artificial display planes for each eye located at optical distances that can be dynamically adjusted based on a location within a scene presented by the HMD that the user views. For example, a scene is presented on two or more electronic display elements (e.g., screens) of the HMD. A focal length of an optics block that directs image light from the electronic display elements towards the eyes of a user is adjusted using a varifocal system (e.g., an element that mechanically changes a distance between a lens system in the optics block and the electronic display element, an element that changes shape of one or more lenses in the lens system in the optics block, etc.) based on a location or object within the scene where the user is looking.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-02-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.917538781},{"pair":"US-2019318530-A1 & US-2018061119-A1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9163212891},{"pair":"US-2019318529-A1 & US-2018061119-A1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9159036215},{"pair":"US-2017262054-A1 & US-10241329-B2","patent_1":"US-2017262054-A1","title_1":"Focus adjusting headset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170262054A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality (VR) headset adjusts the phase of light of a virtual scene received from a display element using a spatial light modulator (SLM) to accommodate changes in vergence for a user viewing objects in the virtual scene. The VR headset receives virtual scene data that includes depth information for components of the virtual scene and the SLM adjusts a wavefront of the light of the virtual scene by generating a phase function that adjusts the light of the virtual scene with phase delays based the depth values. Individual phase delays shift components of the virtual scene based on the depth values to a target focal plane to accommodate a user at a vergence depth for a frame of the virtual scene. Further, the SLM can provide optical defocus by shifting components of the virtual scene with the phase delays for depth of field blur.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-03-11T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9111468018},{"pair":"US-2020081252-A1 & US-9851565-B1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-03-15T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9108401606},{"pair":"US-9984507-B2 & US-10241329-B2","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2015-11-19T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9100341587},{"pair":"US-10529117-B2 & US-10089796-B1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-04-16T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9097425047},{"pair":"US-2019313087-A1 & US-2018239141-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9096731823},{"pair":"US-2019318528-A1 & US-10089796-B1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-04-16T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9094865055},{"pair":"US-10317680-B1 & US-10241329-B2","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-11-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9088558593},{"pair":"US-2019318529-A1 & US-10089796-B1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-04-16T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9086743259},{"pair":"US-2020027261-A1 & US-2018329602-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9085872257},{"pair":"US-2019318530-A1 & US-10089796-B1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-04-16T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9085631969},{"pair":"US-2020064641-A1 & US-2020073123-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-08-24T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9083692332},{"pair":"US-2019313087-A1 & US-9671614-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-04-06T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9076408118},{"pair":"US-10481321-B1 & US-2020041798-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-09-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9068852595},{"pair":"US-2019313087-A1 & US-10162180-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10162180-B2","title_2":"Efficient thin curved eyepiece for see-through head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10162180B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, an input coupler, and an output coupler. The curved lightguide component guides display light received at an input region peripherally located from a viewing region and emits the display light along an eye-ward direction in the viewing region. The curved lightguide component includes an eye-ward facing surface that is concave and a world facing surface that is convex. The input coupler is disposed at the input region to couple the display light into the curved lightguide component. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is partially transmissive to ambient light incident through the world facing surface. The display light is guided between the input coupler and the output coupler entirely by total internal reflection.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-06-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9064036391},{"pair":"US-10600352-B1 & US-9851565-B1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-12-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9063001902},{"pair":"US-2016085301-A1 & US-9536354-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9048726782},{"pair":"US-2020027261-A1 & US-2018329485-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9043198163},{"pair":"US-2019285891-A1 & US-9851565-B1","patent_1":"US-2019285891-A1","title_1":"Image quality of pancharatnam berry phase components using polarizers ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190285891A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Various embodiments set forth a near eye display (NED) that includes an electronic display configured to output image light. Further, the NED includes multiple Pancharatnam Berry Phase (PBP) optical elements that are combined with one or more circular polarizers to improve optical performance. A PBP element produces an output of three diffraction orders. Typically in an optical system that includes such a PBP element, one of the three diffraction orders is used while the other two are undesirable and preferably maintained at a relatively low intensity. A circular polarizer may reduce the intensities of the two undesired diffraction orders.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-03-15T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9043198109},{"pair":"US-2019313087-A1 & US-2016240013-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9034492898},{"pair":"US-2019313087-A1 & US-9946074-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9033010894},{"pair":"US-10460500-B1 & US-10089796-B1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-04-13T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9031467095},{"pair":"US-2016085301-A1 & US-9934583-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9026195844},{"pair":"US-10600352-B1 & US-10545347-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-12-04T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9024510517},{"pair":"US-2020064641-A1 & US-9851565-B1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-24T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9024479216},{"pair":"US-2020027261-A1 & US-10540818-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9021774382},{"pair":"US-10107950-B2 & US-2015146301-A1","patent_1":"US-10107950-B2","title_1":"Flexible light combiner backlight used in a head mounted display ","patent_2":"US-2015146301-A1","title_2":"Lighting adjustment for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10107950B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150146301A1\/en","abstract_1":"A liquid crystal display (LCD) device including a backlight with an LED assembly. The LED assembly includes a flexible light combiner and two or more different color LEDs optically coupled with a first end of the flexible light combiner. The flexible light combiner includes light channels that transmit color light, and output the color light at a second end of the flexible light combiner. The second end defines a light output region of the flexible light combiner. The light output regions of multiple LED assemblies are arranged behind an LCD panel, along one or more edges, to illuminate the LCD panel. The LED assembly provides edge-lit backlighting with enhanced brightness and color gamut, and flexible LED placement within the LCD device.","abstract_2":"An apparatus includes a light source, a display array, a light relay, a photodetector, and control circuitry. The light source is for providing lamp light during an ON-time of the light source. The display array is positioned to receive and selectively manipulate the lamp light. The light relay is positioned to receive the image light from the display array. Control circuitry is coupled to the light source for adjusting the light source and coupled to receive an output of the photodetector.","priority_1":"2016-12-06T00:00:00","priority_2":"2012-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9016144112},{"pair":"US-2016085301-A1 & US-2015242414-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9008707218},{"pair":"US-10473939-B1 & US-2020041798-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9008515638},{"pair":"US-10210660-B2 & US-2018101984-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2016-04-06T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8998376548},{"pair":"US-10210660-B2 & US-2016323567-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2016323567-A1","title_2":"Virtual eyeglass set for viewing actual scene that corrects for different location of lenses than eyes ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160323567A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A virtual eyeglass set may include a frame, a first virtual lens and second virtual lens, and a processor. The frame may mount onto a user's head and hold the first virtual lens in front of the user's left eye and the second virtual lens in front of the user's right eye. A first side of each lens may face the user and a second side of each lens may face away from the user. Each of the first virtual lens and the second virtual lens may include a light field display on the first side, and a light field camera on the second side. The processor may construct, for display on each of the light field displays based on image data received via each of the light field cameras, an image from a perspective of the user's respective eye.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8995085178},{"pair":"US-2019313087-A1 & US-9709797-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8993803688},{"pair":"US-10025060-B2 & US-10241329-B2","patent_1":"US-10025060-B2","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10025060B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality headset displays a three-dimensional (3D) virtual scene and includes a varifocal element to dynamically adjust a focal length of an optics block included in the virtual reality headset based on a location in the virtual scene where the user is looking. The headset tracks a user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The varifocal element adjusts the focal length of the optics block so the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change. Based on the plane of focus, the virtual reality headset may provide depth cues, such as depth of field blur, to planes in the virtual scene deeper in the user's field of view than the plane of focus.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2015-12-08T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8990877659},{"pair":"US-2020027261-A1 & US-9704282-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8989890799},{"pair":"US-2017160798-A1 & US-10241329-B2","patent_1":"US-2017160798-A1","title_1":"Focus adjustment method for a virtual reality headset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170160798A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality headset displays a three-dimensional (3D) virtual scene and includes a varifocal element to dynamically adjust a focal length of an optics block included in the virtual reality headset based on a location in the virtual scene where the user is looking. The headset tracks a user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The varifocal element adjusts the focal length of the optics block so the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change. Based on the plane of focus, the virtual reality headset may provide depth cues, such as depth of field blur, to planes in the virtual scene deeper in the user's field of view than the plane of focus.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2015-12-08T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8989053894},{"pair":"US-2017293146-A1 & US-10241329-B2","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-04-07T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8984173914},{"pair":"US-2019313087-A1 & US-10545347-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8981061066},{"pair":"US-2019311522-A1 & US-9704282-B1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8968984119},{"pair":"US-10460500-B1 & US-2018061119-A1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-04-13T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.896544597},{"pair":"US-2019384070-A1 & US-2017293143-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8959387305},{"pair":"US-2019311522-A1 & US-2018061119-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-04-05T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8957288507},{"pair":"US-2019037137-A1 & US-2018329485-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2017-07-31T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8955472464},{"pair":"US-2019187482-A1 & US-9851565-B1","patent_1":"US-2019187482-A1","title_1":"Integrated Augmented Reality Head-Mounted Display for Pupil Steering ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190187482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display device for providing augmented reality contents to a wearer includes an eye tracker, a light projector, a beam steerer and a combiner. The eye tracker is configured to determine a position of a pupil of an eye of the wearer. The light projector is configured to project light for rendering images. The beam steerer is configured to change a direction of the light from the light projector based on the position of the pupil. The combiner is configured to combine the light from the light projector and light from an outside of the head-mounted display device for providing an overlap of the rendered image and a real image that corresponds to the light from the outside of the head-mounted display device.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.895451142},{"pair":"US-2019313087-A1 & US-2017293143-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8949359253},{"pair":"US-2017358136-A1 & US-9851565-B1","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-06-10T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8947046262},{"pair":"US-2019197667-A1 & US-2018012371-A1","patent_1":"US-2019197667-A1","title_1":"Computing high-resolution depth images using machine learning techniques ","patent_2":"US-2018012371-A1","title_2":"Image Registration with Device Data ","link_1":"https:\/\/patents.google.com\/patent\/US20190197667A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180012371A1\/en","abstract_1":"A system trains a machine learning model to generate a high-resolution depth image. During a training phase, the system generates an accurate three dimensional reconstruction of a training scene such that the machine learning model is iteratively trained to minimize an error between the higher resolution depth image and the depth information in the accurate three dimensional reconstruction. During a real-time phase, the system applies the trained machine learning model to images captured from a scene of interest and generates a higher resolution depth image with higher accuracy. Thus, the higher resolution depth image can be subsequently used to solve computer vision problems.","abstract_2":"Systems and methods for image registration using data collected by an electronic device, such as a mobile device, capable of simultaneous localization and mapping are provided. An electronic device, such as a mobile device, can be can be configured to collect data using a variety of sensors as the device is carried or transported through a space. The collected data can be processed and analyzed to generate a three-dimensional representation of the space and objects in the space in near real time as the device is carried through the space. The data can be used for a variety of purposes, including registering imagery for localization and image processing.","priority_1":"2017-12-26T00:00:00","priority_2":"2014-01-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8943482701},{"pair":"US-10520742-B1 & US-9851565-B1","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-02-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8940935393},{"pair":"US-10345600-B1 & US-10241329-B2","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-06-08T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8940928811},{"pair":"US-2020064627-A1 & US-10032074-B2","patent_1":"US-2020064627-A1","title_1":"Illumination assembly with in-field micro devices ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20200064627A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"An illumination assembly includes a transparent substrate and a plurality of micro devices. The transparent substrate includes a first surface and a second surface opposite the first surface. The first surface includes a viewing region through which light passes prior to reaching an eyebox. The plurality of micro devices are coupled to respective conductive pathways that are affixed to the first surface. The plurality of micro devices including at least one micro device that is positioned within the viewing region. In some embodiments, the conductive pathways are arranged in a pseudo random manner. In some instances, the viewing region is composed of a circuity free region that is circumscribed by an outer region, and the plurality of micro devices are coupled to respective conductive pathways that are affixed to the first surface in the outer region.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2018-08-21T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8936415113},{"pair":"US-10429656-B1 & US-9851565-B1","patent_1":"US-10429656-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10429656B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light is captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8932734345},{"pair":"US-10429657-B1 & US-9851565-B1","patent_1":"US-10429657-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10429657B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block. Moreover, each reflection results in a particular view of the eye that results in multiple views of the eye being received by the image capturing element.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8932734345},{"pair":"US-2019313087-A1 & US-2020041790-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2020041790-A1","title_2":"Catadioptric freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041790A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical device, such as a head mounted display, includes a display that emits light, a reflector, and a partially reflective circular polarizer (RCP) positioned between the reflector and a user's eye or eyes. The reflector can be partially reflective. The partially reflective circular polarizer, the reflector, or both, can be curved. Light from the display is reflected one or more times by the reflector. The RCP can include one or more of a quarter-wave plate (QWP), a reflective polarizer layer, a linear polarizer, a supportive substrate, and an anti-reflective film. The reflector can include a mirror coating and an anti-reflection coating.","priority_1":"2018-04-06T00:00:00","priority_2":"2018-08-02T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8930297067},{"pair":"US-10429927-B1 & US-9851565-B1","patent_1":"US-10429927-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10429927B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8929813514},{"pair":"US-2020064641-A1 & US-2020041798-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8929483764},{"pair":"US-10488921-B1 & US-9851565-B1","patent_1":"US-10488921-B1","title_1":"Pellicle beamsplitter for eye tracking ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10488921B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a pellicle beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The pellicle beamsplitter is positioned along the optical axis between the optics assembly and the electronic display. The pellicle beamsplitter includes a front surface and a back surface. Each of the front surface and the back surface comprising a first radius curvature in a first plane and a second radius curvature in a second plane that is perpendicular to the first plane.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-09-08T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8923218944},{"pair":"US-2016085301-A1 & US-9298256-B1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9298256-B1","title_2":"Visual completion ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9298256B1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Methods and devices for initiating, updating, and displaying the results of a search of an object-model database are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device and, based on the video data, detecting a movement corresponding to a selection of an object. The method further includes, before the movement is complete, initiating a search on the object of an object-model database. The method still further includes, during the movement, periodically updating the search and causing the wearable computing device to overlay the object with object-models from the database corresponding to results of the search.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8921078611},{"pair":"US-2020064641-A1 & US-10365491-B1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10365491-B1","title_2":"Head-mounted display including diffractive combiner to integrate a display and an eye-tracking sensor ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10365491B1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An apparatus comprising a diffractive combiner having a front side, a back side, and a combiner optical axis running substantially through the diffractive combiner and normal to the back side. A display unit having a display optical axis that directs the display light along the display optical axis toward the diffractive combiner. An eye-tracking sensor having a sensor optical axis that is positioned to receive eye-tracking radiation reflected by the diffractive combiner along the sensor optical axis. The combiner optical axis, the display optical axis, and the sensor optical axis intersect each other at the diffractive combiner.","priority_1":"2018-08-24T00:00:00","priority_2":"2013-04-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8920461303},{"pair":"US-10345600-B1 & US-9851565-B1","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-06-08T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8908534507},{"pair":"US-2016085301-A1 & US-9405977-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9405977-B2","title_2":"Using visual layers to aid in initiating a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9405977B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Methods and devices for initiating a search are disclosed. In one embodiment, a method is disclosed that includes causing a camera on a wearable computing device to record video data, segmenting the video data into a number of layers and, based on the video data, detecting that a pointing object is in proximity to a first layer. The method further includes initiating a first search on the first layer. In another embodiment, a wearable computing device is disclosed that includes a camera configured to record video data, a processor, and data storage comprising instructions executable by the processor to segment the video data into a number of layers and, based on the video data, detect that a pointing object is in proximity to a first layer. The instructions are further executable by the processor to initiate a first search on the first layer.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8903057168},{"pair":"US-2019361523-A1 & US-9870049-B2","patent_1":"US-2019361523-A1","title_1":"In-field illumination and imaging for eye tracking ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US20190361523A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"Disclosed herein are techniques for eye tracking in near-eye display devices. In some embodiments, an illuminator for eye tracking is provided. The illuminator includes a light source configured to be positioned within a field of view of an eye of a user; a first reflector configured to shadow the light source from a field of view of a camera; and a second reflector configured to receive light from the light source that is reflected by the eye of the user, and to direct the light toward the camera.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2018-05-23T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8896673989},{"pair":"US-2019098276-A1 & US-2017059305-A1","patent_1":"US-2019098276-A1","title_1":"3-d 360 degree depth projector ","patent_2":"US-2017059305-A1","title_2":"Active illumination for enhanced depth map generation ","link_1":"https:\/\/patents.google.com\/patent\/US20190098276A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170059305A1\/en","abstract_1":"A camera system configured to generate depth information for a local area. The camera system comprises a plurality of depth camera sub-assemblies arranged in a substantially spherical arrangement. Each sub-assembly comprises a projector that projects a structured light pattern onto a portion of the local area, such that the projected light patterns of the plurality of sub-assemblies form a tiled light pattern covering 360 degrees of the local area. Each sub-assembly further comprises at least one camera is configured to capture images of the local area. A controller of the camera system is configured to receive the captured images and to construct a 360 degree depth map of the scene, based upon the structured light patterns projected by the projectors of the plurality captured in the received images.","abstract_2":"A depth map may be generated in conjunction with generation of a digital image such as a light-field image. A light pattern source may be used to project a light pattern into a scene with one or more objects. A camera may be used to capture first light and second light reflected from the one or more objects. The first light may be a reflection of light originating from one or more other light sources independent of the light pattern source. The second light may be a reflection of the light pattern from the one or more objects. In a processor, at least the first light may be used to generate an image such as a light-field image. Further, in the processor, at least the second light may be used to generate a depth map indicative of distance between the one or more objects and the camera.","priority_1":"2017-09-27T00:00:00","priority_2":"2015-08-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8895922284},{"pair":"US-2020064641-A1 & US-9671614-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-24T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8886646294},{"pair":"US-10248890-B2 & US-2018158198-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018158198-A1","title_2":"Multi-view rotoscope contour propagation ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180158198A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A video stream may be captured, and may have a plurality of frames including at least a first frame and a second frame. Each of the frames may have a plurality of views obtained from viewpoints that are offset from each other. A source contour, associated with a source view of the first frame, may be retrieved. Camera parameters, associated with the image capture device used to capture the video stream, may also be retrieved. The camera parameters may include a first offset between the source view and a destination view of the first frame. At least the first offset may be used to project the source contour to the destination view to generate a destination contour associated with the destination view.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-12-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8885768128},{"pair":"US-2019227322-A1 & US-2018239141-A1","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-01-25T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8881294391},{"pair":"US-2020064641-A1 & US-2016240013-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-08-24T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8880298738},{"pair":"US-2019313087-A1 & US-2020073123-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-04-06T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.88797972},{"pair":"US-2020064641-A1 & US-2018239141-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8879704148},{"pair":"US-10154254-B2 & US-9934583-B2","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-01-17T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8878752658},{"pair":"US-2019037137-A1 & US-2018101984-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2017-07-31T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8874652918},{"pair":"US-9984507-B2 & US-2019020869-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2015-11-19T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8874428628},{"pair":"US-10481321-B1 & US-9851565-B1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-09-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8873156593},{"pair":"US-2020064641-A1 & US-2017293143-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8871427565},{"pair":"US-10416461-B2 & US-2019271844-A1","patent_1":"US-10416461-B2","title_1":"Pancake lens with large FOV ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10416461B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A HMD includes an electronic display and a pancake lens block. The pancake lens block includes a back curved optical element and a front curved optical element. Light propagating through the pancake lens block undergoes multiple reflections and to mitigate parasitic reflections, there are no air gaps between optical elements of the pancake lens block. A hybrid film that operates as a waveplate surface and a mirrored surface can be placed between the front curved optical element and the back curved optical element. A wide FOV can be obtained by making the coupling surfaces of the front optical element and the back optical element to be based on a convex cylindrical surface profile and a concave cylindrical surface profile, with the axis of the cylinder surface in a vertical direction for a user wearing the HMD.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2016-10-27T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.887122562},{"pair":"US-2019037137-A1 & US-2017180705-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2017180705-A1","title_2":"Capture and render of virtual reality content employing a light field camera array ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180705A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Systems and method relating to creating a virtual reality, such as a three-dimensional virtual reality, representation of physical scene. In this aspect, such a method may comprise gathering information from an array of cameras positioned on a two-dimensional planar surface. In this particular aspect, one or more of the cameras may be positioned at a different angle relative to the two-dimensional planar surface based at least in part on a respective distance of each of the one or more cameras from a midpoint of the planar surface. Furthermore, in this general aspect the method may further comprise processing the gathered information at least in part to render a virtual reality representation of the physical scene.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8870508513},{"pair":"US-2018120497-A1 & US-2015146301-A1","patent_1":"US-2018120497-A1","title_1":"Thick backlight for rgb led of a liquid crystal display used in a virtual reality head mounted display ","patent_2":"US-2015146301-A1","title_2":"Lighting adjustment for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20180120497A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150146301A1\/en","abstract_1":"A liquid crystal display (LCD) device including a backlight with vertically stacked light emitting diodes (LEDs). The LCD device includes an LCD panel and a backlight for illuminating the LCD panel. The backlight includes a plurality of LEDs and a light guide. The plurality of LEDs are stacked vertically and disposed behind the LCD panel along one or more edges of the LCD panel. The plurality of LEDs include at least a first color LED and a second color LED emitting first light and second light at a first direction, respectively, at a first wavelength and a second wavelength, respectively. The light guide is disposed behind the LCD panel and adjacent to the plurality of LEDs. The light guide is configured to combine the first light and the second light received from the plurality of LEDs into combined light to illuminate the LCD panel.","abstract_2":"An apparatus includes a light source, a display array, a light relay, a photodetector, and control circuitry. The light source is for providing lamp light during an ON-time of the light source. The display array is positioned to receive and selectively manipulate the lamp light. The light relay is positioned to receive the image light from the display array. Control circuitry is coupled to the light source for adjusting the light source and coupled to receive an output of the photodetector.","priority_1":"2016-10-31T00:00:00","priority_2":"2012-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8870178035},{"pair":"US-2019313087-A1 & US-2019086675-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8869058296},{"pair":"US-2019353898-A1 & US-2020041798-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.88671025},{"pair":"US-10546430-B1 & US-10241329-B2","patent_1":"US-10546430-B1","title_1":"Image plane adjustment in a near-eye display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10546430B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A near-eye display (NED) has an orientation detection device and a display block. The orientation detection device collects orientation data that describe an orientation of the NED. The display block has a display assembly, a focusing assembly, and a controller. The controller determines an orientation vector of the NED based in part on the orientation data and computes an angular difference between the orientation vector of the NED and a gravity vector. After comparing the angular difference to a threshold value, the controller generates multifocal instructions that adjusts the optical element to display an augmented scene at the selected image plane corresponding to the multifocal instructions.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-08-29T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8866918515},{"pair":"US-2019037137-A1 & US-2018329602-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2017-07-31T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8861298167},{"pair":"US-2019384070-A1 & US-9671614-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-06-18T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.885923051},{"pair":"US-2018173303-A1 & US-2019311467-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2019311467-A1","title_2":"Enhanced specular reflections for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311467A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Systems and methods for enhanced specular reflections are provided. An example method may include determining a first portion of a specular reflection associated with a computer-generated object based on a first contribution from an environment map component at a shading point of the computer-generated object and determining a second portion of the specular reflection associated with the computer-generated object based on a second contribution from a camera feed component at an intersection point of a camera feed and a reflection vector associated with the environment map component. The example method may further include determining the specular reflection, at the shading point, associated with the computer-generated object based on a blending of the first and second portions of the specular reflection.","priority_1":"2016-12-21T00:00:00","priority_2":"2018-04-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8858974969},{"pair":"US-10481321-B1 & US-9671614-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-09-06T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8858122192},{"pair":"US-2019361518-A1 & US-10129527-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10129527-B2","title_2":"Camera pose estimation for mobile devices ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10129527B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"Systems and methods are described for estimating a camera pose. The estimation may include obtaining a sequence of images including a plurality of image frames of a scene, detecting a first set of feature points in a first image frame, and tracking the first set of feature points in a plurality of subsequent image frames. While continuing to track the first set of feature points, the estimation can include detecting a second set of feature points in a second image frame, tracking the second set of feature points, selecting a first initial camera pose associated with the first image frame and a second initial camera pose associated with the second image frame, determining projection locations, the projection locations based on the first initial camera pose and the second initial camera pose, and comparing the projection locations corresponding to each feature point in the first and second sets of feature points.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-07-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8856881517},{"pair":"US-2019227322-A1 & US-2020041798-A1","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-25T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8855583819},{"pair":"US-2019311522-A1 & US-2018329602-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2018-04-05T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8851342868},{"pair":"US-2019285891-A1 & US-2020041798-A1","patent_1":"US-2019285891-A1","title_1":"Image quality of pancharatnam berry phase components using polarizers ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190285891A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Various embodiments set forth a near eye display (NED) that includes an electronic display configured to output image light. Further, the NED includes multiple Pancharatnam Berry Phase (PBP) optical elements that are combined with one or more circular polarizers to improve optical performance. A PBP element produces an output of three diffraction orders. Typically in an optical system that includes such a PBP element, one of the three diffraction orders is used while the other two are undesirable and preferably maintained at a relatively low intensity. A circular polarizer may reduce the intensities of the two undesired diffraction orders.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-03-15T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8850770514},{"pair":"US-10133168-B1 & US-2020041798-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-02-01T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8849436295},{"pair":"US-2019037137-A1 & US-10540818-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8845458209},{"pair":"US-10571692-B2 & US-2020041798-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-03-02T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8843284795},{"pair":"US-10108261-B1 & US-2015169054-A1","patent_1":"US-10108261-B1","title_1":"Eye tracking based on light polarization ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10108261B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using polarization. The eye tracking system includes an illumination source and an eye tracking unit comprising a polarization sensitive optical detector. The one or more illumination sources are configured to illuminate an eye and generate reflections directed towards the optical detector. The eye tracking unit is configured to determine a 3D shape of the eye based on the polarization of the reflections. The determined 3D shape of the eye is used to update a stored model of the eye in response to the one or more model parameter values extracted from the determined depth map of the corneal surface. The eye tracking system determines eye tracking information based on the updated model in order to improve eye tracking performance.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-07-05T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8842729514},{"pair":"US-10520729-B1 & US-9851565-B1","patent_1":"US-10520729-B1","title_1":"Light scattering element for providing optical cues for lens position adjustment ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10520729B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A method includes displaying a high contrast image on a display screen; and projecting the high contrast image through a Fresnel lens to provide a cue for adjusting a position of the Fresnel lens. Also disclosed is a device for determining and\/or adjusting an offset of a Fresnel lens. The device includes a Fresnel lens and a display screen configured to project a high contrast image through the Fresnel lens. Further disclosed is a method for adjusting a position of a Fresnel lens. The method includes receiving a projection of a high contrast image transmitted through a Fresnel lens; and adjusting a position of the Fresnel lens based on the projection of the high contrast image.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-04-25T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8841168912},{"pair":"US-2017262054-A1 & US-2018343443-A1","patent_1":"US-2017262054-A1","title_1":"Focus adjusting headset ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20170262054A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A virtual reality (VR) headset adjusts the phase of light of a virtual scene received from a display element using a spatial light modulator (SLM) to accommodate changes in vergence for a user viewing objects in the virtual scene. The VR headset receives virtual scene data that includes depth information for components of the virtual scene and the SLM adjusts a wavefront of the light of the virtual scene by generating a phase function that adjusts the light of the virtual scene with phase delays based the depth values. Individual phase delays shift components of the virtual scene based on the depth values to a target focal plane to accommodate a user at a vergence depth for a frame of the virtual scene. Further, the SLM can provide optical defocus by shifting components of the virtual scene with the phase delays for depth of field blur.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2016-03-11T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8840591592},{"pair":"US-10540930-B1 & US-2017116950-A1","patent_1":"US-10540930-B1","title_1":"Apparatus, systems, and methods for temperature-sensitive illumination of liquid crystal displays ","patent_2":"US-2017116950-A1","title_2":"Liquid crystal display with variable drive voltage ","link_1":"https:\/\/patents.google.com\/patent\/US10540930B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170116950A1\/en","abstract_1":"A display device may include (1) a liquid crystal (LC) panel with rows of pixel elements that include LC material capable of transitioning between two states, (2) a backlight coupled to the LC panel behind the rows of pixel elements and configured to emit light towards the rows of pixel elements, (3) a temperature sensor configured to measure a temperature of the LC panel, and (4) a display driver configured to (a) scan data to the rows of pixel elements such that the LC material makes a transition between the two states, (b) read, from the temperature sensor, the temperature of the LC panel, (c) calculate, based on the temperature of the LC panel, an estimated transition period for the transition, and (d) initiate, after the estimated transition period, an illumination of the backlight to illuminate the rows of pixel elements. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A technique for operation of a display system includes displaying a display image from a liquid crystal display source, measuring a brightness of ambient light, and selecting a drive voltage for driving liquid crystal cells within the liquid crystal display source based upon the brightness of the ambient light. The drive voltage is used for driving the liquid crystal cells into an on-state or an off-state while displaying the display image.","priority_1":"2018-01-05T00:00:00","priority_2":"2015-10-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8839728954},{"pair":"US-2019361523-A1 & US-9934583-B2","patent_1":"US-2019361523-A1","title_1":"In-field illumination and imaging for eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20190361523A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Disclosed herein are techniques for eye tracking in near-eye display devices. In some embodiments, an illuminator for eye tracking is provided. The illuminator includes a light source configured to be positioned within a field of view of an eye of a user; a first reflector configured to shadow the light source from a field of view of a camera; and a second reflector configured to receive light from the light source that is reflected by the eye of the user, and to direct the light toward the camera.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-05-23T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8839175437},{"pair":"US-10248890-B2 & US-9551579-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9551579-B1","title_2":"Automatic connection of images using visual features ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551579B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Aspects of the disclosure relate generating navigation paths between images. A first image taken from a first location and a second image taken from a second location may be selected. A position of the first location in relation to the second location may be determined. First and second frames for the first and second images may be selected based on the position. First and second sets of visual features for each of the first and second image frames may be identified. Matching visual features between the first set of visual features and the second set of visual features may be determined. A confidence level for a line-of-sight between the first and second images may be determined by evaluating one or more positions of the matching visual features. Based on at least the confidence level, a navigation path from the first image to the second image is generated.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-08-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8837408689},{"pair":"US-2018157053-A1 & US-2015146301-A1","patent_1":"US-2018157053-A1","title_1":"Dichroic combiner backlight used in a head mounted display ","patent_2":"US-2015146301-A1","title_2":"Lighting adjustment for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20180157053A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150146301A1\/en","abstract_1":"A liquid crystal display (LCD) device including a backlight with an LED assembly. The LED assembly includes a dichroic combiner and two or more different color LEDs. A substrate of the dichroic combiner receives color light from multiple color LEDs at different input regions and propagating in different directions. Dielectric layers within the substrate selectively reflect or transmit the color light to spatially superimpose the color light, and output the color light in a particular direction at a light output region of the substrate. The light output regions of LED assemblies are arranged behind an LCD panel, along one or more edges, to illuminate the LCD panel. The LED assembly provides edge-lighting without requiring LED placement along the one or more edges.","abstract_2":"An apparatus includes a light source, a display array, a light relay, a photodetector, and control circuitry. The light source is for providing lamp light during an ON-time of the light source. The display array is positioned to receive and selectively manipulate the lamp light. The light relay is positioned to receive the image light from the display array. Control circuitry is coupled to the light source for adjusting the light source and coupled to receive an output of the photodetector.","priority_1":"2016-12-06T00:00:00","priority_2":"2012-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8836690233},{"pair":"US-2019313087-A1 & US-10146054-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10146054-B2","title_2":"Adding prescriptive correction to eyepieces for see-through head wearable displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146054B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, a curved see-through component, an output coupler, and a prescription layer. The curved lightguide component guides display light received at an input region and releases the display light along an eye-ward direction in a viewing region. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is at least partially transmissive to ambient light incident through a world-facing side such that the viewing region is see-through. The curved see-through component is mated to the world-facing side of the curved lightguide component. The prescription layer has a first side mated to an eye-facing side of the curved lightguide component and a second side having a curvature that introduces prescriptive lensing to both the ambient light and the display light.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8836662676},{"pair":"US-10466496-B2 & US-9851565-B1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8836374296},{"pair":"US-2020090406-A1 & US-2018329485-A1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2018-09-17T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8835044911},{"pair":"US-2019384070-A1 & US-2020041798-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8833528434},{"pair":"US-2019384070-A1 & US-2019271844-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-06-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8831837},{"pair":"US-2019369390-A1 & US-9671614-B2","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-06-04T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8830280025},{"pair":"US-2019313087-A1 & US-10133074-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10133074-B2","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10133074B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Systems and methods are described for receiving image content from an emissive display toward a first filter stack, the first filter stack adapted to be oriented in a first direction from an optical axis of a first lens, and toward the first lens, transmitting the image content through a curved lens parallel to the optical axis of the first lens, wherein the curved lens transmits a portion of the image content to at least one optical element and to a second filter stack, the second filter stack being adapted to be oriented in a second direction from the optical axis of the first lens, and receiving the portion from the second filter stack and providing at least some of the portion to the first lens for viewing by a user.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8828487764},{"pair":"US-2018335630-A1 & US-9851565-B1","patent_1":"US-2018335630-A1","title_1":"Liquid crystal cells for polarization rotation ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180335630A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical element comprising a stacked liquid crystal (LC) structure for rotating polarization (e.g., handedness) of an incident circularly polarized light over a broad wavelength and incident angle for head-mounted displays (HMD)s display application is proposed. The stacked LC structure has a dual cell structures, which includes at least a first LC cell and a second LC cell, and the stacked LC structure rotates the polarized light for a broad band of light (e.g., visible spectrum) over a given field a view. The performance of designed dual LC cells structures may be optimized for narrow band wavelength and a narrow incident angle for different application cases.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-05-17T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8826326668},{"pair":"US-10410591-B1 & US-2015146301-A1","patent_1":"US-10410591-B1","title_1":"Liquid crystal display device with RGB backlight ","patent_2":"US-2015146301-A1","title_2":"Lighting adjustment for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10410591B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150146301A1\/en","abstract_1":"An electronic display comprises a backlight unit and a liquid crystal (LC) layer, wherein the backlight combines and directs light from a plurality of light sources towards the LC layer, which controls an amount of light to be displayed. The light sources comprise at least two different types of light sources associated with different wavelength ranges, to provide improved spectrum intensity for a wider range of wavelengths. The intensity of the light sources may be adjusted based upon the input data for an image to be displayed. For example, the light sources may be dimmed based upon a determined amount of the received image data associated with a particular gray level.","abstract_2":"An apparatus includes a light source, a display array, a light relay, a photodetector, and control circuitry. The light source is for providing lamp light during an ON-time of the light source. The display array is positioned to receive and selectively manipulate the lamp light. The light relay is positioned to receive the image light from the display array. Control circuitry is coupled to the light source for adjusting the light source and coupled to receive an output of the photodetector.","priority_1":"2016-07-18T00:00:00","priority_2":"2012-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8824468537},{"pair":"US-10534185-B1 & US-10241329-B2","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-02-14T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8822141045},{"pair":"US-2019353906-A1 & US-9851565-B1","patent_1":"US-2019353906-A1","title_1":"Optical Assembly with Polarization Volume Holographic Element ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190353906A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical assembly includes a partial reflector that is optically coupled with a first polarization volume holographic element. The partial reflector is capable of receiving first light having a first circular polarization and transmitting a portion of the first light having a first circular polarization. The first polarization volume holographic element is configured to receive the first portion of the first light and reflect the first portion of the first light as second light having the first circular polarization. The partial reflector is capable of receiving the second light and reflecting a first portion of the second light as third light having a second circular polarization opposite to the first polarization. The first polarization volume holographic element is configured to receive the third light having the second circular polarization and transmit the third light having the second circular polarization.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8818955677},{"pair":"US-2019353898-A1 & US-9851565-B1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8818218486},{"pair":"US-2017161951-A1 & US-10241329-B2","patent_1":"US-2017161951-A1","title_1":"Autofocus virtual reality headset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170161951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A scene presented by a headset is adjusted to correct for distortion from optical errors of an optics block in the headset. To correct for the distortion, the scene is pre-distorted when presented based on previously modeled distortion of the optics block, so distortion from the optics block corrects the pre-distortion. To model the distortion, the headset displays calibration image including features and images of the calibration image are captured from multiple positions. Differences between locations of features in the calibration images and locations of corresponding features in captured images of the calibration image are identified and a distortion correction is determined based on the differences.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2015-12-08T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8816955205},{"pair":"US-10528128-B1 & US-9851565-B1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-15T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8812936428},{"pair":"US-10248890-B2 & US-2019287259-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2019287259-A1","title_2":"Hierarchical disparity hypothesis generation with slanted support windows ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190287259A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A method includes capturing a first image and a second image of a scene using at least one imaging camera of an imaging system. The first image and the second image form a stereo image pair and each comprises a plurality of pixels. Each of the plurality of pixels in the second image is initialized with a disparity hypothesis. Matching costs of the disparity hypothesis for each of the plurality of pixels in the second image are recursively determined, from an image tile of a smaller pixel size to an image tile of a larger pixel size, to generate an initial tiled disparity map including a plurality of image tiles. After refining the disparity value estimate of each image tile and including a slant hypothesis, a final disparity estimate for each pixel of the image is generated.","priority_1":"2017-04-13T00:00:00","priority_2":"2018-03-14T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8810344255},{"pair":"US-10599215-B2 & US-10032074-B2","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-04-26T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8808890714},{"pair":"US-2019361518-A1 & US-10453175-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10453175-B2","title_2":"Separate time-warping for a scene and an object for display of virtual reality content ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10453175B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"An example technique may include performing a first time-warping of a scene of virtual reality content based on head pose information received during or after a rendering of the scene to obtain a time-warped scene, performing a second time-warping of an object based at least on object pose information received during or after a rendering of the object to obtain a time-warped object, and displaying on a display device a composite image based on the time-warped scene and the time-warped object.","priority_1":"2018-05-22T00:00:00","priority_2":"2016-02-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8808727916},{"pair":"US-2019311522-A1 & US-2018329485-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2018-04-05T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8807741601},{"pair":"US-2020057304-A1 & US-2020073123-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-08-16T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8807185112},{"pair":"US-2019318528-A1 & US-10460505-B2","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8806819315},{"pair":"US-2019037137-A1 & US-10275898-B1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10275898-B1","title_2":"Wedge-based light-field video capture ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10275898B1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A combined video of a scene may be generated for applications such as virtual reality or augmented reality. In one method, a camera system may be oriented at a first orientation and used to capture first video of a first portion of the scene. The camera system may then be rotated to a second orientation and used to capture second video of a second portion of the scene that is offset from the first portion such that the first video and the second video each have an overlapping video portion depicting an overlapping portion of the scene in which the first portion and the second portion of the scene overlap with each other. The first and second portions may be combined together to generate the combined video, which may depict the first and second portions substantially without duplicative inclusion of the overlapping video portion.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8806441935},{"pair":"US-10345600-B1 & US-2016240013-A1","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-06-08T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8806418989},{"pair":"US-2019101767-A1 & US-2019271844-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8806087911},{"pair":"US-2019318530-A1 & US-10460505-B2","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8805264542},{"pair":"US-10529117-B2 & US-10460505-B2","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8805021796},{"pair":"US-10598928-B1 & US-9851565-B1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8799172467},{"pair":"US-2018284884-A1 & US-9851565-B1","patent_1":"US-2018284884-A1","title_1":"Waveguide display with spatially switchable grating ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180284884A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye-display (NED) includes an eye tracking system and a waveguide display. The eye tracking system tracks locations based on a location of the user's eyes. The waveguide display includes a light source, an output waveguide and a controller. The output waveguide includes a dynamic output grating that outputs an expanded image light to the tracked eyebox locations. The decoupling grating is a 2D array of spatially switchable liquid crystal (LC) pixels including an active subset of LC pixels emitting light to regions within the tracked eyebox locations. The decoupling grating dynamically out-couples the expanded image light to the tracked location based on switching instructions generated and provided by the controller.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-04-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8798973669},{"pair":"US-10600352-B1 & US-2019271844-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-12-04T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8797010751},{"pair":"US-2018173303-A1 & US-2019102936-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2019102936-A1","title_2":"Lighting for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102936A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Systems and methods for lighting inserted content are provided. For example, the inserted content may include augmented reality content that is inserted into an image of a physical space. An example system and method may include determining a location within an image to insert content. For example, the image may be captured by a camera device. The example system and method may also include identifying a region of the image based on the determined location to insert the content, determining at least one lighting parameter based on the identified region, and rendering the content using the determined at least one lighting parameter.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8796657684},{"pair":"US-10261324-B2 & US-2016198949-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2016198949-A1","title_2":"Hybrid lens system for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160198949A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"A hybrid optical system for a head wearable display includes a central vision lens and a peripheral vision lens. The central vision lens approximately aligns with a cornea of a user to provide lensing to a central vision of the user when the user is looking straight forward. The peripheral vision lens, different than the central vision lens, provides lensing to an extended field of view that extends angularly beyond the central vision lensed by the central vision lens when the user is looking straight forward. The peripheral vision lens is disposed around the central vision lens. The peripheral vision lens has a co-incident optical center with the central vision lens but the central vision lens is offset from a physical center of the peripheral vision lens.","priority_1":"2017-08-10T00:00:00","priority_2":"2015-01-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8796651383},{"pair":"US-2019318529-A1 & US-10460505-B2","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8796105756},{"pair":"US-10248890-B2 & US-2018329485-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8795585856},{"pair":"US-10502963-B1 & US-9851565-B1","patent_1":"US-10502963-B1","title_1":"Immersed fresnel structure with curable liquid polymer ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10502963B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A method is presented herein for manufacturing an immersed Fresnel structure. A first liquid polymer is applied to a first surface of a substrate, the substrate having a second surface that is opposite the first surface. The first liquid polymer is illuminated with light to change at least one property of the first liquid polymer and obtain a modified polymer attached to the first surface of the substrate. A second liquid polymer is applied to at least a portion of a surface of a Fresnel structure. The second surface of the substrate is applied to an outer surface of the second liquid polymer applied to the Fresnel structure to obtain a stacked Fresnel surface. The stacked Fresnel surface is illuminated with light to obtain an immersed Fresnel structure. The immersed Fresnel structure can be used as part of a near-eye display.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-07-16T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8794159353},{"pair":"US-2017061838-A1 & US-9851565-B1","patent_1":"US-2017061838-A1","title_1":"Compensation of Chromatic Dispersion in a Tunable Beam Steering Device for Improved Display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170061838A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device includes a plurality of pixels. Each pixel includes two or more subpixels. The plurality of pixels includes a first subpixel configured to transmit light of a first color and a second subpixel configured to transmit light of a second color that is distinct from the first color. The display device also includes a beam steering device, and one or more compensators located between the plurality of pixels and the beam steering device and configured to change a direction of the light from the first subpixel and transmit the light toward the beam steering device and change a direction of the light from the second subpixel and transmit the light toward the beam steering device.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-08-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8794158069},{"pair":"US-2019311522-A1 & US-10540818-B2","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2018-04-05T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8793986034},{"pair":"US-2019197667-A1 & US-2018352213-A1","patent_1":"US-2019197667-A1","title_1":"Computing high-resolution depth images using machine learning techniques ","patent_2":"US-2018352213-A1","title_2":"Learning-based matching for active stereo systems ","link_1":"https:\/\/patents.google.com\/patent\/US20190197667A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180352213A1\/en","abstract_1":"A system trains a machine learning model to generate a high-resolution depth image. During a training phase, the system generates an accurate three dimensional reconstruction of a training scene such that the machine learning model is iteratively trained to minimize an error between the higher resolution depth image and the depth information in the accurate three dimensional reconstruction. During a real-time phase, the system applies the trained machine learning model to images captured from a scene of interest and generates a higher resolution depth image with higher accuracy. Thus, the higher resolution depth image can be subsequently used to solve computer vision problems.","abstract_2":"A first and second image of a scene are captured. Each of a plurality of pixels in the first image is associated with a disparity value. An image patch associated with each of the plurality of pixels of the first image and the second image is mapped into a binary vector. Thus, values of pixels in an image are mapped to a binary space using a function that preserves characteristics of values of the pixels. The difference between the binary vector associated with each of the plurality of pixels of the first image and its corresponding binary vector in the second image designated by the disparity value associated with each of the plurality of pixels of the first image is determined. Based on the determined difference between binary vectors, correspondence between the plurality of pixels of the first image and the second image is established.","priority_1":"2017-12-26T00:00:00","priority_2":"2017-06-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8791147168},{"pair":"US-2020064641-A1 & US-2017235145-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8791067133},{"pair":"US-2020064641-A1 & US-2017357090-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2017357090-A1","title_2":"Head-wearable displays with a tiled field of view using a single microdisplay ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170357090A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"Implementations are described of an eyepiece for a head wearable display. The eyepiece includes a curved lightguide for guiding display light via total internal reflection between a peripherally-located input surface and a viewing region and an output coupler disposed across the viewing region to redirect the display light towards an eyeward direction for output from the curved light guide. The output coupler has an optical axis and has a set of reflective surfaces that includes at least two individual reflective surfaces to reflect incident display light toward the eyeward direction in at least two different directions relative to the optical axis of the output coupler. Other embodiments are disclosed and claimed.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-06-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8789329079},{"pair":"US-2019313087-A1 & US-2019025602-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8785141066},{"pair":"US-2019313087-A1 & US-10095036-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10095036-B2","title_2":"Compact near-eye display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10095036B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Systems and methods that employ a near-eye display system including an optical assembly are described. The optical assembly may include a head-mounted display device worn by a user in which the head-mounted display device adapted to house an image projecting device and an optical assembly. The optical assembly may include, for at least one eyepiece, a first flat filter stack operable to be oriented in a first direction. and a second flat filter stack operable to be oriented in a second direction. The near-eye display system assembly may also include a display panel adapted to receive image content from the image projecting device, wherein the display panel is adapted to be oriented in the second direction.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8784898844},{"pair":"US-2020027261-A1 & US-2017228926-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017228926-A1","title_2":"Determining Two-Dimensional Images Using Three-Dimensional Models ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170228926A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for determining two-dimensional (2D) images are presented. For instance, data indicative of a three-dimensional (3D) model of a geographic area can be obtained. A 2D output image can be generated depicting at least a portion of the geographic area based at least in part on the 3D model. Each pixel in the output image can then be reprojected to the 3D model. A plurality of aerial images depicting the geographic area can be obtained. A source image can then be determined for each pixel in the output image from the plurality of aerial images. The source image can be determined based at least in part on the reprojection of the pixel in the output image to the three-dimensional model.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-11-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8784422389},{"pair":"US-2020090406-A1 & US-10593098-B2","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-09-17T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.878118598},{"pair":"US-2019369390-A1 & US-2019025602-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-06-04T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8781134021},{"pair":"US-10248890-B2 & US-10540818-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8779725292},{"pair":"US-2018172999-A1 & US-9851565-B1","patent_1":"US-2018172999-A1","title_1":"Multifocal system with polarizing elements ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180172999A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes a multifocal block having one or more possible focal distances and includes a multifocal structure. The multifocal structure has a first focal distance and a second focal distance of the one or more possible focal distances. The multifocal structure includes one or more optical components positioned in series such that light from an electronic display is received and passes through each of the one or more optical components at least once before being output from the multifocal structure. The one or more optical components includes a switchable half waveplate (SHWP). The SHWP has a first state that causes the multifocal structure to output image light at the first focal distance, and a second state that causes the multifocal structure to output the image light at the first focal distance.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-12-20T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8778249994},{"pair":"US-10345600-B1 & US-2019020869-A1","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-06-08T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8776828452},{"pair":"US-2016085301-A1 & US-2019020869-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2014-09-22T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8776778821},{"pair":"US-2019037137-A1 & US-2016328882-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2016328882-A1","title_2":"Pass-through display of captured imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160328882A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A method includes sequentially outputting from an imaging sensor each pixel row of a set of pixel rows of an image captured by the imaging sensor. The method further includes displaying, at a display device, a pixel row representative of a first pixel row of the captured image prior to a second pixel row of the captured image being output by the imaging sensor. An apparatus includes an imaging sensor having a first lens that imparts a first type of spatial distortion, a display device coupled to the imaging sensor, the display to display imagery captured by the imaging sensor with the first spatial distortion, and an eyepiece lens aligned with the display, the eyepiece lens imparting a second type of spatial distortion that compensates for the first type of spatial distortion.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-05-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8776474},{"pair":"US-10528128-B1 & US-9934583-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-12-15T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8774718291},{"pair":"US-2017059960-A1 & US-9851565-B1","patent_1":"US-2017059960-A1","title_1":"Devices and Methods for Removing Zeroth Order Leakage in Beam Steering Devices ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170059960A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A beam steering device includes a first active deflector. The first active deflector includes a first substrate with one or more electrodes, a second substrate with one or more electrodes, and liquid crystals located between the first substrate and the second substrate. The second substrate is distinct from the first substrate. The beam steering device also includes a passive deflector positioned parallel to the first active deflector. The passive deflector includes a third substrate, a fourth substrate that is distinct from the third substrate, and liquid crystals located between the third substrate and the fourth substrate. A method for separating zeroth order leakage with the beam steering device is also disclosed.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-08-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.877453069},{"pair":"US-10495798-B1 & US-2020041798-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8773964257},{"pair":"US-10248890-B2 & US-2018329602-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.877088995},{"pair":"US-2019384070-A1 & US-9946074-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8770034703},{"pair":"US-2020064633-A1 & US-2019265477-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2019265477-A1","title_2":"Augmented reality light field head-mounted displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190265477A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A near-eye display system includes a transmissive display panel to display a near-eye light field frame comprising an array of elemental images. The transmissive display panel is configured to transmit light rays of the near-eye light field frame away from the user's eye and towards an array of curved beam splitters. The curved beam splitters collimate the transmitted light rays and reflect the collimated light rays back towards the transmissive display panel for passing to the user's eye.","priority_1":"2018-08-23T00:00:00","priority_2":"2018-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8769606985},{"pair":"US-2019311522-A1 & US-10593098-B2","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8768193018},{"pair":"US-2019318530-A1 & US-9734579-B1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8767088244},{"pair":"US-10200624-B2 & US-9900510-B1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-9900510-B1","title_2":"Motion blur for light-field images ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9900510B1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"Motion blur may be applied to a light-field image. The light-field image may be captured with a light-field camera having a main lens, an image sensor, and a plurality of microlenses positioned between the main lens and the image sensor. The light-field image may have a plurality of lenslet images, each of which corresponds to one microlens of the microlens array. The light-field image may be used to generate a mosaic of subaperture images, each of which has pixels from the same location on each of the lenslet images. Motion vectors may be computed to indicate motion occurring within at least a primary subaperture image of the mosaic. The motion vectors may be used to carry out shutter reconstruction of the mosaic to generate a mosaic of blurred subaperture images, which may then be used to generate a motion-blurred light-field image.","priority_1":"2016-04-06T00:00:00","priority_2":"2016-12-08T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8766638672},{"pair":"US-2017115519-A1 & US-9851565-B1","patent_1":"US-2017115519-A1","title_1":"Time-Domain Adjustment of Phase Retardation in a Liquid Crystal Grating for a Color Display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170115519A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A method includes sequentially transmitting, through a beam steering device, light of a first color and light of a second color that is distinct from the first color. The method also includes applying a first voltage to the beam steering device for transmission of the light of the first color through the beam steering device; and applying a second voltage to the beam steering device for transmission of the light of the second color through the beam steering device. A device configured to perform the method is also described.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-08-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8766044653},{"pair":"US-2019318528-A1 & US-9734579-B1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8765074875},{"pair":"US-2018173303-A1 & US-9536354-B2","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8764637528},{"pair":"US-10509228-B1 & US-10241329-B2","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-12-20T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8763655285},{"pair":"US-2019369390-A1 & US-2019271844-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-06-04T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8763612821},{"pair":"US-10529276-B2 & US-2017116950-A1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-2017116950-A1","title_2":"Liquid crystal display with variable drive voltage ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170116950A1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A technique for operation of a display system includes displaying a display image from a liquid crystal display source, measuring a brightness of ambient light, and selecting a drive voltage for driving liquid crystal cells within the liquid crystal display source based upon the brightness of the ambient light. The drive voltage is used for driving the liquid crystal cells into an on-state or an off-state while displaying the display image.","priority_1":"2018-01-05T00:00:00","priority_2":"2015-10-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8762878512},{"pair":"US-10529117-B2 & US-9734579-B1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8762118506},{"pair":"US-10291855-B2 & US-10419737-B2","patent_1":"US-10291855-B2","title_1":"Three-dimensional, 360-degree virtual reality camera live preview ","patent_2":"US-10419737-B2","title_2":"Data structures and delivery methods for expediting virtual reality playback ","link_1":"https:\/\/patents.google.com\/patent\/US10291855B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10419737B2\/en","abstract_1":"A camera system provides a live preview that provides a user device a pseudo-real time depiction of what the camera assembly is imaging. The camera system captures images from a plurality of cameras. The camera system captures images from a plurality of cameras. The camera system stores the captured images in respective memory locations of a buffer. The stored captured images form a high priority data stream that generates content associated with the portion of the local area. The camera system selects, as part of a low priority data stream, one or more of the images from memory locations. The camera system encodes the selected one or more images. The camera system packetizes the encoded one or more images to form an image frame in a video feed. The camera system provides the image frame to a user device that presents the image frame as part of the video feed.","abstract_2":"A video stream for a scene for a virtual reality or augmented reality experience may be stored and delivered to a viewer. The video stream may be divided into a plurality of units based on time segmentation, viewpoint segmentation, and\/or view orientation segmentation. Each of the units may be divided into a plurality of sub-units based on a different segmentation from the units, via time segmentation, viewpoint segmentation, and\/or view orientation segmentation. At least a portion of the video stream may be stored in a file that includes a plurality of the units. Each unit may be a group of pictures that is a sequence of successive frames in time. Each sub-unit may be a vantage defining a viewpoint from which the scene is viewable. Each vantage may be further divided into tiles, each of which is part of the vantage, limited to one or more particular view orientations.","priority_1":"2017-04-14T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8760810674},{"pair":"US-10200624-B2 & US-2017256036-A1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-2017256036-A1","title_2":"Automatic microlens array artifact correction for light-field images ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170256036A1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"According to various embodiments, light-field image data may be processed so as to prevent, remove, and\/or mitigate artifacts caused by previous processing steps. A light-field image may first be captured by a light-field camera. One or more processing steps may be applied to the light-field image to generate a processed light-field image having one or more artifacts. A flat white modulation light-field image may also be captured by the light-field camera. The same processing steps previously applied to the light-field image may be applied to the modulation light-field image to generate a processed modulation light-field image with the same artifacts. The artifacts may then be identified in the processed modulation light-field image to generate an identification of the artifacts. This identification may be used to identify the same artifacts in the processed light-field image, which may then be corrected to remove the artifacts to generate a corrected, processed light-field image.","priority_1":"2016-04-06T00:00:00","priority_2":"2016-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.875999926},{"pair":"US-10506217-B2 & US-2019037194-A1","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.875860108},{"pair":"US-10481321-B1 & US-2018239141-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-09-06T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8757910942},{"pair":"US-10599215-B2 & US-9934583-B2","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-04-26T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.875593671},{"pair":"US-2020064641-A1 & US-9946074-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8755901481},{"pair":"US-10248890-B2 & US-2018061119-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8755670186},{"pair":"US-2019311522-A1 & US-2018350032-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2018350032-A1","title_2":"Smoothly varying foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180350032A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Systems and methods for performing foveated rendering are provided. An example system and method may warp a 3D scene based on a fixation point. The system and method may also render the warped 3D scene to generate a first image. The system and method may also unwarp the first image to generate a second image. For example, the first image may have fewer pixels than the second image.","priority_1":"2018-04-05T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.875450817},{"pair":"US-10495798-B1 & US-9851565-B1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-07T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8753752462},{"pair":"US-2018173303-A1 & US-2018350032-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2018350032-A1","title_2":"Smoothly varying foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180350032A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Systems and methods for performing foveated rendering are provided. An example system and method may warp a 3D scene based on a fixation point. The system and method may also render the warped 3D scene to generate a first image. The system and method may also unwarp the first image to generate a second image. For example, the first image may have fewer pixels than the second image.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8752667962},{"pair":"US-2019227322-A1 & US-9851565-B1","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-25T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8752338848},{"pair":"US-10345600-B1 & US-10591731-B2","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-06-08T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8751350944},{"pair":"US-10248890-B2 & US-2017358092-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017358092-A1","title_2":"Multi-view scene segmentation and propagation ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170358092A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A depth-based effect may be applied to a multi-view video stream to generate a modified multi-view video stream. User input may designate a boundary between a foreground region and a background region, at a different depth from the foreground region, of a reference image of the video stream. Based on the user input, a reference mask may be generated to indicate the foreground region and the background region. The reference mask may be used to generate one or more other masks that indicate the foreground and background regions for one or more different images, from different frames and\/or different views from the reference image. The reference mask and other mask(s) may be used to apply the effect to the multi-view video stream to generate the modified multi-view video stream.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-06-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8751229416},{"pair":"US-10557994-B1 & US-2018239141-A1","patent_1":"US-10557994-B1","title_1":"Waveguide grating with spatial variation of optical phase ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10557994B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"An optical waveguide is disclosed. The optical waveguide includes a plate of transparent material comprising opposed first and second surfaces for guiding an optical beam between the surfaces by at least one of reflection or diffraction. A diffraction grating is disposed at the first surface for spreading the optical beam by diffracting portions thereof into a non-zero diffraction order to propagate inside the plate. The first diffraction grating includes an array of parallel grooves structured to provide a spatial variation of optical phase of the portions of the optical beam diffracted by the first diffraction grating into the non-zero diffraction order.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-09-24T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8751130879},{"pair":"US-10599215-B2 & US-9870049-B2","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2016-04-26T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8750725564},{"pair":"US-2019318529-A1 & US-9734579-B1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8750684674},{"pair":"US-2019311522-A1 & US-9626790-B1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-9626790-B1","title_2":"View-dependent textures for interactive geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9626790B1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a polygon mesh to provide a textured three-dimensional model of a geographic area are provided. The view-dependent texture can be optimized for viewing the three-dimensional model from a single reference direction. When a user navigates to a camera viewpoint of the three-dimensional model associated with the single reference direction, the view-dependent texture can be rendered in conjunction with the three-dimensional model to provide a more realistic representation of the geographic area to the user. When a user navigates to a camera viewpoint of the three-dimensional model that is not associated with the single reference direction, a base texture can be rendered in conjunction with the three-dimensional model. The base texture can be optimized based on viewing the three-dimensional model from a plurality of differing viewpoints.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8750683628},{"pair":"US-10502963-B1 & US-2020041798-A1","patent_1":"US-10502963-B1","title_1":"Immersed fresnel structure with curable liquid polymer ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10502963B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A method is presented herein for manufacturing an immersed Fresnel structure. A first liquid polymer is applied to a first surface of a substrate, the substrate having a second surface that is opposite the first surface. The first liquid polymer is illuminated with light to change at least one property of the first liquid polymer and obtain a modified polymer attached to the first surface of the substrate. A second liquid polymer is applied to at least a portion of a surface of a Fresnel structure. The second surface of the substrate is applied to an outer surface of the second liquid polymer applied to the Fresnel structure to obtain a stacked Fresnel surface. The stacked Fresnel surface is illuminated with light to obtain an immersed Fresnel structure. The immersed Fresnel structure can be used as part of a near-eye display.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-07-16T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8750682423},{"pair":"US-10379348-B2 & US-9851565-B1","patent_1":"US-10379348-B2","title_1":"Hybrid fresnel lens with increased field of view ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10379348B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens defined by a first lens surface and a second lens surface opposite to the first lens surface is disclosed. The lens includes a first portion; and a second portion that is distinct from the first portion and is located around the first portion. The first lens surface for the first portion of the lens is defined by a Fresnel surface profile. The second lens surface for the first portion of the lens is defined by a smooth surface profile. The first lens surface for a second portion of the lens is defined by a Fresnel surface profile. The second lens surface for the second portion of the lens is defined by a Fresnel surface profile.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-09-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8749317382},{"pair":"US-10489648-B2 & US-9934583-B2","patent_1":"US-10489648-B2","title_1":"Eye tracking using time multiplexing ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10489648B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system implements time-multiplexing by configuring a source assembly comprising a plurality of light sources to project at least a first light pattern towards the user's eye over a first time period, and a second light pattern towards the user's eye over a second time period in accordance with a set of emission instructions. A camera assembly is configured to capture images of the user's eye during the first and second time periods in accordance with a set of imaging instructions, the captured images containing one or more glints corresponding to reflections of the first or second light patterns on the cornea of the user's eye. The location of the glints may be used to determine a shape or orientation of the eye.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-08-04T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8748601739},{"pair":"US-10534156-B2 & US-9851565-B1","patent_1":"US-10534156-B2","title_1":"Devices and methods for lens alignment based on encoded color patterns ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10534156B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display device includes a first light element configured to transmit a first light having a first color; a second light element configured to transmit a second light having a second color; a first lens configured for directing the first light in a first direction and directing the second light in a second direction; and a first set of one or more lenses configured for directing the first light and the second light from the first lens toward a first eye of a user. Also disclosed is a method that includes transmitting a first light and a second light through a first lens and a first set of one or more lenses and directing the first light and the second light toward a first eye of a user. Further disclosed is a method for adjusting a position of one or more lenses.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-05-01T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8748080706},{"pair":"US-2019313087-A1 & US-2019018255-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019018255-A1","title_2":"Compact near-eye optical system including a refractive beam-splitting convex lens ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190018255A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical system includes a first filter stack to convert light to a first circular polarization, and a second filter stack that reflects light having the first circular polarization and transmits light having a second circular polarization. A refractive beam splitting convex lens is disposed intermediate the first filter stack and the second filter stack. The first filter stack can include a first linear polarizer to convert light to a first linear polarization and a first quarter wave plate to convert the light from the first linear polarization to a first circular polarization. The second filter stack can include a second quarter wave plate to convert the light from the first circular polarization to a second linear polarization that is transverse to the first linear polarization, a polarization-dependent beam splitter to pass the first polarization and reflect the second polarization, and a linear polarizer to pass the second polarization.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-07-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8748055616},{"pair":"US-10474229-B1 & US-2019025602-A1","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2017-11-01T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8745840922},{"pair":"US-10481321-B1 & US-2019271844-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-09-06T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8745814808},{"pair":"US-10557994-B1 & US-2020041798-A1","patent_1":"US-10557994-B1","title_1":"Waveguide grating with spatial variation of optical phase ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10557994B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical waveguide is disclosed. The optical waveguide includes a plate of transparent material comprising opposed first and second surfaces for guiding an optical beam between the surfaces by at least one of reflection or diffraction. A diffraction grating is disposed at the first surface for spreading the optical beam by diffracting portions thereof into a non-zero diffraction order to propagate inside the plate. The first diffraction grating includes an array of parallel grooves structured to provide a spatial variation of optical phase of the portions of the optical beam diffracted by the first diffraction grating into the non-zero diffraction order.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-09-24T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8745140339},{"pair":"US-2019037137-A1 & US-10038887-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10038887-B2","title_2":"Capture and render of panoramic virtual reality content ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10038887B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Systems and methods are described for defining a set of images based on captured images, receiving a viewing direction associated with a user of a virtual reality (VR) head mounted display, receiving an indication of a change in the viewing direction. The methods further include configuring, a re-projection of a portion of the set of images, the re-projection based at least in part on the changed viewing direction and a field of view associated with the captured images, and converting the portion from a spherical perspective projection into a planar perspective projection, rendering by the computing device and for display in the VR head mounted display, an updated view based on the re-projection, the updated view configured to correct distortion and provide stereo parallax in the portion, and providing, to the head mounted display, the updated view including a stereo panoramic scene corresponding to the changed viewing direction.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8743964123},{"pair":"US-10466484-B1 & US-9851565-B1","patent_1":"US-10466484-B1","title_1":"Compact head-mounted display for artificial reality ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10466484B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes a dichroic element, an eye tracking system, a controller, and an external focus camera. The dichroic element is transmissive to the light in a first optical band (e.g., visible light) but reflective to light in a second optical band (e.g., IR light). The eye tracking system includes a source assembly and a tracking camera. The source assembly projects light in the second optical band into an eyebox of the HMD. The tracking camera captures images of at least a portion of a user's eye in the eyebox. The controller of the HMD determines a gaze direction of the user based on the captured images. An orientation of the external focus camera corresponds to the gaze direction. The external focus camera captures image data of a portion of a local area surrounding the HMD at the orientation.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-14T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8742922481},{"pair":"US-10504243-B2 & US-10242454-B2","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-10242454-B2","title_2":"System for depth data filtering based on amplitude energy values ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10242454B2\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"An electronic device includes a time of flight (ToF) camera and one or more processors. The ToF camera captures raw depth images. The processors determine a depth frame and an amplitude frame from the raw depth images. The depth frame comprises an array of pixels, each pixel having a depth value. The amplitude frame comprises an array of pixels, each pixel having an amplitude energy value. The processors determine a first energy threshold value based on the amplitude energy values of the array of pixels of the amplitude frame and determine, for the depth value of a first pixel of the depth frame, a confidence value representing a corresponding validity of a depth represented by the depth value, based on a comparison of the amplitude energy value of a corresponding first pixel of the amplitude frame to the first energy threshold value.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-01-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8742801792},{"pair":"US-2020090406-A1 & US-9704282-B1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-09-17T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8742560774},{"pair":"US-2019037137-A1 & US-2016353090-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2016353090-A1","title_2":"Omnistereo capture and render of panoramic virtual reality content ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160353090A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Systems and methods are described include defining, at a computing device, a set of images based on captured images, projecting, at the computing device, a portion of the set of images from a planar perspective image plane onto a spherical image plane by recasting a plurality of viewing rays associated with the portion of the set of images from a plurality of viewpoints arranged around a curved path to a viewpoint, determining, at the computing device, a periphery boundary corresponding to the viewpoint and generating updated images by removing pixels that are outside of the periphery boundary, and providing, for display, the updated images within the bounds of the periphery boundary.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8741477434},{"pair":"US-10595000-B1 & US-2018192033-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2018192033-A1","title_2":"Multi-view scene flow stitching ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180192033A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A method of multi-view scene flow stitching includes capture of imagery from a three-dimensional (3D) scene by a plurality of cameras and stitching together captured imagery to generate virtual reality video that is both 360-degree panoramic and stereoscopic. The plurality of cameras capture sequences of video frames, with each camera providing a different viewpoint of the 3D scene. Each image pixel of the sequences of video frames is projected into 3D space to generate a plurality of 3D points. By optimizing for a set of synchronization parameters, stereoscopic image pairs may be generated for synthesizing views from any viewpoint. In some embodiments, the set of synchronization parameters includes a depth map for each of the plurality of video frames, a plurality of motion vectors representing movement of each one of the plurality of 3D points in 3D space over a period of time, and a set of time calibration parameters.","priority_1":"2018-08-02T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8741368811},{"pair":"US-10416461-B2 & US-9671614-B2","patent_1":"US-10416461-B2","title_1":"Pancake lens with large FOV ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10416461B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A HMD includes an electronic display and a pancake lens block. The pancake lens block includes a back curved optical element and a front curved optical element. Light propagating through the pancake lens block undergoes multiple reflections and to mitigate parasitic reflections, there are no air gaps between optical elements of the pancake lens block. A hybrid film that operates as a waveplate surface and a mirrored surface can be placed between the front curved optical element and the back curved optical element. A wide FOV can be obtained by making the coupling surfaces of the front optical element and the back optical element to be based on a convex cylindrical surface profile and a concave cylindrical surface profile, with the axis of the cylinder surface in a vertical direction for a user wearing the HMD.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2016-10-27T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8741264341},{"pair":"US-2016085301-A1 & US-2016357266-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2016357266-A1","title_2":"Methods And Systems For Hands-Free Browsing In A Wearable Computing Device ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160357266A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Methods and systems for hands-free browsing in a wearable computing device are provided. A wearable computing device may provide for display a view of a first card of a plurality of cards which include respective virtual displays of content. The wearable computing device may determine a first rotation of the wearable computing device about a first axis and one or more eye gestures. Based on a combination of the first rotation and the eye gestures, the wearable computing device may provide for display the navigable menu, which may include an alternate view of the first card and at least a portion of one or more cards. Then, based on a determined second rotation of the wearable computing device about a second axis and based on a direction of the second rotation, the wearable computing device may generate a display indicative of navigation through the navigable menu.","priority_1":"2014-09-22T00:00:00","priority_2":"2014-01-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8740752171},{"pair":"US-10338379-B1 & US-9851565-B1","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-10-09T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8740443254},{"pair":"US-10133168-B1 & US-9946074-B2","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-02-01T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8739086909},{"pair":"US-10528128-B1 & US-9870049-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2017-12-15T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8739051075},{"pair":"US-10534185-B1 & US-9851565-B1","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-02-14T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8739030048},{"pair":"US-2018074320-A1 & US-9851565-B1","patent_1":"US-2018074320-A1","title_1":"Dynamic Draft for Fresnel Lenses ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180074320A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The draft facet is characterized by a draft angle. The draft angle of the respective Fresnel structure is based on a distance of the respective Fresnel structure from a center of the lens.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-09-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8738927279},{"pair":"US-2018239145-A1 & US-9851565-B1","patent_1":"US-2018239145-A1","title_1":"Focus adjusting multiplanar head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180239145A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A multiplanar head mounted display (HMD) includes two or more artificial display planes for each eye located at optical distances that can be dynamically adjusted based on a location within a scene presented by the HMD that the user views. For example, a scene is presented on two or more electronic display elements (e.g., screens) of the HMD. A focal length of an optics block that directs image light from the electronic display elements towards the eyes of a user is adjusted using a varifocal system (e.g., an element that mechanically changes a distance between a lens system in the optics block and the electronic display element, an element that changes shape of one or more lenses in the lens system in the optics block, etc.) based on a location or object within the scene where the user is looking.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-02-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8738920752},{"pair":"US-10521658-B2 & US-2019101757-A1","patent_1":"US-10521658-B2","title_1":"Embedded eye tracker with dichroic mirror ","patent_2":"US-2019101757-A1","title_2":"Eye tracking using light guide with faceted combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10521658B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190101757A1\/en","abstract_1":"An eyewear device has an optical element, a source, a dichroic mirror, and a camera. The optical element has a front surface, a back surface, a rim, and an angled portion of the rim. The source emits light in a first band of light and is configured to illuminate a portion of an eye of a user of the eyewear device. The dichroic mirror is arranged proximate to the angled portion of the rim, is reflective in the first band of light, is transmissive in a second band of light, and is configured to direct light in the first band reflected from the portion of the eye toward a first position. The camera is located in the first position that is located in a plane of the optical element, and the camera is configured to capture images of the light in the first band reflected by the dichroic mirror.","abstract_2":"An eye tracking system includes a light guide comprising a first eye-facing surface, a second surface, a third surface, and a plurality of facets formed in the second surface. The facets reflect a portion of light incident on a user eye into the light guide, which is positioned proximate to the user eye and between the user eye and a display. A surface of a compensator may be shaped complementary to the second surface of the light guide and placed proximate to the light guide. A camera or image sensor is oriented toward the third surface of the light guide and captures an image based on internally reflected light. An IR light source may be included. The image sensor may be an IR image sensor. Based on the image, a pose of the user eye is determined. A faceted light guide assembly may include a reflective coating adjacent the facets.","priority_1":"2017-07-07T00:00:00","priority_2":"2017-10-02T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8738823627},{"pair":"US-10599215-B2 & US-9851565-B1","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-04-26T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.873873677},{"pair":"US-2018173303-A1 & US-9934583-B2","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8737587685},{"pair":"US-10534177-B1 & US-2020041798-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-10-10T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8735125187},{"pair":"US-10210660-B2 & US-10038887-B2","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-10038887-B2","title_2":"Capture and render of panoramic virtual reality content ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10038887B2\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"Systems and methods are described for defining a set of images based on captured images, receiving a viewing direction associated with a user of a virtual reality (VR) head mounted display, receiving an indication of a change in the viewing direction. The methods further include configuring, a re-projection of a portion of the set of images, the re-projection based at least in part on the changed viewing direction and a field of view associated with the captured images, and converting the portion from a spherical perspective projection into a planar perspective projection, rendering by the computing device and for display in the VR head mounted display, an updated view based on the re-projection, the updated view configured to correct distortion and provide stereo parallax in the portion, and providing, to the head mounted display, the updated view including a stereo panoramic scene corresponding to the changed viewing direction.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8735073508},{"pair":"US-2018164591-A1 & US-9851565-B1","patent_1":"US-2018164591-A1","title_1":"Tiled waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180164591A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A waveguide display includes light sources, a source waveguide, an output waveguide, and a controller. Light from each of the light sources is coupled into the source waveguide. The source waveguide includes gratings with a constant period determined based on the conditions for total internal reflection and first order diffraction of the received image light. The emitted image light is coupled into the output waveguide at several entrance locations. The output waveguide outputs expanded image lights at a location offset from the entrance location, and the location\/direction of the emitted expanded image light is based in part on the orientation of the light sources. Each of the expanded image light is associated with a field of view of the expanded image light emitted by the output waveguide.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-12-12T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8734892578},{"pair":"US-10598938-B1 & US-9798147-B1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2018-11-09T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8734588665},{"pair":"US-10154254-B2 & US-2016057339-A1","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2017-01-17T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8734202972},{"pair":"US-2020064641-A1 & US-2018343443-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8733666623},{"pair":"US-10107950-B2 & US-2017116950-A1","patent_1":"US-10107950-B2","title_1":"Flexible light combiner backlight used in a head mounted display ","patent_2":"US-2017116950-A1","title_2":"Liquid crystal display with variable drive voltage ","link_1":"https:\/\/patents.google.com\/patent\/US10107950B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170116950A1\/en","abstract_1":"A liquid crystal display (LCD) device including a backlight with an LED assembly. The LED assembly includes a flexible light combiner and two or more different color LEDs optically coupled with a first end of the flexible light combiner. The flexible light combiner includes light channels that transmit color light, and output the color light at a second end of the flexible light combiner. The second end defines a light output region of the flexible light combiner. The light output regions of multiple LED assemblies are arranged behind an LCD panel, along one or more edges, to illuminate the LCD panel. The LED assembly provides edge-lit backlighting with enhanced brightness and color gamut, and flexible LED placement within the LCD device.","abstract_2":"A technique for operation of a display system includes displaying a display image from a liquid crystal display source, measuring a brightness of ambient light, and selecting a drive voltage for driving liquid crystal cells within the liquid crystal display source based upon the brightness of the ambient light. The drive voltage is used for driving the liquid crystal cells into an on-state or an off-state while displaying the display image.","priority_1":"2016-12-06T00:00:00","priority_2":"2015-10-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8732850444},{"pair":"US-2018164591-A1 & US-10546518-B2","patent_1":"US-2018164591-A1","title_1":"Tiled waveguide display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180164591A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A waveguide display includes light sources, a source waveguide, an output waveguide, and a controller. Light from each of the light sources is coupled into the source waveguide. The source waveguide includes gratings with a constant period determined based on the conditions for total internal reflection and first order diffraction of the received image light. The emitted image light is coupled into the output waveguide at several entrance locations. The output waveguide outputs expanded image lights at a location offset from the entrance location, and the location\/direction of the emitted expanded image light is based in part on the orientation of the light sources. Each of the expanded image light is associated with a field of view of the expanded image light emitted by the output waveguide.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-12-12T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8732579275},{"pair":"US-2020057304-A1 & US-10545347-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-08-16T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8732377772},{"pair":"US-2016267884-A1 & US-2018261003-A1","patent_1":"US-2016267884-A1","title_1":"Non-uniform rescaling of input data for displaying on display device ","patent_2":"US-2018261003-A1","title_2":"Reducing visually induced motion sickness in head mounted display systems ","link_1":"https:\/\/patents.google.com\/patent\/US20160267884A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180261003A1\/en","abstract_1":"A method for rescaling data to be displayed on a display device (e.g., an organic light emitting diode display device) is disclosed. The method includes receiving a frame of data for displaying on the display device, where the received data includes a first portion of the data corresponding to a first pixel region at a first pixel resolution and a second portion of the data corresponding to a second pixel region at a second pixel resolution lower than the first pixel resolution. The method also includes rescaling the received data for displaying the received data at a native pixel resolution of the display device, where the rescaling of the received data includes scaling the first portion of the data using a first scaling factor and the second portion of the data using a second scaling factor. The method further includes providing the rescaled data for displaying on the display device.","abstract_2":"A head mounted display (HMD) for displaying images to a user includes a sensor unit configured to detect motion of a head of the user of the HMD. The HMD also includes one or more processors configured to, in response to the motion, reduce contrast in a peripheral area of an image displayed to the user from an original contrast of the image, the image having a foveal area and the peripheral area relative to the optical axis of the eye of the user, the contrast being least reduced in a first portion of the peripheral area closest the foveal area and being most reduced in a second portion of the peripheral area farthest from the foveal area.","priority_1":"2015-03-12T00:00:00","priority_2":"2017-03-07T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8731924971},{"pair":"US-2019101767-A1 & US-2020041798-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.873185017},{"pair":"US-2019384070-A1 & US-2019025602-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-06-18T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.87311766},{"pair":"US-10509228-B1 & US-2016240013-A1","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-12-20T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8729765722},{"pair":"US-10291855-B2 & US-2017244948-A1","patent_1":"US-10291855-B2","title_1":"Three-dimensional, 360-degree virtual reality camera live preview ","patent_2":"US-2017244948-A1","title_2":"Spatial random access enabled video system with a three-dimensional viewing volume ","link_1":"https:\/\/patents.google.com\/patent\/US10291855B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170244948A1\/en","abstract_1":"A camera system provides a live preview that provides a user device a pseudo-real time depiction of what the camera assembly is imaging. The camera system captures images from a plurality of cameras. The camera system captures images from a plurality of cameras. The camera system stores the captured images in respective memory locations of a buffer. The stored captured images form a high priority data stream that generates content associated with the portion of the local area. The camera system selects, as part of a low priority data stream, one or more of the images from memory locations. The camera system encodes the selected one or more images. The camera system packetizes the encoded one or more images to form an image frame in a video feed. The camera system provides the image frame to a user device that presents the image frame as part of the video feed.","abstract_2":"An environment may be displayed from a viewpoint. According to one method, volumetric video data may be acquired depicting the environment, for example, using a tiled camera array. A plurality of vantages may be distributed throughout a viewing volume from which the environment is to be viewed. The volumetric video data may be used to generate video data for each vantage, representing the view of the environment from that vantage. User input may be received designating a viewpoint within the viewing volume. From among the plurality of vantages, a subset nearest to the viewpoint may be identified. The video data from the subset may be retrieved and combined to generate viewpoint video data depicting the environment from the viewpoint. The viewpoint video data may be displayed for the viewer to display a view of the environment from the viewpoint selected by the user.","priority_1":"2017-04-14T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8729050571},{"pair":"US-10598928-B1 & US-2020041798-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-12-21T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8728458887},{"pair":"US-10598928-B1 & US-2019271844-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-12-21T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8728365145},{"pair":"US-2019361518-A1 & US-2016328882-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2016328882-A1","title_2":"Pass-through display of captured imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160328882A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A method includes sequentially outputting from an imaging sensor each pixel row of a set of pixel rows of an image captured by the imaging sensor. The method further includes displaying, at a display device, a pixel row representative of a first pixel row of the captured image prior to a second pixel row of the captured image being output by the imaging sensor. An apparatus includes an imaging sensor having a first lens that imparts a first type of spatial distortion, a display device coupled to the imaging sensor, the display to display imagery captured by the imaging sensor with the first spatial distortion, and an eyepiece lens aligned with the display, the eyepiece lens imparting a second type of spatial distortion that compensates for the first type of spatial distortion.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-05-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.87270834},{"pair":"US-10506217-B2 & US-10591731-B2","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-10-09T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8727081373},{"pair":"US-2019313087-A1 & US-10365491-B1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10365491-B1","title_2":"Head-mounted display including diffractive combiner to integrate a display and an eye-tracking sensor ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10365491B1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An apparatus comprising a diffractive combiner having a front side, a back side, and a combiner optical axis running substantially through the diffractive combiner and normal to the back side. A display unit having a display optical axis that directs the display light along the display optical axis toward the diffractive combiner. An eye-tracking sensor having a sensor optical axis that is positioned to receive eye-tracking radiation reflected by the diffractive combiner along the sensor optical axis. The combiner optical axis, the display optical axis, and the sensor optical axis intersect each other at the diffractive combiner.","priority_1":"2018-04-06T00:00:00","priority_2":"2013-04-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8725853513},{"pair":"US-2020057304-A1 & US-9851565-B1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-16T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8725074773},{"pair":"US-2018173303-A1 & US-10546518-B2","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8723964478},{"pair":"US-10291855-B2 & US-10546424-B2","patent_1":"US-10291855-B2","title_1":"Three-dimensional, 360-degree virtual reality camera live preview ","patent_2":"US-10546424-B2","title_2":"Layered content delivery for virtual and augmented reality experiences ","link_1":"https:\/\/patents.google.com\/patent\/US10291855B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546424B2\/en","abstract_1":"A camera system provides a live preview that provides a user device a pseudo-real time depiction of what the camera assembly is imaging. The camera system captures images from a plurality of cameras. The camera system captures images from a plurality of cameras. The camera system stores the captured images in respective memory locations of a buffer. The stored captured images form a high priority data stream that generates content associated with the portion of the local area. The camera system selects, as part of a low priority data stream, one or more of the images from memory locations. The camera system encodes the selected one or more images. The camera system packetizes the encoded one or more images to form an image frame in a video feed. The camera system provides the image frame to a user device that presents the image frame as part of the video feed.","abstract_2":"A virtual reality or augmented reality experience of a scene may be presented to a viewer using layered data retrieval and\/or processing. A first layer of a video stream may be retrieved, and a first viewer position and\/or orientation may be received. The first layer may be processed to generate first viewpoint video of the scene from a first virtual viewpoint corresponding to the first viewer position and\/or orientation. The first viewpoint video may be displayed for the viewer. Then, a second layer of the video stream may be retrieved, and a second viewer position and\/or orientation may be received. The second layer may be processed to generate second viewpoint video of the scene from a second virtual viewpoint corresponding to the second viewer position and\/or orientation, with higher quality than the first viewpoint video. The second viewpoint video may be displayed for the viewer.","priority_1":"2017-04-14T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8723865232},{"pair":"US-2019342647-A1 & US-10133358-B1","patent_1":"US-2019342647-A1","title_1":"Hybrid audio system for eyewear devices ","patent_2":"US-10133358-B1","title_2":"Fitting detection for a bone conduction transducer (BCT) using an inertial measurement unit (IMU) sensor ","link_1":"https:\/\/patents.google.com\/patent\/US20190342647A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10133358B1\/en","abstract_1":"An audio system for providing content to a user. The system includes a first and a second transducer assembly of a plurality of transducer assemblies, an acoustic sensor, and a controller. The first transducer assembly couples to a portion of an auricle of the user's ear and vibrates over a first range of frequencies based on a first set of audio instructions. The vibration causes the portion of the ear to create a first range of acoustic pressure waves. The second transducer assembly is configured to vibrate over a second range of frequencies to produce a second range of acoustic pressure waves based on a second set of audio instructions. The acoustic sensor detects acoustic pressure waves at an entrance of the ear. The controller generates the audio instructions based on audio content to be provided to the user and the detected acoustic pressure waves from the acoustic sensor.","abstract_2":"An example system is described that includes a head-mountable device (HMD) with a bone conduction transducer that transmits an audio signal and an inertial measurement unit (IMU) sensor connected to the bone conduction transducer. The IMU sensor detects movement of the HMD due to vibrations of the bone conduction transducer transmitting the audio signal and the IMU sensor provides outputs. The system also includes one or more processors that receive the outputs of the IMU sensor and compare the outputs of the IMU sensor with at least one reference signal. The at least one reference signal is based on the audio signal that is transmitted. The one or more processors output an HMD fitting parameter based on the comparison.","priority_1":"2018-05-01T00:00:00","priority_2":"2016-06-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8722392507},{"pair":"US-2019361518-A1 & US-2017345220-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2017345220-A1","title_2":"Time-warping adjustment based on depth information in a virtual\/augmented reality system ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170345220A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A technique includes determining a depth value for each of a plurality of pixels of a frame, down-sampling the depth values of a tile of the frame to obtain a plurality of down-sampled depth values, the frame including one or more tiles, determining a change in a head pose, determining, from the plurality of down-sampled depth values, a down-sampled depth value for a vertex, determining an adjusted position for the vertex based on the change in head pose and the down-sampled depth value for the vertex, performing, based on at least the adjusted position for the vertex, a depth-adjusted time-warping of the frame to obtain a depth-adjusted time-warped frame, and triggering display of the depth-adjusted time-warped frame.","priority_1":"2018-05-22T00:00:00","priority_2":"2016-05-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8722179487},{"pair":"US-2017371159-A1 & US-9851565-B1","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-06-28T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8722049325},{"pair":"US-2020064633-A1 & US-10365491-B1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-10365491-B1","title_2":"Head-mounted display including diffractive combiner to integrate a display and an eye-tracking sensor ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10365491B1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An apparatus comprising a diffractive combiner having a front side, a back side, and a combiner optical axis running substantially through the diffractive combiner and normal to the back side. A display unit having a display optical axis that directs the display light along the display optical axis toward the diffractive combiner. An eye-tracking sensor having a sensor optical axis that is positioned to receive eye-tracking radiation reflected by the diffractive combiner along the sensor optical axis. The combiner optical axis, the display optical axis, and the sensor optical axis intersect each other at the diffractive combiner.","priority_1":"2018-08-23T00:00:00","priority_2":"2013-04-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8721698311},{"pair":"US-10120193-B2 & US-2019086675-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8720851318},{"pair":"US-2019384070-A1 & US-2017357090-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2017357090-A1","title_2":"Head-wearable displays with a tiled field of view using a single microdisplay ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170357090A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"Implementations are described of an eyepiece for a head wearable display. The eyepiece includes a curved lightguide for guiding display light via total internal reflection between a peripherally-located input surface and a viewing region and an output coupler disposed across the viewing region to redirect the display light towards an eyeward direction for output from the curved light guide. The output coupler has an optical axis and has a set of reflective surfaces that includes at least two individual reflective surfaces to reflect incident display light toward the eyeward direction in at least two different directions relative to the optical axis of the output coupler. Other embodiments are disclosed and claimed.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-06-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.872064299},{"pair":"US-10520742-B1 & US-2015169054-A1","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-02-13T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8719770324},{"pair":"US-2018173303-A1 & US-2018101984-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2016-12-21T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8719509774},{"pair":"US-2019311232-A1 & US-9536354-B2","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2018-04-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8719050476},{"pair":"US-10600352-B1 & US-2020073123-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-12-04T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8718791201},{"pair":"US-2020064641-A1 & US-10545347-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8717673747},{"pair":"US-10598928-B1 & US-2019025602-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2017-12-21T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8716746615},{"pair":"US-10108261-B1 & US-10032074-B2","patent_1":"US-10108261-B1","title_1":"Eye tracking based on light polarization ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10108261B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using polarization. The eye tracking system includes an illumination source and an eye tracking unit comprising a polarization sensitive optical detector. The one or more illumination sources are configured to illuminate an eye and generate reflections directed towards the optical detector. The eye tracking unit is configured to determine a 3D shape of the eye based on the polarization of the reflections. The determined 3D shape of the eye is used to update a stored model of the eye in response to the one or more model parameter values extracted from the determined depth map of the corneal surface. The eye tracking system determines eye tracking information based on the updated model in order to improve eye tracking performance.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-07-05T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8716476061},{"pair":"US-10571692-B2 & US-2019271844-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2016-03-02T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8715394594},{"pair":"US-10345600-B1 & US-10546518-B2","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-06-08T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8714826245},{"pair":"US-2017287194-A1 & US-9536354-B2","patent_1":"US-2017287194-A1","title_1":"Tracking portions of a user's face uncovered by a head mounted display worn by the user ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20170287194A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A virtual reality system includes a head-mounted display (HMD) having one or more facial sensors and illumination sources mounted to a surface of the HMD. For example, the facial sensors are image capture devices coupled to a bottom side of the HMD. The illumination sources illuminate portions of a user's face outside of the HMD, while the facial sensors capture images of the illuminated portions of the user's face. A controller receives the captured images and generates a representation of the portions of the user's face by identifying landmarks of the user's face in the captured images and performing other suitable image processing methods. Based on the representation, the controller or another component of the virtual reality system generates content for presentation to the user.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2016-04-01T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8714617173},{"pair":"US-10210660-B2 & US-2016353090-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2016353090-A1","title_2":"Omnistereo capture and render of panoramic virtual reality content ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160353090A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"Systems and methods are described include defining, at a computing device, a set of images based on captured images, projecting, at the computing device, a portion of the set of images from a planar perspective image plane onto a spherical image plane by recasting a plurality of viewing rays associated with the portion of the set of images from a plurality of viewpoints arranged around a curved path to a viewpoint, determining, at the computing device, a periphery boundary corresponding to the viewpoint and generating updated images by removing pixels that are outside of the periphery boundary, and providing, for display, the updated images within the bounds of the periphery boundary.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8713221835},{"pair":"US-10345600-B1 & US-2018343443-A1","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-06-08T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8712219958},{"pair":"US-10598938-B1 & US-9810910-B1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2018-11-09T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711701111},{"pair":"US-10571692-B2 & US-9671614-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2016-03-02T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711694583},{"pair":"US-2020064641-A1 & US-2019086675-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711449187},{"pair":"US-2019101767-A1 & US-9851565-B1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711038571},{"pair":"US-9984507-B2 & US-2018261003-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2018261003-A1","title_2":"Reducing visually induced motion sickness in head mounted display systems ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180261003A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A head mounted display (HMD) for displaying images to a user includes a sensor unit configured to detect motion of a head of the user of the HMD. The HMD also includes one or more processors configured to, in response to the motion, reduce contrast in a peripheral area of an image displayed to the user from an original contrast of the image, the image having a foveal area and the peripheral area relative to the optical axis of the eye of the user, the contrast being least reduced in a first portion of the peripheral area closest the foveal area and being most reduced in a second portion of the peripheral area farthest from the foveal area.","priority_1":"2015-11-19T00:00:00","priority_2":"2017-03-07T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.871093971},{"pair":"US-10598938-B1 & US-9934583-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-11-09T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8710207531},{"pair":"US-2020027261-A1 & US-10593098-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8709841148},{"pair":"US-10203504-B1 & US-9851565-B1","patent_1":"US-10203504-B1","title_1":"Scanning waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10203504B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A waveguide display is used for presenting media to a user. The waveguide assembly includes a light source, a source waveguide, an output waveguide, and a controller. The light source emits image light based on scanning instructions from the controller. The source waveguide receives the image light from the light source, expands the image light in at least one dimension, and outputs an expanded image light to the output waveguide at an input area. The output waveguide outputs the expanded image light from a portion of an output area based on a direction of the expanded light from the source waveguide.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-05-27T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8709804042},{"pair":"US-10429927-B1 & US-2017147859-A1","patent_1":"US-10429927-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10429927B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-01-18T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8709797687},{"pair":"US-2018173303-A1 & US-10241329-B2","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8709101522},{"pair":"US-10416461-B2 & US-2020041798-A1","patent_1":"US-10416461-B2","title_1":"Pancake lens with large FOV ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10416461B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A HMD includes an electronic display and a pancake lens block. The pancake lens block includes a back curved optical element and a front curved optical element. Light propagating through the pancake lens block undergoes multiple reflections and to mitigate parasitic reflections, there are no air gaps between optical elements of the pancake lens block. A hybrid film that operates as a waveplate surface and a mirrored surface can be placed between the front curved optical element and the back curved optical element. A wide FOV can be obtained by making the coupling surfaces of the front optical element and the back optical element to be based on a convex cylindrical surface profile and a concave cylindrical surface profile, with the axis of the cylinder surface in a vertical direction for a user wearing the HMD.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-10-27T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8708740741},{"pair":"US-2015199559-A1 & US-2016057339-A1","patent_1":"US-2015199559-A1","title_1":"Systems and methods of light modulation in eye tracking devices ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20150199559A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"An image of a user's eyes and face may be analyzed using computer-vision algorithms. A computing device may use the image to determine the location of the user's eyes and estimate the direction in which the user is looking. The eye tracking technology may be used in a wide range of lighting conditions and with many different and varying light levels. When a user is near a light source, an automatic exposure feature in the camera may result in the user's face and eyes appearing too dark in the image, possibly reducing the likelihood of face and eye detection. Adjusting attributes such as the camera exposure time and the intensity and illumination interval of the light sources based on motion and light levels may improve detection of a user's features.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2014-01-10T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8708006306},{"pair":"US-10572731-B1 & US-9851565-B1","patent_1":"US-10572731-B1","title_1":"Infrared transparent backlight device for eye tracking applications ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10572731B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A backlight device provides light in a first optical band to a spatial light modulator, and is transmissive to light in a second optical band. The backlight device includes a structured dichroic reflector that is substantially reflective, and scatters light in the first optical band. The structured dichroic reflector is also substantially transparent in the second optical band, and the second optical band is different than the first optical band. The backlight device is configured to receive light in the first optical band from an illumination source. The dichroic reflector is configured to reflect light in the first optical band toward a display panel that converts the light from the backlight device to image light. The backlight device may be part of a head-mounted display.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-03-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.870652695},{"pair":"US-2019342647-A1 & US-2017160394-A1","patent_1":"US-2019342647-A1","title_1":"Hybrid audio system for eyewear devices ","patent_2":"US-2017160394-A1","title_2":"Using Sounds For Determining A Worn State Of A Wearable Computing Device ","link_1":"https:\/\/patents.google.com\/patent\/US20190342647A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170160394A1\/en","abstract_1":"An audio system for providing content to a user. The system includes a first and a second transducer assembly of a plurality of transducer assemblies, an acoustic sensor, and a controller. The first transducer assembly couples to a portion of an auricle of the user's ear and vibrates over a first range of frequencies based on a first set of audio instructions. The vibration causes the portion of the ear to create a first range of acoustic pressure waves. The second transducer assembly is configured to vibrate over a second range of frequencies to produce a second range of acoustic pressure waves based on a second set of audio instructions. The acoustic sensor detects acoustic pressure waves at an entrance of the ear. The controller generates the audio instructions based on audio content to be provided to the user and the detected acoustic pressure waves from the acoustic sensor.","abstract_2":"Methods, apparatus, and computer-readable media are described herein related to using self-generated sounds for determining a worn state of a wearable computing device. A wearable computing device can transmit an audio signal. One or more sensors coupled to the wearable computing device may then receive a modified version of the audio signal. A comparison may be made between the modified version of the audio signal and at least one reference signal, where the at least one reference signal is based on the audio signal that is transmitted. Based on an output of the comparison, a determination can be made of whether the wearable computing device is being worn.","priority_1":"2018-05-01T00:00:00","priority_2":"2013-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8706356803},{"pair":"US-10228565-B1 & US-9851565-B1","patent_1":"US-10228565-B1","title_1":"Variable focus waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10228565B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A waveguide display presents media to users. The waveguide assembly includes a light source, a source waveguide, an output waveguide, an actuator assembly, and a controller. The light source emits image light based on scanning instructions from the controller. The source waveguide receives the emitted image light, expands the image light in at least one dimension, and outputs an expanded image light to the output waveguide at an input area. The output waveguide outputs the expanded image light from a portion of an output area. The actuator assembly adjusts a first curvature of the source waveguide with a first set of actuators and adjusts a second curvature of the output waveguide with a second set of actuators, where the first curvature is orthogonal to the first curvature.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-05-27T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8704357191},{"pair":"US-2016267715-A1 & US-2018136720-A1","patent_1":"US-2016267715-A1","title_1":"Display device supporting configurable resolution regions ","patent_2":"US-2018136720-A1","title_2":"Dual-path foveated graphics pipeline ","link_1":"https:\/\/patents.google.com\/patent\/US20160267715A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180136720A1\/en","abstract_1":"A virtual reality system and a display device that can be used, for example, as part of the virtual reality system. The display device can have more than one data driver, such as an even row data driver and an odd row data driver. The display device can have a configurable resolution such that one region of the display device operates at full resolution while another region of the display device operates at a reduced resolution. The virtual reality system can also track an eye gaze and adjust the full resolution region of the display device to track the eye gaze.","abstract_2":"A foveated display system includes a rendering device including at least one graphics processing unit (GPU) to render a foveal region and a peripheral region of a first image, wherein the foveal region has a higher resolution than the peripheral region. The system further includes a display device coupled to the rendering device via at least one physical layer. The display device includes a pixel array and a display controller coupled to the pixel array. The display controller includes a scaling component to upscale the first peripheral region to generate a scaled first peripheral region and a blending component to blend the foveal region with the scaled first peripheral region to generate a second image.","priority_1":"2015-03-11T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8703933594},{"pair":"US-10529087-B1 & US-2015244930-A1","patent_1":"US-10529087-B1","title_1":"System for a depth mapping device ","patent_2":"US-2015244930-A1","title_2":"Synthetic camera lenses ","link_1":"https:\/\/patents.google.com\/patent\/US10529087B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150244930A1\/en","abstract_1":"A depth mapping device comprises a plurality of imaging components arranged among one or more rings. A depth mapping device may be designed by identifying a plurality of configurations satisfying a set of input parameters that includes a number of imaging components, each configuration indicating a different arrangement of imaging components among one or more rings. Coverages for different configuration parameter sets for the configuration are analyzed to determine a configuration parameter set associated with the configuration having a highest coverage, where the coverage is indicative of an amount of a local area viewable by a depth mapping device using the configuration and associated configuration parameter set. A target configuration having a highest coverage is selected and used to generate a depth mapping device design to be manufactured.","abstract_2":"A method and system is disclosed for simulating different types of camera lens on a device by guiding a user through a set of images to be captured in connection with one or more desired lens effects. In one aspect, a wide-angle lens may be simulated by taking a plurality of images that have been taken at a particular location over a set of camera orientations that are determined based on the selection of the wide-angle lens. The mobile device may provide prompts to the user indicating the camera orientations for which images should be captured in order to generate the simulated camera lens effect.","priority_1":"2017-09-26T00:00:00","priority_2":"2014-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8703716247},{"pair":"US-10248890-B2 & US-10593098-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8703605162},{"pair":"US-10504243-B2 & US-2019037194-A1","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8703330399},{"pair":"US-10248890-B2 & US-9734579-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702980191},{"pair":"US-2018173303-A1 & US-2019102935-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2019102935-A1","title_2":"Shadows for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102935A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Systems and methods for generating shadows for inserted content are provided. The inserted content may include augmented reality content that is inserted into an image of a physical space. An example includes determining a location to insert content within an image. The content may include a polygonal mesh defined in part by a skeleton that has a plurality of joints. Examples may further include selecting a plurality of selected joints form the plurality of joints. Examples may also include generating a shadow polygon based on the content and determining shadow contributions values for the plurality of selected joints for pixels of the shadow polygon. Examples may also include combining the shadow contribution values from the selected joints to generate shadow magnitude values for the pixels, rendering the shadow polygon using the shadow magnitude values, and overlaying the inserted content on the rendered shadow polygon.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702758454},{"pair":"US-10429657-B1 & US-2017147859-A1","patent_1":"US-10429657-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10429657B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block. Moreover, each reflection results in a particular view of the eye that results in multiple views of the eye being received by the image capturing element.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-01-18T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702679177},{"pair":"US-10429656-B1 & US-2017147859-A1","patent_1":"US-10429656-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10429656B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light is captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-01-18T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702679177},{"pair":"US-10585477-B1 & US-2016057339-A1","patent_1":"US-10585477-B1","title_1":"Patterned optical filter for eye tracking ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US10585477B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"An eyewear device has an optical element, a patterned optical filter, and a camera. The optical element receives light that includes light in a visible band and light in an infrared (IR) band. The patterned optical filter is disposed on the optical element and has a filtering portion and a plurality of non-filtering portions. The filtering portion is transmissive to light in the visible band and filtering of light in the IR band. The non-filtering portions are transmissive to light in the visible band and transmissive to light in the IR band. Some portion of the received light in the IR band passes through the non-filtering portions and illuminates a portion of an eye of a user with a pattern. The camera captures images of the portion of the eye that is illuminated with the pattern.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2018-04-05T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702066279},{"pair":"US-2020090355-A1 & US-10242454-B2","patent_1":"US-2020090355-A1","title_1":"Depth measurement assembly with a structured light source and a time of flight camera ","patent_2":"US-10242454-B2","title_2":"System for depth data filtering based on amplitude energy values ","link_1":"https:\/\/patents.google.com\/patent\/US20200090355A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10242454B2\/en","abstract_1":"A depth measurement assembly (DMA) includes an illumination source that projects pulses of light (e.g., structured light) at a temporal pulsing frequency into a local area. The DMA includes a sensor that capture images of the pulses of light reflected from the local area and determines, using one or more of the captured images, one or more TOF phase shifts for the pulses of light. The DMA includes a controller coupled to the sensor and configured to determine a first set of estimated radial distances to an object in the local area based on the one or more TOF phase shifts. The controller determines a second estimated radial distance to the object based on an encoding of structured light and at least one of the captured images. The controller selects an estimated radial distance from the first set of radial distances.","abstract_2":"An electronic device includes a time of flight (ToF) camera and one or more processors. The ToF camera captures raw depth images. The processors determine a depth frame and an amplitude frame from the raw depth images. The depth frame comprises an array of pixels, each pixel having a depth value. The amplitude frame comprises an array of pixels, each pixel having an amplitude energy value. The processors determine a first energy threshold value based on the amplitude energy values of the array of pixels of the amplitude frame and determine, for the depth value of a first pixel of the depth frame, a confidence value representing a corresponding validity of a depth represented by the depth value, based on a comparison of the amplitude energy value of a corresponding first pixel of the amplitude frame to the first energy threshold value.","priority_1":"2018-09-14T00:00:00","priority_2":"2017-01-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8701674905},{"pair":"US-2019361518-A1 & US-2018350032-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2018350032-A1","title_2":"Smoothly varying foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180350032A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"Systems and methods for performing foveated rendering are provided. An example system and method may warp a 3D scene based on a fixation point. The system and method may also render the warped 3D scene to generate a first image. The system and method may also unwarp the first image to generate a second image. For example, the first image may have fewer pixels than the second image.","priority_1":"2018-05-22T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8701119536},{"pair":"US-2019311522-A1 & US-9734579-B1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-04-05T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8700150034},{"pair":"US-10474229-B1 & US-2017147859-A1","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2017-11-01T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8699818723},{"pair":"US-2019101767-A1 & US-9946074-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8699785297},{"pair":"US-10595000-B1 & US-2019182468-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2019182468-A1","title_2":"Methods, systems, and media for generating and rendering immersive video content ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190182468A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"Methods, systems, and media for generating and rendering immersive video content are provided. In some embodiments, the method comprises: receiving information indicating positions of cameras in a plurality of cameras; generating a mesh on which video content is to be projected based on the positions of the cameras in the plurality of cameras, wherein the mesh is comprised of a portion of a faceted cylinder, and wherein the faceted cylinder has a plurality of facets each corresponding to a projection from a camera in the plurality of cameras; receiving video content corresponding to the plurality of cameras; and transmitting the video content and the generated mesh to a user device in response to receiving a request for the video content from the user device.","priority_1":"2018-08-02T00:00:00","priority_2":"2017-12-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.86996015},{"pair":"US-10528128-B1 & US-2015169054-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-12-15T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8699113517},{"pair":"US-10248842-B1 & US-2019102936-A1","patent_1":"US-10248842-B1","title_1":"Face tracking using structured light within a head-mounted display ","patent_2":"US-2019102936-A1","title_2":"Lighting for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US10248842B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102936A1\/en","abstract_1":"A head mounted display (HMD) displays content to a user wearing the HMD, where the content may be based on a facial model of the user. The HMD uses an electronic display to illuminate a portion of the face of the user with. The electronic display emits a pattern of structured light and\/or monochromatic light of a given color. A camera assembly captures images of the illuminated portion of the face. A controller processes the captured images to determine depth information or color information of the face of the user. Further, the processed images may be used to update the facial model, for example, which is represented as a virtual avatar and presented to the user in a virtual reality, augmented reality, or mixed reality environment.","abstract_2":"Systems and methods for lighting inserted content are provided. For example, the inserted content may include augmented reality content that is inserted into an image of a physical space. An example system and method may include determining a location within an image to insert content. For example, the image may be captured by a camera device. The example system and method may also include identifying a region of the image based on the determined location to insert the content, determining at least one lighting parameter based on the identified region, and rendering the content using the determined at least one lighting parameter.","priority_1":"2018-01-09T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8699048936},{"pair":"US-2016267715-A1 & US-2017236466-A1","patent_1":"US-2016267715-A1","title_1":"Display device supporting configurable resolution regions ","patent_2":"US-2017236466-A1","title_2":"Foveally-rendered display ","link_1":"https:\/\/patents.google.com\/patent\/US20160267715A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170236466A1\/en","abstract_1":"A virtual reality system and a display device that can be used, for example, as part of the virtual reality system. The display device can have more than one data driver, such as an even row data driver and an odd row data driver. The display device can have a configurable resolution such that one region of the display device operates at full resolution while another region of the display device operates at a reduced resolution. The virtual reality system can also track an eye gaze and adjust the full resolution region of the display device to track the eye gaze.","abstract_2":"A display system includes a display panel having an input to receive pixel data, the pixel data comprising a plurality of pixel values, an array of pixels partitioned into a foveal region and at least one peripheral region, and an array controller to group pixels in the at least one peripheral region into subsets of at least two pixels and to control each subset using a corresponding single pixel value from the plurality of pixel values. The display system further may include a rendering system to foveally render a display image based on the locations of the foveal region and the at least one peripheral regions, wherein for each row of the display image having pixels within at least one of the peripheral region, a number of pixel values represented in the pixel data for the row is less than a number of pixels in the row.","priority_1":"2015-03-11T00:00:00","priority_2":"2016-02-17T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8698978455},{"pair":"US-10520742-B1 & US-10546518-B2","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-02-13T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8697701147},{"pair":"US-10557994-B1 & US-2019265477-A1","patent_1":"US-10557994-B1","title_1":"Waveguide grating with spatial variation of optical phase ","patent_2":"US-2019265477-A1","title_2":"Augmented reality light field head-mounted displays ","link_1":"https:\/\/patents.google.com\/patent\/US10557994B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190265477A1\/en","abstract_1":"An optical waveguide is disclosed. The optical waveguide includes a plate of transparent material comprising opposed first and second surfaces for guiding an optical beam between the surfaces by at least one of reflection or diffraction. A diffraction grating is disposed at the first surface for spreading the optical beam by diffracting portions thereof into a non-zero diffraction order to propagate inside the plate. The first diffraction grating includes an array of parallel grooves structured to provide a spatial variation of optical phase of the portions of the optical beam diffracted by the first diffraction grating into the non-zero diffraction order.","abstract_2":"A near-eye display system includes a transmissive display panel to display a near-eye light field frame comprising an array of elemental images. The transmissive display panel is configured to transmit light rays of the near-eye light field frame away from the user's eye and towards an array of curved beam splitters. The curved beam splitters collimate the transmitted light rays and reflect the collimated light rays back towards the transmissive display panel for passing to the user's eye.","priority_1":"2018-09-24T00:00:00","priority_2":"2018-02-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8697290187},{"pair":"US-10598938-B1 & US-2018239141-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-11-09T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.869700787},{"pair":"US-2016085301-A1 & US-9784971-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9784971-B2","title_2":"Methods and devices for rendering interactions between virtual and physical objects on a substantially transparent display ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9784971B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Disclosed are methods and devices for rendering interactions between virtual and physical objects on a substantially transparent display are disclosed. In one embodiment, the method includes displaying a user-interface on a substantially transparent display of a wearable computing device. The method further includes displaying a virtual object in the view region at a focal length along a first line of sight and detecting a physical object at a physical distance along a second line of sight. The method still further includes determining that a relationship between the focal length and the physical distance is such that the virtual object and the physical object appear substantially co-located in a user-view through the view region and, responsive to the determination, initiating a collision action between the virtual object and the physical object.","priority_1":"2014-09-22T00:00:00","priority_2":"2011-10-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8696532715},{"pair":"US-2018239145-A1 & US-2019020869-A1","patent_1":"US-2018239145-A1","title_1":"Focus adjusting multiplanar head mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20180239145A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A multiplanar head mounted display (HMD) includes two or more artificial display planes for each eye located at optical distances that can be dynamically adjusted based on a location within a scene presented by the HMD that the user views. For example, a scene is presented on two or more electronic display elements (e.g., screens) of the HMD. A focal length of an optics block that directs image light from the electronic display elements towards the eyes of a user is adjusted using a varifocal system (e.g., an element that mechanically changes a distance between a lens system in the optics block and the electronic display element, an element that changes shape of one or more lenses in the lens system in the optics block, etc.) based on a location or object within the scene where the user is looking.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-02-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8696301062},{"pair":"US-2019318530-A1 & US-2020013214-A1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8696263022},{"pair":"US-2016267715-A1 & US-2018137598-A1","patent_1":"US-2016267715-A1","title_1":"Display device supporting configurable resolution regions ","patent_2":"US-2018137598-A1","title_2":"Early sub-pixel rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20160267715A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180137598A1\/en","abstract_1":"A virtual reality system and a display device that can be used, for example, as part of the virtual reality system. The display device can have more than one data driver, such as an even row data driver and an odd row data driver. The display device can have a configurable resolution such that one region of the display device operates at full resolution while another region of the display device operates at a reduced resolution. The virtual reality system can also track an eye gaze and adjust the full resolution region of the display device to track the eye gaze.","abstract_2":"A display system includes a display device and a graphics processing unit (GPU) coupled via at least one physical layer. The display device includes a pixel array having a non-red-green-blue (non-RGB) pixel format. The GPU is configured to render an image in the non-RGB pixel format and provide the rendered image for transmission to the pixel array via the at least one physical layer.","priority_1":"2015-03-11T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8696140325},{"pair":"US-2019227322-A1 & US-9946074-B2","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-01-25T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8694052591},{"pair":"US-2018239145-A1 & US-2016240013-A1","patent_1":"US-2018239145-A1","title_1":"Focus adjusting multiplanar head mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20180239145A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A multiplanar head mounted display (HMD) includes two or more artificial display planes for each eye located at optical distances that can be dynamically adjusted based on a location within a scene presented by the HMD that the user views. For example, a scene is presented on two or more electronic display elements (e.g., screens) of the HMD. A focal length of an optics block that directs image light from the electronic display elements towards the eyes of a user is adjusted using a varifocal system (e.g., an element that mechanically changes a distance between a lens system in the optics block and the electronic display element, an element that changes shape of one or more lenses in the lens system in the optics block, etc.) based on a location or object within the scene where the user is looking.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-02-21T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8693460977},{"pair":"US-10460500-B1 & US-2017193698-A1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-2017193698-A1","title_2":"On-Demand Transformation Aware Shape Tessellation ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170193698A1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"Disclosed are apparatus and methods for tessellating shapes. A computing device that has a display can receive an instruction to draw a shape. The computing device can determine a scale factor for the shape. The computing device can determine a set of polygons that tessellate the shape based on the scale factor. The set of polygons can include at least two polygons. The computing device can display the polygons in the determined set on the display.","priority_1":"2018-04-13T00:00:00","priority_2":"2013-10-18T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8693266552},{"pair":"US-10497320-B1 & US-2020041798-A1","patent_1":"US-10497320-B1","title_1":"Transparent and reflective illumination source ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10497320B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted display (HMD) includes a display illuminated by one or more illumination sources. An illumination source is coupled to a partially transparent circuit board and is configured to emit light onto a compound mirror. The compound mirror is farther from an exit pupil of the HMD than the display and reflects light from the illumination source back towards the exit pupil of the HMD. Light reflected by the compound mirror is transmitted through the partially transparent circuit board onto the display, illuminating the display.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-07T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8693235175},{"pair":"US-2019318528-A1 & US-2020013214-A1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8692243342},{"pair":"US-2018173303-A1 & US-2019020869-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8692166688},{"pair":"US-10599215-B2 & US-2015169054-A1","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2016-04-26T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8691285101},{"pair":"US-9904054-B2 & US-10319072-B2","patent_1":"US-9904054-B2","title_1":"Headset with strain gauge expression recognition system ","patent_2":"US-10319072-B2","title_2":"Adaptation of presentation speed ","link_1":"https:\/\/patents.google.com\/patent\/US9904054B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10319072B2\/en","abstract_1":"A head-mounted display (HMD) device includes a plurality of deformation sensors attached to a liner formed around a periphery of a HMD, adopted for direct or indirect contact a user's face. The deformation sensors measure deformations of the liner caused by movement of an upper portion of a user's face when the user is wearing the HMD. The deformation sensors are strain gauges embedded in or otherwise coupled to the liner of the HMD. The sensors translate muscle movements of the upper face of the user to changes in the bending strain and radius of curvature on the surface of the strain gauges. The HMD includes a module that reconstructs and projects a facial animation model of the user based on signals from the deformation sensors while the HMD is in use by the user.","abstract_2":"Systems and methods are disclosed for adaptation of presentation speed for content presentation (e.g., audio content presentation). For example, methods may include obtaining an indication of motion in a space; adjusting a presentation speed based on the indication of motion; and presenting a content item associated with a location in the space, wherein the content item is presented using the adjusted presentation speed.","priority_1":"2015-01-23T00:00:00","priority_2":"2017-10-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.869091058},{"pair":"US-10529117-B2 & US-2020013214-A1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8690808695},{"pair":"US-2020027261-A1 & US-9734579-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8690764519},{"pair":"US-2016267715-A1 & US-2018137602-A1","patent_1":"US-2016267715-A1","title_1":"Display device supporting configurable resolution regions ","patent_2":"US-2018137602-A1","title_2":"Low resolution rgb rendering for efficient transmission ","link_1":"https:\/\/patents.google.com\/patent\/US20160267715A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180137602A1\/en","abstract_1":"A virtual reality system and a display device that can be used, for example, as part of the virtual reality system. The display device can have more than one data driver, such as an even row data driver and an odd row data driver. The display device can have a configurable resolution such that one region of the display device operates at full resolution while another region of the display device operates at a reduced resolution. The virtual reality system can also track an eye gaze and adjust the full resolution region of the display device to track the eye gaze.","abstract_2":"A display device includes a pixel array and a display controller. The pixel array has a non-red-green-blue (non-RGB) pixel format that includes at least first, second, and third color components, and wherein sub-pixels of the first color component are present at a first resolution and sub-pixels of each of the second and third color components are present at a second resolution lower than the first resolution. The display controller is configured to receive a first image in a an RGB pixel format in which sub-pixels of the first color component, sub-pixels of the second color component, and sub-pixels of the third color component each are present in the first image at the second resolution. The display controller further is configured to scale sub-pixels of the first color component in the first image from the second resolution to the first resolution to generate a second image having the non-RGB format.","priority_1":"2015-03-11T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8690277978},{"pair":"US-10460500-B1 & US-2017193689-A1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-2017193689-A1","title_2":"Efficient Computation of Shadows for Circular Light Sources ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170193689A1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"Methods and apparatus are provided for displaying shadows of circular light sources. A computing device can determine a light source and an occluding polygon that is between the light source and a receiver surface, where the occluding polygon includes vertices connected by edges. The computing device can determine a shadow of the occluding polygon on the receiver surface by at least: determining, for a particular vertex, a projection vertex on the receiver surface by projecting a ray from the center point through the particular vertex; determining an outline polygon based on the projection vertex; determining a projection circle around the projection vertex; determining a penumbra of the shadow based on exterior tangents outside of the outline polygon; and determining an umbra of the shadow based on interior tangents inside the outline polygon. The computing device can display at least part of the shadow.","priority_1":"2018-04-13T00:00:00","priority_2":"2014-10-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.868984293},{"pair":"US-2018182307-A1 & US-2015146301-A1","patent_1":"US-2018182307-A1","title_1":"Interlaced liquid crystal display panel and backlight used in a head mounted display ","patent_2":"US-2015146301-A1","title_2":"Lighting adjustment for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20180182307A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150146301A1\/en","abstract_1":"A liquid crystal display (LCD) device is driven in interlaced scan to accommodate for liquid crystal (LC) setting times without sacrificing brightness. The LCD device includes an LCD panel including a first group of (e.g., even) pixel lines and a second group (e.g., odd) pixel lines, a backlight disposed behind the LCD panel to emit light toward the even and odd pixel lines, a shift grating disposed between the LCD and the backlight, the shift grating configured to block the light from the backlight from reaching either the first group of pixel lines or the second group of pixel lines, and a controller. The controller drives the LCD panel using an interlaced scan, coordinates the activation of the backlight (e.g., a strobed backlight), and changes the state of the shift grating to block the light from the backlight from reaching either the first group of pixel lines or the second group of pixel lines.","abstract_2":"An apparatus includes a light source, a display array, a light relay, a photodetector, and control circuitry. The light source is for providing lamp light during an ON-time of the light source. The display array is positioned to receive and selectively manipulate the lamp light. The light relay is positioned to receive the image light from the display array. Control circuitry is coupled to the light source for adjusting the light source and coupled to receive an output of the photodetector.","priority_1":"2016-12-27T00:00:00","priority_2":"2012-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8689832345},{"pair":"US-2019313087-A1 & US-2017235145-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8689794752},{"pair":"US-10317680-B1 & US-2018343443-A1","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-11-09T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8689693611},{"pair":"US-2019318529-A1 & US-2020013214-A1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8689077379},{"pair":"US-2018173303-A1 & US-2017147859-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2016-12-21T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.868843927},{"pair":"US-2019318530-A1 & US-10460510-B2","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8688376878},{"pair":"US-10291855-B2 & US-10469873-B2","patent_1":"US-10291855-B2","title_1":"Three-dimensional, 360-degree virtual reality camera live preview ","patent_2":"US-10469873-B2","title_2":"Encoding and decoding virtual reality video ","link_1":"https:\/\/patents.google.com\/patent\/US10291855B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10469873B2\/en","abstract_1":"A camera system provides a live preview that provides a user device a pseudo-real time depiction of what the camera assembly is imaging. The camera system captures images from a plurality of cameras. The camera system captures images from a plurality of cameras. The camera system stores the captured images in respective memory locations of a buffer. The stored captured images form a high priority data stream that generates content associated with the portion of the local area. The camera system selects, as part of a low priority data stream, one or more of the images from memory locations. The camera system encodes the selected one or more images. The camera system packetizes the encoded one or more images to form an image frame in a video feed. The camera system provides the image frame to a user device that presents the image frame as part of the video feed.","abstract_2":"A virtual reality or augmented reality experience of a scene may be decoded for playback for a viewer through a combination of CPU and GPU processing. A video stream may be retrieved from a data store. A first viewer position and\/or orientation may be received from an input device, such as the sensor package on a head-mounted display (HMD). At a processor, the video stream may be partially decoded to generate a partially-decoded bitstream. At a graphics processor, the partially-decoded bitstream may be further decoded to generate viewpoint video of the scene from a first virtual viewpoint corresponding to the first viewer position and\/or orientation. The viewpoint video may be displayed on a display device, such as screen of the HMD.","priority_1":"2017-04-14T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8688368889},{"pair":"US-10268268-B1 & US-9851565-B1","patent_1":"US-10268268-B1","title_1":"Waveguide integrated eye tracking ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10268268B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An eye tracker for determining a position of an eye, which may be integrated into a head-mounted display. The eye tracker includes a waveguide, switchable Bragg gratings (SBGs) that selectively out couple light from the waveguide, light sources coupled to the waveguide, a detector coupled to a return path of the waveguide, and a controller. The controller instructs at least one light source to emit at least one light beam propagating through the waveguide, and activates at least one SBG to out-couple the at least one light beam from the waveguide toward the eye. The waveguide in-couples at least one reflected light signal reflected from the eye that originates from the at least one light beam out-coupled from the waveguide. The detector detects the at least one reflected light signal. The controller determines a position of the eye using the detected at least one reflected light signal.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-09-02T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8687935893},{"pair":"US-2019342647-A1 & US-2016217781-A1","patent_1":"US-2019342647-A1","title_1":"Hybrid audio system for eyewear devices ","patent_2":"US-2016217781-A1","title_2":"Methods And Systems For Implementing Bone Conduction-Based Noise Cancellation For Air-Conducted Sound ","link_1":"https:\/\/patents.google.com\/patent\/US20190342647A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160217781A1\/en","abstract_1":"An audio system for providing content to a user. The system includes a first and a second transducer assembly of a plurality of transducer assemblies, an acoustic sensor, and a controller. The first transducer assembly couples to a portion of an auricle of the user's ear and vibrates over a first range of frequencies based on a first set of audio instructions. The vibration causes the portion of the ear to create a first range of acoustic pressure waves. The second transducer assembly is configured to vibrate over a second range of frequencies to produce a second range of acoustic pressure waves based on a second set of audio instructions. The acoustic sensor detects acoustic pressure waves at an entrance of the ear. The controller generates the audio instructions based on audio content to be provided to the user and the detected acoustic pressure waves from the acoustic sensor.","abstract_2":"A wearable computing device can receive, via at least one input transducer, a first audio signal associated with ambient sound from an environment of the device. The device can then process the first audio signal so as to determine a second audio signal that is out of phase with the first audio signal and effective to substantially cancel at least a portion of the first audio signal. The device may then generate a noise-cancelling audio signal based on the second audio signal, based on a third audio signal, and based on one or more wearer-specific parameters, where the third audio signal is representative of a sound to be provided by the device. The device may then cause a bone conduction transducer (BCT) to vibrate so as to provide to an ear a noise-cancelling sound effective to substantially cancel at least a portion of the ambient sound.","priority_1":"2018-05-01T00:00:00","priority_2":"2013-10-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8687857988},{"pair":"US-10514544-B1 & US-10032074-B2","patent_1":"US-10514544-B1","title_1":"Tilted displays for a wide field of view ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10514544B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head-mounted display device includes a first set of one or more display elements defining a first plane and a second set of one or more display elements defining a second plane that is not parallel to the first plane. The display device also includes a first set of one or more lenses defining a third plane and configured to transmit light from the first set of one or more display elements toward a first eye of a user, and a second set of one or more lenses defining a fourth that is not parallel to the third plane, and configured to transmit light from the second set of one or more display elements toward a second eye of the user. The second set of one or more lenses is distinct and separate from the first set of one or more lenses.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-11-01T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8687810228},{"pair":"US-2018173303-A1 & US-2019122440-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2019122440-A1","title_2":"Content display property management ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190122440A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Systems and methods for inserting and transforming content are provided. For example, the inserted content may include augmented reality content that is inserted into a physical space or a representation of the physical space such as an image. An example system and method may include receiving an image and identifying a physical location associated with a display management entity within the image. The example system and method may also include retrieving content display parameters associated with the display management entity. Additionally, the example system and method may also include identifying content to display and displaying the content using the display parameters associated with the display management entity.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-10-20T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8687626922},{"pair":"US-10254507-B1 & US-9851565-B1","patent_1":"US-10254507-B1","title_1":"Devices and methods for adjusting an interpupillary distance based on encoded light patterns ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10254507B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A device includes a first light source device configured to transmit a first light and a second light. The device also includes a first set of one or more lenses configured for directing the first light and the second light toward a first eye of a user. The first light is spatially offset from the second light. The first light and the second light provide a cue for adjusting a location of the first set of one or more lenses. Also disclosed is a method that includes transmitting a first light and a second light through a first set of one or more lenses and directing the first light and the second light toward a first eye of a user. Further disclosed is a method for adjusting a position of one or more lenses.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-05-01T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8686817026},{"pair":"US-10330936-B2 & US-10241329-B2","patent_1":"US-10330936-B2","title_1":"Focal surface display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10330936B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head mounted display (HMD) adjusts the phase of light of a virtual scene using a spatially programmable focusing element. Depths of the virtual scene are approximated to one or more focal surfaces and the shape of the focal surfaces is then adjusted to minimize the distance of the focal surface to features in the virtual scene. The resulting shape of the focal surface is a continuous piecewise smooth three-dimensional curve. A phase function is generated for each focal surface that, when executed by the spatially programmable focusing element, reproduces a focal pattern corresponding to the each focal surface, which bends and shapes the wavefront to produce a focal pattern that conforms to the scene geometry.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-01-19T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8685879768},{"pair":"US-2019318528-A1 & US-10460510-B2","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.868465885},{"pair":"US-10495798-B1 & US-9798147-B1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2018-08-07T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8684621837},{"pair":"US-2019212482-A1 & US-10546518-B2","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-01-10T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8684034957},{"pair":"US-10495798-B1 & US-9709797-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8683305012},{"pair":"US-10473939-B1 & US-9709797-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8683240014},{"pair":"US-10529117-B2 & US-10460510-B2","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8683105738},{"pair":"US-2017161951-A1 & US-2018343443-A1","patent_1":"US-2017161951-A1","title_1":"Autofocus virtual reality headset ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20170161951A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A scene presented by a headset is adjusted to correct for distortion from optical errors of an optics block in the headset. To correct for the distortion, the scene is pre-distorted when presented based on previously modeled distortion of the optics block, so distortion from the optics block corrects the pre-distortion. To model the distortion, the headset displays calibration image including features and images of the calibration image are captured from multiple positions. Differences between locations of features in the calibration images and locations of corresponding features in captured images of the calibration image are identified and a distortion correction is determined based on the differences.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2015-12-08T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8683027776},{"pair":"US-2016085301-A1 & US-2017123209-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2014-09-22T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8682133329},{"pair":"US-10311584-B1 & US-10032074-B2","patent_1":"US-10311584-B1","title_1":"Estimation of absolute depth from polarization measurements ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10311584B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head mounted display comprises an eye tracking system configured to enable eye tracking using polarization. The eye tracking system includes one or more illumination sources and an optical detector comprising polarization sensitive pixels. The one or more illumination sources are configured to illuminate a user's eye and generate reflections directed towards the optical detector. The eye tracking system determines, for each polarization sensitive pixel in a subset of the polarization sensitive pixels, one or more estimation parameters. The eye tracking system determines, for the subset of the polarization sensitive pixels, depth information for one or more glints associated with one or more surfaces of the eye, based in part on the polarization of the reflections and the one or more estimation parameters. The determined depth information is used to update a model of the eye. The eye tracking system determines eye tracking information based on the updated model.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-11-09T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.868150933},{"pair":"US-2019318529-A1 & US-10460510-B2","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8681375319},{"pair":"US-2018164591-A1 & US-2020041798-A1","patent_1":"US-2018164591-A1","title_1":"Tiled waveguide display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20180164591A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A waveguide display includes light sources, a source waveguide, an output waveguide, and a controller. Light from each of the light sources is coupled into the source waveguide. The source waveguide includes gratings with a constant period determined based on the conditions for total internal reflection and first order diffraction of the received image light. The emitted image light is coupled into the output waveguide at several entrance locations. The output waveguide outputs expanded image lights at a location offset from the entrance location, and the location\/direction of the emitted expanded image light is based in part on the orientation of the light sources. Each of the expanded image light is associated with a field of view of the expanded image light emitted by the output waveguide.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-12-12T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8681138064},{"pair":"US-2019227322-A1 & US-2018343443-A1","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-01-25T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8680503319},{"pair":"US-2020027261-A1 & US-2017103091-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017103091-A1","title_2":"Displaying objects based on a plurality of models ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170103091A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A system and method is provided for displaying surfaces of an object from a vantage point different from the vantage point from which imagery of the object was captured. In some aspects, imagery may be generated for display by combining visual characteristics from multiple source images and applying greater weight to the visual characteristics of some of the source images relative to the other source images. The weight may be based on the orientation of the surface relative to the location from which the image was captured and the location from which the object will be displayed.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8679976054},{"pair":"US-2019037137-A1 & US-2017363949-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2017363949-A1","title_2":"Multi-tier camera rig for stereoscopic image capture ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170363949A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"In on the general aspect, a camera rig can include a first tier of images sensors including a first plurality of image sensors where the first plurality of image sensors are arranged in a circular shape and oriented such that a field of view of each of the first plurality of image sensors has an axis perpendicular to a tangent of the circular shape. The camera rig can include a second tier of image sensors including a second plurality of image sensors where the second plurality of image sensors are oriented such that a field of view of each of the second plurality of image sensors has an axis non-parallel to the field of view of each of the first plurality of image sensors.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8679442859},{"pair":"US-10466496-B2 & US-9798147-B1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2017-12-06T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8678664363},{"pair":"US-10546430-B1 & US-9851565-B1","patent_1":"US-10546430-B1","title_1":"Image plane adjustment in a near-eye display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10546430B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display (NED) has an orientation detection device and a display block. The orientation detection device collects orientation data that describe an orientation of the NED. The display block has a display assembly, a focusing assembly, and a controller. The controller determines an orientation vector of the NED based in part on the orientation data and computes an angular difference between the orientation vector of the NED and a gravity vector. After comparing the angular difference to a threshold value, the controller generates multifocal instructions that adjusts the optical element to display an augmented scene at the selected image plane corresponding to the multifocal instructions.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-08-29T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8677395164},{"pair":"US-2016210782-A1 & US-10241329-B2","patent_1":"US-2016210782-A1","title_1":"Compressible eyecup assemblies in a virtual reality headset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20160210782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality (VR) headset includes an electronic display element, an optics block, and an adjustment mechanism. The electronic display element outputs image light. The optics block includes a cone and an additional cone coupled to a lens and an additional lens, respectively. Image light is directed to the lens and to the additional lens via the cone and additional cone, respectively. Each of the cones comprises an opaque material that is deformable to adjust a distance from a base portion of a cone to a top portion of a cone may be adjusted, via, compression, elongation, or both. An adjustment mechanism may receive input from a user and configured to adjust the distance one or more of the cone and the additional cone.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2015-01-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.86769923},{"pair":"US-10528128-B1 & US-2017123209-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2017-12-15T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8675296489},{"pair":"US-10109067-B2 & US-10241329-B2","patent_1":"US-10109067-B2","title_1":"Corneal sphere tracking for generating an eye model ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10109067B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system comprises two or more illumination sources positioned relative to one another and an optical detector in order to capture. The optical detector is configured to capture images of the cornea based on one or more reflections. The eye tracking unit is configured to generate a model of the user's eye. The generated eye model is used to determine eye tracking information such as gaze direction as the user glances at different objects in the HMD.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-03-11T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8675283316},{"pair":"US-2018239145-A1 & US-2018343443-A1","patent_1":"US-2018239145-A1","title_1":"Focus adjusting multiplanar head mounted display ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20180239145A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A multiplanar head mounted display (HMD) includes two or more artificial display planes for each eye located at optical distances that can be dynamically adjusted based on a location within a scene presented by the HMD that the user views. For example, a scene is presented on two or more electronic display elements (e.g., screens) of the HMD. A focal length of an optics block that directs image light from the electronic display elements towards the eyes of a user is adjusted using a varifocal system (e.g., an element that mechanically changes a distance between a lens system in the optics block and the electronic display element, an element that changes shape of one or more lenses in the lens system in the optics block, etc.) based on a location or object within the scene where the user is looking.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-02-21T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8675089855},{"pair":"US-10120193-B2 & US-9851565-B1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-27T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8675055268},{"pair":"US-10520729-B1 & US-2015169054-A1","patent_1":"US-10520729-B1","title_1":"Light scattering element for providing optical cues for lens position adjustment ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10520729B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A method includes displaying a high contrast image on a display screen; and projecting the high contrast image through a Fresnel lens to provide a cue for adjusting a position of the Fresnel lens. Also disclosed is a device for determining and\/or adjusting an offset of a Fresnel lens. The device includes a Fresnel lens and a display screen configured to project a high contrast image through the Fresnel lens. Further disclosed is a method for adjusting a position of a Fresnel lens. The method includes receiving a projection of a high contrast image transmitted through a Fresnel lens; and adjusting a position of the Fresnel lens based on the projection of the high contrast image.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-04-25T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8674713472},{"pair":"US-10546430-B1 & US-2020049994-A1","patent_1":"US-10546430-B1","title_1":"Image plane adjustment in a near-eye display ","patent_2":"US-2020049994-A1","title_2":"Tilted focal plane for near-eye display system ","link_1":"https:\/\/patents.google.com\/patent\/US10546430B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200049994A1\/en","abstract_1":"A near-eye display (NED) has an orientation detection device and a display block. The orientation detection device collects orientation data that describe an orientation of the NED. The display block has a display assembly, a focusing assembly, and a controller. The controller determines an orientation vector of the NED based in part on the orientation data and computes an angular difference between the orientation vector of the NED and a gravity vector. After comparing the angular difference to a threshold value, the controller generates multifocal instructions that adjusts the optical element to display an augmented scene at the selected image plane corresponding to the multifocal instructions.","abstract_2":"A near-eye display device reduces vergence accommodation conflict by adjusting a tilt and\/or distance of a focal plane of a display panel based on scene depth statistics. For example, many three-dimensional (3D) scenes have closer objects in the lower visual field and farther objects in the upper visual field. Changing the tilt of the focal plane of the display panel to match average 3D screen depths reduces the discrepancy between vergence and accommodation distances. In some embodiments, the near-eye display device employs a fixed tilt of the display panel to match average scene depth statistics across a variety of scenes. In some embodiments, the near-eye display device dynamically adjusts the pitch and yaw of the focal plane of the display panel to match scene statistics for a given scene.","priority_1":"2017-08-29T00:00:00","priority_2":"2018-08-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8673644653},{"pair":"US-2018120497-A1 & US-2017116950-A1","patent_1":"US-2018120497-A1","title_1":"Thick backlight for rgb led of a liquid crystal display used in a virtual reality head mounted display ","patent_2":"US-2017116950-A1","title_2":"Liquid crystal display with variable drive voltage ","link_1":"https:\/\/patents.google.com\/patent\/US20180120497A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170116950A1\/en","abstract_1":"A liquid crystal display (LCD) device including a backlight with vertically stacked light emitting diodes (LEDs). The LCD device includes an LCD panel and a backlight for illuminating the LCD panel. The backlight includes a plurality of LEDs and a light guide. The plurality of LEDs are stacked vertically and disposed behind the LCD panel along one or more edges of the LCD panel. The plurality of LEDs include at least a first color LED and a second color LED emitting first light and second light at a first direction, respectively, at a first wavelength and a second wavelength, respectively. The light guide is disposed behind the LCD panel and adjacent to the plurality of LEDs. The light guide is configured to combine the first light and the second light received from the plurality of LEDs into combined light to illuminate the LCD panel.","abstract_2":"A technique for operation of a display system includes displaying a display image from a liquid crystal display source, measuring a brightness of ambient light, and selecting a drive voltage for driving liquid crystal cells within the liquid crystal display source based upon the brightness of the ambient light. The drive voltage is used for driving the liquid crystal cells into an on-state or an off-state while displaying the display image.","priority_1":"2016-10-31T00:00:00","priority_2":"2015-10-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8673625719},{"pair":"US-10481321-B1 & US-9709797-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2018-09-06T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8673496347},{"pair":"US-10466496-B2 & US-9810910-B1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2017-12-06T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.86719954},{"pair":"US-2019311522-A1 & US-2017228926-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2017228926-A1","title_2":"Determining Two-Dimensional Images Using Three-Dimensional Models ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170228926A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Systems and methods for determining two-dimensional (2D) images are presented. For instance, data indicative of a three-dimensional (3D) model of a geographic area can be obtained. A 2D output image can be generated depicting at least a portion of the geographic area based at least in part on the 3D model. Each pixel in the output image can then be reprojected to the 3D model. A plurality of aerial images depicting the geographic area can be obtained. A source image can then be determined for each pixel in the output image from the plurality of aerial images. The source image can be determined based at least in part on the reprojection of the pixel in the output image to the three-dimensional model.","priority_1":"2018-04-05T00:00:00","priority_2":"2015-11-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8671684902},{"pair":"US-2018173303-A1 & US-2015242414-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8671045572},{"pair":"US-2020018962-A1 & US-9851565-B1","patent_1":"US-2020018962-A1","title_1":"Adaptive lenses for near-eye displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200018962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes two or more polarization-dependent lenses sensitive to either linear or circular polarization, and at least one switchable polarization converter. The switchable polarization converter is configured to rotate linearly polarized light or change the handedness of circularly polarized light when switched on. The lens assembly is configurable to project displayed images on two or more different image planes. For example, when the switchable polarization converter is switched off, the lens assembly projects a displayed image on a first image plane. When the switchable polarization converter is switched on, the lens assembly projects a displayed image on a second image plane different from the first image plane.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-07-11T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.867101997},{"pair":"US-2017358136-A1 & US-2016240013-A1","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2016-06-10T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8670553205},{"pair":"US-10210660-B2 & US-2018192033-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2018192033-A1","title_2":"Multi-view scene flow stitching ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180192033A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A method of multi-view scene flow stitching includes capture of imagery from a three-dimensional (3D) scene by a plurality of cameras and stitching together captured imagery to generate virtual reality video that is both 360-degree panoramic and stereoscopic. The plurality of cameras capture sequences of video frames, with each camera providing a different viewpoint of the 3D scene. Each image pixel of the sequences of video frames is projected into 3D space to generate a plurality of 3D points. By optimizing for a set of synchronization parameters, stereoscopic image pairs may be generated for synthesizing views from any viewpoint. In some embodiments, the set of synchronization parameters includes a depth map for each of the plurality of video frames, a plurality of motion vectors representing movement of each one of the plurality of 3D points in 3D space over a period of time, and a set of time calibration parameters.","priority_1":"2016-04-06T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8669953994},{"pair":"US-10473939-B1 & US-2019025602-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-01-08T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8669574455},{"pair":"US-10527854-B1 & US-2020041798-A1","patent_1":"US-10527854-B1","title_1":"Illumination source for a waveguide display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10527854B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near eye display (NED) that includes an illumination source including a photonic array. The photonic array includes at least one waveguide that divides light from one or more emitters into a number of channels, and outputs the divided light using a plurality of outputs. An optical switching assembly includes a one or more input ports and a plurality of output ports. The optical switching assembly is configured to map light from the one or more input ports to the plurality of outputs. In various embodiments, the optical switching assembly is additionally configured to control the relative illumination, timing, and phase of light produced by each of the plurality of outputs. The optical switching assembly selectively outputs some or all of the incoupled light via output ports of the plurality of output ports in accordance with instructions from a controller, the outcoupled light forming a light pattern.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8668841027},{"pair":"US-10528128-B1 & US-9536354-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2017-12-15T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8668220304},{"pair":"US-10210660-B2 & US-2019129174-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2019129174-A1","title_2":"Multi-perspective eye-tracking for vr\/ar systems ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190129174A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A display system, such as a head mounted display, tracks a pose of a user's eye based on multiple perspectives of the eye captured via a segmented optics array, such as a lenslet array or Fresnel lens. The display system reflects light (e.g., infra-red light) off each segment of the segmented optics array, and captures an image based on the reflected light. Because of the segmented optics, the captured image represents multiple concurrent perspectives of the user's eye. The display system analyzes the different perspectives and selects a perspective, or combination of perspectives, and based on the selected perspective or combination, identifies a pose of the user's eye.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-10-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.866757111},{"pair":"US-2016267884-A1 & US-10591731-B2","patent_1":"US-2016267884-A1","title_1":"Non-uniform rescaling of input data for displaying on display device ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20160267884A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A method for rescaling data to be displayed on a display device (e.g., an organic light emitting diode display device) is disclosed. The method includes receiving a frame of data for displaying on the display device, where the received data includes a first portion of the data corresponding to a first pixel region at a first pixel resolution and a second portion of the data corresponding to a second pixel region at a second pixel resolution lower than the first pixel resolution. The method also includes rescaling the received data for displaying the received data at a native pixel resolution of the display device, where the rescaling of the received data includes scaling the first portion of the data using a first scaling factor and the second portion of the data using a second scaling factor. The method further includes providing the rescaled data for displaying on the display device.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2015-03-12T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8667358094},{"pair":"US-10295723-B1 & US-2020041798-A1","patent_1":"US-10295723-B1","title_1":"2D pupil expander using holographic Bragg grating ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10295723B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A holographic Bragg grating is used as an output element for a waveguide in a lens used for artificial reality. By using a Bragg grating, a number of waveguides can be reduced. The output element has a first super grating and a second super grating written in a single grating layer of the waveguide. The first super grating has a grating vector that is skew to a grating vector of the second super grating to provide both deflection and out coupling for two-dimensional output coupling.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-01T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8667354438},{"pair":"US-10495798-B1 & US-9810910-B1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2018-08-07T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8666816689},{"pair":"US-10534185-B1 & US-2018343443-A1","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-02-14T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8666576531},{"pair":"US-10495798-B1 & US-2017235145-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8666478801},{"pair":"US-2016085301-A1 & US-10546518-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2014-09-22T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8665863835},{"pair":"US-2016210782-A1 & US-9851565-B1","patent_1":"US-2016210782-A1","title_1":"Compressible eyecup assemblies in a virtual reality headset ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20160210782A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A virtual reality (VR) headset includes an electronic display element, an optics block, and an adjustment mechanism. The electronic display element outputs image light. The optics block includes a cone and an additional cone coupled to a lens and an additional lens, respectively. Image light is directed to the lens and to the additional lens via the cone and additional cone, respectively. Each of the cones comprises an opaque material that is deformable to adjust a distance from a base portion of a cone to a top portion of a cone may be adjusted, via, compression, elongation, or both. An adjustment mechanism may receive input from a user and configured to adjust the distance one or more of the cone and the additional cone.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-01-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8665623344},{"pair":"US-2019313087-A1 & US-2017357090-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2017357090-A1","title_2":"Head-wearable displays with a tiled field of view using a single microdisplay ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170357090A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Implementations are described of an eyepiece for a head wearable display. The eyepiece includes a curved lightguide for guiding display light via total internal reflection between a peripherally-located input surface and a viewing region and an output coupler disposed across the viewing region to redirect the display light towards an eyeward direction for output from the curved light guide. The output coupler has an optical axis and has a set of reflective surfaces that includes at least two individual reflective surfaces to reflect incident display light toward the eyeward direction in at least two different directions relative to the optical axis of the output coupler. Other embodiments are disclosed and claimed.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-06-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8665484326},{"pair":"US-10599215-B2 & US-2016057339-A1","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2016-04-26T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8665350328},{"pair":"US-10066933-B2 & US-2018134127-A1","patent_1":"US-10066933-B2","title_1":"Camera depth mapping using structured light patterns ","patent_2":"US-2018134127-A1","title_2":"Adaptive glare removal and\/or color correction ","link_1":"https:\/\/patents.google.com\/patent\/US10066933B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180134127A1\/en","abstract_1":"The various embodiments described herein include methods and\/or systems for depth mapping. In one aspect, a method of depth mapping is performed at an apparatus including a projector, a camera, one or more processors, and memory storing one or more programs for execution by the one or more processors. The method includes identifying one or more areas of interest in a scene in accordance with variation of depth in the scene as detected at a first resolution. The method also includes, for each area of interest: (1) applying, via the projector, a respective structured-light pattern to the area of interest; (2) capturing, via the camera, an image of the area of interest with the respective structured-light pattern applied to it; and (3) creating a respective depth map of the area of interest using the captured image, the respective depth map having a higher resolution than the first resolution.","abstract_2":"Some implementations relate to determining whether glare is present in captured image(s) of an object (e.g., a photo) and\/or to determining one or more attributes of any present glare. Some of those implementations further relate to adapting one or more parameters for a glare removal process based on whether the glare is determined to be present and\/or based on one or more of the determined attributes of any glare determined to be present. Some additional and\/or alternative implementations disclosed herein relate to correcting color of a flash image of an object (e.g., a photo). The flash image is based on one or more images captured by a camera of a client device with a flash component of the client device activated. In various implementations, correcting the color of the flash image is based on a determined color space of an ambient image of the object.","priority_1":"2015-05-04T00:00:00","priority_2":"2016-11-14T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8664375281},{"pair":"US-10578875-B1 & US-9900676-B2","patent_1":"US-10578875-B1","title_1":"Head-mounted display with integrated speaker enclosure ","patent_2":"US-9900676-B2","title_2":"Wearable computing device with indirect bone-conduction speaker ","link_1":"https:\/\/patents.google.com\/patent\/US10578875B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9900676B2\/en","abstract_1":"The disclosed head-mounted display system may include (1) a display for displaying computer-generated imagery, (2) a lens, (3) a peripheral wall extending from a back end to a front end, with the back end coupled to the lens and the front end coupled to the display such that the lens, the peripheral wall, and the display together define an enclosure, and (4) a speaker housed by the enclosure. Various other systems and methods of assembling the same are also disclosed.","abstract_2":"Exemplary wearable computing systems may include a head-mounted display that is configured to provide indirect bone-conduction audio. For example, an exemplary head-mounted display may include at least one vibration transducer that is configured to vibrate at least a portion of the head-mounted display based on the audio signal. The vibration transducer is configured such that when the head-mounted display is worn, the vibration transducer vibrates the head-mounted display without directly vibrating a wearer. However, the head-mounted display structure vibrationally couples to a bone structure of the wearer, such that vibrations from the vibration transducer may be indirectly transferred to the wearer's bone structure.","priority_1":"2018-05-30T00:00:00","priority_2":"2011-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8663659681},{"pair":"US-10210660-B2 & US-2020049994-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2020049994-A1","title_2":"Tilted focal plane for near-eye display system ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200049994A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A near-eye display device reduces vergence accommodation conflict by adjusting a tilt and\/or distance of a focal plane of a display panel based on scene depth statistics. For example, many three-dimensional (3D) scenes have closer objects in the lower visual field and farther objects in the upper visual field. Changing the tilt of the focal plane of the display panel to match average 3D screen depths reduces the discrepancy between vergence and accommodation distances. In some embodiments, the near-eye display device employs a fixed tilt of the display panel to match average scene depth statistics across a variety of scenes. In some embodiments, the near-eye display device dynamically adjusts the pitch and yaw of the focal plane of the display panel to match scene statistics for a given scene.","priority_1":"2016-04-06T00:00:00","priority_2":"2018-08-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8663654006},{"pair":"US-10509228-B1 & US-9851565-B1","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-20T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8662792231},{"pair":"US-2018172995-A1 & US-9851565-B1","patent_1":"US-2018172995-A1","title_1":"Waveguide display with a small form factor, a large field of view, and a large eyebox ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180172995A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A waveguide display is used for presenting media to a user. The waveguide display includes light source assembly, an output waveguide, and a controller. The light source assembly includes one or more projectors projecting an image light at least along one dimension. The output waveguide includes a waveguide body with two opposite surfaces. The output waveguide includes a first grating receiving an image light propagating along an input wave vector, a second grating, and a third grating positioned opposite to the second grating and outputting an expanded image light with wave vectors matching the input wave vector. The controller controls the scanning of the one or more source assemblies to form a two-dimensional image.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-12-20T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.86627878},{"pair":"US-10546430-B1 & US-2019020869-A1","patent_1":"US-10546430-B1","title_1":"Image plane adjustment in a near-eye display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10546430B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A near-eye display (NED) has an orientation detection device and a display block. The orientation detection device collects orientation data that describe an orientation of the NED. The display block has a display assembly, a focusing assembly, and a controller. The controller determines an orientation vector of the NED based in part on the orientation data and computes an angular difference between the orientation vector of the NED and a gravity vector. After comparing the angular difference to a threshold value, the controller generates multifocal instructions that adjusts the optical element to display an augmented scene at the selected image plane corresponding to the multifocal instructions.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-08-29T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8662402564},{"pair":"US-2019311232-A1 & US-10241329-B2","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-04-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8662162818},{"pair":"US-2019361518-A1 & US-2018101984-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-05-22T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8661929964},{"pair":"US-10546430-B1 & US-10546518-B2","patent_1":"US-10546430-B1","title_1":"Image plane adjustment in a near-eye display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10546430B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near-eye display (NED) has an orientation detection device and a display block. The orientation detection device collects orientation data that describe an orientation of the NED. The display block has a display assembly, a focusing assembly, and a controller. The controller determines an orientation vector of the NED based in part on the orientation data and computes an angular difference between the orientation vector of the NED and a gravity vector. After comparing the angular difference to a threshold value, the controller generates multifocal instructions that adjusts the optical element to display an augmented scene at the selected image plane corresponding to the multifocal instructions.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-08-29T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8661268899},{"pair":"US-2020090406-A1 & US-2018350032-A1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-2018350032-A1","title_2":"Smoothly varying foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180350032A1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Systems and methods for performing foveated rendering are provided. An example system and method may warp a 3D scene based on a fixation point. The system and method may also render the warped 3D scene to generate a first image. The system and method may also unwarp the first image to generate a second image. For example, the first image may have fewer pixels than the second image.","priority_1":"2018-09-17T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8660960093},{"pair":"US-10506217-B2 & US-10242454-B2","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-10242454-B2","title_2":"System for depth data filtering based on amplitude energy values ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10242454B2\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"An electronic device includes a time of flight (ToF) camera and one or more processors. The ToF camera captures raw depth images. The processors determine a depth frame and an amplitude frame from the raw depth images. The depth frame comprises an array of pixels, each pixel having a depth value. The amplitude frame comprises an array of pixels, each pixel having an amplitude energy value. The processors determine a first energy threshold value based on the amplitude energy values of the array of pixels of the amplitude frame and determine, for the depth value of a first pixel of the depth frame, a confidence value representing a corresponding validity of a depth represented by the depth value, based on a comparison of the amplitude energy value of a corresponding first pixel of the amplitude frame to the first energy threshold value.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-01-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8660742273},{"pair":"US-10474229-B1 & US-2019271844-A1","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-11-01T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8660165481},{"pair":"US-2017358136-A1 & US-10241329-B2","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-06-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8659613671},{"pair":"US-10326977-B1 & US-10241329-B2","patent_1":"US-10326977-B1","title_1":"Multifocal test system ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10326977B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A multifocal test system is described herein. The system includes a plurality of displays located at different focal distances. Each display includes a plurality of pixels with pixel intensity values. The system includes an eye tracking system that determines eye tracking information about a position of an eye relative to the displays. A controller is configured to determine pixel intensity values based on decomposition of a scene across the plurality of displays, and the position of the eye.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-01-19T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8659516083},{"pair":"US-2016248971-A1 & US-2016057339-A1","patent_1":"US-2016248971-A1","title_1":"Illumination system synchronized with image sensor ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20160248971A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"Eye tracking technology may be used in a wide range of lighting conditions and with many different and varying light levels. In some embodiments, an eye tracking device may employ active illumination (e.g., in the form of infrared light-emitting diodes (LEDs)). However, employing active illumination may reduce the battery life of the device. Under some circumstances (e.g., in a dark environment), the light intensity may be excessive and could be reduced, thereby reducing energy consumption and extending the battery life of the device. An algorithm may be used to adjust the duration of light in eye tracking systems that employ active illumination.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2015-02-23T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8659450661},{"pair":"US-2017293146-A1 & US-10032074-B2","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-04-07T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8659306418},{"pair":"US-2020013184-A1 & US-10553016-B2","patent_1":"US-2020013184-A1","title_1":"Systems and methods for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit ","patent_2":"US-10553016-B2","title_2":"Phase aligned foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20200013184A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10553016B2\/en","abstract_1":"The disclosed computer-implemented method for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit may include (1) sending imaging data from an imaging device to a hardware accelerator unit, and (2) directing the hardware accelerator unit to generate a multi-scale representation of the imaging data sent from the imaging device, (3) preparing a set of input data for a set of image-based tracking operations, and (4) directing the hardware accelerator unit to execute the set of image-based tracking operations using the generated multi-scale representation of the imaging data and the prepared set of input data. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A display device, such as a head mounted device (HMD), displays a virtual scene. The display device includes a motion tracker for detecting rotation and\/or translation of the display device. The display device also includes a processor that is configured to determine, in response to the detected, an orientation of the display device relative to a plurality of world-aligned viewing frustums that are stationary relative to the virtual scene. The processor is also configured to identify a set of those world-aligned viewing frustums that overlap with an output field of view. The processor is further configured to render pixels of the set of those world-aligned viewing frustums that overlap with an output field of view and upsample the rendered pixels to generate values of display pixels for presentation by the display device.","priority_1":"2018-07-06T00:00:00","priority_2":"2017-11-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8659073112},{"pair":"US-2019212482-A1 & US-9851565-B1","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-10T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8659026212},{"pair":"US-10529113-B1 & US-10241329-B2","patent_1":"US-10529113-B1","title_1":"Generating graphical representation of facial expressions of a user wearing a head mounted display accounting for previously captured images of the user's facial expressions ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10529113B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality (VR) or augmented reality (AR) head mounted display (HMD) includes various image capture devices that capture images of portions of the user's face. Through image analysis, points of each portion of the user's face are identified from the images and their movement is tracked. The identified points are mapped to a three dimensional model of a face. From the identified points, a blendshape vector is determined for each captured image, resulting in various vectors indicating the user's facial expressions. A direct expression model that directly maps images to blendshape coefficients for a set of facial expressions based on captured information from a set of users may augment the blendshape vector in various embodiments. From the blendshape vectors and transforms mapping the captured images to three dimensions, the three dimensional model of the face is altered to render the user's facial expressions.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2019-01-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8657955239},{"pair":"US-2017352178-A1 & US-9934583-B2","patent_1":"US-2017352178-A1","title_1":"Facial animation using facial sensors within a head-mounted display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20170352178A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A facial tracking system generates a virtual rendering of a portion of a face of a user wearing a head-mounted display (HMD). The facial tracking system illuminates portions of the face inside the HMD. The facial tracking system captures a plurality of facial data of the portion of the face using one or more facial sensors located inside the HMD. A plurality of planar sections of the portion of the face are identified based at least in part on the plurality of facial data. The plurality of planar sections are mapped to one or more landmarks of the face. Facial animation information is generated based at least in part on the mapping, the facial animation information describing a portion of a virtual face corresponding to the portion of the user's face.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8657466802},{"pair":"US-2020081252-A1 & US-2017293143-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-03-15T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.865740337},{"pair":"US-10574938-B1 & US-10242454-B2","patent_1":"US-10574938-B1","title_1":"Variable frame rate depth camera assembly ","patent_2":"US-10242454-B2","title_2":"System for depth data filtering based on amplitude energy values ","link_1":"https:\/\/patents.google.com\/patent\/US10574938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10242454B2\/en","abstract_1":"A depth camera assembly (DCA) for depth sensing of a local area. The DCA includes a light generator, a detector, and a controller. The light generator illuminates a local area with a light pattern. The detector captures portions of the light pattern reflected from an object in the local area. The detector includes pixel rows and pixel columns that form a dynamically adjustable read-out area. The controller reads first data of the captured portions of the reflected light pattern that correspond to a first read-out area, and locates the object based on the first data. The controller determines a second read-out area of the detector based on a portion of the read-out area associated with the object. The controller reads second data of the captured portions of the reflected light pattern that correspond to the second read-out area, and determines depth information for the object based on the second data.","abstract_2":"An electronic device includes a time of flight (ToF) camera and one or more processors. The ToF camera captures raw depth images. The processors determine a depth frame and an amplitude frame from the raw depth images. The depth frame comprises an array of pixels, each pixel having a depth value. The amplitude frame comprises an array of pixels, each pixel having an amplitude energy value. The processors determine a first energy threshold value based on the amplitude energy values of the array of pixels of the amplitude frame and determine, for the depth value of a first pixel of the depth frame, a confidence value representing a corresponding validity of a depth represented by the depth value, based on a comparison of the amplitude energy value of a corresponding first pixel of the amplitude frame to the first energy threshold value.","priority_1":"2017-06-27T00:00:00","priority_2":"2017-01-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8655454661},{"pair":"US-2020064641-A1 & US-10095036-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10095036-B2","title_2":"Compact near-eye display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10095036B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"Systems and methods that employ a near-eye display system including an optical assembly are described. The optical assembly may include a head-mounted display device worn by a user in which the head-mounted display device adapted to house an image projecting device and an optical assembly. The optical assembly may include, for at least one eyepiece, a first flat filter stack operable to be oriented in a first direction. and a second flat filter stack operable to be oriented in a second direction. The near-eye display system assembly may also include a display panel adapted to receive image content from the image projecting device, wherein the display panel is adapted to be oriented in the second direction.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8655224032},{"pair":"US-2018173303-A1 & US-9405977-B2","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-9405977-B2","title_2":"Using visual layers to aid in initiating a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9405977B2\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Methods and devices for initiating a search are disclosed. In one embodiment, a method is disclosed that includes causing a camera on a wearable computing device to record video data, segmenting the video data into a number of layers and, based on the video data, detecting that a pointing object is in proximity to a first layer. The method further includes initiating a first search on the first layer. In another embodiment, a wearable computing device is disclosed that includes a camera configured to record video data, a processor, and data storage comprising instructions executable by the processor to segment the video data into a number of layers and, based on the video data, detect that a pointing object is in proximity to a first layer. The instructions are further executable by the processor to initiate a first search on the first layer.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8654664512},{"pair":"US-10571692-B2 & US-9851565-B1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-03-02T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.865449355},{"pair":"US-2016085301-A1 & US-9727174-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9727174-B2","title_2":"Methods and systems for a virtual input device ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9727174B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"The present application discloses systems and methods for a virtual input device. In one example, the virtual input device includes a projector and a camera. The projector projects a pattern onto a surface. The camera captures images that can be interpreted by a processor to determine actions. The projector may be mounted on an arm of a pair of eyeglasses and the camera may be mounted on an opposite arm of the eyeglasses. A pattern for a virtual input device can be projected onto a \u201cdisplay hand\u201d of a user, and the camera may be able to detect when the user uses an opposite hand to select items of the virtual input device. In another example, the camera may detect when the display hand is moving and interpret display hand movements as inputs to the virtual input device, and\/or realign the projection onto the moving display hand.","priority_1":"2014-09-22T00:00:00","priority_2":"2011-07-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8654091415},{"pair":"US-2019361518-A1 & US-2019102936-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2019102936-A1","title_2":"Lighting for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102936A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"Systems and methods for lighting inserted content are provided. For example, the inserted content may include augmented reality content that is inserted into an image of a physical space. An example system and method may include determining a location within an image to insert content. For example, the image may be captured by a camera device. The example system and method may also include identifying a region of the image based on the determined location to insert the content, determining at least one lighting parameter based on the identified region, and rendering the content using the determined at least one lighting parameter.","priority_1":"2018-05-22T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8653908588},{"pair":"US-2019369390-A1 & US-2017357090-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2017357090-A1","title_2":"Head-wearable displays with a tiled field of view using a single microdisplay ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170357090A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"Implementations are described of an eyepiece for a head wearable display. The eyepiece includes a curved lightguide for guiding display light via total internal reflection between a peripherally-located input surface and a viewing region and an output coupler disposed across the viewing region to redirect the display light towards an eyeward direction for output from the curved light guide. The output coupler has an optical axis and has a set of reflective surfaces that includes at least two individual reflective surfaces to reflect incident display light toward the eyeward direction in at least two different directions relative to the optical axis of the output coupler. Other embodiments are disclosed and claimed.","priority_1":"2018-06-04T00:00:00","priority_2":"2016-06-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8652796817},{"pair":"US-2017262054-A1 & US-9851565-B1","patent_1":"US-2017262054-A1","title_1":"Focus adjusting headset ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170262054A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A virtual reality (VR) headset adjusts the phase of light of a virtual scene received from a display element using a spatial light modulator (SLM) to accommodate changes in vergence for a user viewing objects in the virtual scene. The VR headset receives virtual scene data that includes depth information for components of the virtual scene and the SLM adjusts a wavefront of the light of the virtual scene by generating a phase function that adjusts the light of the virtual scene with phase delays based the depth values. Individual phase delays shift components of the virtual scene based on the depth values to a target focal plane to accommodate a user at a vergence depth for a frame of the virtual scene. Further, the SLM can provide optical defocus by shifting components of the virtual scene with the phase delays for depth of field blur.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-03-11T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8652142683},{"pair":"US-10200624-B2 & US-2017059305-A1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-2017059305-A1","title_2":"Active illumination for enhanced depth map generation ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170059305A1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"A depth map may be generated in conjunction with generation of a digital image such as a light-field image. A light pattern source may be used to project a light pattern into a scene with one or more objects. A camera may be used to capture first light and second light reflected from the one or more objects. The first light may be a reflection of light originating from one or more other light sources independent of the light pattern source. The second light may be a reflection of the light pattern from the one or more objects. In a processor, at least the first light may be used to generate an image such as a light-field image. Further, in the processor, at least the second light may be used to generate a depth map indicative of distance between the one or more objects and the camera.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-08-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651992853},{"pair":"US-10546430-B1 & US-2015169054-A1","patent_1":"US-10546430-B1","title_1":"Image plane adjustment in a near-eye display ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10546430B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A near-eye display (NED) has an orientation detection device and a display block. The orientation detection device collects orientation data that describe an orientation of the NED. The display block has a display assembly, a focusing assembly, and a controller. The controller determines an orientation vector of the NED based in part on the orientation data and computes an angular difference between the orientation vector of the NED and a gravity vector. After comparing the angular difference to a threshold value, the controller generates multifocal instructions that adjusts the optical element to display an augmented scene at the selected image plane corresponding to the multifocal instructions.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-08-29T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651854817},{"pair":"US-2017358136-A1 & US-2020073123-A1","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2016-06-10T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651626815},{"pair":"US-2020064641-A1 & US-10133074-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10133074-B2","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10133074B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"Systems and methods are described for receiving image content from an emissive display toward a first filter stack, the first filter stack adapted to be oriented in a first direction from an optical axis of a first lens, and toward the first lens, transmitting the image content through a curved lens parallel to the optical axis of the first lens, wherein the curved lens transmits a portion of the image content to at least one optical element and to a second filter stack, the second filter stack being adapted to be oriented in a second direction from the optical axis of the first lens, and receiving the portion from the second filter stack and providing at least some of the portion to the first lens for viewing by a user.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651448779},{"pair":"US-10488921-B1 & US-2020041798-A1","patent_1":"US-10488921-B1","title_1":"Pellicle beamsplitter for eye tracking ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10488921B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a pellicle beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The pellicle beamsplitter is positioned along the optical axis between the optics assembly and the electronic display. The pellicle beamsplitter includes a front surface and a back surface. Each of the front surface and the back surface comprising a first radius curvature in a first plane and a second radius curvature in a second plane that is perpendicular to the first plane.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-09-08T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651426779},{"pair":"US-10025060-B2 & US-2018343443-A1","patent_1":"US-10025060-B2","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10025060B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A virtual reality headset displays a three-dimensional (3D) virtual scene and includes a varifocal element to dynamically adjust a focal length of an optics block included in the virtual reality headset based on a location in the virtual scene where the user is looking. The headset tracks a user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The varifocal element adjusts the focal length of the optics block so the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change. Based on the plane of focus, the virtual reality headset may provide depth cues, such as depth of field blur, to planes in the virtual scene deeper in the user's field of view than the plane of focus.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2015-12-08T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651186325},{"pair":"US-2020090406-A1 & US-10540818-B2","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2018-09-17T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8651007305},{"pair":"US-2017287194-A1 & US-9405977-B2","patent_1":"US-2017287194-A1","title_1":"Tracking portions of a user's face uncovered by a head mounted display worn by the user ","patent_2":"US-9405977-B2","title_2":"Using visual layers to aid in initiating a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20170287194A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9405977B2\/en","abstract_1":"A virtual reality system includes a head-mounted display (HMD) having one or more facial sensors and illumination sources mounted to a surface of the HMD. For example, the facial sensors are image capture devices coupled to a bottom side of the HMD. The illumination sources illuminate portions of a user's face outside of the HMD, while the facial sensors capture images of the illuminated portions of the user's face. A controller receives the captured images and generates a representation of the portions of the user's face by identifying landmarks of the user's face in the captured images and performing other suitable image processing methods. Based on the representation, the controller or another component of the virtual reality system generates content for presentation to the user.","abstract_2":"Methods and devices for initiating a search are disclosed. In one embodiment, a method is disclosed that includes causing a camera on a wearable computing device to record video data, segmenting the video data into a number of layers and, based on the video data, detecting that a pointing object is in proximity to a first layer. The method further includes initiating a first search on the first layer. In another embodiment, a wearable computing device is disclosed that includes a camera configured to record video data, a processor, and data storage comprising instructions executable by the processor to segment the video data into a number of layers and, based on the video data, detect that a pointing object is in proximity to a first layer. The instructions are further executable by the processor to initiate a first search on the first layer.","priority_1":"2016-04-01T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8650993995},{"pair":"US-10600352-B1 & US-2019086675-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-12-04T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8650959413},{"pair":"US-2020027261-A1 & US-10460505-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8650544383},{"pair":"US-10495798-B1 & US-2018239141-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-08-07T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8650426722},{"pair":"US-2019369390-A1 & US-2020041798-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8649562971},{"pair":"US-2019369390-A1 & US-2019018255-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2019018255-A1","title_2":"Compact near-eye optical system including a refractive beam-splitting convex lens ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190018255A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An optical system includes a first filter stack to convert light to a first circular polarization, and a second filter stack that reflects light having the first circular polarization and transmits light having a second circular polarization. A refractive beam splitting convex lens is disposed intermediate the first filter stack and the second filter stack. The first filter stack can include a first linear polarizer to convert light to a first linear polarization and a first quarter wave plate to convert the light from the first linear polarization to a first circular polarization. The second filter stack can include a second quarter wave plate to convert the light from the first circular polarization to a second linear polarization that is transverse to the first linear polarization, a polarization-dependent beam splitter to pass the first polarization and reflect the second polarization, and a linear polarizer to pass the second polarization.","priority_1":"2018-06-04T00:00:00","priority_2":"2017-07-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8649424044},{"pair":"US-2020064633-A1 & US-9851565-B1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-23T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8647501894},{"pair":"US-2020081252-A1 & US-2017357090-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2017357090-A1","title_2":"Head-wearable displays with a tiled field of view using a single microdisplay ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170357090A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"Implementations are described of an eyepiece for a head wearable display. The eyepiece includes a curved lightguide for guiding display light via total internal reflection between a peripherally-located input surface and a viewing region and an output coupler disposed across the viewing region to redirect the display light towards an eyeward direction for output from the curved light guide. The output coupler has an optical axis and has a set of reflective surfaces that includes at least two individual reflective surfaces to reflect incident display light toward the eyeward direction in at least two different directions relative to the optical axis of the output coupler. Other embodiments are disclosed and claimed.","priority_1":"2018-03-15T00:00:00","priority_2":"2016-06-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.86471951},{"pair":"US-2019227321-A1 & US-2017235145-A1","patent_1":"US-2019227321-A1","title_1":"Rainbow reduction in waveguide displays ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190227321A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"A waveguide display includes a first substrate and one or more grating layers on a first surface of the first substrate. The one or more grating layers are configured to cause destructive interference between ambient light diffracted by at least two grating layers or between ambient light diffracted by different portions of one grating layer. In some embodiments, the waveguide display also includes an angular-selective transmissive layer. The angular-selective transmissive layer is configured to reflect, diffract, or absorb ambient light incident on the angular-selective reflective layer with an incidence angle greater than a threshold value.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-01-23T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8646846679},{"pair":"US-10534209-B1 & US-9851565-B1","patent_1":"US-10534209-B1","title_1":"Liquid crystal structure for controlling brightness uniformity in a waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10534209B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display (NED) includes a source assembly that emits image light, a waveguide-based display assembly, and a controller coupled to the waveguide-based display assembly, and an optical assembly. The waveguide-based display assembly includes a liquid crystal (LC) waveguide, an input area, and an output area. The LC waveguide comprising a first glass layer, a second glass layer, and a LC layer between the first and second glass layers. The LC waveguide propagates the image light in-coupled via the input area in accordance with emission instructions toward the output area that out-couples the image light to a user's eye. The controller generates the emission instructions and provides the emission instructions to the LC waveguide for generating the image light of substantially uniform brightness.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-08-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8646756508},{"pair":"US-10534185-B1 & US-2016240013-A1","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-02-14T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.864671199},{"pair":"US-10451885-B2 & US-9851565-B1","patent_1":"US-10451885-B2","title_1":"Multifocal system using pixel level polarization controllers and folded optics ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10451885B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) that includes optical components that provide multiple focal distances for light emitted from an electronic display. The HMD includes a multifocal structure having a plurality of optical components positioned in series such that light from an electronic display is received and passes through the optical components at least once before being output from the multifocal structure. The plurality of optical components includes a pixel level polarizer positioned to receive light from the electronic display. The pixel level polarizer has a first configuration that causes the pixel level polarizer to linearly polarize light in a first direction and a second configuration that causes the pixel level polarizer to linearly polarize light in a second direction that is different than the first direction. The multifocal structure is configured to output image light different focal distances based in part on the configuration of the pixel level polarizer.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-03-28T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8646703393},{"pair":"US-10345600-B1 & US-2020049994-A1","patent_1":"US-10345600-B1","title_1":"Dynamic control of optical axis location in head-mounted displays ","patent_2":"US-2020049994-A1","title_2":"Tilted focal plane for near-eye display system ","link_1":"https:\/\/patents.google.com\/patent\/US10345600B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200049994A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display, an optical assembly with a dynamic optical axis component (DOAC), an eye tracker and a controller. The electronic display is configured to emit image light. The eye tracker is configured to determine a gaze vector of a user wearing the HMD. The DOAC is positioned in front of the electronic display and refracts the image light received from the electronic display. The controller provides emission instructions to the DOAC to dynamically move an optical axis of the DOAC to align the optical axis with the determined gaze vector. The optical assembly directs the image light refracted by the DOAC to an eye box of the HMD corresponding to a location of an eye of the user. An optical error associated with the refracted image light directed to the eye box is reduced.","abstract_2":"A near-eye display device reduces vergence accommodation conflict by adjusting a tilt and\/or distance of a focal plane of a display panel based on scene depth statistics. For example, many three-dimensional (3D) scenes have closer objects in the lower visual field and farther objects in the upper visual field. Changing the tilt of the focal plane of the display panel to match average 3D screen depths reduces the discrepancy between vergence and accommodation distances. In some embodiments, the near-eye display device employs a fixed tilt of the display panel to match average scene depth statistics across a variety of scenes. In some embodiments, the near-eye display device dynamically adjusts the pitch and yaw of the focal plane of the display panel to match scene statistics for a given scene.","priority_1":"2017-06-08T00:00:00","priority_2":"2018-08-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8646641384},{"pair":"US-2017160798-A1 & US-2018343443-A1","patent_1":"US-2017160798-A1","title_1":"Focus adjustment method for a virtual reality headset ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20170160798A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A virtual reality headset displays a three-dimensional (3D) virtual scene and includes a varifocal element to dynamically adjust a focal length of an optics block included in the virtual reality headset based on a location in the virtual scene where the user is looking. The headset tracks a user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The varifocal element adjusts the focal length of the optics block so the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change. Based on the plane of focus, the virtual reality headset may provide depth cues, such as depth of field blur, to planes in the virtual scene deeper in the user's field of view than the plane of focus.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2015-12-08T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8645933631},{"pair":"US-10291855-B2 & US-2018097867-A1","patent_1":"US-10291855-B2","title_1":"Three-dimensional, 360-degree virtual reality camera live preview ","patent_2":"US-2018097867-A1","title_2":"Video compression with adaptive view-dependent lighting removal ","link_1":"https:\/\/patents.google.com\/patent\/US10291855B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180097867A1\/en","abstract_1":"A camera system provides a live preview that provides a user device a pseudo-real time depiction of what the camera assembly is imaging. The camera system captures images from a plurality of cameras. The camera system captures images from a plurality of cameras. The camera system stores the captured images in respective memory locations of a buffer. The stored captured images form a high priority data stream that generates content associated with the portion of the local area. The camera system selects, as part of a low priority data stream, one or more of the images from memory locations. The camera system encodes the selected one or more images. The camera system packetizes the encoded one or more images to form an image frame in a video feed. The camera system provides the image frame to a user device that presents the image frame as part of the video feed.","abstract_2":"A video stream of a scene for a virtual reality or augmented reality experience may be captured by one or more image capture devices. Data from the video stream may be retrieved, including base vantage data with base vantage color data depicting the scene from a base vantage location, and target vantage data with target vantage color data depicting the scene from a target vantage location. The base vantage data may be reprojected to the target vantage location to obtain reprojected target vantage data. The reprojected target vantage data may be compared with the target vantage data to obtain residual data. The residual data may be compressed by removing a subset of the residual data that is likely to be less viewer-discernable than a remainder of the residual data. A compressed video stream may be stored, including the base vantage data and the compressed residual data.","priority_1":"2017-04-14T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8645623554},{"pair":"US-2019227322-A1 & US-10546518-B2","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-01-25T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8644880898},{"pair":"US-10417784-B1 & US-9934583-B2","patent_1":"US-10417784-B1","title_1":"Boundary region glint tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10417784B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Embodiments relate to a head-mounted display including an eye tracking system. The eye tracking system includes a source assembly, a camera, and a controller. In some embodiments, the source assembly is a plurality of sources and are positioned to illuminate at least a peripheral area of a cornea of an eye. In some embodiments, the sources are masked to be a particular shape. The peripheral region is a location on the eye where the cornea transitions to the sclera. In some embodiments, the camera can detect a polarization of the reflected light, and uses polarization to disambiguate possible reflection locations. Similarly, time of flight may also be used to disambiguate potential reflection locations. The controller uses information from the detector to track positions of the user's eyes.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-06-29T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.864416097},{"pair":"US-2019384070-A1 & US-9851565-B1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8644134436},{"pair":"US-2020090406-A1 & US-2018329602-A1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2018-09-17T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8643498396},{"pair":"US-2019037137-A1 & US-10027887-B1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10027887-B1","title_2":"Dynamic 3D panoramas ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10027887B1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"The technology relates to transitioning between panoramic imagery and the imagery from which the panoramic imagery was generated. Individual images of a portion of a scene may be combined to create a panoramic image of the entire scene. The individual images may be associated with the portion of the panoramic image which they form. The full panoramic image may then be displayed. Based on user input, a portion of the panoramic image may be zoomed-in on, and the individual image associated with that portion of the panoramic image may be displayed.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-01-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8642555554},{"pair":"US-10598928-B1 & US-9671614-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-12-21T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8641843254},{"pair":"US-2019311522-A1 & US-10089796-B1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-04-05T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8641124599},{"pair":"US-10466779-B1 & US-2019037194-A1","patent_1":"US-10466779-B1","title_1":"Event camera for eye tracking ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US10466779B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"An eye tracking system includes an event camera. The event camera includes an event sensor and a controller. The event sensor includes a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes of light reflected from a user's eyes. The controller populates an event matrix based in part on data values asynchronously received from the event sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image of the user's eyes for the first time period using the event matrix and the change matrix. The eye tracking system uses the image of the user's eyes to determine eye tracking information indicating positions, orientations and\/or movement of the user's eyes.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2017-07-24T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8640897149},{"pair":"US-10210660-B2 & US-10275898-B1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-10275898-B1","title_2":"Wedge-based light-field video capture ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10275898B1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A combined video of a scene may be generated for applications such as virtual reality or augmented reality. In one method, a camera system may be oriented at a first orientation and used to capture first video of a first portion of the scene. The camera system may then be rotated to a second orientation and used to capture second video of a second portion of the scene that is offset from the first portion such that the first video and the second video each have an overlapping video portion depicting an overlapping portion of the scene in which the first portion and the second portion of the scene overlap with each other. The first and second portions may be combined together to generate the combined video, which may depict the first and second portions substantially without duplicative inclusion of the overlapping video portion.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8640425234},{"pair":"US-10330789-B1 & US-10032074-B2","patent_1":"US-10330789-B1","title_1":"Proximity sensor system with an infrared optical element ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10330789B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A proximity sensor system for detecting the presence of an object includes a light emitter configured to project light in a first direction, an optical element configured to steer the light, and a sensor. The optical element has a first surface configured to receive the light from the light emitter and a second surface that is non-parallel to the first surface. The second surface is configured to transmit a first portion of the light in a second direction and internally reflect a second portion of the light from the light emitter. The optical element includes a third surface configured to prevent internal reflection of the second portion of the light by the third surface. The sensor is configured to detect at least a portion of the first portion of the light returned from the object and transmitted through the second surface and the first surface of the optical element.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2018-04-10T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8640307442},{"pair":"US-10495798-B1 & US-2019086675-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-08-07T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8639080946},{"pair":"US-10521658-B2 & US-9851565-B1","patent_1":"US-10521658-B2","title_1":"Embedded eye tracker with dichroic mirror ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10521658B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An eyewear device has an optical element, a source, a dichroic mirror, and a camera. The optical element has a front surface, a back surface, a rim, and an angled portion of the rim. The source emits light in a first band of light and is configured to illuminate a portion of an eye of a user of the eyewear device. The dichroic mirror is arranged proximate to the angled portion of the rim, is reflective in the first band of light, is transmissive in a second band of light, and is configured to direct light in the first band reflected from the portion of the eye toward a first position. The camera is located in the first position that is located in a plane of the optical element, and the camera is configured to capture images of the light in the first band reflected by the dichroic mirror.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-07-07T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8638343701},{"pair":"US-2019311522-A1 & US-10460505-B2","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-04-05T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8638113688},{"pair":"US-10495882-B1 & US-10241329-B2","patent_1":"US-10495882-B1","title_1":"Positioning cameras in a head mounted display to capture images of portions of a face of a user ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10495882B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality (VR) or augmented reality (AR) head mounted display (HMD) includes multiple image capture devices positioned within and on the HMD to capture portions of a face of a user wearing the HMD. Multiple image capture devices are included within the HMD to capture different portions of the face of the user within the HMD, and one or more other image capture devices are positioned to capture portions of the face of the user external to the HMD. Captured images from various image capture devices may be communicated to a console or a controller that generates a graphical representation of the user's face based on the captured images.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-06-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8638038008},{"pair":"US-10066933-B2 & US-2018012371-A1","patent_1":"US-10066933-B2","title_1":"Camera depth mapping using structured light patterns ","patent_2":"US-2018012371-A1","title_2":"Image Registration with Device Data ","link_1":"https:\/\/patents.google.com\/patent\/US10066933B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180012371A1\/en","abstract_1":"The various embodiments described herein include methods and\/or systems for depth mapping. In one aspect, a method of depth mapping is performed at an apparatus including a projector, a camera, one or more processors, and memory storing one or more programs for execution by the one or more processors. The method includes identifying one or more areas of interest in a scene in accordance with variation of depth in the scene as detected at a first resolution. The method also includes, for each area of interest: (1) applying, via the projector, a respective structured-light pattern to the area of interest; (2) capturing, via the camera, an image of the area of interest with the respective structured-light pattern applied to it; and (3) creating a respective depth map of the area of interest using the captured image, the respective depth map having a higher resolution than the first resolution.","abstract_2":"Systems and methods for image registration using data collected by an electronic device, such as a mobile device, capable of simultaneous localization and mapping are provided. An electronic device, such as a mobile device, can be can be configured to collect data using a variety of sensors as the device is carried or transported through a space. The collected data can be processed and analyzed to generate a three-dimensional representation of the space and objects in the space in near real time as the device is carried through the space. The data can be used for a variety of purposes, including registering imagery for localization and image processing.","priority_1":"2015-05-04T00:00:00","priority_2":"2014-01-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8637862236},{"pair":"US-10120193-B2 & US-10095036-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-10095036-B2","title_2":"Compact near-eye display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10095036B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"Systems and methods that employ a near-eye display system including an optical assembly are described. The optical assembly may include a head-mounted display device worn by a user in which the head-mounted display device adapted to house an image projecting device and an optical assembly. The optical assembly may include, for at least one eyepiece, a first flat filter stack operable to be oriented in a first direction. and a second flat filter stack operable to be oriented in a second direction. The near-eye display system assembly may also include a display panel adapted to receive image content from the image projecting device, wherein the display panel is adapted to be oriented in the second direction.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8637492375},{"pair":"US-2019311522-A1 & US-9672656-B1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-9672656-B1","title_2":"Variable level-of-detail map rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9672656B1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"To render features on a digital map, a position and orientation of a virtual camera relative to a plane of the digital map is determined. The plane is tilted so that a plane of a viewport of the digital map is not parallel to the plane of the digital map, where the viewport delimiting a view of the digital map. Map features are selected for inclusion in the view of the digital map in accordance with the determined position and orientation of the virtual camera. A level-of-detail (LOD) is determined for each of the map features in accordance with a distance between the virtual camera and the map feature. The map features are rendered, using a rendering engine, in accordance with the determined LODs.","priority_1":"2018-04-05T00:00:00","priority_2":"2015-12-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.863738881},{"pair":"US-2017352183-A1 & US-9934583-B2","patent_1":"US-2017352183-A1","title_1":"Face and eye tracking using facial sensors within a head-mounted display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20170352183A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head mounted display (HMD) in a VR system includes sensors for tracking the eyes and face of a user wearing the HMD. The VR system records calibration attributes such as landmarks of the face of the user. Light sources illuminate portions of the user's face covered by the HMD. In conjunction, facial sensors capture facial data. The VR system analyzes the facial data to determine the orientation of planar sections of the illuminated portions of face. The VR system aggregates planar sections of the face and maps the planar sections to landmarks of the face to generate a facial animation of the user, which can also include eye orientation information. The facial animation is represented as a virtual avatar and presented to the user.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8637340613},{"pair":"US-2019311232-A1 & US-2017147859-A1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-04-10T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8636791386},{"pair":"US-10572731-B1 & US-9934583-B2","patent_1":"US-10572731-B1","title_1":"Infrared transparent backlight device for eye tracking applications ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10572731B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A backlight device provides light in a first optical band to a spatial light modulator, and is transmissive to light in a second optical band. The backlight device includes a structured dichroic reflector that is substantially reflective, and scatters light in the first optical band. The structured dichroic reflector is also substantially transparent in the second optical band, and the second optical band is different than the first optical band. The backlight device is configured to receive light in the first optical band from an illumination source. The dichroic reflector is configured to reflect light in the first optical band toward a display panel that converts the light from the backlight device to image light. The backlight device may be part of a head-mounted display.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-03-13T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8635625306},{"pair":"US-2016335773-A1 & US-2018101984-A1","patent_1":"US-2016335773-A1","title_1":"Augmenting a depth map representation with a reflectivity map representation ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20160335773A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A solution for generating a 3D representation of an object in a scene is provided. A depth map representation of the object is combined with a reflectivity map representation of the object to generate the 3D representation of the object. The 3D representation of the object provides more complete and accurate information of the object. An image of the object is illuminated by structured light and is captured. Pattern features rendered in the captured image of the object are analyzed to derive a depth map representation and a reflectivity map representation of the illuminated object. The depth map representation provides depth information while the reflectivity map representation provides surface information (e.g., reflectivity) of the illuminated object. The 3D representation of the object can be enhanced with additional illumination projected onto the object and additional images of the object.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2015-05-13T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8635555634},{"pair":"US-2019384070-A1 & US-2019086675-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8634318256},{"pair":"US-2017039906-A1 & US-9851565-B1","patent_1":"US-2017039906-A1","title_1":"Enhanced Visual Perception Through Distance-Based Ocular Projection ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170039906A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device includes a two-dimensional array of tiles. Each tile includes a two-dimensional array of pixels and an electro-optic element of a two-dimensional array of electro-optic elements. The device includes one or more processors configured to: obtain an image of an object; activate at least a subset of the two-dimensional array of tiles for outputting a collective pattern of light that includes at least a portion of the image of the object; and activate at least a subset of the two-dimensional array of electro-optic elements for projecting the collective pattern of light. At least the subset of the two-dimensional array of electro-optic elements is configured to have a focal length, that is selected based on proximity of the object in a distance model, for projecting the collective pattern of light.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-08-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8634092987},{"pair":"US-2020064641-A1 & US-2019271844-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8633758825},{"pair":"US-10154254-B2 & US-10032074-B2","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-01-17T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8633248139},{"pair":"US-10473939-B1 & US-2019271844-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8633059291},{"pair":"US-2020027261-A1 & US-2016307368-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8632637853},{"pair":"US-10248890-B2 & US-2017180705-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017180705-A1","title_2":"Capture and render of virtual reality content employing a light field camera array ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180705A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and method relating to creating a virtual reality, such as a three-dimensional virtual reality, representation of physical scene. In this aspect, such a method may comprise gathering information from an array of cameras positioned on a two-dimensional planar surface. In this particular aspect, one or more of the cameras may be positioned at a different angle relative to the two-dimensional planar surface based at least in part on a respective distance of each of the one or more cameras from a midpoint of the planar surface. Furthermore, in this general aspect the method may further comprise processing the gathered information at least in part to render a virtual reality representation of the physical scene.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8632359875},{"pair":"US-2019037137-A1 & US-2017046594-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2017046594-A1","title_2":"Managing feature data for environment mapping on an electronic device ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170046594A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"An electronic device reduces localization data based on feature characteristics identified from the data. Based on the feature characteristics, a quality value can be assigned to each identified feature, indicating the likelihood that the data associated with the feature will be useful in mapping a local environment of the electronic device. The localization data is reduced by removing data associated with features have a low quality value, and the reduced localization data is used to map the local environment of the device by locating features identified from the reduced localization data in a frame of reference for the electronic device.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-08-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8631927661},{"pair":"US-10598928-B1 & US-10545347-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2017-12-21T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8631820348},{"pair":"US-10504243-B2 & US-10591731-B2","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-10-09T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8631567709},{"pair":"US-10210660-B2 & US-2018329485-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8630802698},{"pair":"US-2019037137-A1 & US-2017076429-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2017076429-A1","title_2":"General spherical capture methods ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170076429A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Systems and methods are described for capturing spherical content. The systems and methods can include determining a region within a plurality of images captured with a plurality of cameras in which to transform two-dimensional data into three-dimensional data, calculating a depth value for a portion of pixels in the region, generating a spherical image, the spherical image including image data for the portion of pixels in the region, constructing, using the image data, a three-dimensional surface in three-dimensional space of a computer graphics object generated by an image processing system, generating, using the image data, a texture mapping to a surface of the computer graphics object, and transmitting the spherical image and the texture mapping for display in a head-mounted display device.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-09-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8630258871},{"pair":"US-2017352178-A1 & US-10032074-B2","patent_1":"US-2017352178-A1","title_1":"Facial animation using facial sensors within a head-mounted display ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20170352178A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A facial tracking system generates a virtual rendering of a portion of a face of a user wearing a head-mounted display (HMD). The facial tracking system illuminates portions of the face inside the HMD. The facial tracking system captures a plurality of facial data of the portion of the face using one or more facial sensors located inside the HMD. A plurality of planar sections of the portion of the face are identified based at least in part on the plurality of facial data. The plurality of planar sections are mapped to one or more landmarks of the face. Facial animation information is generated based at least in part on the mapping, the facial animation information describing a portion of a virtual face corresponding to the portion of the user's face.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-06-03T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8629536088},{"pair":"US-10133168-B1 & US-2019271844-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-02-01T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8628803835},{"pair":"US-2020027261-A1 & US-9665989-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9665989-B1","title_2":"Feature agnostic geometric alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9665989B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and apparatus for aligning objects are provided. A computing device can receive first and second object representations that are respectively associated with first and second surface representations. The computing device can apply an object transformation to the respective first and second object representations to modify geometric features of the respective first and second object representations based on one or more values of one or more characteristics of the respective first and second surface representation. The computing device can align the first object representation and the second object representation using an alignment of the transformed first object representation and the transformed second object representation. The computing device can provide an output based on the aligned first object representation and second object representation.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-02-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8628348967},{"pair":"US-2017287194-A1 & US-2015242414-A1","patent_1":"US-2017287194-A1","title_1":"Tracking portions of a user's face uncovered by a head mounted display worn by the user ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20170287194A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"A virtual reality system includes a head-mounted display (HMD) having one or more facial sensors and illumination sources mounted to a surface of the HMD. For example, the facial sensors are image capture devices coupled to a bottom side of the HMD. The illumination sources illuminate portions of a user's face outside of the HMD, while the facial sensors capture images of the illuminated portions of the user's face. A controller receives the captured images and generates a representation of the portions of the user's face by identifying landmarks of the user's face in the captured images and performing other suitable image processing methods. Based on the representation, the controller or another component of the virtual reality system generates content for presentation to the user.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2016-04-01T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8627316051},{"pair":"US-2020081252-A1 & US-2020041798-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-03-15T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8627301402},{"pair":"US-10317680-B1 & US-2019020869-A1","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-11-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8627250106},{"pair":"US-2019311232-A1 & US-9405977-B2","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-9405977-B2","title_2":"Using visual layers to aid in initiating a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9405977B2\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"Methods and devices for initiating a search are disclosed. In one embodiment, a method is disclosed that includes causing a camera on a wearable computing device to record video data, segmenting the video data into a number of layers and, based on the video data, detecting that a pointing object is in proximity to a first layer. The method further includes initiating a first search on the first layer. In another embodiment, a wearable computing device is disclosed that includes a camera configured to record video data, a processor, and data storage comprising instructions executable by the processor to segment the video data into a number of layers and, based on the video data, detect that a pointing object is in proximity to a first layer. The instructions are further executable by the processor to initiate a first search on the first layer.","priority_1":"2018-04-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.862690727},{"pair":"US-10598928-B1 & US-2020073123-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2017-12-21T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8626754493},{"pair":"US-10529276-B2 & US-2017212717-A1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-2017212717-A1","title_2":"Global command interface for a hybrid display ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170212717A1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A hybrid display includes a first display having a first interface and a second display having a second interface. A third interface is configured to receive a first command that includes a first value indicating a modification of pixels in the hybrid display. A finite state machine is configured to translate the first value to a second value indicating a modification of pixels in the first display and a third value indicating a modification of pixels in the second display. The first interface transmits a second command including the second value to the first interface and a third command including the third value to the second interface. The first and second commands are transmitted at times determined by a relative delay between the first display and the second display.","priority_1":"2018-01-05T00:00:00","priority_2":"2016-01-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.862583451},{"pair":"US-10474229-B1 & US-2020073123-A1","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2017-11-01T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8625431945},{"pair":"US-2019353898-A1 & US-2019271844-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-05-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8625053627},{"pair":"US-2019037137-A1 & US-10545215-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10545215-B2","title_2":"4D camera tracking and optical stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545215B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A light-field video stream may be processed to modify the camera pathway from which the light-field video stream is projected. A plurality of target pixels may be selected, in a plurality of key frames of the light-field video stream. The target pixels may be used to generate a camera pathway indicative of motion of the camera during generation of the light-field video stream. The camera pathway may be adjusted to generate an adjusted camera pathway. This may be done, for example, to carry out image stabilization. The light-field video stream may be projected to a viewpoint defined by the adjusted camera pathway to generate a projected video stream with the image stabilization.","priority_1":"2017-07-31T00:00:00","priority_2":"2017-09-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8624842479},{"pair":"US-10528128-B1 & US-2017147859-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2017-12-15T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8624764462},{"pair":"US-2017352178-A1 & US-2016057339-A1","patent_1":"US-2017352178-A1","title_1":"Facial animation using facial sensors within a head-mounted display ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20170352178A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A facial tracking system generates a virtual rendering of a portion of a face of a user wearing a head-mounted display (HMD). The facial tracking system illuminates portions of the face inside the HMD. The facial tracking system captures a plurality of facial data of the portion of the face using one or more facial sensors located inside the HMD. A plurality of planar sections of the portion of the face are identified based at least in part on the plurality of facial data. The plurality of planar sections are mapped to one or more landmarks of the face. Facial animation information is generated based at least in part on the mapping, the facial animation information describing a portion of a virtual face corresponding to the portion of the user's face.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8624064375},{"pair":"US-10495798-B1 & US-2019271844-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8624005801},{"pair":"US-10248890-B2 & US-2016005145-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2016005145-A1","title_2":"Aligning Ground Based Images and Aerial Imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160005145A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for aligning ground based images of a geographic area taken from a perspective at or near ground level and a set of aerial images taken from, for instance, an oblique perspective, are provided. More specifically, candidate aerial imagery can be identified for alignment with the ground based image. Geometric data associated with the ground based image can be obtained and used to warp the ground based image to a perspective associated with the candidate aerial imagery. One or more feature matches between the warped image and the candidate aerial imagery can then be identified using a feature matching technique. The matched features can be used to align the ground based image with the candidate aerial imagery.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8623923544},{"pair":"US-2019369390-A1 & US-2017293143-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-06-04T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8623589621},{"pair":"US-10248842-B1 & US-2019102935-A1","patent_1":"US-10248842-B1","title_1":"Face tracking using structured light within a head-mounted display ","patent_2":"US-2019102935-A1","title_2":"Shadows for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US10248842B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102935A1\/en","abstract_1":"A head mounted display (HMD) displays content to a user wearing the HMD, where the content may be based on a facial model of the user. The HMD uses an electronic display to illuminate a portion of the face of the user with. The electronic display emits a pattern of structured light and\/or monochromatic light of a given color. A camera assembly captures images of the illuminated portion of the face. A controller processes the captured images to determine depth information or color information of the face of the user. Further, the processed images may be used to update the facial model, for example, which is represented as a virtual avatar and presented to the user in a virtual reality, augmented reality, or mixed reality environment.","abstract_2":"Systems and methods for generating shadows for inserted content are provided. The inserted content may include augmented reality content that is inserted into an image of a physical space. An example includes determining a location to insert content within an image. The content may include a polygonal mesh defined in part by a skeleton that has a plurality of joints. Examples may further include selecting a plurality of selected joints form the plurality of joints. Examples may also include generating a shadow polygon based on the content and determining shadow contributions values for the plurality of selected joints for pixels of the shadow polygon. Examples may also include combining the shadow contribution values from the selected joints to generate shadow magnitude values for the pixels, rendering the shadow polygon using the shadow magnitude values, and overlaying the inserted content on the rendered shadow polygon.","priority_1":"2018-01-09T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8623549527},{"pair":"US-10210660-B2 & US-2019020869-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8623252892},{"pair":"US-10317680-B1 & US-2020049994-A1","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-2020049994-A1","title_2":"Tilted focal plane for near-eye display system ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200049994A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A near-eye display device reduces vergence accommodation conflict by adjusting a tilt and\/or distance of a focal plane of a display panel based on scene depth statistics. For example, many three-dimensional (3D) scenes have closer objects in the lower visual field and farther objects in the upper visual field. Changing the tilt of the focal plane of the display panel to match average 3D screen depths reduces the discrepancy between vergence and accommodation distances. In some embodiments, the near-eye display device employs a fixed tilt of the display panel to match average scene depth statistics across a variety of scenes. In some embodiments, the near-eye display device dynamically adjusts the pitch and yaw of the focal plane of the display panel to match scene statistics for a given scene.","priority_1":"2017-11-09T00:00:00","priority_2":"2018-08-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8623112172},{"pair":"US-2020064641-A1 & US-9709797-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8622403022},{"pair":"US-2016085301-A1 & US-2019102936-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2019102936-A1","title_2":"Lighting for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102936A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Systems and methods for lighting inserted content are provided. For example, the inserted content may include augmented reality content that is inserted into an image of a physical space. An example system and method may include determining a location within an image to insert content. For example, the image may be captured by a camera device. The example system and method may also include identifying a region of the image based on the determined location to insert the content, determining at least one lighting parameter based on the identified region, and rendering the content using the determined at least one lighting parameter.","priority_1":"2014-09-22T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8621721402},{"pair":"US-2019311232-A1 & US-2019033988-A1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-2019033988-A1","title_2":"Controller tracking for multiple degrees of freedom ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190033988A1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"A method for controller tracking with multiple degrees of freedom includes generating depth data at an electronic device based on a local environment proximate the electronic device. A set of positional data is generated for at least one spatial feature associated with a controller based on a pose of the electronic device, as determined using the depth data, relative to the at least one spatial feature associated with the controller. A set of rotational data is received that represents three degrees-of-freedom (3DoF) orientation of the controller within the local environment, and a six degrees-of-freedom (6DoF) position of the controller within the local environment is tracked based on the set of positional data and the set of rotational data.","priority_1":"2018-04-10T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8621446915},{"pair":"US-10291855-B2 & US-2016307372-A1","patent_1":"US-10291855-B2","title_1":"Three-dimensional, 360-degree virtual reality camera live preview ","patent_2":"US-2016307372-A1","title_2":"Capturing light-field volume image and video data using tiled light-field cameras ","link_1":"https:\/\/patents.google.com\/patent\/US10291855B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307372A1\/en","abstract_1":"A camera system provides a live preview that provides a user device a pseudo-real time depiction of what the camera assembly is imaging. The camera system captures images from a plurality of cameras. The camera system captures images from a plurality of cameras. The camera system stores the captured images in respective memory locations of a buffer. The stored captured images form a high priority data stream that generates content associated with the portion of the local area. The camera system selects, as part of a low priority data stream, one or more of the images from memory locations. The camera system encodes the selected one or more images. The camera system packetizes the encoded one or more images to form an image frame in a video feed. The camera system provides the image frame to a user device that presents the image frame as part of the video feed.","abstract_2":"A capture system may capture light-field data representative of an environment for use in virtual reality, augmented reality, and the like. The system may have a plurality of light-field cameras arranged to capture a light-field volume within the environment, and a processor. The processor may use the light-field volume to generate a first virtual view depicting the environment from a first virtual viewpoint. The light-field cameras may be arranged in a tiled array to define a capture surface with a ring-shaped, spherical, or other arrangement. The processor may map the pixels captured by the image sensors to light rays received in the light-field volume, and store data descriptive of the light rays in a coordinate system representative of the light-field volume.","priority_1":"2017-04-14T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8620784111},{"pair":"US-2019285891-A1 & US-2017293143-A1","patent_1":"US-2019285891-A1","title_1":"Image quality of pancharatnam berry phase components using polarizers ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190285891A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"Various embodiments set forth a near eye display (NED) that includes an electronic display configured to output image light. Further, the NED includes multiple Pancharatnam Berry Phase (PBP) optical elements that are combined with one or more circular polarizers to improve optical performance. A PBP element produces an output of three diffraction orders. Typically in an optical system that includes such a PBP element, one of the three diffraction orders is used while the other two are undesirable and preferably maintained at a relatively low intensity. A circular polarizer may reduce the intensities of the two undesired diffraction orders.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-03-15T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8620403217},{"pair":"US-2020064633-A1 & US-2020041798-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-23T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8620107699},{"pair":"US-2019361518-A1 & US-9813621-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-9813621-B2","title_2":"Omnistereo capture for mobile devices ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9813621B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"Systems and methods for capturing omnistereo content for a mobile device may include receiving an indication to capture a plurality of images of a scene, capturing the plurality of images using a camera associated with a mobile device and displaying on a screen of the mobile device and during capture, a representation of the plurality of images and presenting a composite image that includes a target capture path and an indicator that provides alignment information corresponding to a source capture path associated with the mobile device during capture of the plurality of images. The system may detect that a portion of the source capture path does not match a target capture path. The system can provide an updated indicator in the screen that may include a prompt to a user of the mobile device to adjust the mobile device to align the source capture path with the target capture path.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8617925104},{"pair":"US-2019313087-A1 & US-10546518-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8617816698},{"pair":"US-10210660-B2 & US-2017180705-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2017180705-A1","title_2":"Capture and render of virtual reality content employing a light field camera array ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180705A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"Systems and method relating to creating a virtual reality, such as a three-dimensional virtual reality, representation of physical scene. In this aspect, such a method may comprise gathering information from an array of cameras positioned on a two-dimensional planar surface. In this particular aspect, one or more of the cameras may be positioned at a different angle relative to the two-dimensional planar surface based at least in part on a respective distance of each of the one or more cameras from a midpoint of the planar surface. Furthermore, in this general aspect the method may further comprise processing the gathered information at least in part to render a virtual reality representation of the physical scene.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8616795427},{"pair":"US-2017295358-A1 & US-2017180705-A1","patent_1":"US-2017295358-A1","title_1":"Camera calibration system ","patent_2":"US-2017180705-A1","title_2":"Capture and render of virtual reality content employing a light field camera array ","link_1":"https:\/\/patents.google.com\/patent\/US20170295358A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180705A1\/en","abstract_1":"A camera calibration system jointly calibrates multiple cameras in a camera rig system. The camera calibration system obtains configuration information about the multiple cameras in the camera rig system, such as position and orientation for each camera relative to other cameras. The camera calibration system estimates calibration parameters (e.g., rotation and translation) for the multiple cameras based on the obtained configuration information. The camera calibration system receives 2D images of a test object captured by the multiple cameras and obtains known information about the test object such as location, size, texture and detailed information of visually distinguishable points of the test object. The camera calibration system then generates a 3D model of the test object based on the received 2D images and the estimated calibration parameters. The generated 3D model is evaluated in comparison with the actual test object to determine a calibration error. The calibration parameters for the cameras are updated to reduce the calibration error for the multiple cameras.","abstract_2":"Systems and method relating to creating a virtual reality, such as a three-dimensional virtual reality, representation of physical scene. In this aspect, such a method may comprise gathering information from an array of cameras positioned on a two-dimensional planar surface. In this particular aspect, one or more of the cameras may be positioned at a different angle relative to the two-dimensional planar surface based at least in part on a respective distance of each of the one or more cameras from a midpoint of the planar surface. Furthermore, in this general aspect the method may further comprise processing the gathered information at least in part to render a virtual reality representation of the physical scene.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8616630505},{"pair":"US-9984507-B2 & US-9934583-B2","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2015-11-19T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8616353479},{"pair":"US-2018173303-A1 & US-9298256-B1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-9298256-B1","title_2":"Visual completion ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9298256B1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Methods and devices for initiating, updating, and displaying the results of a search of an object-model database are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device and, based on the video data, detecting a movement corresponding to a selection of an object. The method further includes, before the movement is complete, initiating a search on the object of an object-model database. The method still further includes, during the movement, periodically updating the search and causing the wearable computing device to overlay the object with object-models from the database corresponding to results of the search.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8616151448},{"pair":"US-2019311232-A1 & US-2019392630-A1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-2019392630-A1","title_2":"Automated understanding of three dimensional (3d) scenes for augmented reality applications ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190392630A1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"An electronic device is configured to performing a three-dimensional (3D) scan of an interior space. In some cases, the electronic device acquires information and depth measurements relative to the electronic device. The electronic device acquires voxels in a 3D grid that is generated from the 3D scan. The voxels represent portions of the volume of the interior space. The electronic device determines a trajectory and poses of the electronic device concurrently with performing the 3D scan of the interior space. The electronic device labels voxels representing objects in the interior space based on the trajectory and the poses. In some cases, the electronic device uses queries to perform spatial reasoning at an object level of granularity, positions, overlays, or blends virtual objects into an augmented reality representation of the interior space or modifies positions or orientations of the objects by applying a transformation to corresponding connected components.","priority_1":"2018-04-10T00:00:00","priority_2":"2018-06-20T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8616116955},{"pair":"US-2019313087-A1 & US-2017123207-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2017123207-A1","title_2":"Free space optical combiner with prescription integration ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123207A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A prescriptive see-through eyepiece includes a meniscus lens body and an optical combiner. The meniscus lens body has an external scene side with a convex curvature and an eye-ward side with a concave curvature. The optical combiner is disposed within the meniscus lens body to combine image light incident through the eye-ward side with external scene light incident through the external scene side into a combined image. The optical combiner is partially reflective and imparts substantially no lensing power to the external scene light passing through. The optical combiner along with the concave curvature of the eye-ward side are configured to impart prescriptive lensing to the image light while the convex curvature of the external scene side and the concave curvature of the eye-ward side are configured to impart the prescriptive lensing to the external scene light.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-10-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8615966007},{"pair":"US-2019311522-A1 & US-2017032568-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8615721697},{"pair":"US-2017352183-A1 & US-2016057339-A1","patent_1":"US-2017352183-A1","title_1":"Face and eye tracking using facial sensors within a head-mounted display ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20170352183A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A head mounted display (HMD) in a VR system includes sensors for tracking the eyes and face of a user wearing the HMD. The VR system records calibration attributes such as landmarks of the face of the user. Light sources illuminate portions of the user's face covered by the HMD. In conjunction, facial sensors capture facial data. The VR system analyzes the facial data to determine the orientation of planar sections of the illuminated portions of face. The VR system aggregates planar sections of the face and maps the planar sections to landmarks of the face to generate a facial animation of the user, which can also include eye orientation information. The facial animation is represented as a virtual avatar and presented to the user.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8615685489},{"pair":"US-10460500-B1 & US-10460505-B2","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-04-13T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8615634272},{"pair":"US-10528128-B1 & US-10032074-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-12-15T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8615448492},{"pair":"US-9984507-B2 & US-9536354-B2","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2015-11-19T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8615318668},{"pair":"US-2019311232-A1 & US-9934583-B2","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-04-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8614928079},{"pair":"US-10489648-B2 & US-2017147859-A1","patent_1":"US-10489648-B2","title_1":"Eye tracking using time multiplexing ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10489648B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system implements time-multiplexing by configuring a source assembly comprising a plurality of light sources to project at least a first light pattern towards the user's eye over a first time period, and a second light pattern towards the user's eye over a second time period in accordance with a set of emission instructions. A camera assembly is configured to capture images of the user's eye during the first and second time periods in accordance with a set of imaging instructions, the captured images containing one or more glints corresponding to reflections of the first or second light patterns on the cornea of the user's eye. The location of the glints may be used to determine a shape or orientation of the eye.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2017-08-04T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8614911378},{"pair":"US-10598938-B1 & US-9870049-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2018-11-09T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8614746044},{"pair":"US-10520742-B1 & US-9934583-B2","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-02-13T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8614636501},{"pair":"US-2019197667-A1 & US-2016005145-A1","patent_1":"US-2019197667-A1","title_1":"Computing high-resolution depth images using machine learning techniques ","patent_2":"US-2016005145-A1","title_2":"Aligning Ground Based Images and Aerial Imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20190197667A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160005145A1\/en","abstract_1":"A system trains a machine learning model to generate a high-resolution depth image. During a training phase, the system generates an accurate three dimensional reconstruction of a training scene such that the machine learning model is iteratively trained to minimize an error between the higher resolution depth image and the depth information in the accurate three dimensional reconstruction. During a real-time phase, the system applies the trained machine learning model to images captured from a scene of interest and generates a higher resolution depth image with higher accuracy. Thus, the higher resolution depth image can be subsequently used to solve computer vision problems.","abstract_2":"Systems and methods for aligning ground based images of a geographic area taken from a perspective at or near ground level and a set of aerial images taken from, for instance, an oblique perspective, are provided. More specifically, candidate aerial imagery can be identified for alignment with the ground based image. Geometric data associated with the ground based image can be obtained and used to warp the ground based image to a perspective associated with the candidate aerial imagery. One or more feature matches between the warped image and the candidate aerial imagery can then be identified using a feature matching technique. The matched features can be used to align the ground based image with the candidate aerial imagery.","priority_1":"2017-12-26T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8614411758},{"pair":"US-2019197667-A1 & US-2019392630-A1","patent_1":"US-2019197667-A1","title_1":"Computing high-resolution depth images using machine learning techniques ","patent_2":"US-2019392630-A1","title_2":"Automated understanding of three dimensional (3d) scenes for augmented reality applications ","link_1":"https:\/\/patents.google.com\/patent\/US20190197667A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190392630A1\/en","abstract_1":"A system trains a machine learning model to generate a high-resolution depth image. During a training phase, the system generates an accurate three dimensional reconstruction of a training scene such that the machine learning model is iteratively trained to minimize an error between the higher resolution depth image and the depth information in the accurate three dimensional reconstruction. During a real-time phase, the system applies the trained machine learning model to images captured from a scene of interest and generates a higher resolution depth image with higher accuracy. Thus, the higher resolution depth image can be subsequently used to solve computer vision problems.","abstract_2":"An electronic device is configured to performing a three-dimensional (3D) scan of an interior space. In some cases, the electronic device acquires information and depth measurements relative to the electronic device. The electronic device acquires voxels in a 3D grid that is generated from the 3D scan. The voxels represent portions of the volume of the interior space. The electronic device determines a trajectory and poses of the electronic device concurrently with performing the 3D scan of the interior space. The electronic device labels voxels representing objects in the interior space based on the trajectory and the poses. In some cases, the electronic device uses queries to perform spatial reasoning at an object level of granularity, positions, overlays, or blends virtual objects into an augmented reality representation of the interior space or modifies positions or orientations of the objects by applying a transformation to corresponding connected components.","priority_1":"2017-12-26T00:00:00","priority_2":"2018-06-20T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8613977931},{"pair":"US-10338379-B1 & US-10546518-B2","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8613945359},{"pair":"US-9984507-B2 & US-2020049994-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2020049994-A1","title_2":"Tilted focal plane for near-eye display system ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200049994A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A near-eye display device reduces vergence accommodation conflict by adjusting a tilt and\/or distance of a focal plane of a display panel based on scene depth statistics. For example, many three-dimensional (3D) scenes have closer objects in the lower visual field and farther objects in the upper visual field. Changing the tilt of the focal plane of the display panel to match average 3D screen depths reduces the discrepancy between vergence and accommodation distances. In some embodiments, the near-eye display device employs a fixed tilt of the display panel to match average scene depth statistics across a variety of scenes. In some embodiments, the near-eye display device dynamically adjusts the pitch and yaw of the focal plane of the display panel to match scene statistics for a given scene.","priority_1":"2015-11-19T00:00:00","priority_2":"2018-08-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.86134396},{"pair":"US-10598938-B1 & US-2020041798-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-11-09T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8612809145},{"pair":"US-10248890-B2 & US-9736451-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9736451-B1","title_2":"Efficient dense stereo computation ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9736451B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Example embodiments may allow for the efficient determination of disparity information for a stereo image pair by embedding pixels of the image pair in a multidimensional dimensional vertex space. Regularly-spaced vertices in the vertex space are associated with pixels of the stereo image pair and disparity loss functions are determined for each of the vertices based on disparity loss functions of the associated pixels. The determined vertex-disparity loss functions can be used to determine vertex disparity values for each of the vertices. Disparity values for pixels of the stereo image pair can be determined based on determined vertex disparity values for respective one or more vertices associated with each of the pixels. The determined pixel disparity values can be used to enable depth-selective image processing, determination of pixel depth maps, mapping and\/or navigation of an environment, human-computer interfacing, biometrics, augmented reality, or other applications.","priority_1":"2017-04-13T00:00:00","priority_2":"2014-09-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8612785523},{"pair":"US-10599215-B2 & US-10241329-B2","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-04-26T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.861261886},{"pair":"US-10379359-B2 & US-9851565-B1","patent_1":"US-10379359-B2","title_1":"Fresnel lens with dynamic draft for reduced optical artifacts ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10379359B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The draft facet is characterized by a draft angle which is based on a distance of the respective Fresnel structure from a reference axis of the lens. The draft angle is between a first angle and a second angle, the first angle corresponding to a direction of a ray, in a first medium, transmitted from a reference off-axis position through the respective Fresnel structure toward a reference pupil. The second angle corresponding to a direction of the ray, in the optically transparent substrate, transmitted from the reference off-axis position through the respective Fresnel structure toward the reference pupil.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-09-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8612599733},{"pair":"US-10338379-B1 & US-9934583-B2","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-10-09T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8611845742},{"pair":"US-10038894-B1 & US-2017358092-A1","patent_1":"US-10038894-B1","title_1":"Three-dimensional scene reconstruction from set of two dimensional images for consumption in virtual reality ","patent_2":"US-2017358092-A1","title_2":"Multi-view scene segmentation and propagation ","link_1":"https:\/\/patents.google.com\/patent\/US10038894B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170358092A1\/en","abstract_1":"To enable better sharing and preservation of immersive experiences, a graphics system reconstructs a three-dimensional scene from a set of images of the scene taken from different vantage points. The system processes each image to extract depth information therefrom and then stitches the images (both color and depth information) into a multi-layered panorama that includes at least front and back surface layers. The front and back surface layers are then merged to remove redundancies and create connections between neighboring pixels that are likely to represent the same object, while removing connections between neighboring pixels that are not. The resulting layered panorama with depth information can be rendered using a virtual reality (VR) system, a mobile device, or other computing and display platforms using standard rendering techniques, to enable three-dimensional viewing of the scene.","abstract_2":"A depth-based effect may be applied to a multi-view video stream to generate a modified multi-view video stream. User input may designate a boundary between a foreground region and a background region, at a different depth from the foreground region, of a reference image of the video stream. Based on the user input, a reference mask may be generated to indicate the foreground region and the background region. The reference mask may be used to generate one or more other masks that indicate the foreground and background regions for one or more different images, from different frames and\/or different views from the reference image. The reference mask and other mask(s) may be used to apply the effect to the multi-view video stream to generate the modified multi-view video stream.","priority_1":"2017-01-17T00:00:00","priority_2":"2016-06-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8611677558},{"pair":"US-10495798-B1 & US-9671614-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-07T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8610852264},{"pair":"US-2017352183-A1 & US-10032074-B2","patent_1":"US-2017352183-A1","title_1":"Face and eye tracking using facial sensors within a head-mounted display ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20170352183A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head mounted display (HMD) in a VR system includes sensors for tracking the eyes and face of a user wearing the HMD. The VR system records calibration attributes such as landmarks of the face of the user. Light sources illuminate portions of the user's face covered by the HMD. In conjunction, facial sensors capture facial data. The VR system analyzes the facial data to determine the orientation of planar sections of the illuminated portions of face. The VR system aggregates planar sections of the face and maps the planar sections to landmarks of the face to generate a facial animation of the user, which can also include eye orientation information. The facial animation is represented as a virtual avatar and presented to the user.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-06-03T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8610255783},{"pair":"US-2019353898-A1 & US-9285877-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9285877-B2","title_2":"Heads-up display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9285877B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"Embodiments of an apparatus comprising a light guide including a proximal end, a distal end, a display positioned near the proximal end, an eye-measurement camera positioned at or near the proximal end to image eye-measurement radiation, a proximal optical element positioned in the light guide near the proximal end and a distal optical element positioned in the light guide near the distal end. The proximal optical element is optically coupled to the display, the eye-measurement camera and the distal optical element and the distal optical element is optically coupled to the proximal optical element, the ambient input region and the input\/output region. Other embodiments are disclosed and claimed.","priority_1":"2018-05-18T00:00:00","priority_2":"2012-02-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8608674325},{"pair":"US-2020064633-A1 & US-2016240013-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-08-23T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8608595051},{"pair":"US-2019313087-A1 & US-10241329-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8608496796},{"pair":"US-10425762-B1 & US-9560467-B2","patent_1":"US-10425762-B1","title_1":"Head-related impulse responses for area sound sources located in the near field ","patent_2":"US-9560467-B2","title_2":"3D immersive spatial audio systems and methods ","link_1":"https:\/\/patents.google.com\/patent\/US10425762B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9560467B2\/en","abstract_1":"A virtual-reality device displays a virtual scene. The scene includes an area sound source, which is located within a predefined near-field distance from the listener (e.g., less than one meter). The device selects sample point sources from the area source and projects audio data from each sample onto a virtual sphere surrounding the listener. The virtual sphere comprises multiple concentric spherical shells that extend from the listener. The device determines, for each sample, energy contributions of the sample to two respective successive shells that enclose the sample. The device determines a head-related impulse response (HRIR) for each shell by combining energy contributions that are associated with the respective shell. The device determines an overall HRIR for the virtual scene by combining the determined HRIRs for the shells. The device convolves the audio data with the overall HRIR and transmits the convolved audio data to sound-producing devices of the virtual-reality device.","abstract_2":"Provided are methods and systems for delivering three-dimensional, immersive spatial audio to a user over a headphone, where the headphone includes one or more virtual speaker conditions. The methods and systems recreate a naturally sounding sound field at the user's ears, including cues for elevation and depth perception. Among numerous other potential uses and applications, the methods and systems of the present disclosure may be implemented for virtual reality applications.","priority_1":"2018-10-19T00:00:00","priority_2":"2014-11-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8608236157},{"pair":"US-10359845-B1 & US-10591731-B2","patent_1":"US-10359845-B1","title_1":"Display assembly using dynamic liquid crystal array ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10359845B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A head-mounted display includes an electronic display, a liquid crystal (LC) array with LC cells forming a dynamic lens array, an optical assembly, an eye tracker, and a controller. The LC array refracts image light emitted from the electronic display. The LC array includes a gaze region with a subset of the LC cells forming a portion of the dynamic lens array having a lens density different than that associated with remaining portions of the LC cells outside the gaze region. The eye tracker tracks a gaze location corresponding to a foveal region of a user's eye. The controller generates emission instructions and provides the emission instructions to the LC array to change location of the gaze region in the LC array based on the tracked gaze location. The optical assembly directs portions of image light refracted by the gaze region toward the foveal region of the user's eye.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2018-05-01T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8607998113},{"pair":"US-2019313087-A1 & US-2016198949-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2016198949-A1","title_2":"Hybrid lens system for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160198949A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A hybrid optical system for a head wearable display includes a central vision lens and a peripheral vision lens. The central vision lens approximately aligns with a cornea of a user to provide lensing to a central vision of the user when the user is looking straight forward. The peripheral vision lens, different than the central vision lens, provides lensing to an extended field of view that extends angularly beyond the central vision lensed by the central vision lens when the user is looking straight forward. The peripheral vision lens is disposed around the central vision lens. The peripheral vision lens has a co-incident optical center with the central vision lens but the central vision lens is offset from a physical center of the peripheral vision lens.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-01-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8607917521},{"pair":"US-10248890-B2 & US-10460505-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8606411082},{"pair":"US-10495798-B1 & US-10545347-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-08-07T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8606118218},{"pair":"US-10506217-B2 & US-2016328882-A1","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-2016328882-A1","title_2":"Pass-through display of captured imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160328882A1\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"A method includes sequentially outputting from an imaging sensor each pixel row of a set of pixel rows of an image captured by the imaging sensor. The method further includes displaying, at a display device, a pixel row representative of a first pixel row of the captured image prior to a second pixel row of the captured image being output by the imaging sensor. An apparatus includes an imaging sensor having a first lens that imparts a first type of spatial distortion, a display device coupled to the imaging sensor, the display to display imagery captured by the imaging sensor with the first spatial distortion, and an eyepiece lens aligned with the display, the eyepiece lens imparting a second type of spatial distortion that compensates for the first type of spatial distortion.","priority_1":"2017-10-09T00:00:00","priority_2":"2015-05-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8605987796},{"pair":"US-10520742-B1 & US-2017147859-A1","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2017-02-13T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8605907348},{"pair":"US-2017295354-A1 & US-9736451-B1","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-9736451-B1","title_2":"Efficient dense stereo computation ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9736451B1\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"Example embodiments may allow for the efficient determination of disparity information for a stereo image pair by embedding pixels of the image pair in a multidimensional dimensional vertex space. Regularly-spaced vertices in the vertex space are associated with pixels of the stereo image pair and disparity loss functions are determined for each of the vertices based on disparity loss functions of the associated pixels. The determined vertex-disparity loss functions can be used to determine vertex disparity values for each of the vertices. Disparity values for pixels of the stereo image pair can be determined based on determined vertex disparity values for respective one or more vertices associated with each of the pixels. The determined pixel disparity values can be used to enable depth-selective image processing, determination of pixel depth maps, mapping and\/or navigation of an environment, human-computer interfacing, biometrics, augmented reality, or other applications.","priority_1":"2016-04-06T00:00:00","priority_2":"2014-09-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8605890242},{"pair":"US-2019227322-A1 & US-2016240013-A1","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-01-25T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8605301069},{"pair":"US-10466496-B2 & US-10545347-B2","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2017-12-06T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8605065903},{"pair":"US-10509228-B1 & US-2019020869-A1","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-12-20T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.860475209},{"pair":"US-9910282-B2 & US-9851565-B1","patent_1":"US-9910282-B2","title_1":"Increasing field of view of head-mounted display using a mirror ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US9910282B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) (e.g., VR headset or AR headset) displays a 3D virtual scene and includes a mirror to increase a field of view (FOV). The HMD includes an electronic display that further includes a primary display and an extended display, where the content displayed on the primary display is presented to the user's eye at an exit pupil through a lens and content displayed on the extended display is presented at the exit pupil through reflections of the mirror. The mirror is positioned between the exit pupil and the electronic display such that the mirror reflects light originating from the extended display and provides the reflected light to the exit pupil to increase the FOV. The combination of the content viewed through the lens and that of the reflected light of the extended display results in an FOV larger than when the content is viewed only through the lens.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-12-28T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8604610399},{"pair":"US-2019353906-A1 & US-9798147-B1","patent_1":"US-2019353906-A1","title_1":"Optical Assembly with Polarization Volume Holographic Element ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20190353906A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"An optical assembly includes a partial reflector that is optically coupled with a first polarization volume holographic element. The partial reflector is capable of receiving first light having a first circular polarization and transmitting a portion of the first light having a first circular polarization. The first polarization volume holographic element is configured to receive the first portion of the first light and reflect the first portion of the first light as second light having the first circular polarization. The partial reflector is capable of receiving the second light and reflecting a first portion of the second light as third light having a second circular polarization opposite to the first polarization. The first polarization volume holographic element is configured to receive the third light having the second circular polarization and transmit the third light having the second circular polarization.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2018-05-18T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8603366322},{"pair":"US-2019086669-A1 & US-10591731-B2","patent_1":"US-2019086669-A1","title_1":"Multiple layer projector for a head-mounted display ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20190086669A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A head-mounted display (HMD) including multiple layered display panels. The HMD may include a first display panel to display a first image, and a second display panel positioned in front of the first display panel to at least partially overlap with the first display panel. The second display panel may include a display substrate, and a plurality of light emitting diodes (LEDs) positioned on the display substrate. The plurality of LEDs display a second image. The display substrate and the plurality of LEDs are transparent for the first image to be visible through the second display panel.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-09-20T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8603331373},{"pair":"US-10600352-B1 & US-10133074-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-10133074-B2","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10133074B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"Systems and methods are described for receiving image content from an emissive display toward a first filter stack, the first filter stack adapted to be oriented in a first direction from an optical axis of a first lens, and toward the first lens, transmitting the image content through a curved lens parallel to the optical axis of the first lens, wherein the curved lens transmits a portion of the image content to at least one optical element and to a second filter stack, the second filter stack being adapted to be oriented in a second direction from the optical axis of the first lens, and receiving the portion from the second filter stack and providing at least some of the portion to the first lens for viewing by a user.","priority_1":"2018-12-04T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8603209023},{"pair":"US-2019369718-A1 & US-10241329-B2","patent_1":"US-2019369718-A1","title_1":"Determining fixation of a user's eyes from images of portions of the user's face enclosed by a head mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190369718A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A virtual reality (VR) or augmented reality (AR) head mounted display (HMD) includes multiple image capture devices positioned within the HMD to capture portions of a face of a user wearing the HMD. Images from an image capture device include a user's eye, while additional images from another image capture device include the user's other eye. The images and the additional images are provided to a controller, which applies a trained model to the images and the additional images to generate a vector identifying a position of the user's head and positions of the user's eye and fixation of each of the user's eyes. Additionally, illumination sources illuminating portions of the user's face include in the images and in the additional images are configured when the user wears the HMD to prevent over-saturation or under-saturation of the images and the additional images.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-06-01T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8603183572},{"pair":"US-10120193-B2 & US-10133074-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-10133074-B2","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10133074B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"Systems and methods are described for receiving image content from an emissive display toward a first filter stack, the first filter stack adapted to be oriented in a first direction from an optical axis of a first lens, and toward the first lens, transmitting the image content through a curved lens parallel to the optical axis of the first lens, wherein the curved lens transmits a portion of the image content to at least one optical element and to a second filter stack, the second filter stack being adapted to be oriented in a second direction from the optical axis of the first lens, and receiving the portion from the second filter stack and providing at least some of the portion to the first lens for viewing by a user.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8603123405},{"pair":"US-2019361518-A1 & US-10102666-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10102666-B2","title_2":"Electronic display stabilization for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10102666B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A method includes determining, at a first time, a representation of a first head rotation of a head mounted display (HMD) using a first inertial sensor sample stream and rendering, at an application processor, a texture based on the first head rotation. The method further includes determining, at a second time subsequent to the first time, a representation of a second head rotation of the HMD using a second inertial sensor sample stream having a higher sampling rate than the first inertial sensor sample stream, and generating, at a compositor, a rotated representation of the texture based on a difference between the first head rotation and the second head rotation.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-06-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8603028439},{"pair":"US-2018284884-A1 & US-10546518-B2","patent_1":"US-2018284884-A1","title_1":"Waveguide display with spatially switchable grating ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180284884A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near-eye-display (NED) includes an eye tracking system and a waveguide display. The eye tracking system tracks locations based on a location of the user's eyes. The waveguide display includes a light source, an output waveguide and a controller. The output waveguide includes a dynamic output grating that outputs an expanded image light to the tracked eyebox locations. The decoupling grating is a 2D array of spatially switchable liquid crystal (LC) pixels including an active subset of LC pixels emitting light to regions within the tracked eyebox locations. The decoupling grating dynamically out-couples the expanded image light to the tracked location based on switching instructions generated and provided by the controller.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-04-03T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8602345246},{"pair":"US-2017293146-A1 & US-9934583-B2","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-04-07T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8602094778},{"pair":"US-2019212482-A1 & US-10241329-B2","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-01-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8602070908},{"pair":"US-2019101767-A1 & US-10162180-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-10162180-B2","title_2":"Efficient thin curved eyepiece for see-through head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10162180B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, an input coupler, and an output coupler. The curved lightguide component guides display light received at an input region peripherally located from a viewing region and emits the display light along an eye-ward direction in the viewing region. The curved lightguide component includes an eye-ward facing surface that is concave and a world facing surface that is convex. The input coupler is disposed at the input region to couple the display light into the curved lightguide component. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is partially transmissive to ambient light incident through the world facing surface. The display light is guided between the input coupler and the output coupler entirely by total internal reflection.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-06-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8601952373},{"pair":"US-10248890-B2 & US-9704282-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8601906921},{"pair":"US-2019318678-A1 & US-10310314-B2","patent_1":"US-2019318678-A1","title_1":"Translating color selector layer for display resolution enhancement ","patent_2":"US-10310314-B2","title_2":"Bright edge display for seamless tileable display panels ","link_1":"https:\/\/patents.google.com\/patent\/US20190318678A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10310314B2\/en","abstract_1":"A display device may include (1) a light-emitting layer having a plurality of light-emitting regions, with at least some of the light-emitting regions operable to emit a varying, controlled intensity of light at a fixed location, (2) a color selector layer disposed over the plurality of light-emitting regions, the color selector layer having at least one group of color selectors, and (3) an actuator operable to move the color selector layer relative to the light-emitting layer. The movement of the color selector layer may result in each color selector of the at least one group of color selectors passing each fixed location. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A display panel includes an array of display pixels to output an image. The array of display pixels includes a central pixel region and a perimeter pixel region. The central pixel region includes central pixel units each having three different colored sub-pixels. The different colored sub-pixels of the central pixel units are organized according to a central layout pattern that repeats across the central pixel region. The perimeter pixel region is disposed along a perimeter of the central pixel region and includes perimeter pixel units that increase a brightness of the image along edges of the central pixel region to mask gaps around the array of display pixels when tiling the array of display pixels with other arrays of display pixels.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-08-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8601262467},{"pair":"US-10133168-B1 & US-2019025602-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-02-01T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8601043506},{"pair":"US-10460500-B1 & US-9704282-B1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-04-13T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8600196545},{"pair":"US-2019311232-A1 & US-10591731-B2","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2018-04-10T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.85999309},{"pair":"US-2016085301-A1 & US-2017078651-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2017078651-A1","title_2":"Stereo rendering system ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170078651A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A method includes receiving an indication of a field of view associated with a three-dimensional (3D) image being displayed on a head mount display (HMD), receiving an indication of a depth of view associated with the 3D image being displayed on the HMD, selecting a first right eye image and a second right eye image based on the field of view, combining the first right eye image and the second right eye image based on the depth of view, selecting a first left eye image and a second left eye image based on the field of view, and combining the first left eye image and the second left eye image based on the depth of view.","priority_1":"2014-09-22T00:00:00","priority_2":"2015-09-10T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.859970482},{"pair":"US-10600352-B1 & US-9671614-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-12-04T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8599281596},{"pair":"US-2019037137-A1 & US-10127712-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10127712-B2","title_2":"Immersive content framing ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10127712B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A virtual view of a scene may be generated through the use of various systems and methods. In one exemplary method, from a tiled array of cameras, image data may be received. The image data may depict a capture volume comprising a scene volume in which a scene is located. A viewing volume may be defined. A virtual occluder may be positioned at least partially within the capture volume such that a virtual window of the virtual occluder is between the viewing volume and the scene. A virtual viewpoint within the viewing volume may be selected. A virtual view may be generated to depict the scene from the virtual viewpoint.","priority_1":"2017-07-31T00:00:00","priority_2":"2016-07-08T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8598131886},{"pair":"US-2018172995-A1 & US-2020041798-A1","patent_1":"US-2018172995-A1","title_1":"Waveguide display with a small form factor, a large field of view, and a large eyebox ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20180172995A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A waveguide display is used for presenting media to a user. The waveguide display includes light source assembly, an output waveguide, and a controller. The light source assembly includes one or more projectors projecting an image light at least along one dimension. The output waveguide includes a waveguide body with two opposite surfaces. The output waveguide includes a first grating receiving an image light propagating along an input wave vector, a second grating, and a third grating positioned opposite to the second grating and outputting an expanded image light with wave vectors matching the input wave vector. The controller controls the scanning of the one or more source assemblies to form a two-dimensional image.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-12-20T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597875243},{"pair":"US-2020027261-A1 & US-2018061119-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597558841},{"pair":"US-2019037137-A1 & US-2019182468-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2019182468-A1","title_2":"Methods, systems, and media for generating and rendering immersive video content ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190182468A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Methods, systems, and media for generating and rendering immersive video content are provided. In some embodiments, the method comprises: receiving information indicating positions of cameras in a plurality of cameras; generating a mesh on which video content is to be projected based on the positions of the cameras in the plurality of cameras, wherein the mesh is comprised of a portion of a faceted cylinder, and wherein the faceted cylinder has a plurality of facets each corresponding to a projection from a camera in the plurality of cameras; receiving video content corresponding to the plurality of cameras; and transmitting the video content and the generated mesh to a user device in response to receiving a request for the video content from the user device.","priority_1":"2017-07-31T00:00:00","priority_2":"2017-12-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597487165},{"pair":"US-2017358136-A1 & US-2018239141-A1","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2016-06-10T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597480093},{"pair":"US-2017371159-A1 & US-2019020869-A1","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-06-28T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597185333},{"pair":"US-10598938-B1 & US-2018136468-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2018136468-A1","title_2":"Freeform projected display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180136468A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A freeform projection display includes an optical emitter configured to output one or more wavelengths of light and an optical diffuser optically coupled to receive and disperse the one or more wavelengths of light from the optical emitter, wherein the optical diffuser has at least one radius of curvature. The freeform projection display further includes a refractive lens optically coupled to receive the one or more wavelengths of light from the optical diffuser and to project the one or more wavelengths of light. The freeform projection display further may include a light modulator disposed between the optical emitter and the optical diffuser, wherein the light modulator oscillates to project the image on the optical diffuser. An illuminated area of the optical diffuser is dimensioned so that the image produced by the light modulator fills an aperture of the refractive lens.","priority_1":"2018-11-09T00:00:00","priority_2":"2016-11-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597038716},{"pair":"US-10248890-B2 & US-9916679-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9916679-B2","title_2":"Deepstereo: learning to predict new views from real world imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9916679B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A system and method of deep learning using deep networks to predict new views from existing images may generate and improve models and representations from large-scale data. This system and method of deep learning may employ a deep architecture performing new view synthesis directly from pixels, trained from large numbers of posed image sets. A system employing this type of deep network may produce pixels of an unseen view based on pixels of neighboring views, lending itself to applications in graphics generation.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-05-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597007932},{"pair":"US-2019361518-A1 & US-10553016-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10553016-B2","title_2":"Phase aligned foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10553016B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A display device, such as a head mounted device (HMD), displays a virtual scene. The display device includes a motion tracker for detecting rotation and\/or translation of the display device. The display device also includes a processor that is configured to determine, in response to the detected, an orientation of the display device relative to a plurality of world-aligned viewing frustums that are stationary relative to the virtual scene. The processor is also configured to identify a set of those world-aligned viewing frustums that overlap with an output field of view. The processor is further configured to render pixels of the set of those world-aligned viewing frustums that overlap with an output field of view and upsample the rendered pixels to generate values of display pixels for presentation by the display device.","priority_1":"2018-05-22T00:00:00","priority_2":"2017-11-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8596714497},{"pair":"US-10506217-B2 & US-2018101984-A1","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2017-10-09T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8596697968},{"pair":"US-2019313087-A1 & US-10302945-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10302945-B2","title_2":"Near-eye display with stacked lightguides ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10302945B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Embodiments are described of an apparatus including an eyepiece having a front surface, a back surface spaced apart from the front surface, and an edge forming a perimeter of the eyepiece. The eyepiece includes an angled surface to direct light eye-measurement light reflected from an eye into the eyepiece and to direct display light out of the eyepiece to the eye. A first waveguide is formed in the eyepiece and extending from the angled surface to the edge, the first waveguide being optically coupled to a first portion of the angled surface having a first surface treatment. And a second waveguide is formed in the eyepiece and extending from the angled surface to the edge, the second waveguide being optically coupled to a second portion of the angled surface having a second surface treatment.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-08-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8596215283},{"pair":"US-2016085301-A1 & US-2016057339-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8596204514},{"pair":"US-10528128-B1 & US-10241329-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-12-15T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8596133602},{"pair":"US-2019361518-A1 & US-2017148206-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2017148206-A1","title_2":"Electronic display stabilization using pixel velocities ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170148206A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A system includes a head mounted display (HMD) device comprising at least one display and at least one sensor to provide pose information for the HMD device. The system further includes a sensor integrator module coupled to the at least one sensor, the sensor integrator module to determine a motion vector for the HMD device based on the pose information, and an application processor to render a first texture based on pose of the HMD device determined from the pose information. The system further includes a motion analysis module to determine a first velocity field having a pixel velocity for at least a subset of pixels of the first texture, and a compositor to render a second texture based on the first texture, the first velocity field and the motion vector for the HMD, and to provide the second texture to the display of the HMD device.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-11-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595805674},{"pair":"US-10473939-B1 & US-9671614-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-01-08T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595536003},{"pair":"US-10248890-B2 & US-10545215-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10545215-B2","title_2":"4D camera tracking and optical stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545215B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A light-field video stream may be processed to modify the camera pathway from which the light-field video stream is projected. A plurality of target pixels may be selected, in a plurality of key frames of the light-field video stream. The target pixels may be used to generate a camera pathway indicative of motion of the camera during generation of the light-field video stream. The camera pathway may be adjusted to generate an adjusted camera pathway. This may be done, for example, to carry out image stabilization. The light-field video stream may be projected to a viewpoint defined by the adjusted camera pathway to generate a projected video stream with the image stabilization.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-09-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595501461},{"pair":"US-2017293146-A1 & US-2018343443-A1","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2016-04-07T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595247117},{"pair":"US-10473939-B1 & US-9946074-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-01-08T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.859522026},{"pair":"US-2020018962-A1 & US-9798147-B1","patent_1":"US-2020018962-A1","title_1":"Adaptive lenses for near-eye displays ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20200018962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"A lens assembly includes two or more polarization-dependent lenses sensitive to either linear or circular polarization, and at least one switchable polarization converter. The switchable polarization converter is configured to rotate linearly polarized light or change the handedness of circularly polarized light when switched on. The lens assembly is configurable to project displayed images on two or more different image planes. For example, when the switchable polarization converter is switched off, the lens assembly projects a displayed image on a first image plane. When the switchable polarization converter is switched on, the lens assembly projects a displayed image on a second image plane different from the first image plane.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2018-07-11T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595191307},{"pair":"US-10598942-B1 & US-2020041798-A1","patent_1":"US-10598942-B1","title_1":"Mounting assembly with reworkable active alignment ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598942B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A mounting assembly for optical elements in a head-mounted display. The mounting assembly includes a housing and an element retainer. The housing encloses an optical element. The element retainer includes a first surface and a second surface. The first surface is fixed to the optical element via a first adhesive element. The second surface is fixed to the housing via a second adhesive element.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-10-05T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595149939},{"pair":"US-10120193-B2 & US-2019018255-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2019018255-A1","title_2":"Compact near-eye optical system including a refractive beam-splitting convex lens ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190018255A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An optical system includes a first filter stack to convert light to a first circular polarization, and a second filter stack that reflects light having the first circular polarization and transmits light having a second circular polarization. A refractive beam splitting convex lens is disposed intermediate the first filter stack and the second filter stack. The first filter stack can include a first linear polarizer to convert light to a first linear polarization and a first quarter wave plate to convert the light from the first linear polarization to a first circular polarization. The second filter stack can include a second quarter wave plate to convert the light from the first circular polarization to a second linear polarization that is transverse to the first linear polarization, a polarization-dependent beam splitter to pass the first polarization and reflect the second polarization, and a linear polarizer to pass the second polarization.","priority_1":"2017-01-27T00:00:00","priority_2":"2017-07-11T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595049162},{"pair":"US-10200624-B2 & US-10275898-B1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-10275898-B1","title_2":"Wedge-based light-field video capture ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10275898B1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"A combined video of a scene may be generated for applications such as virtual reality or augmented reality. In one method, a camera system may be oriented at a first orientation and used to capture first video of a first portion of the scene. The camera system may then be rotated to a second orientation and used to capture second video of a second portion of the scene that is offset from the first portion such that the first video and the second video each have an overlapping video portion depicting an overlapping portion of the scene in which the first portion and the second portion of the scene overlap with each other. The first and second portions may be combined together to generate the combined video, which may depict the first and second portions substantially without duplicative inclusion of the overlapping video portion.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595024171},{"pair":"US-10511832-B1 & US-9851565-B1","patent_1":"US-10511832-B1","title_1":"Calibration of virtual image system with extended nasal field of view ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10511832B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A method for calibrating includes obtaining a head-mounted display device that includes an electronic display having an array of display elements and an array of beam steerers located over an inner left portion and an inner right portion of the electronic display. The method also includes obtaining alignment information by selecting a first respective subset of the array of display elements and causing it to emit light, and determining whether the light is received by a first optical sensor in a first position or a second optical sensor in a second position, thereby determining whether the first respective subset of the array of display elements is aligned for the first or the second optical sensor. The method also includes repeating the selecting, causing, and determining operations for a second subset of the array of display elements, and storing the alignment information for calibrating images for presentation by the electronic display.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-02-14T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8594715395},{"pair":"US-10317680-B1 & US-9851565-B1","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-11-09T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8594501324},{"pair":"US-2017295358-A1 & US-2018158198-A1","patent_1":"US-2017295358-A1","title_1":"Camera calibration system ","patent_2":"US-2018158198-A1","title_2":"Multi-view rotoscope contour propagation ","link_1":"https:\/\/patents.google.com\/patent\/US20170295358A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180158198A1\/en","abstract_1":"A camera calibration system jointly calibrates multiple cameras in a camera rig system. The camera calibration system obtains configuration information about the multiple cameras in the camera rig system, such as position and orientation for each camera relative to other cameras. The camera calibration system estimates calibration parameters (e.g., rotation and translation) for the multiple cameras based on the obtained configuration information. The camera calibration system receives 2D images of a test object captured by the multiple cameras and obtains known information about the test object such as location, size, texture and detailed information of visually distinguishable points of the test object. The camera calibration system then generates a 3D model of the test object based on the received 2D images and the estimated calibration parameters. The generated 3D model is evaluated in comparison with the actual test object to determine a calibration error. The calibration parameters for the cameras are updated to reduce the calibration error for the multiple cameras.","abstract_2":"A video stream may be captured, and may have a plurality of frames including at least a first frame and a second frame. Each of the frames may have a plurality of views obtained from viewpoints that are offset from each other. A source contour, associated with a source view of the first frame, may be retrieved. Camera parameters, associated with the image capture device used to capture the video stream, may also be retrieved. The camera parameters may include a first offset between the source view and a destination view of the first frame. At least the first offset may be used to project the source contour to the destination view to generate a destination contour associated with the destination view.","priority_1":"2016-04-06T00:00:00","priority_2":"2016-12-05T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8594453571},{"pair":"US-2020043391-A1 & US-9851565-B1","patent_1":"US-2020043391-A1","title_1":"Wearable Display With Coherent Replication ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200043391A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A wearable display with coherent replication of optical beams is presented. The display includes a replication element comprising a plurality of features configured to receive and split impinging light into a plurality of sub-beams for propagation in a plurality of directions. At least a portion of the split sub-beams propagating in a direction of an eyebox of the NED form an image by optical interference.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-02T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8594394229},{"pair":"US-2018188631-A1 & US-2016240013-A1","patent_1":"US-2018188631-A1","title_1":"Switchable bragg gratings for chromatic error correction of pancharatnam berry phase (pbp) components ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20180188631A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A Pancharatnam Berry Phase (PBP) color corrected structure is presented that comprises a plurality of switchable gratings and a plurality of PBP active elements. Each switchable grating has an inactive mode when reflects light of a specific color channel, of a set of color channels, and transmits light of other color channels in the set of color channels, wherein the specific color channel is different for each of the plurality of switchable gratings, and to have an active mode to transmit light that is inclusive of the set of color channels. The PBP active elements receive light output from at least one of the plurality of switchable gratings. Each of the PBP active elements is configured to adjust light of a different color channel of the set of color channels by a same amount to output light corrected for chromatic aberration for the set of color channels.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2016-12-29T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.859427075},{"pair":"US-2020064641-A1 & US-2019025602-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8593848632},{"pair":"US-10585477-B1 & US-9934583-B2","patent_1":"US-10585477-B1","title_1":"Patterned optical filter for eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10585477B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An eyewear device has an optical element, a patterned optical filter, and a camera. The optical element receives light that includes light in a visible band and light in an infrared (IR) band. The patterned optical filter is disposed on the optical element and has a filtering portion and a plurality of non-filtering portions. The filtering portion is transmissive to light in the visible band and filtering of light in the IR band. The non-filtering portions are transmissive to light in the visible band and transmissive to light in the IR band. Some portion of the received light in the IR band passes through the non-filtering portions and illuminates a portion of an eye of a user with a pattern. The camera captures images of the portion of the eye that is illuminated with the pattern.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-04-05T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8593622936},{"pair":"US-10460500-B1 & US-9384596-B2","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-04-13T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8593566141},{"pair":"US-10595000-B1 & US-10460505-B2","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-08-02T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8593441459},{"pair":"US-10154254-B2 & US-2015169054-A1","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-01-17T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8593396175},{"pair":"US-2019361523-A1 & US-2015169054-A1","patent_1":"US-2019361523-A1","title_1":"In-field illumination and imaging for eye tracking ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US20190361523A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"Disclosed herein are techniques for eye tracking in near-eye display devices. In some embodiments, an illuminator for eye tracking is provided. The illuminator includes a light source configured to be positioned within a field of view of an eye of a user; a first reflector configured to shadow the light source from a field of view of a camera; and a second reflector configured to receive light from the light source that is reflected by the eye of the user, and to direct the light toward the camera.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2018-05-23T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8593049377},{"pair":"US-2018074325-A1 & US-9810910-B1","patent_1":"US-2018074325-A1","title_1":"Fresnel Lens with Dynamic Pitch ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US20180074325A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The respective Fresnel structure of the plurality of Fresnel structures is characterized by a representative pitch. The representative pitch of the respective Fresnel structure is based on a distance of the respective Fresnel structure from a reference axis of the lens. A display device that includes the lens and an electronic display coupled with the lens for outputting light through the lens and a method for transmitting light from an electronic display toward the lens are also described.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2016-09-13T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592990423},{"pair":"US-10168531-B1 & US-2017147859-A1","patent_1":"US-10168531-B1","title_1":"Lightfield waveguide integrated eye tracking ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10168531B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"An eye tracker for determining a position of an eye, which may be integrated into a head-mounted display. The eye tracker includes at least one waveguides with an array of grating structures, an array of light sources, a detector, and a controller. The controller activates at least one light source at a time to emit at least one light beam that propagates through the at least one waveguide and couple out via the array of grating structures towards a user's eye. Light signals reflected from the user's eye and skin surfaces are coupled into the at least one waveguide and propagate to the detector that captures the reflected light signals. The controller calculates magnitudes of the reflected light signals to obtain a signature of converted light signals, and determines a position and orientation of the user's eye based on the signature of converted light signals.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2017-01-04T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592955225},{"pair":"US-10504243-B2 & US-2016328882-A1","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-2016328882-A1","title_2":"Pass-through display of captured imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160328882A1\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"A method includes sequentially outputting from an imaging sensor each pixel row of a set of pixel rows of an image captured by the imaging sensor. The method further includes displaying, at a display device, a pixel row representative of a first pixel row of the captured image prior to a second pixel row of the captured image being output by the imaging sensor. An apparatus includes an imaging sensor having a first lens that imparts a first type of spatial distortion, a display device coupled to the imaging sensor, the display to display imagery captured by the imaging sensor with the first spatial distortion, and an eyepiece lens aligned with the display, the eyepiece lens imparting a second type of spatial distortion that compensates for the first type of spatial distortion.","priority_1":"2017-10-09T00:00:00","priority_2":"2015-05-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592934747},{"pair":"US-10473939-B1 & US-10031339-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-10031339-B2","title_2":"Spatially multiplexed lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10031339B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An optical combiner includes an off-axis spatially multiplexed lens optically coupled to receive image light and direct the image light in an eye-ward direction. The off-axis spatially multiplexed lens includes a first sub-lens multiplexed with a second sub-lens. The first sub-lens and the sub-lens are configured to direct the image light to designated eyeward-regions.","priority_1":"2018-01-08T00:00:00","priority_2":"2013-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592574542},{"pair":"US-2017371159-A1 & US-9934583-B2","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-06-28T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.859247568},{"pair":"US-10200624-B2 & US-2016353082-A1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-2016353082-A1","title_2":"Capturing light-field images with uneven and\/or incomplete angular sampling ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160353082A1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"A light-field camera may generate four-dimensional light-field data indicative of incoming light. The light-field camera may have an aperture configured to receive the incoming light, an image sensor, and a microlens array configured to redirect the incoming light at the image sensor. The image sensor may receive the incoming light and, based on the incoming light, generate the four-dimensional light-field data, which may have first and second spatial dimensions and first and second angular dimensions. The first angular dimension may have a first resolution higher than a second resolution of the second angular dimension.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592439515},{"pair":"US-2019369390-A1 & US-10545347-B2","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-06-04T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592112187},{"pair":"US-10248890-B2 & US-2016307368-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592087468},{"pair":"US-2019384070-A1 & US-10146054-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-10146054-B2","title_2":"Adding prescriptive correction to eyepieces for see-through head wearable displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146054B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, a curved see-through component, an output coupler, and a prescription layer. The curved lightguide component guides display light received at an input region and releases the display light along an eye-ward direction in a viewing region. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is at least partially transmissive to ambient light incident through a world-facing side such that the viewing region is see-through. The curved see-through component is mated to the world-facing side of the curved lightguide component. The prescription layer has a first side mated to an eye-facing side of the curved lightguide component and a second side having a curvature that introduces prescriptive lensing to both the ambient light and the display light.","priority_1":"2018-06-18T00:00:00","priority_2":"2015-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8591677608},{"pair":"US-2019037137-A1 & US-2017078651-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2017078651-A1","title_2":"Stereo rendering system ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170078651A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A method includes receiving an indication of a field of view associated with a three-dimensional (3D) image being displayed on a head mount display (HMD), receiving an indication of a depth of view associated with the 3D image being displayed on the HMD, selecting a first right eye image and a second right eye image based on the field of view, combining the first right eye image and the second right eye image based on the depth of view, selecting a first left eye image and a second left eye image based on the field of view, and combining the first left eye image and the second left eye image based on the depth of view.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-09-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8591633941},{"pair":"US-2019361518-A1 & US-10084962-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10084962-B2","title_2":"Spherical video stabilization based on accelerometer data ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10084962B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A method includes identifying a frame of a spherical video as a key frame, storing a compensation component based on position data of a camera in association with the key frame, and compensating for a movement of the camera in a subsequent frame of the spherical video based on the key frame and the compensation component associated with the key frame.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-11-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8591099557},{"pair":"US-2019353906-A1 & US-9810910-B1","patent_1":"US-2019353906-A1","title_1":"Optical Assembly with Polarization Volume Holographic Element ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353906A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"An optical assembly includes a partial reflector that is optically coupled with a first polarization volume holographic element. The partial reflector is capable of receiving first light having a first circular polarization and transmitting a portion of the first light having a first circular polarization. The first polarization volume holographic element is configured to receive the first portion of the first light and reflect the first portion of the first light as second light having the first circular polarization. The partial reflector is capable of receiving the second light and reflecting a first portion of the second light as third light having a second circular polarization opposite to the first polarization. The first polarization volume holographic element is configured to receive the third light having the second circular polarization and transmit the third light having the second circular polarization.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2018-05-18T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.859086812},{"pair":"US-10598928-B1 & US-9946074-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-12-21T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8590667937},{"pair":"US-2018210139-A1 & US-9851565-B1","patent_1":"US-2018210139-A1","title_1":"Corner cut liquid crystal display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180210139A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A corner cut liquid crystal display (LCD) device including a LCD panel and a backlight. The LCD panel includes adjacent panel portions of different width that collectively define a corner cut profile shape for the LCD panel. The backlight includes a light guide and light sources that emit light into the light guide. The backlight directs the light from the light sources toward the LCD panel. The light guide includes adjacent light guide portions of different width that define the corner cut profile shape. Each light guide portion illuminates a corresponding LCD panel portion. The LCD device can be incorporated into a head-mounted display (HMD). The corner cut profile shapes of two adjacent LCD devices, one for the left eye and one for the right eye, may define an open region for placement of other components or parts of the user, such as the user's nose when wearing the HMD.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-23T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8590382113},{"pair":"US-10429657-B1 & US-2019271844-A1","patent_1":"US-10429657-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10429657B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block. Moreover, each reflection results in a particular view of the eye that results in multiple views of the eye being received by the image capturing element.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-01-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8589654367},{"pair":"US-10429656-B1 & US-2019271844-A1","patent_1":"US-10429656-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10429656B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light is captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-01-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8589654367},{"pair":"US-2019101767-A1 & US-9671614-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8589508093},{"pair":"US-10311584-B1 & US-2019020869-A1","patent_1":"US-10311584-B1","title_1":"Estimation of absolute depth from polarization measurements ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10311584B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head mounted display comprises an eye tracking system configured to enable eye tracking using polarization. The eye tracking system includes one or more illumination sources and an optical detector comprising polarization sensitive pixels. The one or more illumination sources are configured to illuminate a user's eye and generate reflections directed towards the optical detector. The eye tracking system determines, for each polarization sensitive pixel in a subset of the polarization sensitive pixels, one or more estimation parameters. The eye tracking system determines, for the subset of the polarization sensitive pixels, depth information for one or more glints associated with one or more surfaces of the eye, based in part on the polarization of the reflections and the one or more estimation parameters. The determined depth information is used to update a model of the eye. The eye tracking system determines eye tracking information based on the updated model.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-11-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8588854697},{"pair":"US-2019197667-A1 & US-9916679-B2","patent_1":"US-2019197667-A1","title_1":"Computing high-resolution depth images using machine learning techniques ","patent_2":"US-9916679-B2","title_2":"Deepstereo: learning to predict new views from real world imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20190197667A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9916679B2\/en","abstract_1":"A system trains a machine learning model to generate a high-resolution depth image. During a training phase, the system generates an accurate three dimensional reconstruction of a training scene such that the machine learning model is iteratively trained to minimize an error between the higher resolution depth image and the depth information in the accurate three dimensional reconstruction. During a real-time phase, the system applies the trained machine learning model to images captured from a scene of interest and generates a higher resolution depth image with higher accuracy. Thus, the higher resolution depth image can be subsequently used to solve computer vision problems.","abstract_2":"A system and method of deep learning using deep networks to predict new views from existing images may generate and improve models and representations from large-scale data. This system and method of deep learning may employ a deep architecture performing new view synthesis directly from pixels, trained from large numbers of posed image sets. A system employing this type of deep network may produce pixels of an unseen view based on pixels of neighboring views, lending itself to applications in graphics generation.","priority_1":"2017-12-26T00:00:00","priority_2":"2015-05-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8588764463},{"pair":"US-2019146518-A1 & US-2017353653-A1","patent_1":"US-2019146518-A1","title_1":"Interactive robots positionable for optimal interactions ","patent_2":"US-2017353653-A1","title_2":"Optical flow based auto focus ","link_1":"https:\/\/patents.google.com\/patent\/US20190146518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170353653A1\/en","abstract_1":"A system may include a robot that includes (1) an imaging device that generates image data corresponding to a field of view of the imaging device and (2) a mobility subsystem that moves the robot. The system may also an imaging subsystem that (1) tracks the image data, (2) detects an object of interest in the field of view of the imaging device, and (3) generates region-of-interest image data that includes only a portion of the tracked image data corresponding to a region of interest. Additionally, the system may include a positioning subsystem that (1) determines an initial proximity of the robot to the object of interest and (2) determines a target location for the robot. Various other robots, systems, and methods are also disclosed.","abstract_2":"A method is described that includes identifying a set of features of an object, the features being tracked in an image captured by a camera. The method also includes creating a field of vectors for the reference points. The vectors indicate magnitude and direction of change in position of the reference points across more than one frame of the image. The method further includes identifying existence of out of plane movement of the object's features from same radial orientation of the vectors. The method further includes determining an amount of closer\/farther movement of the object's features to\/from the camera from change in distances between a plurality of the reference points. The method further includes adjusting a position of camera's lens in view of the amount of closer\/farther movement of the object's features to keep the camera focused on the object.","priority_1":"2017-11-14T00:00:00","priority_2":"2016-06-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8588608844},{"pair":"US-9984507-B2 & US-10546518-B2","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2015-11-19T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8588593142},{"pair":"US-2019369390-A1 & US-9946074-B2","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-06-04T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8588407863},{"pair":"US-10237481-B2 & US-10546518-B2","patent_1":"US-10237481-B2","title_1":"Event camera for generation of event-based images ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10237481B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An imaging device operates as an event camera. The device includes an event sensor and a controller. The sensor comprises a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes within a local area. The controller populates an event matrix based in part on data values asynchronously received from the sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image for the first time period using the event matrix and the change matrix.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-04-18T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8587996488},{"pair":"US-2020027261-A1 & US-9672656-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9672656-B1","title_2":"Variable level-of-detail map rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9672656B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"To render features on a digital map, a position and orientation of a virtual camera relative to a plane of the digital map is determined. The plane is tilted so that a plane of a viewport of the digital map is not parallel to the plane of the digital map, where the viewport delimiting a view of the digital map. Map features are selected for inclusion in the view of the digital map in accordance with the determined position and orientation of the virtual camera. A level-of-detail (LOD) is determined for each of the map features in accordance with a distance between the virtual camera and the map feature. The map features are rendered, using a rendering engine, in accordance with the determined LODs.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-12-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8587617666},{"pair":"US-2020027261-A1 & US-2017032568-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858702826},{"pair":"US-10528128-B1 & US-2016080672-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2016080672-A1","title_2":"Preparation of Image Capture Device in Response to Pre-Image-Capture Signal ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160080672A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"Embodiments may be implemented by a computing device, such as a head-mountable display or mobile phone, in order to pre-emptively warm up the device's camera, when it is probable that a user will be taking a photo. An illustrative method involves a computing device (a) receiving sensor data from one or more sensors associated with the computing device, wherein the computing device comprises an image-capture device, (b) analyzing the sensor data to detect at least one pre-image-capture signal, wherein the at least one pre-image-capture signal indicates a subsequent image-capture signal is likely to be received, and (c) in response to detecting the at least one pre-image-capture signal, causing the computing device to initiate an image-capture preparation process that prepares the image-capture device to capture an image.","priority_1":"2017-12-15T00:00:00","priority_2":"2013-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8586881914},{"pair":"US-2017293146-A1 & US-9851565-B1","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-04-07T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8586718651},{"pair":"US-10595000-B1 & US-2018101984-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-08-02T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8586624414},{"pair":"US-2020090406-A1 & US-2018101984-A1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-09-17T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8586618367},{"pair":"US-2017206660-A1 & US-2018350087-A1","patent_1":"US-2017206660-A1","title_1":"Depth mapping using structured light and time of flight ","patent_2":"US-2018350087-A1","title_2":"System and method for active stereo depth sensing ","link_1":"https:\/\/patents.google.com\/patent\/US20170206660A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180350087A1\/en","abstract_1":"A depth camera assembly (DCA) determines distances between the DCA and objects in a local area within a field of view of the DCA. The DCA includes an illumination source that projects a known spatial pattern modulated with a temporal carrier signal into the local area. An imaging device capture the modulated pattern projected into the local area. The imaging device includes a detector that comprises different pixel groups that are each activated to captured light at different times. Hence, different pixel groups capture different phases of the temporally modulated pattern from the local area. The DCA determines times for light from the illumination source to be reflected and captured by the imaging device from the phases captured by the different pixel groups and also determines distances between the DCA and objects in the local area based on deformation of the spatial pattern captured by the imaging device.","abstract_2":"An electronic device estimates a depth map of an environment based on stereo depth images captured by depth cameras having exposure times that are offset from each other in conjunction with illuminators pulsing illumination patterns into the environment. A processor of the electronic device matches small sections of the depth images from the cameras to each other and to corresponding patches of immediately preceding depth images (e.g., a spatio-temporal image patch \u201ccube\u201d). The processor computes a matching cost for each spatio-temporal image patch cube by converting each spatio-temporal image patch into binary codes and defining a cost function between two stereo image patches as the difference between the binary codes. The processor minimizes the matching cost to generate a disparity map, and optimizes the disparity map by rejecting outliers using a decision tree with learned pixel offsets and refining subpixels to generate a depth map of the environment.","priority_1":"2016-01-15T00:00:00","priority_2":"2017-05-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.85861155},{"pair":"US-2019311232-A1 & US-9298256-B1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-9298256-B1","title_2":"Visual completion ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9298256B1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"Methods and devices for initiating, updating, and displaying the results of a search of an object-model database are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device and, based on the video data, detecting a movement corresponding to a selection of an object. The method further includes, before the movement is complete, initiating a search on the object of an object-model database. The method still further includes, during the movement, periodically updating the search and causing the wearable computing device to overlay the object with object-models from the database corresponding to results of the search.","priority_1":"2018-04-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8585942645},{"pair":"US-10338379-B1 & US-10241329-B2","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8585923957},{"pair":"US-2020018962-A1 & US-9810910-B1","patent_1":"US-2020018962-A1","title_1":"Adaptive lenses for near-eye displays ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US20200018962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"A lens assembly includes two or more polarization-dependent lenses sensitive to either linear or circular polarization, and at least one switchable polarization converter. The switchable polarization converter is configured to rotate linearly polarized light or change the handedness of circularly polarized light when switched on. The lens assembly is configurable to project displayed images on two or more different image planes. For example, when the switchable polarization converter is switched off, the lens assembly projects a displayed image on a first image plane. When the switchable polarization converter is switched on, the lens assembly projects a displayed image on a second image plane different from the first image plane.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2018-07-11T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8585846308},{"pair":"US-2019311522-A1 & US-10553016-B2","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-10553016-B2","title_2":"Phase aligned foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10553016B2\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"A display device, such as a head mounted device (HMD), displays a virtual scene. The display device includes a motion tracker for detecting rotation and\/or translation of the display device. The display device also includes a processor that is configured to determine, in response to the detected, an orientation of the display device relative to a plurality of world-aligned viewing frustums that are stationary relative to the virtual scene. The processor is also configured to identify a set of those world-aligned viewing frustums that overlap with an output field of view. The processor is further configured to render pixels of the set of those world-aligned viewing frustums that overlap with an output field of view and upsample the rendered pixels to generate values of display pixels for presentation by the display device.","priority_1":"2018-04-05T00:00:00","priority_2":"2017-11-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8585837296},{"pair":"US-10504243-B2 & US-2018101984-A1","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2017-10-09T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8585776391},{"pair":"US-2019037137-A1 & US-2018342075-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2018342075-A1","title_2":"Multi-view back-projection to a light-field ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180342075A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Dense light-field data can be generated from image data that does not include light-field data, or from image data that includes sparse light-field data. In at least one embodiment, the source light-field data may include one or more sub-aperture images that may be used to reconstruct the light-field in denser form. In other embodiments, the source data can take other forms. Examples include data derived from or ancillary to a set of sub-aperture images, synthetic data, or captured image data that does not include full light-field data. Interpolation, back-projection, and\/or other techniques are used in connection with source sub-aperture images or their equivalents, to generate dense light-field data.","priority_1":"2017-07-31T00:00:00","priority_2":"2017-05-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858522463},{"pair":"US-9904054-B2 & US-2019033988-A1","patent_1":"US-9904054-B2","title_1":"Headset with strain gauge expression recognition system ","patent_2":"US-2019033988-A1","title_2":"Controller tracking for multiple degrees of freedom ","link_1":"https:\/\/patents.google.com\/patent\/US9904054B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190033988A1\/en","abstract_1":"A head-mounted display (HMD) device includes a plurality of deformation sensors attached to a liner formed around a periphery of a HMD, adopted for direct or indirect contact a user's face. The deformation sensors measure deformations of the liner caused by movement of an upper portion of a user's face when the user is wearing the HMD. The deformation sensors are strain gauges embedded in or otherwise coupled to the liner of the HMD. The sensors translate muscle movements of the upper face of the user to changes in the bending strain and radius of curvature on the surface of the strain gauges. The HMD includes a module that reconstructs and projects a facial animation model of the user based on signals from the deformation sensors while the HMD is in use by the user.","abstract_2":"A method for controller tracking with multiple degrees of freedom includes generating depth data at an electronic device based on a local environment proximate the electronic device. A set of positional data is generated for at least one spatial feature associated with a controller based on a pose of the electronic device, as determined using the depth data, relative to the at least one spatial feature associated with the controller. A set of rotational data is received that represents three degrees-of-freedom (3DoF) orientation of the controller within the local environment, and a six degrees-of-freedom (6DoF) position of the controller within the local environment is tracked based on the set of positional data and the set of rotational data.","priority_1":"2015-01-23T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858521253},{"pair":"US-2018033405-A1 & US-2016323567-A1","patent_1":"US-2018033405-A1","title_1":"Adaptive parameters in image regions based on eye tracking information ","patent_2":"US-2016323567-A1","title_2":"Virtual eyeglass set for viewing actual scene that corrects for different location of lenses than eyes ","link_1":"https:\/\/patents.google.com\/patent\/US20180033405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160323567A1\/en","abstract_1":"A display system divides a screen into regions and applies a different set of rendering\/encoding parameters to each region. The system applies a first set of parameters to a first region that is being viewed by a fovea of an eye of a user. The system may also apply a second set of parameters to a second region that is being viewed by a parafovea of the eye, and apply a third set of parameters to a third region that is being viewed by the area of the eye outside of the parafovea. The first set of parameters are selected to yield relatively high image quality, while the second set of parameters are yield intermediate quality, and the third set of parameters yield lower quality. As a result, the second region and the third region can be rendered, encoded, and transmitted with less computing power and less bandwidth.","abstract_2":"A virtual eyeglass set may include a frame, a first virtual lens and second virtual lens, and a processor. The frame may mount onto a user's head and hold the first virtual lens in front of the user's left eye and the second virtual lens in front of the user's right eye. A first side of each lens may face the user and a second side of each lens may face away from the user. Each of the first virtual lens and the second virtual lens may include a light field display on the first side, and a light field camera on the second side. The processor may construct, for display on each of the light field displays based on image data received via each of the light field cameras, an image from a perspective of the user's respective eye.","priority_1":"2016-08-01T00:00:00","priority_2":"2015-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858519206},{"pair":"US-10598938-B1 & US-2018343443-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-11-09T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8585012919},{"pair":"US-2020027261-A1 & US-2018089791-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018089791-A1","title_2":"Rendering map data using descriptions of raster differences ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180089791A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A network server receives, from a client device, an indication of a first raster map image that depicts a geographic map of a certain region and a certain zoom level. The network server obtains a second raster map image corresponding to the geographic region and the zoom level and generating a description of a difference in pixels between the indicated first raster map image and the second raster map image. The network server then provides the description of the determined difference in pixels to the client device for generating the second raster map image at the client device.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8584545433},{"pair":"US-2019311232-A1 & US-10546518-B2","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-04-10T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858362107},{"pair":"US-2019313039-A1 & US-2019385359-A1","patent_1":"US-2019313039-A1","title_1":"Systems and methods for synchronizing image sensors ","patent_2":"US-2019385359-A1","title_2":"Shading images in three-dimensional content system ","link_1":"https:\/\/patents.google.com\/patent\/US20190313039A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190385359A1\/en","abstract_1":"This disclosure describes systems, methods, and devices related to the synchronization of image sensors with different exposure durations. In some embodiments, a system may include multiple image sensors, such as cameras, that have differing exposure durations. A data management component may be configured to receive sensor data from the image sensors. In addition, a synchronization component may be configured to transmit a shutter synchronization pulse to the image sensors. Finally, a tracking component may be configured to temporally center, based at least in part on the shutter synchronization pulse, the differing exposure durations of the image sensors. Various other systems and methods are also disclosed.","abstract_2":"A method includes: receiving three-dimensional (3D) information generated by a first 3D system, the 3D information including images of a scene and depth data about the scene; identifying, using the depth data, first image content in the images associated with a depth value that satisfies a criterion; and generating modified 3D information by applying first shading regarding the identified first image content. The modified 3D information can be provided to a second 3D system. The scene can contain an object in the images, and generating the modified 3D information can include determining a surface normal for second image content of the object, and applying second shading regarding the second image content based on the determined surface normal. A portion of the object can have a greater depth value than another portion, and second shading can be applied regarding a portion of the images where the second portion is located.","priority_1":"2018-04-09T00:00:00","priority_2":"2018-06-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8583234041},{"pair":"US-10120193-B2 & US-2020041798-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-01-27T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8583164911},{"pair":"US-10534185-B1 & US-2019020869-A1","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-02-14T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8583048493},{"pair":"US-2018074325-A1 & US-9798147-B1","patent_1":"US-2018074325-A1","title_1":"Fresnel Lens with Dynamic Pitch ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20180074325A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The respective Fresnel structure of the plurality of Fresnel structures is characterized by a representative pitch. The representative pitch of the respective Fresnel structure is based on a distance of the respective Fresnel structure from a reference axis of the lens. A display device that includes the lens and an electronic display coupled with the lens for outputting light through the lens and a method for transmitting light from an electronic display toward the lens are also described.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2016-09-13T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8582988229},{"pair":"US-10528128-B1 & US-2019020869-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-12-15T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8582231315},{"pair":"US-10495798-B1 & US-2020073123-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-08-07T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8581815107},{"pair":"US-2019361523-A1 & US-9536354-B2","patent_1":"US-2019361523-A1","title_1":"In-field illumination and imaging for eye tracking ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20190361523A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"Disclosed herein are techniques for eye tracking in near-eye display devices. In some embodiments, an illuminator for eye tracking is provided. The illuminator includes a light source configured to be positioned within a field of view of an eye of a user; a first reflector configured to shadow the light source from a field of view of a camera; and a second reflector configured to receive light from the light source that is reflected by the eye of the user, and to direct the light toward the camera.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2018-05-23T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8581214048},{"pair":"US-2019311232-A1 & US-2019129174-A1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-2019129174-A1","title_2":"Multi-perspective eye-tracking for vr\/ar systems ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190129174A1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"A display system, such as a head mounted display, tracks a pose of a user's eye based on multiple perspectives of the eye captured via a segmented optics array, such as a lenslet array or Fresnel lens. The display system reflects light (e.g., infra-red light) off each segment of the segmented optics array, and captures an image based on the reflected light. Because of the segmented optics, the captured image represents multiple concurrent perspectives of the user's eye. The display system analyzes the different perspectives and selects a perspective, or combination of perspectives, and based on the selected perspective or combination, identifies a pose of the user's eye.","priority_1":"2018-04-10T00:00:00","priority_2":"2017-10-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8581196736},{"pair":"US-10529276-B2 & US-9466112-B1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-9466112-B1","title_2":"Zoom and image capture based on features of interest ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9466112B1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"Methods and systems for intelligently zooming to and capturing a first image of a feature of interest are provided. The feature of interest may be determined based on a first interest criteria. The captured image may be provided to a user, who may indicate a level of interest in the feature of interest. The level of interest may be based upon to store the captured image and capture another image. The level of interest may be a gradient value, or a binary value. The level of interest may be based upon to determine whether to store the captured image, and if so, a resolution at which the captured image is to be stored. The level of interest may also be based upon to determine whether to zoom to and capture a second image of a second feature of interest based on the first interest criteria or a second interest criteria.","priority_1":"2018-01-05T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8580579013},{"pair":"US-10599215-B2 & US-10546518-B2","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-04-26T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8579596955},{"pair":"US-10509228-B1 & US-9934583-B2","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-12-20T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8579016891},{"pair":"US-10504243-B2 & US-2019033988-A1","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-2019033988-A1","title_2":"Controller tracking for multiple degrees of freedom ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190033988A1\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"A method for controller tracking with multiple degrees of freedom includes generating depth data at an electronic device based on a local environment proximate the electronic device. A set of positional data is generated for at least one spatial feature associated with a controller based on a pose of the electronic device, as determined using the depth data, relative to the at least one spatial feature associated with the controller. A set of rotational data is received that represents three degrees-of-freedom (3DoF) orientation of the controller within the local environment, and a six degrees-of-freedom (6DoF) position of the controller within the local environment is tracked based on the set of positional data and the set of rotational data.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8578460855},{"pair":"US-10571692-B2 & US-2017293143-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2016-03-02T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8577911841},{"pair":"US-10522110-B1 & US-2017123209-A1","patent_1":"US-10522110-B1","title_1":"Apparatuses, systems, and methods for measuring and adjusting the luminance of a head-mounted display ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10522110B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"An ocular assembly for a head-mounted display may include an opaque enclosure that defines (1) an interior space, (2) an exterior space, (3) a display aperture that admits image light emitted by a display screen into the interior space, (4) a lens aperture, and (5) a lateral aperture that admits the light from the interior space into the exterior space. The ocular assembly may also include an opaque covering for the lateral aperture that is moveable between (1) a closed position that prevents the image light from passing from the interior space through the lateral aperture to the exterior space and (2) an open position that allows the image light to pass from the interior space through the lateral aperture to the exterior space. Various other apparatuses, methods, and systems are also disclosed.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2017-08-30T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8576836322},{"pair":"US-10248842-B1 & US-2019311467-A1","patent_1":"US-10248842-B1","title_1":"Face tracking using structured light within a head-mounted display ","patent_2":"US-2019311467-A1","title_2":"Enhanced specular reflections for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US10248842B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311467A1\/en","abstract_1":"A head mounted display (HMD) displays content to a user wearing the HMD, where the content may be based on a facial model of the user. The HMD uses an electronic display to illuminate a portion of the face of the user with. The electronic display emits a pattern of structured light and\/or monochromatic light of a given color. A camera assembly captures images of the illuminated portion of the face. A controller processes the captured images to determine depth information or color information of the face of the user. Further, the processed images may be used to update the facial model, for example, which is represented as a virtual avatar and presented to the user in a virtual reality, augmented reality, or mixed reality environment.","abstract_2":"Systems and methods for enhanced specular reflections are provided. An example method may include determining a first portion of a specular reflection associated with a computer-generated object based on a first contribution from an environment map component at a shading point of the computer-generated object and determining a second portion of the specular reflection associated with the computer-generated object based on a second contribution from a camera feed component at an intersection point of a camera feed and a reflection vector associated with the environment map component. The example method may further include determining the specular reflection, at the shading point, associated with the computer-generated object based on a blending of the first and second portions of the specular reflection.","priority_1":"2018-01-09T00:00:00","priority_2":"2018-04-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8576713711},{"pair":"US-10168531-B1 & US-9934583-B2","patent_1":"US-10168531-B1","title_1":"Lightfield waveguide integrated eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10168531B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An eye tracker for determining a position of an eye, which may be integrated into a head-mounted display. The eye tracker includes at least one waveguides with an array of grating structures, an array of light sources, a detector, and a controller. The controller activates at least one light source at a time to emit at least one light beam that propagates through the at least one waveguide and couple out via the array of grating structures towards a user's eye. Light signals reflected from the user's eye and skin surfaces are coupled into the at least one waveguide and propagate to the detector that captures the reflected light signals. The controller calculates magnitudes of the reflected light signals to obtain a signature of converted light signals, and determines a position and orientation of the user's eye based on the signature of converted light signals.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-01-04T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8576016339},{"pair":"US-10210660-B2 & US-2017078651-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2017078651-A1","title_2":"Stereo rendering system ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170078651A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A method includes receiving an indication of a field of view associated with a three-dimensional (3D) image being displayed on a head mount display (HMD), receiving an indication of a depth of view associated with the 3D image being displayed on the HMD, selecting a first right eye image and a second right eye image based on the field of view, combining the first right eye image and the second right eye image based on the depth of view, selecting a first left eye image and a second left eye image based on the field of view, and combining the first left eye image and the second left eye image based on the depth of view.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-09-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8575875538},{"pair":"US-2018063508-A1 & US-10242454-B2","patent_1":"US-2018063508-A1","title_1":"Array detector for depth mapping ","patent_2":"US-10242454-B2","title_2":"System for depth data filtering based on amplitude energy values ","link_1":"https:\/\/patents.google.com\/patent\/US20180063508A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10242454B2\/en","abstract_1":"A depth camera assembly (DCA) captures data describing depth information in a local area. The DCA includes an array detector, a controller, and an illumination source. The array detector includes a detector that is overlaid with a lens array. The detector includes a plurality of pixels, the plurality of pixels are divided into a plurality of different pixel groups. The lens array includes a plurality of lens stacks and each lens stack overlays a different pixel group. The array detector captures one or more composite images of the local area illuminated with the light from the illumination source. The controller determines depth information for objects in the local area using the one or more composite images.","abstract_2":"An electronic device includes a time of flight (ToF) camera and one or more processors. The ToF camera captures raw depth images. The processors determine a depth frame and an amplitude frame from the raw depth images. The depth frame comprises an array of pixels, each pixel having a depth value. The amplitude frame comprises an array of pixels, each pixel having an amplitude energy value. The processors determine a first energy threshold value based on the amplitude energy values of the array of pixels of the amplitude frame and determine, for the depth value of a first pixel of the depth frame, a confidence value representing a corresponding validity of a depth represented by the depth value, based on a comparison of the amplitude energy value of a corresponding first pixel of the amplitude frame to the first energy threshold value.","priority_1":"2016-08-25T00:00:00","priority_2":"2017-01-25T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8575683259},{"pair":"US-10506217-B2 & US-2019020869-A1","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8575560912},{"pair":"US-10268268-B1 & US-2017147859-A1","patent_1":"US-10268268-B1","title_1":"Waveguide integrated eye tracking ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10268268B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"An eye tracker for determining a position of an eye, which may be integrated into a head-mounted display. The eye tracker includes a waveguide, switchable Bragg gratings (SBGs) that selectively out couple light from the waveguide, light sources coupled to the waveguide, a detector coupled to a return path of the waveguide, and a controller. The controller instructs at least one light source to emit at least one light beam propagating through the waveguide, and activates at least one SBG to out-couple the at least one light beam from the waveguide toward the eye. The waveguide in-couples at least one reflected light signal reflected from the eye that originates from the at least one light beam out-coupled from the waveguide. The detector detects the at least one reflected light signal. The controller determines a position of the eye using the detected at least one reflected light signal.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2016-09-02T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8575163828},{"pair":"US-2020057304-A1 & US-9671614-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-16T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8575011094},{"pair":"US-10595000-B1 & US-10102666-B2","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-10102666-B2","title_2":"Electronic display stabilization for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10102666B2\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A method includes determining, at a first time, a representation of a first head rotation of a head mounted display (HMD) using a first inertial sensor sample stream and rendering, at an application processor, a texture based on the first head rotation. The method further includes determining, at a second time subsequent to the first time, a representation of a second head rotation of the HMD using a second inertial sensor sample stream having a higher sampling rate than the first inertial sensor sample stream, and generating, at a compositor, a rotated representation of the texture based on a difference between the first head rotation and the second head rotation.","priority_1":"2018-08-02T00:00:00","priority_2":"2015-06-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8574133301},{"pair":"US-10317680-B1 & US-10591731-B2","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-11-09T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8574012823},{"pair":"US-2019313039-A1 & US-2016328882-A1","patent_1":"US-2019313039-A1","title_1":"Systems and methods for synchronizing image sensors ","patent_2":"US-2016328882-A1","title_2":"Pass-through display of captured imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20190313039A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160328882A1\/en","abstract_1":"This disclosure describes systems, methods, and devices related to the synchronization of image sensors with different exposure durations. In some embodiments, a system may include multiple image sensors, such as cameras, that have differing exposure durations. A data management component may be configured to receive sensor data from the image sensors. In addition, a synchronization component may be configured to transmit a shutter synchronization pulse to the image sensors. Finally, a tracking component may be configured to temporally center, based at least in part on the shutter synchronization pulse, the differing exposure durations of the image sensors. Various other systems and methods are also disclosed.","abstract_2":"A method includes sequentially outputting from an imaging sensor each pixel row of a set of pixel rows of an image captured by the imaging sensor. The method further includes displaying, at a display device, a pixel row representative of a first pixel row of the captured image prior to a second pixel row of the captured image being output by the imaging sensor. An apparatus includes an imaging sensor having a first lens that imparts a first type of spatial distortion, a display device coupled to the imaging sensor, the display to display imagery captured by the imaging sensor with the first spatial distortion, and an eyepiece lens aligned with the display, the eyepiece lens imparting a second type of spatial distortion that compensates for the first type of spatial distortion.","priority_1":"2018-04-09T00:00:00","priority_2":"2015-05-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8573982745},{"pair":"US-2017180713-A1 & US-2016328882-A1","patent_1":"US-2017180713-A1","title_1":"Range-gated depth camera assembly ","patent_2":"US-2016328882-A1","title_2":"Pass-through display of captured imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20170180713A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160328882A1\/en","abstract_1":"An augmented reality (AR) includes a depth camera assembly (DCA) to capture images of various depth zones of scenes of a local area. The DCA can focus on specific ranges in a scene, important aspects, and\/or regions of interest. The DCA generates image data of the local area such that the image includes information pertaining to a single depth zone. The captured image is specific to the single depth zone and is representative of objects within the single depth zone. The DCA uses the generated image data for the depth zones to generate augmented or partially-augmented images that include depth information for the objects in the local area.","abstract_2":"A method includes sequentially outputting from an imaging sensor each pixel row of a set of pixel rows of an image captured by the imaging sensor. The method further includes displaying, at a display device, a pixel row representative of a first pixel row of the captured image prior to a second pixel row of the captured image being output by the imaging sensor. An apparatus includes an imaging sensor having a first lens that imparts a first type of spatial distortion, a display device coupled to the imaging sensor, the display to display imagery captured by the imaging sensor with the first spatial distortion, and an eyepiece lens aligned with the display, the eyepiece lens imparting a second type of spatial distortion that compensates for the first type of spatial distortion.","priority_1":"2015-12-16T00:00:00","priority_2":"2015-05-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8573231453},{"pair":"US-2018157053-A1 & US-2017116950-A1","patent_1":"US-2018157053-A1","title_1":"Dichroic combiner backlight used in a head mounted display ","patent_2":"US-2017116950-A1","title_2":"Liquid crystal display with variable drive voltage ","link_1":"https:\/\/patents.google.com\/patent\/US20180157053A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170116950A1\/en","abstract_1":"A liquid crystal display (LCD) device including a backlight with an LED assembly. The LED assembly includes a dichroic combiner and two or more different color LEDs. A substrate of the dichroic combiner receives color light from multiple color LEDs at different input regions and propagating in different directions. Dielectric layers within the substrate selectively reflect or transmit the color light to spatially superimpose the color light, and output the color light in a particular direction at a light output region of the substrate. The light output regions of LED assemblies are arranged behind an LCD panel, along one or more edges, to illuminate the LCD panel. The LED assembly provides edge-lighting without requiring LED placement along the one or more edges.","abstract_2":"A technique for operation of a display system includes displaying a display image from a liquid crystal display source, measuring a brightness of ambient light, and selecting a drive voltage for driving liquid crystal cells within the liquid crystal display source based upon the brightness of the ambient light. The drive voltage is used for driving the liquid crystal cells into an on-state or an off-state while displaying the display image.","priority_1":"2016-12-06T00:00:00","priority_2":"2015-10-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8573165276},{"pair":"US-2019361518-A1 & US-2019311467-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2019311467-A1","title_2":"Enhanced specular reflections for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311467A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"Systems and methods for enhanced specular reflections are provided. An example method may include determining a first portion of a specular reflection associated with a computer-generated object based on a first contribution from an environment map component at a shading point of the computer-generated object and determining a second portion of the specular reflection associated with the computer-generated object based on a second contribution from a camera feed component at an intersection point of a camera feed and a reflection vector associated with the environment map component. The example method may further include determining the specular reflection, at the shading point, associated with the computer-generated object based on a blending of the first and second portions of the specular reflection.","priority_1":"2018-05-22T00:00:00","priority_2":"2018-04-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8573072115},{"pair":"US-2019187482-A1 & US-2015169054-A1","patent_1":"US-2019187482-A1","title_1":"Integrated Augmented Reality Head-Mounted Display for Pupil Steering ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US20190187482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head-mounted display device for providing augmented reality contents to a wearer includes an eye tracker, a light projector, a beam steerer and a combiner. The eye tracker is configured to determine a position of a pupil of an eye of the wearer. The light projector is configured to project light for rendering images. The beam steerer is configured to change a direction of the light from the light projector based on the position of the pupil. The combiner is configured to combine the light from the light projector and light from an outside of the head-mounted display device for providing an overlap of the rendered image and a real image that corresponds to the light from the outside of the head-mounted display device.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-12-18T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8573007605},{"pair":"US-2020033693-A1 & US-2019086675-A1","patent_1":"US-2020033693-A1","title_1":"Varifocal system using hybrid tunable liquid crystal lenses ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20200033693A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A varifocal system comprises a stacked first-type liquid crystal (LC) lens structure and a stacked second-type LC lens structure in optical series. The stacked first-type LC lens structure includes a plurality of first-type LC lenses, and a first-type LC lens provides continuously variable optical states in a first step resolution. The stacked second-type LC lens structure includes a plurality of second-type LC lenses and provides a plurality of optical states in a second step resolution. The first step resolution is smaller than the second step resolution, such that when the stacked second-type LC lens structure is switched between two optical states, the first-type LC lenses provide a continuous adjustment of optical power between the two optical states. The stacked first-type LC lens structure and the stacked second-type LC lens structure together provide a continuous adjustment range of optical power for the varifocal system.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-07-30T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572830072},{"pair":"US-2019313087-A1 & US-2019020869-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572710255},{"pair":"US-2019212482-A1 & US-9934583-B2","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-01-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572601426},{"pair":"US-2017308161-A1 & US-9851565-B1","patent_1":"US-2017308161-A1","title_1":"Backlight modulation for liquid crystal display with eyetracking for virtual reality ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20170308161A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head mounted display system includes a display device and an eyetracking device. The display device includes a liquid crystal (LC) panel comprising a plurality of rows of pixels, a back light unit (BLU), and a data driver. The BLU emits light during an illumination period of a frame period from an illumination start time and does not emit light for a remaining portion of the frame period. The eyetracking device determines an eye gaze area of a user in a pixel area of the display device. The illumination start time varies based on a location of the eye gaze area of the user. Liquid crystal material in a row of pixels of the LC panel outside the eye gaze area of the user transitions during the illumination period.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-04-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572554244},{"pair":"US-2018335630-A1 & US-2016240013-A1","patent_1":"US-2018335630-A1","title_1":"Liquid crystal cells for polarization rotation ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20180335630A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"An optical element comprising a stacked liquid crystal (LC) structure for rotating polarization (e.g., handedness) of an incident circularly polarized light over a broad wavelength and incident angle for head-mounted displays (HMD)s display application is proposed. The stacked LC structure has a dual cell structures, which includes at least a first LC cell and a second LC cell, and the stacked LC structure rotates the polarized light for a broad band of light (e.g., visible spectrum) over a given field a view. The performance of designed dual LC cells structures may be optimized for narrow band wavelength and a narrow incident angle for different application cases.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-05-17T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572406893},{"pair":"US-10379419-B1 & US-10241329-B2","patent_1":"US-10379419-B1","title_1":"Focus adjusting pancharatnam berry phase liquid crystal lenses in a head-mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10379419B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A varifocal block includes, in optical series, a switchable half waveplate (SHWP) and a plurality of liquid crystal (LC) lenses. The SHWP outputs circularly polarized light, and a handedness of the circularly polarized light is controlled by the SHWP being in an active state or a non-active state. Each LC lens of the plurality of LC lenses has a plurality of optical states, the plurality of optical states including an additive state that adds optical power to the LC lens and a subtractive state that removes optical power from the LC lens. The plurality of optical states of each of the plurality of the LC lenses compounded in optical series provides a range of adjustment of optical power for the varifocal block.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-11-23T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572237346},{"pair":"US-10497320-B1 & US-9851565-B1","patent_1":"US-10497320-B1","title_1":"Transparent and reflective illumination source ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10497320B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes a display illuminated by one or more illumination sources. An illumination source is coupled to a partially transparent circuit board and is configured to emit light onto a compound mirror. The compound mirror is farther from an exit pupil of the HMD than the display and reflects light from the illumination source back towards the exit pupil of the HMD. Light reflected by the compound mirror is transmitted through the partially transparent circuit board onto the display, illuminating the display.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-07T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572235944},{"pair":"US-10462451-B1 & US-2016282453-A1","patent_1":"US-10462451-B1","title_1":"Asymmetric structured light source ","patent_2":"US-2016282453-A1","title_2":"Methods and Systems for LIDAR Optics Alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10462451B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160282453A1\/en","abstract_1":"A depth camera assembly includes an illumination source assembly, a projection assembly, and an imaging device. The illumination source assembly emits light in accordance with emission instructions. The illumination source assembly includes a plurality of emitters on a single substrate. The projection assembly projects light from the illumination source assembly into a local area. The projection assembly includes an optical element that is positioned to receive light from a first emitter at a first angle and project the received light from the first emitter to a first depth zone in the local area, and to receive light from a second emitter at a second angle and project the received light from the second emitter to a second depth zone in the local area. The imaging device captures one or more images of the local area illuminated with the light from the illumination source assembly.","abstract_2":"A method is provided that involves mounting a transmit block and a receive block in a LIDAR device to provide a relative position between the transmit block and the receive block. The method also involves locating a camera at a given position at which the camera can image light beams emitted by the transmit block and can image the receive block. The method also involves obtaining, using the camera, a first image indicative of light source positions of one or more light sources in the transmit block and a second image indicative of detector positions of one or more detectors in the receive block. The method also involves determining at least one offset based on the first image and the second image. The method also involves adjusting the relative position between the transmit block and the receive block based at least in part on the at least one offset.","priority_1":"2017-05-12T00:00:00","priority_2":"2015-03-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.857179999},{"pair":"US-10466779-B1 & US-10546518-B2","patent_1":"US-10466779-B1","title_1":"Event camera for eye tracking ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10466779B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An eye tracking system includes an event camera. The event camera includes an event sensor and a controller. The event sensor includes a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes of light reflected from a user's eyes. The controller populates an event matrix based in part on data values asynchronously received from the event sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image of the user's eyes for the first time period using the event matrix and the change matrix. The eye tracking system uses the image of the user's eyes to determine eye tracking information indicating positions, orientations and\/or movement of the user's eyes.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-07-24T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8571094001},{"pair":"US-10429657-B1 & US-2020041798-A1","patent_1":"US-10429657-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10429657B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block. Moreover, each reflection results in a particular view of the eye that results in multiple views of the eye being received by the image capturing element.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8571046839},{"pair":"US-10429656-B1 & US-2020041798-A1","patent_1":"US-10429656-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10429656B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light is captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8571046839},{"pair":"US-2020027261-A1 & US-9626790-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9626790-B1","title_2":"View-dependent textures for interactive geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9626790B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a polygon mesh to provide a textured three-dimensional model of a geographic area are provided. The view-dependent texture can be optimized for viewing the three-dimensional model from a single reference direction. When a user navigates to a camera viewpoint of the three-dimensional model associated with the single reference direction, the view-dependent texture can be rendered in conjunction with the three-dimensional model to provide a more realistic representation of the geographic area to the user. When a user navigates to a camera viewpoint of the three-dimensional model that is not associated with the single reference direction, a base texture can be rendered in conjunction with the three-dimensional model. The base texture can be optimized based on viewing the three-dimensional model from a plurality of differing viewpoints.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8570929298},{"pair":"US-2018232047-A1 & US-10032074-B2","patent_1":"US-2018232047-A1","title_1":"Selective Color Sensing for Motion Tracking ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180232047A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"An electronic device is configured to select a first set of one or more distinct wavelengths for tracking a first portable device in communication with the electronic device; and, subsequent to selecting the first set of one or more distinct wavelengths for tracking the first portable device, initiate the first portable device to emit light of the first set of one or more selected wavelengths; receive information identifying one or more respective intensities of light, detected by the one or more optical sensors, for the first set of one or more selected wavelengths; and determine a position of the first portable device based on the information identifying the one or more respective intensities of light, detected by the one or more optical sensors, for the first set of one or more selected wavelengths. A method for determining a position of the first portable device is also described.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-02-14T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8570872719},{"pair":"US-10210660-B2 & US-2017363949-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2017363949-A1","title_2":"Multi-tier camera rig for stereoscopic image capture ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170363949A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"In on the general aspect, a camera rig can include a first tier of images sensors including a first plurality of image sensors where the first plurality of image sensors are arranged in a circular shape and oriented such that a field of view of each of the first plurality of image sensors has an axis perpendicular to a tangent of the circular shape. The camera rig can include a second tier of image sensors including a second plurality of image sensors where the second plurality of image sensors are oriented such that a field of view of each of the second plurality of image sensors has an axis non-parallel to the field of view of each of the first plurality of image sensors.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.857065574},{"pair":"US-9910282-B2 & US-2020041798-A1","patent_1":"US-9910282-B2","title_1":"Increasing field of view of head-mounted display using a mirror ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US9910282B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted display (HMD) (e.g., VR headset or AR headset) displays a 3D virtual scene and includes a mirror to increase a field of view (FOV). The HMD includes an electronic display that further includes a primary display and an extended display, where the content displayed on the primary display is presented to the user's eye at an exit pupil through a lens and content displayed on the extended display is presented at the exit pupil through reflections of the mirror. The mirror is positioned between the exit pupil and the electronic display such that the mirror reflects light originating from the extended display and provides the reflected light to the exit pupil to increase the FOV. The combination of the content viewed through the lens and that of the reflected light of the extended display results in an FOV larger than when the content is viewed only through the lens.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2015-12-28T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8570607409},{"pair":"US-10557994-B1 & US-9851565-B1","patent_1":"US-10557994-B1","title_1":"Waveguide grating with spatial variation of optical phase ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10557994B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical waveguide is disclosed. The optical waveguide includes a plate of transparent material comprising opposed first and second surfaces for guiding an optical beam between the surfaces by at least one of reflection or diffraction. A diffraction grating is disposed at the first surface for spreading the optical beam by diffracting portions thereof into a non-zero diffraction order to propagate inside the plate. The first diffraction grating includes an array of parallel grooves structured to provide a spatial variation of optical phase of the portions of the optical beam diffracted by the first diffraction grating into the non-zero diffraction order.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-09-24T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8570318418},{"pair":"US-10571692-B2 & US-9946074-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2016-03-02T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8569783669},{"pair":"US-10540930-B1 & US-9964767-B2","patent_1":"US-10540930-B1","title_1":"Apparatus, systems, and methods for temperature-sensitive illumination of liquid crystal displays ","patent_2":"US-9964767-B2","title_2":"Display with reflected LED micro-display panels ","link_1":"https:\/\/patents.google.com\/patent\/US10540930B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9964767B2\/en","abstract_1":"A display device may include (1) a liquid crystal (LC) panel with rows of pixel elements that include LC material capable of transitioning between two states, (2) a backlight coupled to the LC panel behind the rows of pixel elements and configured to emit light towards the rows of pixel elements, (3) a temperature sensor configured to measure a temperature of the LC panel, and (4) a display driver configured to (a) scan data to the rows of pixel elements such that the LC material makes a transition between the two states, (b) read, from the temperature sensor, the temperature of the LC panel, (c) calculate, based on the temperature of the LC panel, an estimated transition period for the transition, and (d) initiate, after the estimated transition period, an illumination of the backlight to illuminate the rows of pixel elements. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A display apparatus includes a transparent substrate having first and second sides, an array of LED micro-display panels, and an array of collimating reflectors. The LED micro-display panels are disposed within the transparent substrate between the first and second sides and oriented to emit sub-image portions of a display image towards the first side. The collimating reflectors are disposed within the transparent substrate between the first side and the array of LED micro-display panels. The collimating reflectors are aligned with the LED micro-display panels to reflect the sub-image portions back out the second side of the transparent substrate. The LED micro-display panels are offset from the collimating reflectors to expand the sub-image portions prior to reflection by the collimating reflectors.","priority_1":"2018-01-05T00:00:00","priority_2":"2016-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8569079135},{"pair":"US-2017358136-A1 & US-2019020869-A1","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-06-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8568943075},{"pair":"US-10572731-B1 & US-2017147859-A1","patent_1":"US-10572731-B1","title_1":"Infrared transparent backlight device for eye tracking applications ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10572731B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A backlight device provides light in a first optical band to a spatial light modulator, and is transmissive to light in a second optical band. The backlight device includes a structured dichroic reflector that is substantially reflective, and scatters light in the first optical band. The structured dichroic reflector is also substantially transparent in the second optical band, and the second optical band is different than the first optical band. The backlight device is configured to receive light in the first optical band from an illumination source. The dichroic reflector is configured to reflect light in the first optical band toward a display panel that converts the light from the backlight device to image light. The backlight device may be part of a head-mounted display.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-03-13T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8568609113},{"pair":"US-10460500-B1 & US-9734579-B1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-04-13T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8568582471},{"pair":"US-2016085301-A1 & US-2019129174-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2019129174-A1","title_2":"Multi-perspective eye-tracking for vr\/ar systems ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190129174A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A display system, such as a head mounted display, tracks a pose of a user's eye based on multiple perspectives of the eye captured via a segmented optics array, such as a lenslet array or Fresnel lens. The display system reflects light (e.g., infra-red light) off each segment of the segmented optics array, and captures an image based on the reflected light. Because of the segmented optics, the captured image represents multiple concurrent perspectives of the user's eye. The display system analyzes the different perspectives and selects a perspective, or combination of perspectives, and based on the selected perspective or combination, identifies a pose of the user's eye.","priority_1":"2014-09-22T00:00:00","priority_2":"2017-10-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8568157452},{"pair":"US-10488921-B1 & US-2015169054-A1","patent_1":"US-10488921-B1","title_1":"Pellicle beamsplitter for eye tracking ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10488921B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a pellicle beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The pellicle beamsplitter is positioned along the optical axis between the optics assembly and the electronic display. The pellicle beamsplitter includes a front surface and a back surface. Each of the front surface and the back surface comprising a first radius curvature in a first plane and a second radius curvature in a second plane that is perpendicular to the first plane.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-09-08T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8568045257},{"pair":"US-10540930-B1 & US-9466112-B1","patent_1":"US-10540930-B1","title_1":"Apparatus, systems, and methods for temperature-sensitive illumination of liquid crystal displays ","patent_2":"US-9466112-B1","title_2":"Zoom and image capture based on features of interest ","link_1":"https:\/\/patents.google.com\/patent\/US10540930B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9466112B1\/en","abstract_1":"A display device may include (1) a liquid crystal (LC) panel with rows of pixel elements that include LC material capable of transitioning between two states, (2) a backlight coupled to the LC panel behind the rows of pixel elements and configured to emit light towards the rows of pixel elements, (3) a temperature sensor configured to measure a temperature of the LC panel, and (4) a display driver configured to (a) scan data to the rows of pixel elements such that the LC material makes a transition between the two states, (b) read, from the temperature sensor, the temperature of the LC panel, (c) calculate, based on the temperature of the LC panel, an estimated transition period for the transition, and (d) initiate, after the estimated transition period, an illumination of the backlight to illuminate the rows of pixel elements. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"Methods and systems for intelligently zooming to and capturing a first image of a feature of interest are provided. The feature of interest may be determined based on a first interest criteria. The captured image may be provided to a user, who may indicate a level of interest in the feature of interest. The level of interest may be based upon to store the captured image and capture another image. The level of interest may be a gradient value, or a binary value. The level of interest may be based upon to determine whether to store the captured image, and if so, a resolution at which the captured image is to be stored. The level of interest may also be based upon to determine whether to zoom to and capture a second image of a second feature of interest based on the first interest criteria or a second interest criteria.","priority_1":"2018-01-05T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567900954},{"pair":"US-10416461-B2 & US-9851565-B1","patent_1":"US-10416461-B2","title_1":"Pancake lens with large FOV ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10416461B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A HMD includes an electronic display and a pancake lens block. The pancake lens block includes a back curved optical element and a front curved optical element. Light propagating through the pancake lens block undergoes multiple reflections and to mitigate parasitic reflections, there are no air gaps between optical elements of the pancake lens block. A hybrid film that operates as a waveplate surface and a mirrored surface can be placed between the front curved optical element and the back curved optical element. A wide FOV can be obtained by making the coupling surfaces of the front optical element and the back optical element to be based on a convex cylindrical surface profile and a concave cylindrical surface profile, with the axis of the cylinder surface in a vertical direction for a user wearing the HMD.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-10-27T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.856782251},{"pair":"US-10481321-B1 & US-2016240013-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-09-06T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567746896},{"pair":"US-10248890-B2 & US-9342873-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9342873-B1","title_2":"Tile-based optical flow ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9342873B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A computing device may determine a per-tile motion estimate between a first m\u00d7n pixel tile from a first captured image of a scene and a second m\u00d7n pixel tile from a second captured image of the scene. A per-tile confidence of the per-tile motion estimate may be obtained. The per-tile motion estimate and the per-tile confidence may be upsampled to obtain respective per-pixel motion estimates and associated per-pixel confidences for pixels of the first m\u00d7n pixel tile. The respective per-pixel motion estimates and associated per-pixel confidences may be iteratively filtered. The iterative filtering may involve multiplying the respective per-pixel motion estimates and associated per-pixel confidences by an affinity matrix. The iterative filtering may also smooth the respective per-pixel motion estimates and associated per-pixel confidences.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-05-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567579381},{"pair":"US-10066933-B2 & US-2015310310-A1","patent_1":"US-10066933-B2","title_1":"Camera depth mapping using structured light patterns ","patent_2":"US-2015310310-A1","title_2":"Electronic device localization based on imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10066933B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150310310A1\/en","abstract_1":"The various embodiments described herein include methods and\/or systems for depth mapping. In one aspect, a method of depth mapping is performed at an apparatus including a projector, a camera, one or more processors, and memory storing one or more programs for execution by the one or more processors. The method includes identifying one or more areas of interest in a scene in accordance with variation of depth in the scene as detected at a first resolution. The method also includes, for each area of interest: (1) applying, via the projector, a respective structured-light pattern to the area of interest; (2) capturing, via the camera, an image of the area of interest with the respective structured-light pattern applied to it; and (3) creating a respective depth map of the area of interest using the captured image, the respective depth map having a higher resolution than the first resolution.","abstract_2":"An electronic device includes one or more imaging cameras. After a reset of the device or other specified event, the electronic device identifies an estimate of the device's pose based on location data such as Global Positioning System (GPS) data, cellular tower triangulation data, wireless network address location data, and the like. The one or more imaging cameras may be used to capture imagery of the local environment of the electronic device, and this imagery is used to refine the estimated pose to identify a refined pose of the electronic device. The refined pose may be used to identify additional imagery information, such as environmental features, that can be used to enhance the location based functionality of the electronic device.","priority_1":"2015-05-04T00:00:00","priority_2":"2014-04-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567416745},{"pair":"US-2019361518-A1 & US-2017078651-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2017078651-A1","title_2":"Stereo rendering system ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170078651A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A method includes receiving an indication of a field of view associated with a three-dimensional (3D) image being displayed on a head mount display (HMD), receiving an indication of a depth of view associated with the 3D image being displayed on the HMD, selecting a first right eye image and a second right eye image based on the field of view, combining the first right eye image and the second right eye image based on the depth of view, selecting a first left eye image and a second left eye image based on the field of view, and combining the first left eye image and the second left eye image based on the depth of view.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-09-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567338969},{"pair":"US-10379419-B1 & US-2019086675-A1","patent_1":"US-10379419-B1","title_1":"Focus adjusting pancharatnam berry phase liquid crystal lenses in a head-mounted display ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10379419B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A varifocal block includes, in optical series, a switchable half waveplate (SHWP) and a plurality of liquid crystal (LC) lenses. The SHWP outputs circularly polarized light, and a handedness of the circularly polarized light is controlled by the SHWP being in an active state or a non-active state. Each LC lens of the plurality of LC lenses has a plurality of optical states, the plurality of optical states including an additive state that adds optical power to the LC lens and a subtractive state that removes optical power from the LC lens. The plurality of optical states of each of the plurality of the LC lenses compounded in optical series provides a range of adjustment of optical power for the varifocal block.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2016-11-23T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567068535},{"pair":"US-2018173303-A1 & US-2016057339-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567060791},{"pair":"US-10429927-B1 & US-2019271844-A1","patent_1":"US-10429927-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10429927B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-01-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8566632619},{"pair":"US-10154254-B2 & US-9851565-B1","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-17T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8566117828},{"pair":"US-9779478-B1 & US-10241329-B2","patent_1":"US-9779478-B1","title_1":"Rendering composite content on a head-mounted display including a high resolution inset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US9779478B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display (HMD) divides an image into a high resolution (HR) inset portion at a first resolution, a peripheral portion, and a transitional portion. The peripheral portion is downsampled to a second resolution that is less than the first resolution. The transitional portion is blended such that there is a smooth change in resolution that corresponds to a change in resolution between a fovea region and a non-fovea region of a retina. An inset region is generated using the HR inset portion and the blended transitional portion, and a background region is generated using the downsampled peripheral portion. The inset region is provided to a HR inset display, and the background region is provided to a peripheral display. An optics block combines the displayed inset region with the displayed background region to generate composite content.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-10-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565949221},{"pair":"US-10154254-B2 & US-9870049-B2","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2017-01-17T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565937912},{"pair":"US-2019313087-A1 & US-9964767-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9964767-B2","title_2":"Display with reflected LED micro-display panels ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9964767B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A display apparatus includes a transparent substrate having first and second sides, an array of LED micro-display panels, and an array of collimating reflectors. The LED micro-display panels are disposed within the transparent substrate between the first and second sides and oriented to emit sub-image portions of a display image towards the first side. The collimating reflectors are disposed within the transparent substrate between the first side and the array of LED micro-display panels. The collimating reflectors are aligned with the LED micro-display panels to reflect the sub-image portions back out the second side of the transparent substrate. The LED micro-display panels are offset from the collimating reflectors to expand the sub-image portions prior to reflection by the collimating reflectors.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565836974},{"pair":"US-2018172999-A1 & US-10545347-B2","patent_1":"US-2018172999-A1","title_1":"Multifocal system with polarizing elements ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20180172999A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A head-mounted display (HMD) includes a multifocal block having one or more possible focal distances and includes a multifocal structure. The multifocal structure has a first focal distance and a second focal distance of the one or more possible focal distances. The multifocal structure includes one or more optical components positioned in series such that light from an electronic display is received and passes through each of the one or more optical components at least once before being output from the multifocal structure. The one or more optical components includes a switchable half waveplate (SHWP). The SHWP has a first state that causes the multifocal structure to output image light at the first focal distance, and a second state that causes the multifocal structure to output the image light at the first focal distance.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2016-12-20T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.856563474},{"pair":"US-10528128-B1 & US-2016357266-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2016357266-A1","title_2":"Methods And Systems For Hands-Free Browsing In A Wearable Computing Device ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160357266A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"Methods and systems for hands-free browsing in a wearable computing device are provided. A wearable computing device may provide for display a view of a first card of a plurality of cards which include respective virtual displays of content. The wearable computing device may determine a first rotation of the wearable computing device about a first axis and one or more eye gestures. Based on a combination of the first rotation and the eye gestures, the wearable computing device may provide for display the navigable menu, which may include an alternate view of the first card and at least a portion of one or more cards. Then, based on a determined second rotation of the wearable computing device about a second axis and based on a direction of the second rotation, the wearable computing device may generate a display indicative of navigation through the navigable menu.","priority_1":"2017-12-15T00:00:00","priority_2":"2014-01-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565535553},{"pair":"US-9984507-B2 & US-9851565-B1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2015-11-19T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565168268},{"pair":"US-2019384070-A1 & US-10545347-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-06-18T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565164068},{"pair":"US-10535319-B2 & US-9964767-B2","patent_1":"US-10535319-B2","title_1":"Apparatus, systems, and methods for displaying images in rotated display regions of display screens ","patent_2":"US-9964767-B2","title_2":"Display with reflected LED micro-display panels ","link_1":"https:\/\/patents.google.com\/patent\/US10535319B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9964767B2\/en","abstract_1":"The disclosed display device may include a display screen having (1) a front surface and (2) at least one display region that emits image light from the front surface, the at least one display region including a plurality of pixels arranged in a plurality of pixel rows and a plurality of pixel columns, the plurality of pixel rows and the plurality of pixel columns each extending obliquely relative to a peripheral edge of the front surface. The display device may also include a display driver circuit for driving the plurality of pixels of the at least one display region. The display driver circuit may be disposed adjacent to the peripheral edge of the front surface. Various other methods, systems, and devices are also disclosed.","abstract_2":"A display apparatus includes a transparent substrate having first and second sides, an array of LED micro-display panels, and an array of collimating reflectors. The LED micro-display panels are disposed within the transparent substrate between the first and second sides and oriented to emit sub-image portions of a display image towards the first side. The collimating reflectors are disposed within the transparent substrate between the first side and the array of LED micro-display panels. The collimating reflectors are aligned with the LED micro-display panels to reflect the sub-image portions back out the second side of the transparent substrate. The LED micro-display panels are offset from the collimating reflectors to expand the sub-image portions prior to reflection by the collimating reflectors.","priority_1":"2018-02-23T00:00:00","priority_2":"2016-03-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8565068022},{"pair":"US-10509228-B1 & US-10546518-B2","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-12-20T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8564657909},{"pair":"US-2020064633-A1 & US-2017235145-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-08-23T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8564528252},{"pair":"US-10488921-B1 & US-2019271844-A1","patent_1":"US-10488921-B1","title_1":"Pellicle beamsplitter for eye tracking ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10488921B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a pellicle beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The pellicle beamsplitter is positioned along the optical axis between the optics assembly and the electronic display. The pellicle beamsplitter includes a front surface and a back surface. Each of the front surface and the back surface comprising a first radius curvature in a first plane and a second radius curvature in a second plane that is perpendicular to the first plane.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-09-08T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8564467142},{"pair":"US-2018172995-A1 & US-9709797-B2","patent_1":"US-2018172995-A1","title_1":"Waveguide display with a small form factor, a large field of view, and a large eyebox ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20180172995A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"A waveguide display is used for presenting media to a user. The waveguide display includes light source assembly, an output waveguide, and a controller. The light source assembly includes one or more projectors projecting an image light at least along one dimension. The output waveguide includes a waveguide body with two opposite surfaces. The output waveguide includes a first grating receiving an image light propagating along an input wave vector, a second grating, and a third grating positioned opposite to the second grating and outputting an expanded image light with wave vectors matching the input wave vector. The controller controls the scanning of the one or more source assemblies to form a two-dimensional image.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2016-12-20T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8564290318},{"pair":"US-10481321-B1 & US-10162180-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-10162180-B2","title_2":"Efficient thin curved eyepiece for see-through head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10162180B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, an input coupler, and an output coupler. The curved lightguide component guides display light received at an input region peripherally located from a viewing region and emits the display light along an eye-ward direction in the viewing region. The curved lightguide component includes an eye-ward facing surface that is concave and a world facing surface that is convex. The input coupler is disposed at the input region to couple the display light into the curved lightguide component. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is partially transmissive to ambient light incident through the world facing surface. The display light is guided between the input coupler and the output coupler entirely by total internal reflection.","priority_1":"2018-09-06T00:00:00","priority_2":"2015-06-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8563835578},{"pair":"US-10529276-B2 & US-2017236466-A1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-2017236466-A1","title_2":"Foveally-rendered display ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170236466A1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A display system includes a display panel having an input to receive pixel data, the pixel data comprising a plurality of pixel values, an array of pixels partitioned into a foveal region and at least one peripheral region, and an array controller to group pixels in the at least one peripheral region into subsets of at least two pixels and to control each subset using a corresponding single pixel value from the plurality of pixel values. The display system further may include a rendering system to foveally render a display image based on the locations of the foveal region and the at least one peripheral regions, wherein for each row of the display image having pixels within at least one of the peripheral region, a number of pixel values represented in the pixel data for the row is less than a number of pixels in the row.","priority_1":"2018-01-05T00:00:00","priority_2":"2016-02-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8563754337},{"pair":"US-10481321-B1 & US-10146054-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-10146054-B2","title_2":"Adding prescriptive correction to eyepieces for see-through head wearable displays ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146054B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, a curved see-through component, an output coupler, and a prescription layer. The curved lightguide component guides display light received at an input region and releases the display light along an eye-ward direction in a viewing region. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is at least partially transmissive to ambient light incident through a world-facing side such that the viewing region is see-through. The curved see-through component is mated to the world-facing side of the curved lightguide component. The prescription layer has a first side mated to an eye-facing side of the curved lightguide component and a second side having a curvature that introduces prescriptive lensing to both the ambient light and the display light.","priority_1":"2018-09-06T00:00:00","priority_2":"2015-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8563686799},{"pair":"US-2019098276-A1 & US-10545215-B2","patent_1":"US-2019098276-A1","title_1":"3-d 360 degree depth projector ","patent_2":"US-10545215-B2","title_2":"4D camera tracking and optical stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20190098276A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545215B2\/en","abstract_1":"A camera system configured to generate depth information for a local area. The camera system comprises a plurality of depth camera sub-assemblies arranged in a substantially spherical arrangement. Each sub-assembly comprises a projector that projects a structured light pattern onto a portion of the local area, such that the projected light patterns of the plurality of sub-assemblies form a tiled light pattern covering 360 degrees of the local area. Each sub-assembly further comprises at least one camera is configured to capture images of the local area. A controller of the camera system is configured to receive the captured images and to construct a 360 degree depth map of the scene, based upon the structured light patterns projected by the projectors of the plurality captured in the received images.","abstract_2":"A light-field video stream may be processed to modify the camera pathway from which the light-field video stream is projected. A plurality of target pixels may be selected, in a plurality of key frames of the light-field video stream. The target pixels may be used to generate a camera pathway indicative of motion of the camera during generation of the light-field video stream. The camera pathway may be adjusted to generate an adjusted camera pathway. This may be done, for example, to carry out image stabilization. The light-field video stream may be projected to a viewpoint defined by the adjusted camera pathway to generate a projected video stream with the image stabilization.","priority_1":"2017-09-27T00:00:00","priority_2":"2017-09-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8563342184},{"pair":"US-10466496-B2 & US-2020041798-A1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-12-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562625649},{"pair":"US-10248001-B1 & US-9851565-B1","patent_1":"US-10248001-B1","title_1":"Varifocal structure comprising a liquid lens structure in optical series with a liquid crystal lens in a head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10248001B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A varifocal block includes liquid crystal (LC) lens and a liquid lens structure in optical series. The LC lens has a plurality of optical states, including an additive state that adds optical power to the LC lens and a subtractive state that removes optical power from the LC lens. The liquid lens structure comprises a transparent substrate layer, a deformable membrane, and a volume of liquid enclosed between the transparent substrate layer and the deformable membrane. The deformable membrane has an adjustable range of optical power dependent on an adjustable curvature of the deformable membrane. The plurality of optical states of the LC lens and the adjustable range of optical power of the liquid lens structure together provide a continuous range of optical power for the varifocal block.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-11-16T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562428246},{"pair":"US-10598938-B1 & US-10546518-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-11-09T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562258424},{"pair":"US-10572731-B1 & US-10546518-B2","patent_1":"US-10572731-B1","title_1":"Infrared transparent backlight device for eye tracking applications ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10572731B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A backlight device provides light in a first optical band to a spatial light modulator, and is transmissive to light in a second optical band. The backlight device includes a structured dichroic reflector that is substantially reflective, and scatters light in the first optical band. The structured dichroic reflector is also substantially transparent in the second optical band, and the second optical band is different than the first optical band. The backlight device is configured to receive light in the first optical band from an illumination source. The dichroic reflector is configured to reflect light in the first optical band toward a display panel that converts the light from the backlight device to image light. The backlight device may be part of a head-mounted display.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-03-13T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562008664},{"pair":"US-2018074318-A1 & US-9851565-B1","patent_1":"US-2018074318-A1","title_1":"Hybrid Fresnel Lens with Reduced Artifacts ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180074318A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens defined by a first lens surface and a second lens surface opposite to the first lens surface is disclosed. A first portion of the first lens surface is defined by a smooth surface profile function, and a second portion of the first lens surface is defined by a Fresnel surface profile function. The second portion of the first lens surface is around the first portion of the first lens surface. Also disclosed is a display device that includes the lens and an array of light emitting devices coupled with the lens for outputting light through the lens.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-09-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8561933368},{"pair":"US-2019318528-A1 & US-2016307368-A1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.856188252},{"pair":"US-2017295354-A1 & US-2017363949-A1","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-2017363949-A1","title_2":"Multi-tier camera rig for stereoscopic image capture ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170363949A1\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"In on the general aspect, a camera rig can include a first tier of images sensors including a first plurality of image sensors where the first plurality of image sensors are arranged in a circular shape and oriented such that a field of view of each of the first plurality of image sensors has an axis perpendicular to a tangent of the circular shape. The camera rig can include a second tier of image sensors including a second plurality of image sensors where the second plurality of image sensors are oriented such that a field of view of each of the second plurality of image sensors has an axis non-parallel to the field of view of each of the first plurality of image sensors.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.856148617},{"pair":"US-10495798-B1 & US-2017293143-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-08-07T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8561134036},{"pair":"US-10451947-B1 & US-9851565-B1","patent_1":"US-10451947-B1","title_1":"Apochromatic pancharatnam berry phase (PBP) liquid crystal structures for head-mounted displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10451947B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A Pancharatnam Berry Phase (PBP) liquid crystal structure for adjusting or focusing light of a plurality of color channels emitted by a display of a head-mounted display (HMD) comprises a plurality of PBP active elements. Each PBP active element of the structure is configured to act as a half waveplate for light of a corresponding color channel, such that light of the corresponding color channel is adjusted by a predetermined amount. In addition, each PBP active element acts as a one waveplate for light of the remaining color channels, such that light of the remaining color channels passes through the PBP active element substantially unaffected. As such, the PBP structure is able to adjust incident light of the plurality of color channels uniformly in an apochromatic fashion.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-10-31T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8560619056},{"pair":"US-10481321-B1 & US-10546518-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-09-06T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8560445642},{"pair":"US-10529276-B2 & US-10572764-B1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-10572764-B1","title_2":"Adaptive stereo rendering to reduce motion sickness ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10572764B1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"Techniques of displaying video in an HMD include performing an adaptive rendering operation to produce a transition between stereo and non-stereo rendering of objects in a virtual environment during eye saccade. Because viewers generally have low visual perception performance during eye saccade, the viewer will not notice this transition as much and will not experience as much motion sickness.","priority_1":"2018-01-05T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8560125992},{"pair":"US-2019318528-A1 & US-2017032568-A1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559976599},{"pair":"US-2020083402-A1 & US-9798147-B1","patent_1":"US-2020083402-A1","title_1":"Mesa formation for wafer-to-wafer bonding ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20200083402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"Disclosed herein are techniques for wafer-to-wafer bonding for manufacturing light emitting diodes (LEDs). In some embodiments, a method of manufacturing LEDs includes etching a semiconductor material to form a plurality of adjacent mesa shapes. The semiconductor material includes one or more epitaxial layers. The method also includes forming a passivation layer within gaps between the adjacent mesa shapes and bonding a base wafer to a first surface of the semiconductor material.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2018-09-11T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559736157},{"pair":"US-10474229-B1 & US-9285877-B2","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-9285877-B2","title_2":"Heads-up display ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9285877B2\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"Embodiments of an apparatus comprising a light guide including a proximal end, a distal end, a display positioned near the proximal end, an eye-measurement camera positioned at or near the proximal end to image eye-measurement radiation, a proximal optical element positioned in the light guide near the proximal end and a distal optical element positioned in the light guide near the distal end. The proximal optical element is optically coupled to the display, the eye-measurement camera and the distal optical element and the distal optical element is optically coupled to the proximal optical element, the ambient input region and the input\/output region. Other embodiments are disclosed and claimed.","priority_1":"2017-11-01T00:00:00","priority_2":"2012-02-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.855961516},{"pair":"US-10600352-B1 & US-10095036-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-10095036-B2","title_2":"Compact near-eye display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10095036B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"Systems and methods that employ a near-eye display system including an optical assembly are described. The optical assembly may include a head-mounted display device worn by a user in which the head-mounted display device adapted to house an image projecting device and an optical assembly. The optical assembly may include, for at least one eyepiece, a first flat filter stack operable to be oriented in a first direction. and a second flat filter stack operable to be oriented in a second direction. The near-eye display system assembly may also include a display panel adapted to receive image content from the image projecting device, wherein the display panel is adapted to be oriented in the second direction.","priority_1":"2018-12-04T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559508448},{"pair":"US-2019384070-A1 & US-10133074-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-10133074-B2","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10133074B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"Systems and methods are described for receiving image content from an emissive display toward a first filter stack, the first filter stack adapted to be oriented in a first direction from an optical axis of a first lens, and toward the first lens, transmitting the image content through a curved lens parallel to the optical axis of the first lens, wherein the curved lens transmits a portion of the image content to at least one optical element and to a second filter stack, the second filter stack being adapted to be oriented in a second direction from the optical axis of the first lens, and receiving the portion from the second filter stack and providing at least some of the portion to the first lens for viewing by a user.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559469302},{"pair":"US-10595000-B1 & US-2017148206-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2017148206-A1","title_2":"Electronic display stabilization using pixel velocities ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170148206A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A system includes a head mounted display (HMD) device comprising at least one display and at least one sensor to provide pose information for the HMD device. The system further includes a sensor integrator module coupled to the at least one sensor, the sensor integrator module to determine a motion vector for the HMD device based on the pose information, and an application processor to render a first texture based on pose of the HMD device determined from the pose information. The system further includes a motion analysis module to determine a first velocity field having a pixel velocity for at least a subset of pixels of the first texture, and a compositor to render a second texture based on the first texture, the first velocity field and the motion vector for the HMD, and to provide the second texture to the display of the HMD device.","priority_1":"2018-08-02T00:00:00","priority_2":"2015-11-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.855940973},{"pair":"US-2019049720-A1 & US-9851565-B1","patent_1":"US-2019049720-A1","title_1":"Camera assembly with programmable diffractive optical element for depth sensing ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190049720A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A depth camera assembly (DCA) for depth sensing of a local area includes a structured light generator, an imaging device, and a controller. The structured light generator illuminates the local area with a structured light pattern. The structured light generator includes a programmable diffractive optical element (PDOE) that generates diffracted scanning beams using optical beams. The PDOE functions as a dynamic diffraction grating that dynamically adjusts diffraction of the optical beams to generate the diffracted scanning beams of different patterns. The diffracted scanning beams are projected as the structured light pattern into the local area, wherein the structured light pattern is dynamically adjustable based on the PDOE. The imaging device captures image(s) of at least a portion of the structured light pattern reflected from object(s) in the local area. The controller determines depth information for the object(s) based on the captured image(s).","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-08-14T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559399065},{"pair":"US-2019384378-A1 & US-10241329-B2","patent_1":"US-2019384378-A1","title_1":"Flexure based guidance system for varifocal head-mounted displays ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190384378A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A varifocal head mounted display (HMD) includes an electronic display, an optical system, and the guidance system. The electronic display presents content. The optical system includes one or more optical elements and provides the content to an eyebox of the HMD. The guidance system is a flexure based guidance system that includes an actuator and a first and second flexure elements (e.g., parallel beam, dual Roberts, etc.) guiding movement of the electronic display along an optical axis of the optical system in order to adjust a location of one or moveable elements in the optical system and, thereby, control a location of an image plane. The first and second flexure elements are able to flex or bend with movement of the actuator to adjust the location of the one or moveable elements that includes the electronic display and\/or one or more optical elements of the optical system.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-06-15T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559373383},{"pair":"US-2019101767-A1 & US-10302945-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-10302945-B2","title_2":"Near-eye display with stacked lightguides ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10302945B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"Embodiments are described of an apparatus including an eyepiece having a front surface, a back surface spaced apart from the front surface, and an edge forming a perimeter of the eyepiece. The eyepiece includes an angled surface to direct light eye-measurement light reflected from an eye into the eyepiece and to direct display light out of the eyepiece to the eye. A first waveguide is formed in the eyepiece and extending from the angled surface to the edge, the first waveguide being optically coupled to a first portion of the angled surface having a first surface treatment. And a second waveguide is formed in the eyepiece and extending from the angled surface to the edge, the second waveguide being optically coupled to a second portion of the angled surface having a second surface treatment.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-08-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559342387},{"pair":"US-2017358136-A1 & US-2020041798-A1","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-06-10T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559269865},{"pair":"US-2018196509-A1 & US-9934583-B2","patent_1":"US-2018196509-A1","title_1":"Eye tracking architecture for common structured light and time-of-flight framework ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20180196509A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on combining structured light information and time-of-flight information. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source modulates a structured light by a carrier signal and illuminates a user's eye with the modulated structured light. The imaging device includes a detector that captures the modulated structured light. The detector comprises a plurality of pixel groups, each pixel group receiving a control signal determining when a pixel group captures light, the control signal causing pixel groups to capture light at different times relative to other pixel groups. The controller determines phases of the carrier signal based on intensities of light received by different pixel groups and generates depth information related to surfaces of the user's eye, which is used to model and track the user's eye.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-01-06T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8559051805},{"pair":"US-2020064641-A1 & US-10162180-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10162180-B2","title_2":"Efficient thin curved eyepiece for see-through head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10162180B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, an input coupler, and an output coupler. The curved lightguide component guides display light received at an input region peripherally located from a viewing region and emits the display light along an eye-ward direction in the viewing region. The curved lightguide component includes an eye-ward facing surface that is concave and a world facing surface that is convex. The input coupler is disposed at the input region to couple the display light into the curved lightguide component. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is partially transmissive to ambient light incident through the world facing surface. The display light is guided between the input coupler and the output coupler entirely by total internal reflection.","priority_1":"2018-08-24T00:00:00","priority_2":"2015-06-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8558744808},{"pair":"US-2019384070-A1 & US-10095036-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-10095036-B2","title_2":"Compact near-eye display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10095036B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"Systems and methods that employ a near-eye display system including an optical assembly are described. The optical assembly may include a head-mounted display device worn by a user in which the head-mounted display device adapted to house an image projecting device and an optical assembly. The optical assembly may include, for at least one eyepiece, a first flat filter stack operable to be oriented in a first direction. and a second flat filter stack operable to be oriented in a second direction. The near-eye display system assembly may also include a display panel adapted to receive image content from the image projecting device, wherein the display panel is adapted to be oriented in the second direction.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8558708997},{"pair":"US-10488921-B1 & US-2019101757-A1","patent_1":"US-10488921-B1","title_1":"Pellicle beamsplitter for eye tracking ","patent_2":"US-2019101757-A1","title_2":"Eye tracking using light guide with faceted combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10488921B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190101757A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a pellicle beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The pellicle beamsplitter is positioned along the optical axis between the optics assembly and the electronic display. The pellicle beamsplitter includes a front surface and a back surface. Each of the front surface and the back surface comprising a first radius curvature in a first plane and a second radius curvature in a second plane that is perpendicular to the first plane.","abstract_2":"An eye tracking system includes a light guide comprising a first eye-facing surface, a second surface, a third surface, and a plurality of facets formed in the second surface. The facets reflect a portion of light incident on a user eye into the light guide, which is positioned proximate to the user eye and between the user eye and a display. A surface of a compensator may be shaped complementary to the second surface of the light guide and placed proximate to the light guide. A camera or image sensor is oriented toward the third surface of the light guide and captures an image based on internally reflected light. An IR light source may be included. The image sensor may be an IR image sensor. Based on the image, a pose of the user eye is determined. A faceted light guide assembly may include a reflective coating adjacent the facets.","priority_1":"2017-09-08T00:00:00","priority_2":"2017-10-02T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8558686477},{"pair":"US-10495798-B1 & US-10365491-B1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-10365491-B1","title_2":"Head-mounted display including diffractive combiner to integrate a display and an eye-tracking sensor ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10365491B1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An apparatus comprising a diffractive combiner having a front side, a back side, and a combiner optical axis running substantially through the diffractive combiner and normal to the back side. A display unit having a display optical axis that directs the display light along the display optical axis toward the diffractive combiner. An eye-tracking sensor having a sensor optical axis that is positioned to receive eye-tracking radiation reflected by the diffractive combiner along the sensor optical axis. The combiner optical axis, the display optical axis, and the sensor optical axis intersect each other at the diffractive combiner.","priority_1":"2018-08-07T00:00:00","priority_2":"2013-04-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.855867875},{"pair":"US-10474229-B1 & US-9851565-B1","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-11-01T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8558263487},{"pair":"US-2017352178-A1 & US-9536354-B2","patent_1":"US-2017352178-A1","title_1":"Facial animation using facial sensors within a head-mounted display ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20170352178A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A facial tracking system generates a virtual rendering of a portion of a face of a user wearing a head-mounted display (HMD). The facial tracking system illuminates portions of the face inside the HMD. The facial tracking system captures a plurality of facial data of the portion of the face using one or more facial sensors located inside the HMD. A plurality of planar sections of the portion of the face are identified based at least in part on the plurality of facial data. The plurality of planar sections are mapped to one or more landmarks of the face. Facial animation information is generated based at least in part on the mapping, the facial animation information describing a portion of a virtual face corresponding to the portion of the user's face.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8558163304},{"pair":"US-10474229-B1 & US-2019101757-A1","patent_1":"US-10474229-B1","title_1":"Folded viewing optics with high eye tracking contrast ratio ","patent_2":"US-2019101757-A1","title_2":"Eye tracking using light guide with faceted combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10474229B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190101757A1\/en","abstract_1":"An apparatus includes a display configured to emit display light, an optical system configured to provide the display light to an eye of a user and an eye tracking system. The optical system includes a plurality of optical surfaces. The optical system is disposed between an eye tracking light detector and the eye of the user such that a portion of the eye tracking light that is reflected from the eye of the user and is transmitted through the optical system and also reflects from an optical surface of the optical system to generate one or more parasitic reflections of the eye tracking light. At least one of the plurality of optical surfaces is configured to reduce an intensity of the one or more parasitic reflections as measured on a surface of the eye tracking detector.","abstract_2":"An eye tracking system includes a light guide comprising a first eye-facing surface, a second surface, a third surface, and a plurality of facets formed in the second surface. The facets reflect a portion of light incident on a user eye into the light guide, which is positioned proximate to the user eye and between the user eye and a display. A surface of a compensator may be shaped complementary to the second surface of the light guide and placed proximate to the light guide. A camera or image sensor is oriented toward the third surface of the light guide and captures an image based on internally reflected light. An IR light source may be included. The image sensor may be an IR image sensor. Based on the image, a pose of the user eye is determined. A faceted light guide assembly may include a reflective coating adjacent the facets.","priority_1":"2017-11-01T00:00:00","priority_2":"2017-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557924165},{"pair":"US-10356407-B2 & US-10572764-B1","patent_1":"US-10356407-B2","title_1":"Display-side video decompression using quantization tables ","patent_2":"US-10572764-B1","title_2":"Adaptive stereo rendering to reduce motion sickness ","link_1":"https:\/\/patents.google.com\/patent\/US10356407B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10572764B1\/en","abstract_1":"Embodiments relate to a method and a system for performing image compression and decompression of image data. In one or more embodiments, the image data is divided into one or more image data blocks, and the image compression and decompression are performed for each image data block. The image data block is compressed and includes a base value corresponding to a first image component and a compressed difference value corresponding to a second image component. For decompression, a first value of the image data block can be obtained based on the base value, and a second value of the image data block can be obtained based on the first value, the first compressed difference value and a corresponding quantization table. An output image can be presented to a user, according to the decompressed image data block.","abstract_2":"Techniques of displaying video in an HMD include performing an adaptive rendering operation to produce a transition between stereo and non-stereo rendering of objects in a virtual environment during eye saccade. Because viewers generally have low visual perception performance during eye saccade, the viewer will not notice this transition as much and will not experience as much motion sickness.","priority_1":"2015-11-20T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557766328},{"pair":"US-10379419-B1 & US-2020073123-A1","patent_1":"US-10379419-B1","title_1":"Focus adjusting pancharatnam berry phase liquid crystal lenses in a head-mounted display ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10379419B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A varifocal block includes, in optical series, a switchable half waveplate (SHWP) and a plurality of liquid crystal (LC) lenses. The SHWP outputs circularly polarized light, and a handedness of the circularly polarized light is controlled by the SHWP being in an active state or a non-active state. Each LC lens of the plurality of LC lenses has a plurality of optical states, the plurality of optical states including an additive state that adds optical power to the LC lens and a subtractive state that removes optical power from the LC lens. The plurality of optical states of each of the plurality of the LC lenses compounded in optical series provides a range of adjustment of optical power for the varifocal block.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2016-11-23T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557660414},{"pair":"US-2017295354-A1 & US-9900510-B1","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-9900510-B1","title_2":"Motion blur for light-field images ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9900510B1\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"Motion blur may be applied to a light-field image. The light-field image may be captured with a light-field camera having a main lens, an image sensor, and a plurality of microlenses positioned between the main lens and the image sensor. The light-field image may have a plurality of lenslet images, each of which corresponds to one microlens of the microlens array. The light-field image may be used to generate a mosaic of subaperture images, each of which has pixels from the same location on each of the lenslet images. Motion vectors may be computed to indicate motion occurring within at least a primary subaperture image of the mosaic. The motion vectors may be used to carry out shutter reconstruction of the mosaic to generate a mosaic of blurred subaperture images, which may then be used to generate a motion-blurred light-field image.","priority_1":"2016-04-06T00:00:00","priority_2":"2016-12-08T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557587349},{"pair":"US-10595000-B1 & US-2018261003-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2018261003-A1","title_2":"Reducing visually induced motion sickness in head mounted display systems ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180261003A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A head mounted display (HMD) for displaying images to a user includes a sensor unit configured to detect motion of a head of the user of the HMD. The HMD also includes one or more processors configured to, in response to the motion, reduce contrast in a peripheral area of an image displayed to the user from an original contrast of the image, the image having a foveal area and the peripheral area relative to the optical axis of the eye of the user, the contrast being least reduced in a first portion of the peripheral area closest the foveal area and being most reduced in a second portion of the peripheral area farthest from the foveal area.","priority_1":"2018-08-02T00:00:00","priority_2":"2017-03-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557490895},{"pair":"US-10108261-B1 & US-9851565-B1","patent_1":"US-10108261-B1","title_1":"Eye tracking based on light polarization ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10108261B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using polarization. The eye tracking system includes an illumination source and an eye tracking unit comprising a polarization sensitive optical detector. The one or more illumination sources are configured to illuminate an eye and generate reflections directed towards the optical detector. The eye tracking unit is configured to determine a 3D shape of the eye based on the polarization of the reflections. The determined 3D shape of the eye is used to update a stored model of the eye in response to the one or more model parameter values extracted from the determined depth map of the corneal surface. The eye tracking system determines eye tracking information based on the updated model in order to improve eye tracking performance.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-07-05T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557328884},{"pair":"US-10317680-B1 & US-2019037194-A1","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2017-11-09T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557298811},{"pair":"US-10261324-B2 & US-2019271844-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-08-10T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557154089},{"pair":"US-10528128-B1 & US-2015242414-A1","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2017-12-15T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.855663443},{"pair":"US-2019318530-A1 & US-2016307368-A1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8556559178},{"pair":"US-2018232047-A1 & US-2016057339-A1","patent_1":"US-2018232047-A1","title_1":"Selective Color Sensing for Motion Tracking ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US20180232047A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"An electronic device is configured to select a first set of one or more distinct wavelengths for tracking a first portable device in communication with the electronic device; and, subsequent to selecting the first set of one or more distinct wavelengths for tracking the first portable device, initiate the first portable device to emit light of the first set of one or more selected wavelengths; receive information identifying one or more respective intensities of light, detected by the one or more optical sensors, for the first set of one or more selected wavelengths; and determine a position of the first portable device based on the information identifying the one or more respective intensities of light, detected by the one or more optical sensors, for the first set of one or more selected wavelengths. A method for determining a position of the first portable device is also described.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2017-02-14T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8556494515},{"pair":"US-10248842-B1 & US-2018101984-A1","patent_1":"US-10248842-B1","title_1":"Face tracking using structured light within a head-mounted display ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US10248842B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A head mounted display (HMD) displays content to a user wearing the HMD, where the content may be based on a facial model of the user. The HMD uses an electronic display to illuminate a portion of the face of the user with. The electronic display emits a pattern of structured light and\/or monochromatic light of a given color. A camera assembly captures images of the illuminated portion of the face. A controller processes the captured images to determine depth information or color information of the face of the user. Further, the processed images may be used to update the facial model, for example, which is represented as a virtual avatar and presented to the user in a virtual reality, augmented reality, or mixed reality environment.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-01-09T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8556447903},{"pair":"US-2019353898-A1 & US-10545347-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-05-18T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.855576079},{"pair":"US-9984507-B2 & US-2017180721-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2017180721-A1","title_2":"System and method for performing electronic display stabilization via retained lightfield rendering ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180721A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"In a system having a user-portable display device, a method includes maintaining a lightfield data structure representing at least a portion of a four-dimensional (4D) lightfield for a three-dimensional (3D) world in association with a first pose of the user-portable display device relative to the 3D world. The method further includes determining a second pose of the user-portable display device relative to the 3D world, the second pose comprising an updated pose of the user-portable display device. The method additionally includes generating a display frame from the lightfield data structure based on the second pose, the display frame representing a field of view of the 3D world from the second pose.","priority_1":"2015-11-19T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8555618291},{"pair":"US-2019318530-A1 & US-2017032568-A1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8555539901},{"pair":"US-10529117-B2 & US-2017032568-A1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8555538093},{"pair":"US-2017371159-A1 & US-9536354-B2","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2016-06-28T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.855540103},{"pair":"US-2020083399-A1 & US-9798147-B1","patent_1":"US-2020083399-A1","title_1":"Methods for wafer-to-wafer bonding ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20200083399A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"Disclosed herein are techniques for wafer-to-wafer bonding for manufacturing light emitting diodes (LEDs). In some embodiments, a method of manufacturing LEDs includes modifying a p-type layer of a semiconductor material to form a plurality of alternating high resistivity areas and low resistivity areas, wherein the low resistivity areas correspond to light emitters; bonding a base wafer to a first surface of the p-type layer; removing a substrate from a second surface of the semiconductor material, wherein the second surface of the semiconductor material is opposite to the first surface of the p-type layer; and patterning a trench between each adjacent pair of the light emitters.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2018-09-11T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8555267978},{"pair":"US-10599215-B2 & US-2019020869-A1","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-04-26T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8555142297},{"pair":"US-10522110-B1 & US-2018261003-A1","patent_1":"US-10522110-B1","title_1":"Apparatuses, systems, and methods for measuring and adjusting the luminance of a head-mounted display ","patent_2":"US-2018261003-A1","title_2":"Reducing visually induced motion sickness in head mounted display systems ","link_1":"https:\/\/patents.google.com\/patent\/US10522110B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180261003A1\/en","abstract_1":"An ocular assembly for a head-mounted display may include an opaque enclosure that defines (1) an interior space, (2) an exterior space, (3) a display aperture that admits image light emitted by a display screen into the interior space, (4) a lens aperture, and (5) a lateral aperture that admits the light from the interior space into the exterior space. The ocular assembly may also include an opaque covering for the lateral aperture that is moveable between (1) a closed position that prevents the image light from passing from the interior space through the lateral aperture to the exterior space and (2) an open position that allows the image light to pass from the interior space through the lateral aperture to the exterior space. Various other apparatuses, methods, and systems are also disclosed.","abstract_2":"A head mounted display (HMD) for displaying images to a user includes a sensor unit configured to detect motion of a head of the user of the HMD. The HMD also includes one or more processors configured to, in response to the motion, reduce contrast in a peripheral area of an image displayed to the user from an original contrast of the image, the image having a foveal area and the peripheral area relative to the optical axis of the eye of the user, the contrast being least reduced in a first portion of the peripheral area closest the foveal area and being most reduced in a second portion of the peripheral area farthest from the foveal area.","priority_1":"2017-08-30T00:00:00","priority_2":"2017-03-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8555102323},{"pair":"US-10200624-B2 & US-2017026592-A1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-2017026592-A1","title_2":"Automatic lens flare detection and correction for light-field images ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170026592A1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"According to various embodiments, the system and method disclosed herein process light-field image data so as to mitigate lens flare effects. A light-field image may be captured with a light-field image capture device with a microlens array and received in a data store. A plurality of flare-affected pixels may be identified in the light-field image. The flare-affected pixels may have flare-affected pixel values. Flare-corrected pixel values may be generated for the flare-affected pixels. Relative to the flare-affected pixel values, the flare-corrected pixel values may at least partially remove the lens flare effects. The flare-corrected pixel values may be used to generate a corrected light-field image in which the lens flare effects are at least partially corrected. The corrected light-field image may be displayed on a display screen.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-07-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8554826929},{"pair":"US-10534185-B1 & US-2020041798-A1","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-02-14T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8554797083},{"pair":"US-2019285891-A1 & US-2018343443-A1","patent_1":"US-2019285891-A1","title_1":"Image quality of pancharatnam berry phase components using polarizers ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20190285891A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"Various embodiments set forth a near eye display (NED) that includes an electronic display configured to output image light. Further, the NED includes multiple Pancharatnam Berry Phase (PBP) optical elements that are combined with one or more circular polarizers to improve optical performance. A PBP element produces an output of three diffraction orders. Typically in an optical system that includes such a PBP element, one of the three diffraction orders is used while the other two are undesirable and preferably maintained at a relatively low intensity. A circular polarizer may reduce the intensities of the two undesired diffraction orders.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-03-15T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8554029723},{"pair":"US-2017295324-A1 & US-2016353082-A1","patent_1":"US-2017295324-A1","title_1":"Three-dimensional, 360-degree virtual reality camera system ","patent_2":"US-2016353082-A1","title_2":"Capturing light-field images with uneven and\/or incomplete angular sampling ","link_1":"https:\/\/patents.google.com\/patent\/US20170295324A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160353082A1\/en","abstract_1":"A camera system is configured to capture 360 degree image information of a local area, at least a portion of which is in stereo. The camera system includes a plurality of peripheral cameras, a plurality of axis cameras, a first rigid plate, and a second rigid plate, each aligned along an alignment axis. The peripheral cameras are arranged in a ring configuration that allows objects in the local area past a threshold distance to be within the fields of view of at least two peripheral cameras. The first and second rigid plates secure to a top and a bottom surface of the ring of peripheral cameras, respectively. At least one axis camera is arranged along the alignment axis and is coupled perpendicularly to a surface of the first rigid plate.","abstract_2":"A light-field camera may generate four-dimensional light-field data indicative of incoming light. The light-field camera may have an aperture configured to receive the incoming light, an image sensor, and a microlens array configured to redirect the incoming light at the image sensor. The image sensor may receive the incoming light and, based on the incoming light, generate the four-dimensional light-field data, which may have first and second spatial dimensions and first and second angular dimensions. The first angular dimension may have a first resolution higher than a second resolution of the second angular dimension.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553977719},{"pair":"US-2020083402-A1 & US-9810910-B1","patent_1":"US-2020083402-A1","title_1":"Mesa formation for wafer-to-wafer bonding ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US20200083402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"Disclosed herein are techniques for wafer-to-wafer bonding for manufacturing light emitting diodes (LEDs). In some embodiments, a method of manufacturing LEDs includes etching a semiconductor material to form a plurality of adjacent mesa shapes. The semiconductor material includes one or more epitaxial layers. The method also includes forming a passivation layer within gaps between the adjacent mesa shapes and bonding a base wafer to a first surface of the semiconductor material.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2018-09-11T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553817187},{"pair":"US-10529117-B2 & US-2016307368-A1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553788308},{"pair":"US-10595000-B1 & US-2019129174-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2019129174-A1","title_2":"Multi-perspective eye-tracking for vr\/ar systems ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190129174A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A display system, such as a head mounted display, tracks a pose of a user's eye based on multiple perspectives of the eye captured via a segmented optics array, such as a lenslet array or Fresnel lens. The display system reflects light (e.g., infra-red light) off each segment of the segmented optics array, and captures an image based on the reflected light. Because of the segmented optics, the captured image represents multiple concurrent perspectives of the user's eye. The display system analyzes the different perspectives and selects a perspective, or combination of perspectives, and based on the selected perspective or combination, identifies a pose of the user's eye.","priority_1":"2018-08-02T00:00:00","priority_2":"2017-10-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553723219},{"pair":"US-2019212482-A1 & US-2017147859-A1","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-01-10T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553676775},{"pair":"US-10120193-B2 & US-10545347-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2017-01-27T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553624891},{"pair":"US-10175414-B2 & US-2015146301-A1","patent_1":"US-10175414-B2","title_1":"Channel cut backlight for liquid crystal display ","patent_2":"US-2015146301-A1","title_2":"Lighting adjustment for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10175414B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150146301A1\/en","abstract_1":"A liquid crystal display (LCD) device a LCD panel and a segmented backlight for illuminating the LCD panel. The backlight includes a light guide having an array of light channels. The array of light channels is defined by an array of notches on the bottom surface of the light guide. Light emitting diodes (LEDs) are disposed along the side surface of the light guide to emit light in a first direction into the array of light channels of the light guide. The array of light channels receives the light from the LEDs and directs the light in a second direction from the top surface of the light guide toward the LCD panel. One or more LEDs may selectively emit light into each light channel. The notches defined between light channels controls light leakage across adjacent light channels.","abstract_2":"An apparatus includes a light source, a display array, a light relay, a photodetector, and control circuitry. The light source is for providing lamp light during an ON-time of the light source. The display array is positioned to receive and selectively manipulate the lamp light. The light relay is positioned to receive the image light from the display array. Control circuitry is coupled to the light source for adjusting the light source and coupled to receive an output of the photodetector.","priority_1":"2017-01-11T00:00:00","priority_2":"2012-03-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553499524},{"pair":"US-10168531-B1 & US-9851565-B1","patent_1":"US-10168531-B1","title_1":"Lightfield waveguide integrated eye tracking ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10168531B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An eye tracker for determining a position of an eye, which may be integrated into a head-mounted display. The eye tracker includes at least one waveguides with an array of grating structures, an array of light sources, a detector, and a controller. The controller activates at least one light source at a time to emit at least one light beam that propagates through the at least one waveguide and couple out via the array of grating structures towards a user's eye. Light signals reflected from the user's eye and skin surfaces are coupled into the at least one waveguide and propagate to the detector that captures the reflected light signals. The controller calculates magnitudes of the reflected light signals to obtain a signature of converted light signals, and determines a position and orientation of the user's eye based on the signature of converted light signals.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8553044154},{"pair":"US-10595000-B1 & US-2018350032-A1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-2018350032-A1","title_2":"Smoothly varying foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180350032A1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"Systems and methods for performing foveated rendering are provided. An example system and method may warp a 3D scene based on a fixation point. The system and method may also render the warped 3D scene to generate a first image. The system and method may also unwarp the first image to generate a second image. For example, the first image may have fewer pixels than the second image.","priority_1":"2018-08-02T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8552455592},{"pair":"US-2019384070-A1 & US-2019018255-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2019018255-A1","title_2":"Compact near-eye optical system including a refractive beam-splitting convex lens ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190018255A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An optical system includes a first filter stack to convert light to a first circular polarization, and a second filter stack that reflects light having the first circular polarization and transmits light having a second circular polarization. A refractive beam splitting convex lens is disposed intermediate the first filter stack and the second filter stack. The first filter stack can include a first linear polarizer to convert light to a first linear polarization and a first quarter wave plate to convert the light from the first linear polarization to a first circular polarization. The second filter stack can include a second quarter wave plate to convert the light from the first circular polarization to a second linear polarization that is transverse to the first linear polarization, a polarization-dependent beam splitter to pass the first polarization and reflect the second polarization, and a linear polarizer to pass the second polarization.","priority_1":"2018-06-18T00:00:00","priority_2":"2017-07-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8552363919},{"pair":"US-9910282-B2 & US-10546518-B2","patent_1":"US-9910282-B2","title_1":"Increasing field of view of head-mounted display using a mirror ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US9910282B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) (e.g., VR headset or AR headset) displays a 3D virtual scene and includes a mirror to increase a field of view (FOV). The HMD includes an electronic display that further includes a primary display and an extended display, where the content displayed on the primary display is presented to the user's eye at an exit pupil through a lens and content displayed on the extended display is presented at the exit pupil through reflections of the mirror. The mirror is positioned between the exit pupil and the electronic display such that the mirror reflects light originating from the extended display and provides the reflected light to the exit pupil to increase the FOV. The combination of the content viewed through the lens and that of the reflected light of the extended display results in an FOV larger than when the content is viewed only through the lens.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2015-12-28T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8552255658},{"pair":"US-10595000-B1 & US-10572761-B1","patent_1":"US-10595000-B1","title_1":"Systems and methods for using depth information to extrapolate two-dimentional images ","patent_2":"US-10572761-B1","title_2":"Virtual reality system using super-resolution ","link_1":"https:\/\/patents.google.com\/patent\/US10595000B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10572761B1\/en","abstract_1":"The disclosed computer-implemented method may include (1) receiving a first 2D frame depicting an evolving 3D scene and elements in the evolving 3D scene, (2) receiving a second 2D frame depicting the evolving 3D scene and the elements, (3) deriving 2D motion vectors from the first 2D frame and the second 2D frame that each include an estimated offset from coordinates of an element in the first 2D frame to coordinates of the element in the second 2D frame, (4) receiving depth information for the evolving 3D scene, (5) using the 2D motion vectors and the depth information to extrapolate a synthetic 2D frame, and (6) displaying the synthetic 2D frame to a user. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"Displaying video in an HMD may include introducing unperceived noise to the video frame signal in order to enhance dynamic range. For example, each of a viewer's left and right eyes have a field of view (FOV) corresponding to a portion of pixels shown on the HMD. For each of these portions of pixels, the VR system may combine a noise signal (e.g., zero-mean Gaussian white noise) with the video signals corresponding to each of the portions of pixels. The introduction of such noise may improve the dynamic range of the viewer. Further, in some implementations, the noise signal that is combined with the left video signal may be slightly different from the noise signal that is combined with the right video signal. Such slightly different noise signals may provide further improvement to the image seen by the viewer due to binocular summation.","priority_1":"2018-08-02T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8552009093},{"pair":"US-2019212482-A1 & US-10591731-B2","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2018-01-10T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8551724743},{"pair":"US-2017293146-A1 & US-2015169054-A1","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2016-04-07T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8551670311},{"pair":"US-10317680-B1 & US-9934583-B2","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-11-09T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8551632126},{"pair":"US-10529117-B2 & US-9704282-B1","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8551547525},{"pair":"US-10466779-B1 & US-2019020869-A1","patent_1":"US-10466779-B1","title_1":"Event camera for eye tracking ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10466779B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An eye tracking system includes an event camera. The event camera includes an event sensor and a controller. The event sensor includes a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes of light reflected from a user's eyes. The controller populates an event matrix based in part on data values asynchronously received from the event sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image of the user's eyes for the first time period using the event matrix and the change matrix. The eye tracking system uses the image of the user's eyes to determine eye tracking information indicating positions, orientations and\/or movement of the user's eyes.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-07-24T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8551371013},{"pair":"US-2019342647-A1 & US-9900676-B2","patent_1":"US-2019342647-A1","title_1":"Hybrid audio system for eyewear devices ","patent_2":"US-9900676-B2","title_2":"Wearable computing device with indirect bone-conduction speaker ","link_1":"https:\/\/patents.google.com\/patent\/US20190342647A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9900676B2\/en","abstract_1":"An audio system for providing content to a user. The system includes a first and a second transducer assembly of a plurality of transducer assemblies, an acoustic sensor, and a controller. The first transducer assembly couples to a portion of an auricle of the user's ear and vibrates over a first range of frequencies based on a first set of audio instructions. The vibration causes the portion of the ear to create a first range of acoustic pressure waves. The second transducer assembly is configured to vibrate over a second range of frequencies to produce a second range of acoustic pressure waves based on a second set of audio instructions. The acoustic sensor detects acoustic pressure waves at an entrance of the ear. The controller generates the audio instructions based on audio content to be provided to the user and the detected acoustic pressure waves from the acoustic sensor.","abstract_2":"Exemplary wearable computing systems may include a head-mounted display that is configured to provide indirect bone-conduction audio. For example, an exemplary head-mounted display may include at least one vibration transducer that is configured to vibrate at least a portion of the head-mounted display based on the audio signal. The vibration transducer is configured such that when the head-mounted display is worn, the vibration transducer vibrates the head-mounted display without directly vibrating a wearer. However, the head-mounted display structure vibrationally couples to a bone structure of the wearer, such that vibrations from the vibration transducer may be indirectly transferred to the wearer's bone structure.","priority_1":"2018-05-01T00:00:00","priority_2":"2011-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8551221124},{"pair":"US-2019318529-A1 & US-2017032568-A1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8550906303},{"pair":"US-10429927-B1 & US-2020041798-A1","patent_1":"US-10429927-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10429927B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8550891517},{"pair":"US-2020081252-A1 & US-2019271844-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-03-15T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.854999105},{"pair":"US-2018284884-A1 & US-2018343443-A1","patent_1":"US-2018284884-A1","title_1":"Waveguide display with spatially switchable grating ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20180284884A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A near-eye-display (NED) includes an eye tracking system and a waveguide display. The eye tracking system tracks locations based on a location of the user's eyes. The waveguide display includes a light source, an output waveguide and a controller. The output waveguide includes a dynamic output grating that outputs an expanded image light to the tracked eyebox locations. The decoupling grating is a 2D array of spatially switchable liquid crystal (LC) pixels including an active subset of LC pixels emitting light to regions within the tracked eyebox locations. The decoupling grating dynamically out-couples the expanded image light to the tracked location based on switching instructions generated and provided by the controller.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-04-03T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8549890294},{"pair":"US-10529276-B2 & US-2018261003-A1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-2018261003-A1","title_2":"Reducing visually induced motion sickness in head mounted display systems ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180261003A1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A head mounted display (HMD) for displaying images to a user includes a sensor unit configured to detect motion of a head of the user of the HMD. The HMD also includes one or more processors configured to, in response to the motion, reduce contrast in a peripheral area of an image displayed to the user from an original contrast of the image, the image having a foveal area and the peripheral area relative to the optical axis of the eye of the user, the contrast being least reduced in a first portion of the peripheral area closest the foveal area and being most reduced in a second portion of the peripheral area farthest from the foveal area.","priority_1":"2018-01-05T00:00:00","priority_2":"2017-03-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8549834992},{"pair":"US-2019353898-A1 & US-10302945-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-10302945-B2","title_2":"Near-eye display with stacked lightguides ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10302945B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"Embodiments are described of an apparatus including an eyepiece having a front surface, a back surface spaced apart from the front surface, and an edge forming a perimeter of the eyepiece. The eyepiece includes an angled surface to direct light eye-measurement light reflected from an eye into the eyepiece and to direct display light out of the eyepiece to the eye. A first waveguide is formed in the eyepiece and extending from the angled surface to the edge, the first waveguide being optically coupled to a first portion of the angled surface having a first surface treatment. And a second waveguide is formed in the eyepiece and extending from the angled surface to the edge, the second waveguide being optically coupled to a second portion of the angled surface having a second surface treatment.","priority_1":"2018-05-18T00:00:00","priority_2":"2015-08-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8549780826},{"pair":"US-2019318528-A1 & US-9704282-B1","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8549310194},{"pair":"US-9984507-B2 & US-2016323567-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2016323567-A1","title_2":"Virtual eyeglass set for viewing actual scene that corrects for different location of lenses than eyes ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160323567A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"A virtual eyeglass set may include a frame, a first virtual lens and second virtual lens, and a processor. The frame may mount onto a user's head and hold the first virtual lens in front of the user's left eye and the second virtual lens in front of the user's right eye. A first side of each lens may face the user and a second side of each lens may face away from the user. Each of the first virtual lens and the second virtual lens may include a light field display on the first side, and a light field camera on the second side. The processor may construct, for display on each of the light field displays based on image data received via each of the light field cameras, an image from a perspective of the user's respective eye.","priority_1":"2015-11-19T00:00:00","priority_2":"2015-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.854908983},{"pair":"US-2017352183-A1 & US-9536354-B2","patent_1":"US-2017352183-A1","title_1":"Face and eye tracking using facial sensors within a head-mounted display ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US20170352183A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A head mounted display (HMD) in a VR system includes sensors for tracking the eyes and face of a user wearing the HMD. The VR system records calibration attributes such as landmarks of the face of the user. Light sources illuminate portions of the user's face covered by the HMD. In conjunction, facial sensors capture facial data. The VR system analyzes the facial data to determine the orientation of planar sections of the illuminated portions of face. The VR system aggregates planar sections of the face and maps the planar sections to landmarks of the face to generate a facial animation of the user, which can also include eye orientation information. The facial animation is represented as a virtual avatar and presented to the user.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8549034779},{"pair":"US-10520742-B1 & US-2019101757-A1","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-2019101757-A1","title_2":"Eye tracking using light guide with faceted combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190101757A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"An eye tracking system includes a light guide comprising a first eye-facing surface, a second surface, a third surface, and a plurality of facets formed in the second surface. The facets reflect a portion of light incident on a user eye into the light guide, which is positioned proximate to the user eye and between the user eye and a display. A surface of a compensator may be shaped complementary to the second surface of the light guide and placed proximate to the light guide. A camera or image sensor is oriented toward the third surface of the light guide and captures an image based on internally reflected light. An IR light source may be included. The image sensor may be an IR image sensor. Based on the image, a pose of the user eye is determined. A faceted light guide assembly may include a reflective coating adjacent the facets.","priority_1":"2017-02-13T00:00:00","priority_2":"2017-10-02T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8548944483},{"pair":"US-10469722-B2 & US-2016282453-A1","patent_1":"US-10469722-B2","title_1":"Spatially tiled structured light projector ","patent_2":"US-2016282453-A1","title_2":"Methods and Systems for LIDAR Optics Alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10469722B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160282453A1\/en","abstract_1":"An illumination source in a depth camera assembly (DCA) includes multiple emitters on a single substrate and a diffractive optical element (DOE) assembly including multiple DOEs. Each DOE is configured to generate a structured light pattern from the light emitted from a corresponding emitter. The DOE assembly projects the structured light patterns onto portions of a local area based in part on DOE projection geometries associated with the DOEs. The illumination source may also include a second DOE assembly common to the multiple emitters.","abstract_2":"A method is provided that involves mounting a transmit block and a receive block in a LIDAR device to provide a relative position between the transmit block and the receive block. The method also involves locating a camera at a given position at which the camera can image light beams emitted by the transmit block and can image the receive block. The method also involves obtaining, using the camera, a first image indicative of light source positions of one or more light sources in the transmit block and a second image indicative of detector positions of one or more detectors in the receive block. The method also involves determining at least one offset based on the first image and the second image. The method also involves adjusting the relative position between the transmit block and the receive block based at least in part on the at least one offset.","priority_1":"2016-08-29T00:00:00","priority_2":"2015-03-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8548940987},{"pair":"US-2020083399-A1 & US-9810910-B1","patent_1":"US-2020083399-A1","title_1":"Methods for wafer-to-wafer bonding ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US20200083399A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"Disclosed herein are techniques for wafer-to-wafer bonding for manufacturing light emitting diodes (LEDs). In some embodiments, a method of manufacturing LEDs includes modifying a p-type layer of a semiconductor material to form a plurality of alternating high resistivity areas and low resistivity areas, wherein the low resistivity areas correspond to light emitters; bonding a base wafer to a first surface of the p-type layer; removing a substrate from a second surface of the semiconductor material, wherein the second surface of the semiconductor material is opposite to the first surface of the p-type layer; and patterning a trench between each adjacent pair of the light emitters.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2018-09-11T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8548868239},{"pair":"US-2019361518-A1 & US-2019037194-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2018-05-22T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8548759246},{"pair":"US-2019311522-A1 & US-2020013214-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8548026191},{"pair":"US-10429656-B1 & US-10545347-B2","patent_1":"US-10429656-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10429656B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light is captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-01-18T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547930603},{"pair":"US-10429657-B1 & US-10545347-B2","patent_1":"US-10429657-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10429657B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block. Moreover, each reflection results in a particular view of the eye that results in multiple views of the eye being received by the image capturing element.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-01-18T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547930603},{"pair":"US-10379419-B1 & US-9851565-B1","patent_1":"US-10379419-B1","title_1":"Focus adjusting pancharatnam berry phase liquid crystal lenses in a head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10379419B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A varifocal block includes, in optical series, a switchable half waveplate (SHWP) and a plurality of liquid crystal (LC) lenses. The SHWP outputs circularly polarized light, and a handedness of the circularly polarized light is controlled by the SHWP being in an active state or a non-active state. Each LC lens of the plurality of LC lenses has a plurality of optical states, the plurality of optical states including an additive state that adds optical power to the LC lens and a subtractive state that removes optical power from the LC lens. The plurality of optical states of each of the plurality of the LC lenses compounded in optical series provides a range of adjustment of optical power for the varifocal block.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-11-23T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547897899},{"pair":"US-10489648-B2 & US-2016057339-A1","patent_1":"US-10489648-B2","title_1":"Eye tracking using time multiplexing ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US10489648B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system implements time-multiplexing by configuring a source assembly comprising a plurality of light sources to project at least a first light pattern towards the user's eye over a first time period, and a second light pattern towards the user's eye over a second time period in accordance with a set of emission instructions. A camera assembly is configured to capture images of the user's eye during the first and second time periods in accordance with a set of imaging instructions, the captured images containing one or more glints corresponding to reflections of the first or second light patterns on the cornea of the user's eye. The location of the glints may be used to determine a shape or orientation of the eye.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2017-08-04T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547854583},{"pair":"US-10599215-B2 & US-2017147859-A1","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2016-04-26T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547798676},{"pair":"US-2016217613-A1 & US-2020041798-A1","patent_1":"US-2016217613-A1","title_1":"Extendable eyecups for a virtual reality headset ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20160217613A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A virtual reality (VR) headset includes an optics block and an electronic display element outputting image light. The optics block includes a lens and an additional lens each configured to direct portions of the image light to corresponding exit pupils. A cone coupled to the lens and an additional cone coupled to the additional lens, the cone and additional cone configured to direct the image light toward the lens and additional lens, respectively. An extension ring is configured to couple to a mounting surface of a rigid body of the VR headset and to a base portion of the cone, and an additional extension ring is configured to couple to the mounting surface and to an additional base potion of the additional cone. Coupling one or more extension rings to the cone or to the additional cone allows modification of a distance between the lens or the additional lens and eyes of a user.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2015-01-28T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547158058},{"pair":"US-2020057304-A1 & US-2020041798-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-16T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547035732},{"pair":"US-2019318530-A1 & US-9704282-B1","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8546818726},{"pair":"US-10066933-B2 & US-2016163057-A1","patent_1":"US-10066933-B2","title_1":"Camera depth mapping using structured light patterns ","patent_2":"US-2016163057-A1","title_2":"Three-Dimensional Shape Capture Using Non-Collinear Display Illumination ","link_1":"https:\/\/patents.google.com\/patent\/US10066933B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160163057A1\/en","abstract_1":"The various embodiments described herein include methods and\/or systems for depth mapping. In one aspect, a method of depth mapping is performed at an apparatus including a projector, a camera, one or more processors, and memory storing one or more programs for execution by the one or more processors. The method includes identifying one or more areas of interest in a scene in accordance with variation of depth in the scene as detected at a first resolution. The method also includes, for each area of interest: (1) applying, via the projector, a respective structured-light pattern to the area of interest; (2) capturing, via the camera, an image of the area of interest with the respective structured-light pattern applied to it; and (3) creating a respective depth map of the area of interest using the captured image, the respective depth map having a higher resolution than the first resolution.","abstract_2":"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for three-dimensional shape capture. In one aspect, a method includes displaying a first, a second and a third illumination patterns on a display screen, and capturing a first, a second and a third image of an object while the first, the second and the third illumination patterns are respectively displayed. The method further includes determining the three-dimensional shape of the object based on the captured images.","priority_1":"2015-05-04T00:00:00","priority_2":"2014-12-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8546334121},{"pair":"US-2019072771-A1 & US-2016282453-A1","patent_1":"US-2019072771-A1","title_1":"Depth measurement using multiple pulsed structured light projectors ","patent_2":"US-2016282453-A1","title_2":"Methods and Systems for LIDAR Optics Alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190072771A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160282453A1\/en","abstract_1":"A depth measurement assembly (DMA) includes a pulsed illuminator assembly, a depth camera assembly, and a controller. The pulsed illuminator assembly has a structured light projector that projects pulses of structured light at a pulse rate into a local area. The depth camera assembly captures images data of an object in the local area illuminated with the pulses of structured light. An exposure interval of the depth camera assembly is pulsed and synchronized to the pulses projected by the pulsed illuminator assembly. The controller controls the pulsed illuminator assembly and the depth camera assembly so that they are synchronized. The controller also determine depth and\/or tracking information of the object based on the captured image data. In some embodiments, the pulsed illuminator assembly have a plurality of structured light projectors that projects pulses of structured light at different times.","abstract_2":"A method is provided that involves mounting a transmit block and a receive block in a LIDAR device to provide a relative position between the transmit block and the receive block. The method also involves locating a camera at a given position at which the camera can image light beams emitted by the transmit block and can image the receive block. The method also involves obtaining, using the camera, a first image indicative of light source positions of one or more light sources in the transmit block and a second image indicative of detector positions of one or more detectors in the receive block. The method also involves determining at least one offset based on the first image and the second image. The method also involves adjusting the relative position between the transmit block and the receive block based at least in part on the at least one offset.","priority_1":"2017-09-05T00:00:00","priority_2":"2015-03-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8546217167},{"pair":"US-2019037137-A1 & US-10244226-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10244226-B2","title_2":"Camera rig and stereoscopic image capture ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10244226B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"Systems and methods are related to a camera rig and generating stereoscopic panoramas from captured images for display in a virtual reality (VR) environment.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.854617126},{"pair":"US-10451947-B1 & US-2016240013-A1","patent_1":"US-10451947-B1","title_1":"Apochromatic pancharatnam berry phase (PBP) liquid crystal structures for head-mounted displays ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10451947B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A Pancharatnam Berry Phase (PBP) liquid crystal structure for adjusting or focusing light of a plurality of color channels emitted by a display of a head-mounted display (HMD) comprises a plurality of PBP active elements. Each PBP active element of the structure is configured to act as a half waveplate for light of a corresponding color channel, such that light of the corresponding color channel is adjusted by a predetermined amount. In addition, each PBP active element acts as a one waveplate for light of the remaining color channels, such that light of the remaining color channels passes through the PBP active element substantially unaffected. As such, the PBP structure is able to adjust incident light of the plurality of color channels uniformly in an apochromatic fashion.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2016-10-31T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8546040547},{"pair":"US-10317680-B1 & US-2016323567-A1","patent_1":"US-10317680-B1","title_1":"Optical aberration correction based on user eye position in head mounted displays ","patent_2":"US-2016323567-A1","title_2":"Virtual eyeglass set for viewing actual scene that corrects for different location of lenses than eyes ","link_1":"https:\/\/patents.google.com\/patent\/US10317680B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160323567A1\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on the position and\/or orientation of an eye of the user. An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD that contains one or more optical imperfections. The aberration-adjusted image corrects the aberrations caused by these optical imperfections so that the resulting retinal image is free of optical aberrations due to the HMD while preserving correct eye optical aberrations that correlate with a current accommodative state of the eye.","abstract_2":"A virtual eyeglass set may include a frame, a first virtual lens and second virtual lens, and a processor. The frame may mount onto a user's head and hold the first virtual lens in front of the user's left eye and the second virtual lens in front of the user's right eye. A first side of each lens may face the user and a second side of each lens may face away from the user. Each of the first virtual lens and the second virtual lens may include a light field display on the first side, and a light field camera on the second side. The processor may construct, for display on each of the light field displays based on image data received via each of the light field cameras, an image from a perspective of the user's respective eye.","priority_1":"2017-11-09T00:00:00","priority_2":"2015-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545919894},{"pair":"US-10108261-B1 & US-2019020869-A1","patent_1":"US-10108261-B1","title_1":"Eye tracking based on light polarization ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10108261B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using polarization. The eye tracking system includes an illumination source and an eye tracking unit comprising a polarization sensitive optical detector. The one or more illumination sources are configured to illuminate an eye and generate reflections directed towards the optical detector. The eye tracking unit is configured to determine a 3D shape of the eye based on the polarization of the reflections. The determined 3D shape of the eye is used to update a stored model of the eye in response to the one or more model parameter values extracted from the determined depth map of the corneal surface. The eye tracking system determines eye tracking information based on the updated model in order to improve eye tracking performance.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-07-05T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545856763},{"pair":"US-2019361523-A1 & US-2015242414-A1","patent_1":"US-2019361523-A1","title_1":"In-field illumination and imaging for eye tracking ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20190361523A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"Disclosed herein are techniques for eye tracking in near-eye display devices. In some embodiments, an illuminator for eye tracking is provided. The illuminator includes a light source configured to be positioned within a field of view of an eye of a user; a first reflector configured to shadow the light source from a field of view of a camera; and a second reflector configured to receive light from the light source that is reflected by the eye of the user, and to direct the light toward the camera.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2018-05-23T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545549567},{"pair":"US-2019037137-A1 & US-10102666-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10102666-B2","title_2":"Electronic display stabilization for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10102666B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A method includes determining, at a first time, a representation of a first head rotation of a head mounted display (HMD) using a first inertial sensor sample stream and rendering, at an application processor, a texture based on the first head rotation. The method further includes determining, at a second time subsequent to the first time, a representation of a second head rotation of the HMD using a second inertial sensor sample stream having a higher sampling rate than the first inertial sensor sample stream, and generating, at a compositor, a rotated representation of the texture based on a difference between the first head rotation and the second head rotation.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-06-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545411278},{"pair":"US-2016344910-A1 & US-9918024-B2","patent_1":"US-2016344910-A1","title_1":"Methods and Devices for Selective Flash Illumination ","patent_2":"US-9918024-B2","title_2":"Multi functional camera with beam splitter ","link_1":"https:\/\/patents.google.com\/patent\/US20160344910A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9918024B2\/en","abstract_1":"The various embodiments described herein include methods and\/or devices for directing flash illumination. In one aspect, a method is performed at a device including a camera, one or more processors, and memory storing one or more programs configured for execution by the one or more processors. The method includes directing flash illumination to an identified area of interest in a scene by adjusting power supplied to respective elements of a flash array. The method further includes capturing, via the camera, an image of the scene as illuminated by the flash illumination.","abstract_2":"An apparatus is described that includes a camera. The camera has a beam splitter to impose different optical paths for visible light and infra red light received by the camera. The camera has an infra red light detector to detect the infra red light and a visible light detector to detect the visible light.","priority_1":"2015-05-22T00:00:00","priority_2":"2015-05-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545383314},{"pair":"US-2019384070-A1 & US-2017363870-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2017363870-A1","title_2":"Method for fabricating a curved eyepiece ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170363870A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"Techniques and mechanisms for fabricating an eyepiece from a lens blank including blank bodies that are bonded to each other. In an embodiment, the blank bodies are formed by injection molding and adhered to one another. Fabrication of the eyepiece includes variously machining the blank bodies to shape respective lens bodies of the eyepiece. One or more blocking structures are coupled to reinforce the lens blank during at least part of such machining. In another embodiment, any blocking structures that are to resist forces of a particular machining process are coupled only indirectly to one of the blank bodies.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-06-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545372269},{"pair":"US-2017371159-A1 & US-9870049-B2","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2016-06-28T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545194534},{"pair":"US-2019313087-A1 & US-2018343443-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8545043911},{"pair":"US-10585477-B1 & US-9870049-B2","patent_1":"US-10585477-B1","title_1":"Patterned optical filter for eye tracking ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US10585477B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"An eyewear device has an optical element, a patterned optical filter, and a camera. The optical element receives light that includes light in a visible band and light in an infrared (IR) band. The patterned optical filter is disposed on the optical element and has a filtering portion and a plurality of non-filtering portions. The filtering portion is transmissive to light in the visible band and filtering of light in the IR band. The non-filtering portions are transmissive to light in the visible band and transmissive to light in the IR band. Some portion of the received light in the IR band passes through the non-filtering portions and illuminates a portion of an eye of a user with a pattern. The camera captures images of the portion of the eye that is illuminated with the pattern.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2018-04-05T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8544117661},{"pair":"US-10330936-B2 & US-2018343443-A1","patent_1":"US-10330936-B2","title_1":"Focal surface display ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10330936B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A head mounted display (HMD) adjusts the phase of light of a virtual scene using a spatially programmable focusing element. Depths of the virtual scene are approximated to one or more focal surfaces and the shape of the focal surfaces is then adjusted to minimize the distance of the focal surface to features in the virtual scene. The resulting shape of the focal surface is a continuous piecewise smooth three-dimensional curve. A phase function is generated for each focal surface that, when executed by the spatially programmable focusing element, reproduces a focal pattern corresponding to the each focal surface, which bends and shapes the wavefront to produce a focal pattern that conforms to the scene geometry.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-01-19T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8544070641},{"pair":"US-10109067-B2 & US-2015169054-A1","patent_1":"US-10109067-B2","title_1":"Corneal sphere tracking for generating an eye model ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10109067B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system comprises two or more illumination sources positioned relative to one another and an optical detector in order to capture. The optical detector is configured to capture images of the cornea based on one or more reflections. The eye tracking unit is configured to generate a model of the user's eye. The generated eye model is used to determine eye tracking information such as gaze direction as the user glances at different objects in the HMD.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2016-03-11T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8543974232},{"pair":"US-2017262054-A1 & US-2019020869-A1","patent_1":"US-2017262054-A1","title_1":"Focus adjusting headset ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20170262054A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A virtual reality (VR) headset adjusts the phase of light of a virtual scene received from a display element using a spatial light modulator (SLM) to accommodate changes in vergence for a user viewing objects in the virtual scene. The VR headset receives virtual scene data that includes depth information for components of the virtual scene and the SLM adjusts a wavefront of the light of the virtual scene by generating a phase function that adjusts the light of the virtual scene with phase delays based the depth values. Individual phase delays shift components of the virtual scene based on the depth values to a target focal plane to accommodate a user at a vergence depth for a frame of the virtual scene. Further, the SLM can provide optical defocus by shifting components of the virtual scene with the phase delays for depth of field blur.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-03-11T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8543901143},{"pair":"US-2019311522-A1 & US-10460510-B2","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8543867403},{"pair":"US-2019212482-A1 & US-2019020869-A1","patent_1":"US-2019212482-A1","title_1":"Angle selective filter for near eye displays ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190212482A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"One embodiment sets forth a near eye display (NED). The NED includes an electronic display configured to output image light to an optical element. The optical element is configured to receive the image light, direct the image light, and form an image at the eye. The NED also includes an angle selective filter having a curved surface. The angle selective filter is configured to filter out light beams of light exiting the optical element and having an angle of incidence on the curved surface larger than a cut-off angle of incidence.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-01-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8543530946},{"pair":"US-2017295324-A1 & US-10275898-B1","patent_1":"US-2017295324-A1","title_1":"Three-dimensional, 360-degree virtual reality camera system ","patent_2":"US-10275898-B1","title_2":"Wedge-based light-field video capture ","link_1":"https:\/\/patents.google.com\/patent\/US20170295324A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10275898B1\/en","abstract_1":"A camera system is configured to capture 360 degree image information of a local area, at least a portion of which is in stereo. The camera system includes a plurality of peripheral cameras, a plurality of axis cameras, a first rigid plate, and a second rigid plate, each aligned along an alignment axis. The peripheral cameras are arranged in a ring configuration that allows objects in the local area past a threshold distance to be within the fields of view of at least two peripheral cameras. The first and second rigid plates secure to a top and a bottom surface of the ring of peripheral cameras, respectively. At least one axis camera is arranged along the alignment axis and is coupled perpendicularly to a surface of the first rigid plate.","abstract_2":"A combined video of a scene may be generated for applications such as virtual reality or augmented reality. In one method, a camera system may be oriented at a first orientation and used to capture first video of a first portion of the scene. The camera system may then be rotated to a second orientation and used to capture second video of a second portion of the scene that is offset from the first portion such that the first video and the second video each have an overlapping video portion depicting an overlapping portion of the scene in which the first portion and the second portion of the scene overlap with each other. The first and second portions may be combined together to generate the combined video, which may depict the first and second portions substantially without duplicative inclusion of the overlapping video portion.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8543267646},{"pair":"US-2019353906-A1 & US-10545347-B2","patent_1":"US-2019353906-A1","title_1":"Optical Assembly with Polarization Volume Holographic Element ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US20190353906A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"An optical assembly includes a partial reflector that is optically coupled with a first polarization volume holographic element. The partial reflector is capable of receiving first light having a first circular polarization and transmitting a portion of the first light having a first circular polarization. The first polarization volume holographic element is configured to receive the first portion of the first light and reflect the first portion of the first light as second light having the first circular polarization. The partial reflector is capable of receiving the second light and reflecting a first portion of the second light as third light having a second circular polarization opposite to the first polarization. The first polarization volume holographic element is configured to receive the third light having the second circular polarization and transmit the third light having the second circular polarization.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-05-18T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8542416117},{"pair":"US-2018164591-A1 & US-2018343443-A1","patent_1":"US-2018164591-A1","title_1":"Tiled waveguide display ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20180164591A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A waveguide display includes light sources, a source waveguide, an output waveguide, and a controller. Light from each of the light sources is coupled into the source waveguide. The source waveguide includes gratings with a constant period determined based on the conditions for total internal reflection and first order diffraction of the received image light. The emitted image light is coupled into the output waveguide at several entrance locations. The output waveguide outputs expanded image lights at a location offset from the entrance location, and the location\/direction of the emitted expanded image light is based in part on the orientation of the light sources. Each of the expanded image light is associated with a field of view of the expanded image light emitted by the output waveguide.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2016-12-12T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8542405971},{"pair":"US-10210660-B2 & US-2018342075-A1","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-2018342075-A1","title_2":"Multi-view back-projection to a light-field ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180342075A1\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"Dense light-field data can be generated from image data that does not include light-field data, or from image data that includes sparse light-field data. In at least one embodiment, the source light-field data may include one or more sub-aperture images that may be used to reconstruct the light-field in denser form. In other embodiments, the source data can take other forms. Examples include data derived from or ancillary to a set of sub-aperture images, synthetic data, or captured image data that does not include full light-field data. Interpolation, back-projection, and\/or other techniques are used in connection with source sub-aperture images or their equivalents, to generate dense light-field data.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-05-25T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8542373431},{"pair":"US-10506217-B2 & US-2019033988-A1","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-2019033988-A1","title_2":"Controller tracking for multiple degrees of freedom ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190033988A1\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"A method for controller tracking with multiple degrees of freedom includes generating depth data at an electronic device based on a local environment proximate the electronic device. A set of positional data is generated for at least one spatial feature associated with a controller based on a pose of the electronic device, as determined using the depth data, relative to the at least one spatial feature associated with the controller. A set of rotational data is received that represents three degrees-of-freedom (3DoF) orientation of the controller within the local environment, and a six degrees-of-freedom (6DoF) position of the controller within the local environment is tracked based on the set of positional data and the set of rotational data.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8542007154},{"pair":"US-2019318529-A1 & US-2016307368-A1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2018-04-16T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541893116},{"pair":"US-10203504-B1 & US-10546518-B2","patent_1":"US-10203504-B1","title_1":"Scanning waveguide display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10203504B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A waveguide display is used for presenting media to a user. The waveguide assembly includes a light source, a source waveguide, an output waveguide, and a controller. The light source emits image light based on scanning instructions from the controller. The source waveguide receives the image light from the light source, expands the image light in at least one dimension, and outputs an expanded image light to the output waveguide at an input area. The output waveguide outputs the expanded image light from a portion of an output area based on a direction of the expanded light from the source waveguide.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-05-27T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541795069},{"pair":"US-10528128-B1 & US-10546518-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-12-15T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541705779},{"pair":"US-9779478-B1 & US-9934583-B2","patent_1":"US-9779478-B1","title_1":"Rendering composite content on a head-mounted display including a high resolution inset ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US9779478B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display (HMD) divides an image into a high resolution (HR) inset portion at a first resolution, a peripheral portion, and a transitional portion. The peripheral portion is downsampled to a second resolution that is less than the first resolution. The transitional portion is blended such that there is a smooth change in resolution that corresponds to a change in resolution between a fovea region and a non-fovea region of a retina. An inset region is generated using the HR inset portion and the blended transitional portion, and a background region is generated using the downsampled peripheral portion. The inset region is provided to a HR inset display, and the background region is provided to a peripheral display. An optics block combines the displayed inset region with the displayed background region to generate composite content.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-10-04T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541534988},{"pair":"US-9984507-B2 & US-10009542-B2","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-10009542-B2","title_2":"Systems and methods for environment content sharing ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10009542B2\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"Embodiments described herein may help to provide methods for sharing and viewing part of an environment of a computing device, such as a head-mountable device (HMD). An example method involves: (a) determining a still photo panorama of an environment, (b) receiving a video stream of a first portion of the environment from a video camera on a sharing device, (c) determining a registration data stream, where the registration data stream indicates a location and an orientation of the video stream within the still photo panorama of the environment; and (d) transmitting the video stream and the registration data stream to one or more viewing devices.","priority_1":"2015-11-19T00:00:00","priority_2":"2013-06-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541473241},{"pair":"US-10210660-B2 & US-10241329-B2","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541168577},{"pair":"US-10338379-B1 & US-10032074-B2","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-10-09T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8541144692},{"pair":"US-2020064641-A1 & US-10146054-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10146054-B2","title_2":"Adding prescriptive correction to eyepieces for see-through head wearable displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146054B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, a curved see-through component, an output coupler, and a prescription layer. The curved lightguide component guides display light received at an input region and releases the display light along an eye-ward direction in a viewing region. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is at least partially transmissive to ambient light incident through a world-facing side such that the viewing region is see-through. The curved see-through component is mated to the world-facing side of the curved lightguide component. The prescription layer has a first side mated to an eye-facing side of the curved lightguide component and a second side having a curvature that introduces prescriptive lensing to both the ambient light and the display light.","priority_1":"2018-08-24T00:00:00","priority_2":"2015-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8540840489},{"pair":"US-2020064633-A1 & US-2020073123-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-08-23T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8540816228},{"pair":"US-10248890-B2 & US-2017237971-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017237971-A1","title_2":"Image capture for virtual reality displays ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170237971A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A light-field camera system such as a tiled camera array may be used to capture a light-field of an environment. The tiled camera array may be a tiered camera array with a first plurality of cameras and a second plurality of cameras that are arranged more densely, but have lower resolution, than those of the first plurality of cameras. The first plurality of cameras may be interspersed among the second plurality of cameras. The first and second pluralities may cooperate to capture the light-field. According to one method, a subview may be captured by each camera of the first and second pluralities. Estimated world properties of the environment may be computed for each subview. A confidence map may be generated to indicate a level of confidence in the estimated world properties for each subview. The confidence maps and subviews may be used to generate a virtual view of the environment.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8540173343},{"pair":"US-10133168-B1 & US-2018239141-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2018-02-01T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8540077008},{"pair":"US-2017061838-A1 & US-9810910-B1","patent_1":"US-2017061838-A1","title_1":"Compensation of Chromatic Dispersion in a Tunable Beam Steering Device for Improved Display ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US20170061838A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"A display device includes a plurality of pixels. Each pixel includes two or more subpixels. The plurality of pixels includes a first subpixel configured to transmit light of a first color and a second subpixel configured to transmit light of a second color that is distinct from the first color. The display device also includes a beam steering device, and one or more compensators located between the plurality of pixels and the beam steering device and configured to change a direction of the light from the first subpixel and transmit the light toward the beam steering device and change a direction of the light from the second subpixel and transmit the light toward the beam steering device.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2015-08-03T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8540022183},{"pair":"US-2020013184-A1 & US-2017178395-A1","patent_1":"US-2020013184-A1","title_1":"Systems and methods for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit ","patent_2":"US-2017178395-A1","title_2":"Light field rendering of an image using variable computational complexity ","link_1":"https:\/\/patents.google.com\/patent\/US20200013184A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170178395A1\/en","abstract_1":"The disclosed computer-implemented method for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit may include (1) sending imaging data from an imaging device to a hardware accelerator unit, and (2) directing the hardware accelerator unit to generate a multi-scale representation of the imaging data sent from the imaging device, (3) preparing a set of input data for a set of image-based tracking operations, and (4) directing the hardware accelerator unit to execute the set of image-based tracking operations using the generated multi-scale representation of the imaging data and the prepared set of input data. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"Systems and methods are described include generating, using light field rendering based on a plurality of collected images, a rendered image that uses a variable computational complexity to generate a plurality of pixels of the rendered image based on a location of the pixel. The generating may include determining each pixel of a first set of pixels for the rendered image based on a blending, using a first blending technique, of one or more pixels of a first resolution mipmap image for each of the plurality of collected images, and determining each pixel of a second set of pixels for the rendered image based on a blending, using a second blending technique, of one or more pixels of a second resolution mipmap image for each of the plurality of collected images, wherein the second resolution mipmap images are lower resolution than the first resolution mipmap images.","priority_1":"2018-07-06T00:00:00","priority_2":"2015-12-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8539970746},{"pair":"US-2019361518-A1 & US-10417739-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10417739-B2","title_2":"Phase aligned foveated rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10417739B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A display device, such as a head mounted device (HMD), displays a virtual scene. The display device includes a motion tracker for detecting rotation of the display device. The display device also includes a processor that is configured to selectively maintain or modify a position of an array of rendered pixels relative to the virtual scene in response to the detected motion. The processor is also configured to upsample the rendered pixels to generate values of display pixels for presentation by the display device. The processor is further configured to translate the values of the display pixels in a rendering plane of the display device based on the detected motion. The translated values of the display pixels can then be presented on a display of the display device.","priority_1":"2018-05-22T00:00:00","priority_2":"2017-03-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8539607942},{"pair":"US-10488921-B1 & US-2020073123-A1","patent_1":"US-10488921-B1","title_1":"Pellicle beamsplitter for eye tracking ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10488921B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a pellicle beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The pellicle beamsplitter is positioned along the optical axis between the optics assembly and the electronic display. The pellicle beamsplitter includes a front surface and a back surface. Each of the front surface and the back surface comprising a first radius curvature in a first plane and a second radius curvature in a second plane that is perpendicular to the first plane.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2017-09-08T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8539279786},{"pair":"US-2019227321-A1 & US-2019265477-A1","patent_1":"US-2019227321-A1","title_1":"Rainbow reduction in waveguide displays ","patent_2":"US-2019265477-A1","title_2":"Augmented reality light field head-mounted displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190227321A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190265477A1\/en","abstract_1":"A waveguide display includes a first substrate and one or more grating layers on a first surface of the first substrate. The one or more grating layers are configured to cause destructive interference between ambient light diffracted by at least two grating layers or between ambient light diffracted by different portions of one grating layer. In some embodiments, the waveguide display also includes an angular-selective transmissive layer. The angular-selective transmissive layer is configured to reflect, diffract, or absorb ambient light incident on the angular-selective reflective layer with an incidence angle greater than a threshold value.","abstract_2":"A near-eye display system includes a transmissive display panel to display a near-eye light field frame comprising an array of elemental images. The transmissive display panel is configured to transmit light rays of the near-eye light field frame away from the user's eye and towards an array of curved beam splitters. The curved beam splitters collimate the transmitted light rays and reflect the collimated light rays back towards the transmissive display panel for passing to the user's eye.","priority_1":"2018-01-23T00:00:00","priority_2":"2018-02-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8539237966},{"pair":"US-10210660-B2 & US-10244226-B2","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-10244226-B2","title_2":"Camera rig and stereoscopic image capture ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10244226B2\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"Systems and methods are related to a camera rig and generating stereoscopic panoramas from captured images for display in a virtual reality (VR) environment.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8538358448},{"pair":"US-2016085301-A1 & US-2016323567-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2016323567-A1","title_2":"Virtual eyeglass set for viewing actual scene that corrects for different location of lenses than eyes ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160323567A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A virtual eyeglass set may include a frame, a first virtual lens and second virtual lens, and a processor. The frame may mount onto a user's head and hold the first virtual lens in front of the user's left eye and the second virtual lens in front of the user's right eye. A first side of each lens may face the user and a second side of each lens may face away from the user. Each of the first virtual lens and the second virtual lens may include a light field display on the first side, and a light field camera on the second side. The processor may construct, for display on each of the light field displays based on image data received via each of the light field cameras, an image from a perspective of the user's respective eye.","priority_1":"2014-09-22T00:00:00","priority_2":"2015-04-30T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8538202959},{"pair":"US-2019101767-A1 & US-2016240013-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8537996342},{"pair":"US-2018157320-A1 & US-9934583-B2","patent_1":"US-2018157320-A1","title_1":"Air spaced optical assembly with integrated eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20180157320A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted display (HMD) includes a display, an optical assembly and an eye tracking system that determines user's eye tracking information. The optical assembly comprises a front optical element in series with a back optical element adjacent to the display. One surface of the back optical element is coated to reflect infrared (IR) light. The eye tracking system includes an illumination source and an imaging device positioned between the front optical element and the back optical element. The illumination source emits IR light that illuminates the coated surface and reflects towards the user's eye. The imaging device captures an image of the user's eye based on light reflected from the user's eye and from the coated surface. The eye tracking information is determined based on the captured image. The HMD adjusts presentation of images displayed on the display, based on the eye tracking information.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-12-01T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8537701639},{"pair":"US-2019072770-A1 & US-2016282453-A1","patent_1":"US-2019072770-A1","title_1":"Depth measurement using a pulsed structured light projector ","patent_2":"US-2016282453-A1","title_2":"Methods and Systems for LIDAR Optics Alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20190072770A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160282453A1\/en","abstract_1":"A depth measurement assembly (DMA) includes a pulsed illuminator assembly, a depth camera assembly, and a controller. The pulsed illuminator assembly has a structured light projector that projects pulses of structured light at a pulse rate into a local area. The depth camera assembly captures images data of an object in the local area illuminated with the pulses of structured light. An exposure interval of the depth camera assembly is pulsed and synchronized to the pulses projected by the pulsed illuminator assembly. The controller controls the pulsed illuminator assembly and the depth camera assembly so that they are synchronized. The controller also determine depth and\/or tracking information of the object based on the captured image data. In some embodiments, the pulsed illuminator assembly have a plurality of structured light projectors that projects pulses of structured light at different times.","abstract_2":"A method is provided that involves mounting a transmit block and a receive block in a LIDAR device to provide a relative position between the transmit block and the receive block. The method also involves locating a camera at a given position at which the camera can image light beams emitted by the transmit block and can image the receive block. The method also involves obtaining, using the camera, a first image indicative of light source positions of one or more light sources in the transmit block and a second image indicative of detector positions of one or more detectors in the receive block. The method also involves determining at least one offset based on the first image and the second image. The method also involves adjusting the relative position between the transmit block and the receive block based at least in part on the at least one offset.","priority_1":"2017-09-05T00:00:00","priority_2":"2015-03-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8537698689},{"pair":"US-2016344910-A1 & US-9816804-B2","patent_1":"US-2016344910-A1","title_1":"Methods and Devices for Selective Flash Illumination ","patent_2":"US-9816804-B2","title_2":"Multi functional camera with multiple reflection beam splitter ","link_1":"https:\/\/patents.google.com\/patent\/US20160344910A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9816804B2\/en","abstract_1":"The various embodiments described herein include methods and\/or devices for directing flash illumination. In one aspect, a method is performed at a device including a camera, one or more processors, and memory storing one or more programs configured for execution by the one or more processors. The method includes directing flash illumination to an identified area of interest in a scene by adjusting power supplied to respective elements of a flash array. The method further includes capturing, via the camera, an image of the scene as illuminated by the flash illumination.","abstract_2":"An apparatus is described. The apparatus includes a camera comprising a beam splitter to impose different optical paths for visible light and infra red light received by the camera. The camera also includes an infra red light detector to detect the infra red light and a visible light detector to detect the visible light, wherein, the different optical paths include an optical path having more than one internal reflection within the beam splitter.","priority_1":"2015-05-22T00:00:00","priority_2":"2015-07-08T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8537174671},{"pair":"US-2017206660-A1 & US-2017365068-A1","patent_1":"US-2017206660-A1","title_1":"Depth mapping using structured light and time of flight ","patent_2":"US-2017365068-A1","title_2":"Combining light-field data with active depth data for depth map generation ","link_1":"https:\/\/patents.google.com\/patent\/US20170206660A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170365068A1\/en","abstract_1":"A depth camera assembly (DCA) determines distances between the DCA and objects in a local area within a field of view of the DCA. The DCA includes an illumination source that projects a known spatial pattern modulated with a temporal carrier signal into the local area. An imaging device capture the modulated pattern projected into the local area. The imaging device includes a detector that comprises different pixel groups that are each activated to captured light at different times. Hence, different pixel groups capture different phases of the temporally modulated pattern from the local area. The DCA determines times for light from the illumination source to be reflected and captured by the imaging device from the phases captured by the different pixel groups and also determines distances between the DCA and objects in the local area based on deformation of the spatial pattern captured by the imaging device.","abstract_2":"Depths of one or more objects in a scene may be measured with enhanced accuracy through the use of a light-field camera and a depth sensor. The light-field camera may capture a light-field image of the scene. The depth sensor may capture depth sensor data of the scene. Light-field depth data may be extracted from the light-field image and used, in combination with the sensor depth data, to generate a depth map indicative of distance between the light-field camera and one or more objects in the scene. The depth sensor may be an active depth sensor that transmits electromagnetic energy toward the scene; the electromagnetic energy may be reflected off of the scene and detected by the active depth sensor. The active depth sensor may have a 360\u00b0 field of view; accordingly, one or more mirrors may be used to direct the electromagnetic energy between the active depth sensor and the scene.","priority_1":"2016-01-15T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536998778},{"pair":"US-10529117-B2 & US-9384596-B2","patent_1":"US-10529117-B2","title_1":"Systems and methods for rendering optical distortion effects ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US10529117B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"In one embodiment, a computing system may receive a focal surface map, which may be specified by an application. The system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate first coordinates in the 3D space based on the determined orientation and generate second coordinates using the first coordinates and the focal surface map. Each of the first coordinates is associated with one of the second coordinates. For each of the first coordinates, the system may determine visibility of one or more objects defined within the 3D space by projecting a ray from the first coordinate through the associated second coordinate to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-04-16T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536931541},{"pair":"US-10520729-B1 & US-10032074-B2","patent_1":"US-10520729-B1","title_1":"Light scattering element for providing optical cues for lens position adjustment ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10520729B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A method includes displaying a high contrast image on a display screen; and projecting the high contrast image through a Fresnel lens to provide a cue for adjusting a position of the Fresnel lens. Also disclosed is a device for determining and\/or adjusting an offset of a Fresnel lens. The device includes a Fresnel lens and a display screen configured to project a high contrast image through the Fresnel lens. Further disclosed is a method for adjusting a position of a Fresnel lens. The method includes receiving a projection of a high contrast image transmitted through a Fresnel lens; and adjusting a position of the Fresnel lens based on the projection of the high contrast image.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-04-25T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536923275},{"pair":"US-2019318529-A1 & US-9704282-B1","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-04-16T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536620294},{"pair":"US-2019318530-A1 & US-9384596-B2","patent_1":"US-2019318530-A1","title_1":"Systems and Methods for Reducing Rendering Latency ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US20190318530A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"In one embodiment, a computing system may determine a first orientation in a 3D space based on first sensor data generated at a first time. The system may determine a first visibility of an object in the 3D space by projecting rays based on the first orientation to test for intersection. The system may generate first lines of pixels based on the determined first visibility and output the first lines of pixels for display. The system may determine a second orientation based on second sensor data generated at a second time. The system may determine a second visibility of the object by projected rays based on the second orientation to test for intersection. The system may generate second lines of pixels based on the determined second visibility and output the second lines of pixels for display. The second lines of pixels are displayed concurrently with the first lines of pixels.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-04-16T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536605802},{"pair":"US-2019037137-A1 & US-2017118400-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2017118400-A1","title_2":"Balancing exposure and gain at an electronic device based on device motion and scene distance ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170118400A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"An electronic device balances gain and exposure at an imaging sensor of the device based on detected image capture conditions, such as motion of the electronic device, distance of a scene from the electronic device, and predicted illumination conditions for the electronic device. By balancing the gain and exposure, the quality of images captured by the imaging sensor is enhanced, which in turn provides for improved support of location-based functionality.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-10-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536581613},{"pair":"US-10326977-B1 & US-9934583-B2","patent_1":"US-10326977-B1","title_1":"Multifocal test system ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10326977B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A multifocal test system is described herein. The system includes a plurality of displays located at different focal distances. Each display includes a plurality of pixels with pixel intensity values. The system includes an eye tracking system that determines eye tracking information about a position of an eye relative to the displays. A controller is configured to determine pixel intensity values based on decomposition of a scene across the plurality of displays, and the position of the eye.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-01-19T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.853652231},{"pair":"US-10481321-B1 & US-2019025602-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-09-06T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8536279048},{"pair":"US-10379419-B1 & US-2016240013-A1","patent_1":"US-10379419-B1","title_1":"Focus adjusting pancharatnam berry phase liquid crystal lenses in a head-mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10379419B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A varifocal block includes, in optical series, a switchable half waveplate (SHWP) and a plurality of liquid crystal (LC) lenses. The SHWP outputs circularly polarized light, and a handedness of the circularly polarized light is controlled by the SHWP being in an active state or a non-active state. Each LC lens of the plurality of LC lenses has a plurality of optical states, the plurality of optical states including an additive state that adds optical power to the LC lens and a subtractive state that removes optical power from the LC lens. The plurality of optical states of each of the plurality of the LC lenses compounded in optical series provides a range of adjustment of optical power for the varifocal block.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2016-11-23T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8535971358},{"pair":"US-10379348-B2 & US-10032074-B2","patent_1":"US-10379348-B2","title_1":"Hybrid fresnel lens with increased field of view ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10379348B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A lens defined by a first lens surface and a second lens surface opposite to the first lens surface is disclosed. The lens includes a first portion; and a second portion that is distinct from the first portion and is located around the first portion. The first lens surface for the first portion of the lens is defined by a Fresnel surface profile. The second lens surface for the first portion of the lens is defined by a smooth surface profile. The first lens surface for a second portion of the lens is defined by a Fresnel surface profile. The second lens surface for the second portion of the lens is defined by a Fresnel surface profile.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-09-13T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8535782966},{"pair":"US-2019339447-A1 & US-2017235145-A1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-05-04T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8535469407},{"pair":"US-2019311232-A1 & US-2018101984-A1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-04-10T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8535085508},{"pair":"US-2018164591-A1 & US-10241329-B2","patent_1":"US-2018164591-A1","title_1":"Tiled waveguide display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20180164591A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A waveguide display includes light sources, a source waveguide, an output waveguide, and a controller. Light from each of the light sources is coupled into the source waveguide. The source waveguide includes gratings with a constant period determined based on the conditions for total internal reflection and first order diffraction of the received image light. The emitted image light is coupled into the output waveguide at several entrance locations. The output waveguide outputs expanded image lights at a location offset from the entrance location, and the location\/direction of the emitted expanded image light is based in part on the orientation of the light sources. Each of the expanded image light is associated with a field of view of the expanded image light emitted by the output waveguide.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-12-12T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8535008264},{"pair":"US-10598928-B1 & US-2019101757-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2019101757-A1","title_2":"Eye tracking using light guide with faceted combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190101757A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An eye tracking system includes a light guide comprising a first eye-facing surface, a second surface, a third surface, and a plurality of facets formed in the second surface. The facets reflect a portion of light incident on a user eye into the light guide, which is positioned proximate to the user eye and between the user eye and a display. A surface of a compensator may be shaped complementary to the second surface of the light guide and placed proximate to the light guide. A camera or image sensor is oriented toward the third surface of the light guide and captures an image based on internally reflected light. An IR light source may be included. The image sensor may be an IR image sensor. Based on the image, a pose of the user eye is determined. A faceted light guide assembly may include a reflective coating adjacent the facets.","priority_1":"2017-12-21T00:00:00","priority_2":"2017-10-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8534933437},{"pair":"US-10557994-B1 & US-2019243209-A1","patent_1":"US-10557994-B1","title_1":"Waveguide grating with spatial variation of optical phase ","patent_2":"US-2019243209-A1","title_2":"Beam steering optics for virtual reality systems ","link_1":"https:\/\/patents.google.com\/patent\/US10557994B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190243209A1\/en","abstract_1":"An optical waveguide is disclosed. The optical waveguide includes a plate of transparent material comprising opposed first and second surfaces for guiding an optical beam between the surfaces by at least one of reflection or diffraction. A diffraction grating is disposed at the first surface for spreading the optical beam by diffracting portions thereof into a non-zero diffraction order to propagate inside the plate. The first diffraction grating includes an array of parallel grooves structured to provide a spatial variation of optical phase of the portions of the optical beam diffracted by the first diffraction grating into the non-zero diffraction order.","abstract_2":"A near-eye display system includes a display panel to present image frames to the eyes of a user for viewing. The system also includes a beam steering assembly facing the display panel that is configurable to displace a light beam incident on the beam steering assembly, thereby laterally shifting light relative to an optical path of the light beam incident on the beam steering assembly. A method of operation of the near-eye display system includes configuring the beam steering assembly in a first configuration state so that the beam steering assembly displaces a light beam incident on the beam steering assembly, such that the displaced light beam is laterally shifted relative to an optical path of the light beam.","priority_1":"2018-09-24T00:00:00","priority_2":"2018-02-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8534496874},{"pair":"US-2020083399-A1 & US-9934583-B2","patent_1":"US-2020083399-A1","title_1":"Methods for wafer-to-wafer bonding ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20200083399A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Disclosed herein are techniques for wafer-to-wafer bonding for manufacturing light emitting diodes (LEDs). In some embodiments, a method of manufacturing LEDs includes modifying a p-type layer of a semiconductor material to form a plurality of alternating high resistivity areas and low resistivity areas, wherein the low resistivity areas correspond to light emitters; bonding a base wafer to a first surface of the p-type layer; removing a substrate from a second surface of the semiconductor material, wherein the second surface of the semiconductor material is opposite to the first surface of the p-type layer; and patterning a trench between each adjacent pair of the light emitters.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-09-11T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8534345144},{"pair":"US-10599215-B2 & US-9536354-B2","patent_1":"US-10599215-B2","title_1":"Off-axis eye tracker ","patent_2":"US-9536354-B2","title_2":"Object outlining to initiate a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US10599215B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9536354B2\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The two-dimensional array of pixels defines an optical axis. The display device also includes an eye tracker that includes a first reflector positioned to intersect the optical axis; a first lens that is located off the optical axis; and an optical sensor configured to collect light, that is from the first reflector and has passed through the first lens, for determining a position of an eye of a user.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving sensor data from a sensor on a wearable computing device and, based on the sensor data, detecting a movement that defines an outline of an area in the sensor data. The method further includes identifying an object that is located in the area and initiating a search on the object. In another embodiment, a server is disclosed that includes an interface configured to receive sensor data from a sensor on a wearable computing device, at least one processor, and data storage comprising instructions executable by the at least one processor to detect, based on the sensor data, a movement that defines an outline of an area in the sensor data, identify an object that is located in the area, and initiate a search on the object.","priority_1":"2016-04-26T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8534200916},{"pair":"US-2017061838-A1 & US-9798147-B1","patent_1":"US-2017061838-A1","title_1":"Compensation of Chromatic Dispersion in a Tunable Beam Steering Device for Improved Display ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US20170061838A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"A display device includes a plurality of pixels. Each pixel includes two or more subpixels. The plurality of pixels includes a first subpixel configured to transmit light of a first color and a second subpixel configured to transmit light of a second color that is distinct from the first color. The display device also includes a beam steering device, and one or more compensators located between the plurality of pixels and the beam steering device and configured to change a direction of the light from the first subpixel and transmit the light toward the beam steering device and change a direction of the light from the second subpixel and transmit the light toward the beam steering device.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2015-08-03T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8533790988},{"pair":"US-10600352-B1 & US-9946074-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-12-04T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8533781314},{"pair":"US-10534177-B1 & US-2017235145-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2017-10-10T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8533625978},{"pair":"US-2020013184-A1 & US-2018101984-A1","patent_1":"US-2020013184-A1","title_1":"Systems and methods for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US20200013184A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"The disclosed computer-implemented method for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit may include (1) sending imaging data from an imaging device to a hardware accelerator unit, and (2) directing the hardware accelerator unit to generate a multi-scale representation of the imaging data sent from the imaging device, (3) preparing a set of input data for a set of image-based tracking operations, and (4) directing the hardware accelerator unit to execute the set of image-based tracking operations using the generated multi-scale representation of the imaging data and the prepared set of input data. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-07-06T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8533344683},{"pair":"US-9984507-B2 & US-2019037194-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2015-11-19T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8533078159},{"pair":"US-10529276-B2 & US-2017123209-A1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2018-01-05T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8532855558},{"pair":"US-10402950-B1 & US-10241329-B2","patent_1":"US-10402950-B1","title_1":"Optical measurement system ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10402950B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"Methods for quantifying pupil swim are disclosed in order to compensate for the same. A target image, in one embodiment, is displayed on a display of a head mounted display (HMD). Images of the target image are captured from a plurality of positions relative to an optical axis of an optics block of the HMD at an exit pupil of the HMD. The target image includes features and differences between observed locations of the features and their expected locations absent the optics block are determined. From these differences, a wavefront of the optics block is reconstructed and distortion corrections for the optics block are generated using the wavefront. The distortion corrections, when applied to a virtual scene, add pre-distortion that is canceled by the optical imperfections of the optics block as light of the virtual scene with the pre-distortion passes through the optics block.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-11-15T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8532829509},{"pair":"US-10481321-B1 & US-2019086675-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-09-06T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8532741443},{"pair":"US-10527854-B1 & US-9851565-B1","patent_1":"US-10527854-B1","title_1":"Illumination source for a waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10527854B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near eye display (NED) that includes an illumination source including a photonic array. The photonic array includes at least one waveguide that divides light from one or more emitters into a number of channels, and outputs the divided light using a plurality of outputs. An optical switching assembly includes a one or more input ports and a plurality of output ports. The optical switching assembly is configured to map light from the one or more input ports to the plurality of outputs. In various embodiments, the optical switching assembly is additionally configured to control the relative illumination, timing, and phase of light produced by each of the plurality of outputs. The optical switching assembly selectively outputs some or all of the incoupled light via output ports of the plurality of output ports in accordance with instructions from a controller, the outcoupled light forming a light pattern.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.853259944},{"pair":"US-10200624-B2 & US-2016307372-A1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-2016307372-A1","title_2":"Capturing light-field volume image and video data using tiled light-field cameras ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307372A1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"A capture system may capture light-field data representative of an environment for use in virtual reality, augmented reality, and the like. The system may have a plurality of light-field cameras arranged to capture a light-field volume within the environment, and a processor. The processor may use the light-field volume to generate a first virtual view depicting the environment from a first virtual viewpoint. The light-field cameras may be arranged in a tiled array to define a capture surface with a ring-shaped, spherical, or other arrangement. The processor may map the pixels captured by the image sensors to light rays received in the light-field volume, and store data descriptive of the light rays in a coordinate system representative of the light-field volume.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8532205069},{"pair":"US-2019311522-A1 & US-9589385-B1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-9589385-B1","title_2":"Method of annotation across different locations ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9589385B1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"A computer-implemented method, system and computer-readable storage device provide functionality for managing location information for planar regions in two-dimensional views of a three-dimensional environment. A request is received for a first two-dimensional view of a three-dimensional environment that identifies a first planar region associated with content within the three-dimensional environment. The first two-dimensional view is rendered and displayed. A request is received for a second two-dimensional view from a second location. A distance and direction between the location of the first planar region and the location for the second view are determined and used to establish a second location of the planar region in the second two-dimensional view, and then use this information to help render and display the second two-dimensional view.","priority_1":"2018-04-05T00:00:00","priority_2":"2012-07-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8531776037},{"pair":"US-2019086669-A1 & US-9851565-B1","patent_1":"US-2019086669-A1","title_1":"Multiple layer projector for a head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190086669A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) including multiple layered display panels. The HMD may include a first display panel to display a first image, and a second display panel positioned in front of the first display panel to at least partially overlap with the first display panel. The second display panel may include a display substrate, and a plurality of light emitting diodes (LEDs) positioned on the display substrate. The plurality of LEDs display a second image. The display substrate and the plurality of LEDs are transparent for the first image to be visible through the second display panel.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-09-20T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8531467517},{"pair":"US-2019318528-A1 & US-9384596-B2","patent_1":"US-2019318528-A1","title_1":"Computer-Graphics Based on Hierarchical Ray Casting ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US20190318528A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"In one embodiment, a method for determine visibility may perform intersection tests using block beams, tile beams, and rays. First, a computing system may project a block beam to test for intersection with a first bounding volume (BV) in a bounding volume hierarchy. If the beam fully contains BV, the system may test for more granular intersections with the first BV by projecting smaller tile beams contained within the block beam. Upon determining that the first BV partially intersects a tile beam, the system may project the tile beam against a second BV contained within the first BV. If the tile beam fully contains the second BV, the system may test for intersection using rays contained within the tile beam. The system may project procedurally-generated rays to test whether they intersect with objects contained within the second BV. Information associated with intersections may be used to render a computer-generated scene.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-04-16T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8531157406},{"pair":"US-2017295354-A1 & US-10540818-B2","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8530973434},{"pair":"US-10228565-B1 & US-10546518-B2","patent_1":"US-10228565-B1","title_1":"Variable focus waveguide display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10228565B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A waveguide display presents media to users. The waveguide assembly includes a light source, a source waveguide, an output waveguide, an actuator assembly, and a controller. The light source emits image light based on scanning instructions from the controller. The source waveguide receives the emitted image light, expands the image light in at least one dimension, and outputs an expanded image light to the output waveguide at an input area. The output waveguide outputs the expanded image light from a portion of an output area. The actuator assembly adjusts a first curvature of the source waveguide with a first set of actuators and adjusts a second curvature of the output waveguide with a second set of actuators, where the first curvature is orthogonal to the first curvature.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-05-27T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8530830181},{"pair":"US-2019037137-A1 & US-2018077384-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2018077384-A1","title_2":"Three-dimensional telepresence system ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180077384A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"An example telepresence terminal includes a lenticular display, an image sensor, an infrared emitter, and an infrared depth sensor. The terminal may determine image data using visible light emitted by the infrared emitter and captured by the image sensor and determine depth data using infrared light captured by the infrared depth sensor. The terminal may also communicate the depth data and the image data to a remote telepresence terminal and receive remote image data and remote depth data. The terminal may also generate a first display image using the lenticular display based on the remote image data that is viewable from a first viewing location and generate a second display image using the lenticular display based on the remote image data and the remote depth data that is viewable from a second viewing location.","priority_1":"2017-07-31T00:00:00","priority_2":"2016-09-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8530273438},{"pair":"US-2016085301-A1 & US-2016161240-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2016161240-A1","title_2":"Use of Comparative Sensor Data to Determine Orientation of Head Relative to Body ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160161240A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Methods and systems are described that involve a wearable computing device or an associated device determining the orientation of a person's head relative to their body. To do so, example methods and systems may compare sensor data from the wearable computing device to corresponding sensor data from a tracking device that is expected to move in a manner that follows the wearer's body, such a mobile phone that is located in the wearable computing device's wearer's pocket.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-09-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8530238563},{"pair":"US-10248890-B2 & US-2019392630-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2019392630-A1","title_2":"Automated understanding of three dimensional (3d) scenes for augmented reality applications ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190392630A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"An electronic device is configured to performing a three-dimensional (3D) scan of an interior space. In some cases, the electronic device acquires information and depth measurements relative to the electronic device. The electronic device acquires voxels in a 3D grid that is generated from the 3D scan. The voxels represent portions of the volume of the interior space. The electronic device determines a trajectory and poses of the electronic device concurrently with performing the 3D scan of the interior space. The electronic device labels voxels representing objects in the interior space based on the trajectory and the poses. In some cases, the electronic device uses queries to perform spatial reasoning at an object level of granularity, positions, overlays, or blends virtual objects into an augmented reality representation of the interior space or modifies positions or orientations of the objects by applying a transformation to corresponding connected components.","priority_1":"2017-04-13T00:00:00","priority_2":"2018-06-20T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8529757535},{"pair":"US-2020043391-A1 & US-2018343443-A1","patent_1":"US-2020043391-A1","title_1":"Wearable Display With Coherent Replication ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20200043391A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A wearable display with coherent replication of optical beams is presented. The display includes a replication element comprising a plurality of features configured to receive and split impinging light into a plurality of sub-beams for propagation in a plurality of directions. At least a portion of the split sub-beams propagating in a direction of an eyebox of the NED form an image by optical interference.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-08-02T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.852949643},{"pair":"US-10066933-B2 & US-2018342075-A1","patent_1":"US-10066933-B2","title_1":"Camera depth mapping using structured light patterns ","patent_2":"US-2018342075-A1","title_2":"Multi-view back-projection to a light-field ","link_1":"https:\/\/patents.google.com\/patent\/US10066933B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180342075A1\/en","abstract_1":"The various embodiments described herein include methods and\/or systems for depth mapping. In one aspect, a method of depth mapping is performed at an apparatus including a projector, a camera, one or more processors, and memory storing one or more programs for execution by the one or more processors. The method includes identifying one or more areas of interest in a scene in accordance with variation of depth in the scene as detected at a first resolution. The method also includes, for each area of interest: (1) applying, via the projector, a respective structured-light pattern to the area of interest; (2) capturing, via the camera, an image of the area of interest with the respective structured-light pattern applied to it; and (3) creating a respective depth map of the area of interest using the captured image, the respective depth map having a higher resolution than the first resolution.","abstract_2":"Dense light-field data can be generated from image data that does not include light-field data, or from image data that includes sparse light-field data. In at least one embodiment, the source light-field data may include one or more sub-aperture images that may be used to reconstruct the light-field in denser form. In other embodiments, the source data can take other forms. Examples include data derived from or ancillary to a set of sub-aperture images, synthetic data, or captured image data that does not include full light-field data. Interpolation, back-projection, and\/or other techniques are used in connection with source sub-aperture images or their equivalents, to generate dense light-field data.","priority_1":"2015-05-04T00:00:00","priority_2":"2017-05-25T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8529351783},{"pair":"US-2020081252-A1 & US-2016240013-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-03-15T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8529061098},{"pair":"US-2020064641-A1 & US-2019018255-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2019018255-A1","title_2":"Compact near-eye optical system including a refractive beam-splitting convex lens ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190018255A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An optical system includes a first filter stack to convert light to a first circular polarization, and a second filter stack that reflects light having the first circular polarization and transmits light having a second circular polarization. A refractive beam splitting convex lens is disposed intermediate the first filter stack and the second filter stack. The first filter stack can include a first linear polarizer to convert light to a first linear polarization and a first quarter wave plate to convert the light from the first linear polarization to a first circular polarization. The second filter stack can include a second quarter wave plate to convert the light from the first circular polarization to a second linear polarization that is transverse to the first linear polarization, a polarization-dependent beam splitter to pass the first polarization and reflect the second polarization, and a linear polarizer to pass the second polarization.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-07-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8528190936},{"pair":"US-10473939-B1 & US-10146054-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-10146054-B2","title_2":"Adding prescriptive correction to eyepieces for see-through head wearable displays ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10146054B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, a curved see-through component, an output coupler, and a prescription layer. The curved lightguide component guides display light received at an input region and releases the display light along an eye-ward direction in a viewing region. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is at least partially transmissive to ambient light incident through a world-facing side such that the viewing region is see-through. The curved see-through component is mated to the world-facing side of the curved lightguide component. The prescription layer has a first side mated to an eye-facing side of the curved lightguide component and a second side having a curvature that introduces prescriptive lensing to both the ambient light and the display light.","priority_1":"2018-01-08T00:00:00","priority_2":"2015-07-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8528115515},{"pair":"US-2019384070-A1 & US-2016240013-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-06-18T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8528063244},{"pair":"US-2018173303-A1 & US-2015379349-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2015379349-A1","title_2":"Staredown to Produce Changes in Information Density and Type ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150379349A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"A computer-implemented method includes detecting, at a wearable computing device, a first direction of a first stare, wherein the wearable computing device includes a head-mountable display unit, identifying a target based on the detected first direction, and based on a determination that a first time duration of the first stare is greater than or equal to a first predetermined time threshold, identifying information relevant to the target and displaying the identified information on the display unit. Subsequent to displaying the identified information, the method includes detecting a second stare that is directed at the target or at the displayed information, and based on a determination that a second time duration of the second stare is greater than or equal to a second predetermined time threshold, identifying additional information relevant to the target, and displaying the additional information on the display unit.","priority_1":"2016-12-21T00:00:00","priority_2":"2012-03-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8528059947},{"pair":"US-2019318529-A1 & US-9384596-B2","patent_1":"US-2019318529-A1","title_1":"Systems and Methods for Rendering Foveated Effects ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US20190318529A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"In one embodiment, a computer system may determine an orientation in a 3D space based on sensor data generated by a virtual reality device. The system may generate ray footprints in the 3D space based on the determined orientation. For at least one of the ray footprints, the system may identify a corresponding number of subsamples to generate for that ray footprint and generate one or more coordinates in the ray footprint based on the corresponding number of subsamples. The system may determine visibility of one or more objects defined within the 3D space by projecting a ray from each of the one or more coordinates to test for intersection with the one or more objects. The system may generate an image of the one or more objected based on the determined visibility of the one or more objects.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-04-16T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527925013},{"pair":"US-10460500-B1 & US-10593098-B2","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-04-13T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527843641},{"pair":"US-2019353898-A1 & US-9671614-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-05-18T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527778277},{"pair":"US-2019353898-A1 & US-9946074-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-05-18T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527605529},{"pair":"US-2019394564-A1 & US-10241329-B2","patent_1":"US-2019394564-A1","title_1":"Audio system for dynamic determination of personalized acoustic transfer functions ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190394564A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An eyewear device includes an audio system. In one embodiment, the audio system includes a microphone array that includes a plurality of acoustic sensors. Each acoustic sensor is configured to detect sounds within a local area surrounding the microphone array. For a plurality of the detected sounds, the audio system performs a direction of arrival (DoA) estimation. Based on parameters of the detected sound and\/or the DoA estimation, the audio system may then generate or update one or more acoustic transfer functions unique to a user. The audio system may use the one or more acoustic transfer functions to generate audio content for the user.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-06-22T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527034817},{"pair":"US-10520742-B1 & US-2020073123-A1","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2017-02-13T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526989347},{"pair":"US-2018335630-A1 & US-2017293143-A1","patent_1":"US-2018335630-A1","title_1":"Liquid crystal cells for polarization rotation ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20180335630A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"An optical element comprising a stacked liquid crystal (LC) structure for rotating polarization (e.g., handedness) of an incident circularly polarized light over a broad wavelength and incident angle for head-mounted displays (HMD)s display application is proposed. The stacked LC structure has a dual cell structures, which includes at least a first LC cell and a second LC cell, and the stacked LC structure rotates the polarized light for a broad band of light (e.g., visible spectrum) over a given field a view. The performance of designed dual LC cells structures may be optimized for narrow band wavelength and a narrow incident angle for different application cases.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2017-05-17T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526896551},{"pair":"US-10585477-B1 & US-2016080672-A1","patent_1":"US-10585477-B1","title_1":"Patterned optical filter for eye tracking ","patent_2":"US-2016080672-A1","title_2":"Preparation of Image Capture Device in Response to Pre-Image-Capture Signal ","link_1":"https:\/\/patents.google.com\/patent\/US10585477B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160080672A1\/en","abstract_1":"An eyewear device has an optical element, a patterned optical filter, and a camera. The optical element receives light that includes light in a visible band and light in an infrared (IR) band. The patterned optical filter is disposed on the optical element and has a filtering portion and a plurality of non-filtering portions. The filtering portion is transmissive to light in the visible band and filtering of light in the IR band. The non-filtering portions are transmissive to light in the visible band and transmissive to light in the IR band. Some portion of the received light in the IR band passes through the non-filtering portions and illuminates a portion of an eye of a user with a pattern. The camera captures images of the portion of the eye that is illuminated with the pattern.","abstract_2":"Embodiments may be implemented by a computing device, such as a head-mountable display or mobile phone, in order to pre-emptively warm up the device's camera, when it is probable that a user will be taking a photo. An illustrative method involves a computing device (a) receiving sensor data from one or more sensors associated with the computing device, wherein the computing device comprises an image-capture device, (b) analyzing the sensor data to detect at least one pre-image-capture signal, wherein the at least one pre-image-capture signal indicates a subsequent image-capture signal is likely to be received, and (c) in response to detecting the at least one pre-image-capture signal, causing the computing device to initiate an image-capture preparation process that prepares the image-capture device to capture an image.","priority_1":"2018-04-05T00:00:00","priority_2":"2013-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526745686},{"pair":"US-2019311522-A1 & US-2019182468-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2019182468-A1","title_2":"Methods, systems, and media for generating and rendering immersive video content ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190182468A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Methods, systems, and media for generating and rendering immersive video content are provided. In some embodiments, the method comprises: receiving information indicating positions of cameras in a plurality of cameras; generating a mesh on which video content is to be projected based on the positions of the cameras in the plurality of cameras, wherein the mesh is comprised of a portion of a faceted cylinder, and wherein the faceted cylinder has a plurality of facets each corresponding to a projection from a camera in the plurality of cameras; receiving video content corresponding to the plurality of cameras; and transmitting the video content and the generated mesh to a user device in response to receiving a request for the video content from the user device.","priority_1":"2018-04-05T00:00:00","priority_2":"2017-12-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526618031},{"pair":"US-10506217-B2 & US-10241329-B2","patent_1":"US-10506217-B2","title_1":"Head-mounted display tracking system ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10506217B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display (HMD) is configured to capture images and\/or video of a local area. The HMD includes an imaging assembly and a controller. The imaging assembly includes a plurality of cameras positioned at different locations on the HMD and oriented to capture images of different portions of a local area surrounding the HMD. The controller generates imaging instructions for each camera using image information. The imaging instructions cause respective midpoints of exposure times for each camera to occur at a same time value for each of the captured images. The cameras capture images of the local area in accordance with the imaging instructions. The controller determines a location of the HMD in the local area using the captured images and updates a model that represents a mapping function of the depth and exposure settings of the local area.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526405364},{"pair":"US-10061073-B2 & US-9851565-B1","patent_1":"US-10061073-B2","title_1":"Circular backlight for a liquid crystal display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10061073B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A liquid crystal display (LCD) device including a circular backlight that illuminates an LCD panel. The backlight is disposed behind the LCD panel and includes a light guide and an array of light emitting diodes (LEDs). The light guide includes a circular top surface, a circular bottom surface, and a connecting surface between the top and bottom surface. The array of LEDs are disposed along the connecting side surface of the light guide in a circular arrangement to emit light into in first directions toward a center of the light guide. The light guide receives the light from the array of LEDs in the first directions and directs the light in a second direction toward the LCD panel from the circular top surface. The backlight can include brightness enhancement films (BEFS), such as first BEF having concentric circular stripe prisms, and a second BEF having radial stripe prisms.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-20T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.852640254},{"pair":"US-10248890-B2 & US-9743019-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9743019-B2","title_2":"Multiplane panoramas of long scenes ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9743019B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods, systems, and articles of manufacture for generating a panoramic image of a long scene, are disclosed. These include, fitting a plurality of planes to 3D points associated with input images of portions of the long scene, where one or more respective planes are fitted to each of a ground surface, a dominant surface, and at least one of one or more foreground objects and one or more background objects in the long scene, and where distances from the 3D points to the fitted planes are substantially minimized. These also include, selecting, for respective one or more pixels in the panoramic image of the long scene, one of the input images and one of the fitted planes such that a distance is substantially minimized from the selected one of the fitted planes to a surface corresponding to the respective one or more pixels and occlusion of the respective one or more pixels is reduced in the selected one of the input images; and stitching the panoramic image of the long scene by projecting, for the respective one or more pixels in the panoramic image of the long scene, the selected one of the input images using the selected one of the fitted planes into the virtual camera.","priority_1":"2017-04-13T00:00:00","priority_2":"2011-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526307412},{"pair":"US-10481321-B1 & US-10302945-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-10302945-B2","title_2":"Near-eye display with stacked lightguides ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10302945B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"Embodiments are described of an apparatus including an eyepiece having a front surface, a back surface spaced apart from the front surface, and an edge forming a perimeter of the eyepiece. The eyepiece includes an angled surface to direct light eye-measurement light reflected from an eye into the eyepiece and to direct display light out of the eyepiece to the eye. A first waveguide is formed in the eyepiece and extending from the angled surface to the edge, the first waveguide being optically coupled to a first portion of the angled surface having a first surface treatment. And a second waveguide is formed in the eyepiece and extending from the angled surface to the edge, the second waveguide being optically coupled to a second portion of the angled surface having a second surface treatment.","priority_1":"2018-09-06T00:00:00","priority_2":"2015-08-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526305156},{"pair":"US-2017295354-A1 & US-2018329485-A1","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526150514},{"pair":"US-10473939-B1 & US-10162180-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-10162180-B2","title_2":"Efficient thin curved eyepiece for see-through head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10162180B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head wearable display includes a curved lightguide component, an input coupler, and an output coupler. The curved lightguide component guides display light received at an input region peripherally located from a viewing region and emits the display light along an eye-ward direction in the viewing region. The curved lightguide component includes an eye-ward facing surface that is concave and a world facing surface that is convex. The input coupler is disposed at the input region to couple the display light into the curved lightguide component. The output coupler is disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide component. The output coupler is partially transmissive to ambient light incident through the world facing surface. The display light is guided between the input coupler and the output coupler entirely by total internal reflection.","priority_1":"2018-01-08T00:00:00","priority_2":"2015-06-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526148554},{"pair":"US-2019313087-A1 & US-2016377869-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2016377869-A1","title_2":"Head mounted display device with dual curved displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160377869A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A head mounted display (HMD) device includes first and second laterally-curved displays disposed about a medial plane, wherein each of the first and second curved displays includes a first lateral section distal from the medial plane and having a curvature with a first radius and a second lateral section adjacent to the medial plane and having a curvature with a second radius less than the first radius.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-06-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8526108162},{"pair":"US-2016085301-A1 & US-2016118015-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2016118015-A1","title_2":"Device Control Utilizing Optical Flow ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160118015A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"A computing device includes an interface configured to receive image data that is indicative of a field-of-view (FOV) that is associated with a head-mountable display (HMD). The computing device also includes a computing system configured to determine optical flow from the image data and to determine, based on the optical flow, whether or not the HMD is associated with operation of a vehicle. Further, the computing device is configured to control the HMD to display information in a first mode, if the HMD is associated with the operation of the vehicle, and to control the HMD to display information in a second mode, if the HMD is not associated with the operation of the vehicle.","priority_1":"2014-09-22T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.852606768},{"pair":"US-10359845-B1 & US-10546518-B2","patent_1":"US-10359845-B1","title_1":"Display assembly using dynamic liquid crystal array ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10359845B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display includes an electronic display, a liquid crystal (LC) array with LC cells forming a dynamic lens array, an optical assembly, an eye tracker, and a controller. The LC array refracts image light emitted from the electronic display. The LC array includes a gaze region with a subset of the LC cells forming a portion of the dynamic lens array having a lens density different than that associated with remaining portions of the LC cells outside the gaze region. The eye tracker tracks a gaze location corresponding to a foveal region of a user's eye. The controller generates emission instructions and provides the emission instructions to the LC array to change location of the gaze region in the LC array based on the tracked gaze location. The optical assembly directs portions of image light refracted by the gaze region toward the foveal region of the user's eye.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-05-01T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525982239},{"pair":"US-10529087-B1 & US-10545215-B2","patent_1":"US-10529087-B1","title_1":"System for a depth mapping device ","patent_2":"US-10545215-B2","title_2":"4D camera tracking and optical stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10529087B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545215B2\/en","abstract_1":"A depth mapping device comprises a plurality of imaging components arranged among one or more rings. A depth mapping device may be designed by identifying a plurality of configurations satisfying a set of input parameters that includes a number of imaging components, each configuration indicating a different arrangement of imaging components among one or more rings. Coverages for different configuration parameter sets for the configuration are analyzed to determine a configuration parameter set associated with the configuration having a highest coverage, where the coverage is indicative of an amount of a local area viewable by a depth mapping device using the configuration and associated configuration parameter set. A target configuration having a highest coverage is selected and used to generate a depth mapping device design to be manufactured.","abstract_2":"A light-field video stream may be processed to modify the camera pathway from which the light-field video stream is projected. A plurality of target pixels may be selected, in a plurality of key frames of the light-field video stream. The target pixels may be used to generate a camera pathway indicative of motion of the camera during generation of the light-field video stream. The camera pathway may be adjusted to generate an adjusted camera pathway. This may be done, for example, to carry out image stabilization. The light-field video stream may be projected to a viewpoint defined by the adjusted camera pathway to generate a projected video stream with the image stabilization.","priority_1":"2017-09-26T00:00:00","priority_2":"2017-09-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525952248},{"pair":"US-2017295354-A1 & US-2017180705-A1","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-2017180705-A1","title_2":"Capture and render of virtual reality content employing a light field camera array ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180705A1\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"Systems and method relating to creating a virtual reality, such as a three-dimensional virtual reality, representation of physical scene. In this aspect, such a method may comprise gathering information from an array of cameras positioned on a two-dimensional planar surface. In this particular aspect, one or more of the cameras may be positioned at a different angle relative to the two-dimensional planar surface based at least in part on a respective distance of each of the one or more cameras from a midpoint of the planar surface. Furthermore, in this general aspect the method may further comprise processing the gathered information at least in part to render a virtual reality representation of the physical scene.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525880474},{"pair":"US-10473939-B1 & US-2019018255-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2019018255-A1","title_2":"Compact near-eye optical system including a refractive beam-splitting convex lens ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190018255A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An optical system includes a first filter stack to convert light to a first circular polarization, and a second filter stack that reflects light having the first circular polarization and transmits light having a second circular polarization. A refractive beam splitting convex lens is disposed intermediate the first filter stack and the second filter stack. The first filter stack can include a first linear polarizer to convert light to a first linear polarization and a first quarter wave plate to convert the light from the first linear polarization to a first circular polarization. The second filter stack can include a second quarter wave plate to convert the light from the first circular polarization to a second linear polarization that is transverse to the first linear polarization, a polarization-dependent beam splitter to pass the first polarization and reflect the second polarization, and a linear polarizer to pass the second polarization.","priority_1":"2018-01-08T00:00:00","priority_2":"2017-07-11T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525784286},{"pair":"US-10466779-B1 & US-10241329-B2","patent_1":"US-10466779-B1","title_1":"Event camera for eye tracking ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10466779B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An eye tracking system includes an event camera. The event camera includes an event sensor and a controller. The event sensor includes a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes of light reflected from a user's eyes. The controller populates an event matrix based in part on data values asynchronously received from the event sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image of the user's eyes for the first time period using the event matrix and the change matrix. The eye tracking system uses the image of the user's eyes to determine eye tracking information indicating positions, orientations and\/or movement of the user's eyes.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-07-24T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525753148},{"pair":"US-10429927-B1 & US-10545347-B2","patent_1":"US-10429927-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-10545347-B2","title_2":"Compact eye tracking using folded display optics ","link_1":"https:\/\/patents.google.com\/patent\/US10429927B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545347B2\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"Optical assemblies for use in virtual and augmented reality environments are described. The optical assemblies may include lenses, filter stacks, cameras, and image projecting devices. For example, the optical assemblies may include at least one lens, a first filter stack between the at least one lens and an image projecting device, a second filter stack between the first filter stack and the image projecting device, and a camera configured to capture images of an infrared reflection of light through the at least one lens.","priority_1":"2018-01-18T00:00:00","priority_2":"2017-02-23T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525608788},{"pair":"US-2017293146-A1 & US-10591731-B2","patent_1":"US-2017293146-A1","title_1":"Accommodation based optical correction ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20170293146A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"An auto-focus head-mounted display (HMD) dynamically generates aberration-adjusted images based on measured accommodation of user's eye(s). An aberration-adjusted image is an image distorted to correct aberrations that would otherwise occur at a retina of the user due to image light passing through optics of the HMD. The aberration-adjusted image corrects the aberrations of the HMD and \u201caccounts\u201d for the aberrations of the eye so that the resulting retinal image is free of optical aberrations due to the HMD but preserves correct eye optical aberrations that are correlated with a current accommodative state of the eye.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2016-04-07T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8525378181},{"pair":"US-2020083402-A1 & US-9934583-B2","patent_1":"US-2020083402-A1","title_1":"Mesa formation for wafer-to-wafer bonding ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20200083402A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Disclosed herein are techniques for wafer-to-wafer bonding for manufacturing light emitting diodes (LEDs). In some embodiments, a method of manufacturing LEDs includes etching a semiconductor material to form a plurality of adjacent mesa shapes. The semiconductor material includes one or more epitaxial layers. The method also includes forming a passivation layer within gaps between the adjacent mesa shapes and bonding a base wafer to a first surface of the semiconductor material.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-09-11T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8524984559},{"pair":"US-10534185-B1 & US-2018239141-A1","patent_1":"US-10534185-B1","title_1":"Multi-planar display with waveguide and lens stacks ","patent_2":"US-2018239141-A1","title_2":"Freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10534185B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180239141A1\/en","abstract_1":"A near-eye display includes a display assembly, an eye tracking system, and a multifocal module. The display assembly emits image light at a particular focal distance in accordance with multifocal instructions. The display assembly includes focal adjustment lenses and waveguide displays arranged in optical series and configured to emit light in accordance with the multifocal instructions. Different combinations of focal adjustment lenses are associated with different focal distances. Each waveguide display is separated from one or more adjacent waveguide displays by one or more of the plurality of focal adjustment lenses, and is associated with a unique combination of one or more of the focal adjustment lenses and a corresponding focal distance. The eye tracking system determines eye tracking information for a user's eye. The multifocal module generates the multifocal instructions based on the eye tracking information and provides the multifocal instructions to the display assembly.","abstract_2":"An optical apparatus for a near-eye display includes a microdisplay to emit image light and one or more field lenses positioned to receive the image light from the microdisplay. The one or more field lenses have a combined optical power to form a curved intermediate image. A freeform combiner, having an eyeward side and an external side, is positioned to receive the image light from the one or more field lenses and reflect the image light. A curved intermediate image is formed between the freeform combiner and the one or more field lenses.","priority_1":"2017-02-14T00:00:00","priority_2":"2017-02-21T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.852467433},{"pair":"US-2020013184-A1 & US-2017180721-A1","patent_1":"US-2020013184-A1","title_1":"Systems and methods for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit ","patent_2":"US-2017180721-A1","title_2":"System and method for performing electronic display stabilization via retained lightfield rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20200013184A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180721A1\/en","abstract_1":"The disclosed computer-implemented method for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit may include (1) sending imaging data from an imaging device to a hardware accelerator unit, and (2) directing the hardware accelerator unit to generate a multi-scale representation of the imaging data sent from the imaging device, (3) preparing a set of input data for a set of image-based tracking operations, and (4) directing the hardware accelerator unit to execute the set of image-based tracking operations using the generated multi-scale representation of the imaging data and the prepared set of input data. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"In a system having a user-portable display device, a method includes maintaining a lightfield data structure representing at least a portion of a four-dimensional (4D) lightfield for a three-dimensional (3D) world in association with a first pose of the user-portable display device relative to the 3D world. The method further includes determining a second pose of the user-portable display device relative to the 3D world, the second pose comprising an updated pose of the user-portable display device. The method additionally includes generating a display frame from the lightfield data structure based on the second pose, the display frame representing a field of view of the 3D world from the second pose.","priority_1":"2018-07-06T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8524383519},{"pair":"US-2018239145-A1 & US-2020049994-A1","patent_1":"US-2018239145-A1","title_1":"Focus adjusting multiplanar head mounted display ","patent_2":"US-2020049994-A1","title_2":"Tilted focal plane for near-eye display system ","link_1":"https:\/\/patents.google.com\/patent\/US20180239145A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200049994A1\/en","abstract_1":"A multiplanar head mounted display (HMD) includes two or more artificial display planes for each eye located at optical distances that can be dynamically adjusted based on a location within a scene presented by the HMD that the user views. For example, a scene is presented on two or more electronic display elements (e.g., screens) of the HMD. A focal length of an optics block that directs image light from the electronic display elements towards the eyes of a user is adjusted using a varifocal system (e.g., an element that mechanically changes a distance between a lens system in the optics block and the electronic display element, an element that changes shape of one or more lenses in the lens system in the optics block, etc.) based on a location or object within the scene where the user is looking.","abstract_2":"A near-eye display device reduces vergence accommodation conflict by adjusting a tilt and\/or distance of a focal plane of a display panel based on scene depth statistics. For example, many three-dimensional (3D) scenes have closer objects in the lower visual field and farther objects in the upper visual field. Changing the tilt of the focal plane of the display panel to match average 3D screen depths reduces the discrepancy between vergence and accommodation distances. In some embodiments, the near-eye display device employs a fixed tilt of the display panel to match average scene depth statistics across a variety of scenes. In some embodiments, the near-eye display device dynamically adjusts the pitch and yaw of the focal plane of the display panel to match scene statistics for a given scene.","priority_1":"2017-02-21T00:00:00","priority_2":"2018-08-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8524180963},{"pair":"US-9779686-B2 & US-2017140711-A1","patent_1":"US-9779686-B2","title_1":"Aging compensation for virtual reality headset display device ","patent_2":"US-2017140711-A1","title_2":"Head mounted display device with rapid gamma correction between display panels ","link_1":"https:\/\/patents.google.com\/patent\/US9779686B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170140711A1\/en","abstract_1":"An electronic display is driven to compensate for aging of pixels in the electronic display. An aging factor is determined based on initial display data for a display portion of the electronic display during one or more monitored frames. The aging factor is indicative of aging of pixels in the display portion of the electronic display due to use corresponding to the initial display data. An aging counter for the display portion is increased based on the determined aging factor. A compensation value is determined for the display portion based on the aging counter for the display portion. Input display data for the display portion is modified during a subsequent frame according the determined compensation value. The display portion is driven with the modified input display data during the subsequent frame.","abstract_2":"A head mounted display (HMD) device periodically measures a gamma characteristic of each of a plurality of display panels, then adjusts the characteristic of one of the panels to closely match the other. For example, the HMD device can periodically apply a set of currents to selected pixels at each display panel and measure the resulting sets of voltages at the selected pixels. The set of voltages for each display panel indicates the gamma characteristic of the corresponding panel. The HMD device can apply the sets of voltages to a filter to generate a gamma figure of merit (FOM) for each display panel, and adjust a bias (e.g., a backlight bias or a bias of a light emitting diode (LED)) of one or more of the display panels, so that each display panel exhibits similar gamma characteristics.","priority_1":"2015-12-15T00:00:00","priority_2":"2015-11-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8523721924},{"pair":"US-2017371159-A1 & US-2017123209-A1","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2016-06-28T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8523717616},{"pair":"US-10489648-B2 & US-10032074-B2","patent_1":"US-10489648-B2","title_1":"Eye tracking using time multiplexing ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10489648B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system implements time-multiplexing by configuring a source assembly comprising a plurality of light sources to project at least a first light pattern towards the user's eye over a first time period, and a second light pattern towards the user's eye over a second time period in accordance with a set of emission instructions. A camera assembly is configured to capture images of the user's eye during the first and second time periods in accordance with a set of imaging instructions, the captured images containing one or more glints corresponding to reflections of the first or second light patterns on the cornea of the user's eye. The location of the glints may be used to determine a shape or orientation of the eye.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2017-08-04T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8523657335},{"pair":"US-2019098276-A1 & US-2017365068-A1","patent_1":"US-2019098276-A1","title_1":"3-d 360 degree depth projector ","patent_2":"US-2017365068-A1","title_2":"Combining light-field data with active depth data for depth map generation ","link_1":"https:\/\/patents.google.com\/patent\/US20190098276A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170365068A1\/en","abstract_1":"A camera system configured to generate depth information for a local area. The camera system comprises a plurality of depth camera sub-assemblies arranged in a substantially spherical arrangement. Each sub-assembly comprises a projector that projects a structured light pattern onto a portion of the local area, such that the projected light patterns of the plurality of sub-assemblies form a tiled light pattern covering 360 degrees of the local area. Each sub-assembly further comprises at least one camera is configured to capture images of the local area. A controller of the camera system is configured to receive the captured images and to construct a 360 degree depth map of the scene, based upon the structured light patterns projected by the projectors of the plurality captured in the received images.","abstract_2":"Depths of one or more objects in a scene may be measured with enhanced accuracy through the use of a light-field camera and a depth sensor. The light-field camera may capture a light-field image of the scene. The depth sensor may capture depth sensor data of the scene. Light-field depth data may be extracted from the light-field image and used, in combination with the sensor depth data, to generate a depth map indicative of distance between the light-field camera and one or more objects in the scene. The depth sensor may be an active depth sensor that transmits electromagnetic energy toward the scene; the electromagnetic energy may be reflected off of the scene and detected by the active depth sensor. The active depth sensor may have a 360\u00b0 field of view; accordingly, one or more mirrors may be used to direct the electromagnetic energy between the active depth sensor and the scene.","priority_1":"2017-09-27T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8523471127},{"pair":"US-2020013184-A1 & US-10593098-B2","patent_1":"US-2020013184-A1","title_1":"Systems and methods for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US20200013184A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"The disclosed computer-implemented method for offloading image-based tracking operations from a general processing unit to a hardware accelerator unit may include (1) sending imaging data from an imaging device to a hardware accelerator unit, and (2) directing the hardware accelerator unit to generate a multi-scale representation of the imaging data sent from the imaging device, (3) preparing a set of input data for a set of image-based tracking operations, and (4) directing the hardware accelerator unit to execute the set of image-based tracking operations using the generated multi-scale representation of the imaging data and the prepared set of input data. Various other methods, systems, and computer-readable media are also disclosed.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-07-06T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8523331253},{"pair":"US-2017371159-A1 & US-2018343443-A1","patent_1":"US-2017371159-A1","title_1":"Lens Assembly with Multiple Lenses for Relaying Images ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20170371159A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A display device includes a two-dimensional array of pixels configured for outputting a respective pattern of light. The display device also includes a lens assembly configured for relaying the respective pattern of light from the two-dimensional array of pixels to a pupil of an eye of a user. The lens assembly includes two or more lenses. The two or more lenses are configured in such a way that a ray of light from a respective pixel of the two-dimensional array of pixels passes through the two or more lenses of the lens assembly.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2016-06-28T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8522807865},{"pair":"US-2017352178-A1 & US-2015242414-A1","patent_1":"US-2017352178-A1","title_1":"Facial animation using facial sensors within a head-mounted display ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20170352178A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"A facial tracking system generates a virtual rendering of a portion of a face of a user wearing a head-mounted display (HMD). The facial tracking system illuminates portions of the face inside the HMD. The facial tracking system captures a plurality of facial data of the portion of the face using one or more facial sensors located inside the HMD. A plurality of planar sections of the portion of the face are identified based at least in part on the plurality of facial data. The plurality of planar sections are mapped to one or more landmarks of the face. Facial animation information is generated based at least in part on the mapping, the facial animation information describing a portion of a virtual face corresponding to the portion of the user's face.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8522756177},{"pair":"US-10466360-B1 & US-2016282453-A1","patent_1":"US-10466360-B1","title_1":"Depth measurement using scanning diffractive optical elements ","patent_2":"US-2016282453-A1","title_2":"Methods and Systems for LIDAR Optics Alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10466360B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160282453A1\/en","abstract_1":"A depth measurement assembly (DMA) measures depth information of an object in a local area. The DMA includes structured light projector, a depth camera assembly, and a controller. The structured light projector projects structured light patterns into the local area. The structured light projector includes a diffractive optical unit that includes diffractive optical elements (DOEs) and selects a DOE. The selected DOE is illuminated by light from a light source and converts the light into a structured light pattern. In some embodiment, the diffractive optical units selects multiple DOEs associated with multiple structured light patterns. The structured light pattern is projected into the local area by a projection assembly of the structured light projector and illuminates the object. The depth camera assembly captures images of the object. The controller uses the captured images to determine depth information of the object.","abstract_2":"A method is provided that involves mounting a transmit block and a receive block in a LIDAR device to provide a relative position between the transmit block and the receive block. The method also involves locating a camera at a given position at which the camera can image light beams emitted by the transmit block and can image the receive block. The method also involves obtaining, using the camera, a first image indicative of light source positions of one or more light sources in the transmit block and a second image indicative of detector positions of one or more detectors in the receive block. The method also involves determining at least one offset based on the first image and the second image. The method also involves adjusting the relative position between the transmit block and the receive block based at least in part on the at least one offset.","priority_1":"2017-08-31T00:00:00","priority_2":"2015-03-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8522509078},{"pair":"US-10598928-B1 & US-2017293143-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2017-12-21T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8521141202},{"pair":"US-2019101767-A1 & US-9709797-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8521059033},{"pair":"US-10528128-B1 & US-10591731-B2","patent_1":"US-10528128-B1","title_1":"Head-mounted display devices with transparent display panels for eye tracking ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10528128B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A head-mounted display device includes a transparent display for projecting light toward an eye so that images rendered based on the augmented reality contents overlap with real images. The device also includes a mirror configured to reflect infrared light and transmit a portion of visible light corresponding to the real images, and an infrared light source configured to emit infrared light, which is reflected by the mirror toward the transparent display and transmitted through the transparent display toward the eye. The device further includes a sensor configured to detect infrared light reflected from the eye for determining a gaze direction of the eye. The infrared light reflected from the eye is transmitted through the transparent display and reflected by the mirror toward the sensor. In some embodiments, the device includes a lens for transmitting the projected light, the infrared light, and the visible light.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-12-15T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8521008759},{"pair":"US-10473939-B1 & US-10126482-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-10126482-B2","title_2":"Lightguide device with outcoupling structures ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10126482B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"A lightguide assembly including structures to provide for outcoupling of light from an internal reflection structure. In an embodiment, a lightguide assembly includes light transmissive bodies forming respective corrugations which are coupled to one another. Optical coatings are variously disposed between the respective corrugations, wherein the optical coatings provide for redirection of light from the lightguide assembly. In another embodiment, optical coatings are each applied to a respective one of alternate facets of a corrugation. Polymer film portions provide mechanical support for the optical coatings during application to the corrugation.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-02-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8520858048},{"pair":"US-10379359-B2 & US-9810910-B1","patent_1":"US-10379359-B2","title_1":"Fresnel lens with dynamic draft for reduced optical artifacts ","patent_2":"US-9810910-B1","title_2":"Contact lens with phase map display ","link_1":"https:\/\/patents.google.com\/patent\/US10379359B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9810910B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The draft facet is characterized by a draft angle which is based on a distance of the respective Fresnel structure from a reference axis of the lens. The draft angle is between a first angle and a second angle, the first angle corresponding to a direction of a ray, in a first medium, transmitted from a reference off-axis position through the respective Fresnel structure toward a reference pupil. The second angle corresponding to a direction of the ray, in the optically transparent substrate, transmitted from the reference off-axis position through the respective Fresnel structure toward the reference pupil.","abstract_2":"A contact lens includes a transparent material, a substrate material, a light source, an optical system, and a phase map. The transparent material has an eye-side opposite an external side. The eye-side is curved to fit the human eye. The light source is configured to emit illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image at a retina-distance in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that is included in the image.","priority_1":"2016-09-13T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8520226983},{"pair":"US-10466779-B1 & US-10591731-B2","patent_1":"US-10466779-B1","title_1":"Event camera for eye tracking ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10466779B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"An eye tracking system includes an event camera. The event camera includes an event sensor and a controller. The event sensor includes a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes of light reflected from a user's eyes. The controller populates an event matrix based in part on data values asynchronously received from the event sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image of the user's eyes for the first time period using the event matrix and the change matrix. The eye tracking system uses the image of the user's eyes to determine eye tracking information indicating positions, orientations and\/or movement of the user's eyes.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-07-24T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8520124272},{"pair":"US-10338379-B1 & US-2015169054-A1","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2017-10-09T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8520024856},{"pair":"US-10529113-B1 & US-9934583-B2","patent_1":"US-10529113-B1","title_1":"Generating graphical representation of facial expressions of a user wearing a head mounted display accounting for previously captured images of the user's facial expressions ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10529113B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A virtual reality (VR) or augmented reality (AR) head mounted display (HMD) includes various image capture devices that capture images of portions of the user's face. Through image analysis, points of each portion of the user's face are identified from the images and their movement is tracked. The identified points are mapped to a three dimensional model of a face. From the identified points, a blendshape vector is determined for each captured image, resulting in various vectors indicating the user's facial expressions. A direct expression model that directly maps images to blendshape coefficients for a set of facial expressions based on captured information from a set of users may augment the blendshape vector in various embodiments. From the blendshape vectors and transforms mapping the captured images to three dimensions, the three dimensional model of the face is altered to render the user's facial expressions.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2019-01-04T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8519967953},{"pair":"US-10520742-B1 & US-10241329-B2","patent_1":"US-10520742-B1","title_1":"Beamsplitter assembly for eye tracking in head-mounted displays ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10520742B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display includes an electronic display configured to output image light, an optics assembly configured to direct image light in a first band from the electronic display to an eye box, an eye tracking unit configured to generate eye tracking information, and a beamsplitter configured to redirect light in a second band reflected from the eye box toward the eye tracking unit and transmit the image light in the first band. The beamsplitter includes a first region and a second region, and a first portion that joins the first region and the second region is curved such that an angle between the first region and the optical axis is larger than an angle between second region and the optical axis, and the beamsplitter is positioned along the optical axis between the optics assembly and the electronic display.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-02-13T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8519846343},{"pair":"US-10598938-B1 & US-2018024286-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2018024286-A1","title_2":"Head-mounted display with off-board illumination ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180024286A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"Techniques of providing illumination to a head-mounted display (HMD) involve providing off-board illumination apart from the HMD. An off-board illumination unit delivers the illumination to the HMD via optical fibers. The optical fibers are lightweight and do not restrict motion of a user. Because the power source is less restricted, the off-board illumination unit provides flexibility in the hardware used to generate the illumination. For example, the illumination unit may use red, green, and blue narrow-band diode lasers. Further, by controlling modes in the fiber and providing additional light-guiding hardware, the angles at which light strikes LCD pixels may be largely restricted to certain specified angles. Restricted angles of incidence enable the use of fast-switching liquid crystals without degrading the image quality. Such a restriction allows for high-resolution imaging using rapid switching of the liquid crystal which enables very low latencies.","priority_1":"2018-11-09T00:00:00","priority_2":"2016-07-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8519711006},{"pair":"US-2020057304-A1 & US-2019025602-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2019025602-A1","title_2":"Compact near-eye display optics for augmented reality ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190025602A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An optical system includes a first filter stack configured to convert light received from a display to a first circular polarization, a second filter stack configured to convert light received from external sources to a second circular polarization, and a third filter stack configured to reflect light having the first circular polarization and transmit light having the second circular polarization. The optical system also includes a refractive beam splitting lens configured to transmit light received from the second filter stack to the third filter stack. The second filter stack is oriented to reflect light received from the first filter stack onto the refractive beam splitting lens. The optical system is implemented in augmented reality devices, such as head mounted devices (HMDs), to combine images generated by the display with light received from external sources.","priority_1":"2018-08-16T00:00:00","priority_2":"2017-07-20T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8519633406},{"pair":"US-10522110-B1 & US-2017116950-A1","patent_1":"US-10522110-B1","title_1":"Apparatuses, systems, and methods for measuring and adjusting the luminance of a head-mounted display ","patent_2":"US-2017116950-A1","title_2":"Liquid crystal display with variable drive voltage ","link_1":"https:\/\/patents.google.com\/patent\/US10522110B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170116950A1\/en","abstract_1":"An ocular assembly for a head-mounted display may include an opaque enclosure that defines (1) an interior space, (2) an exterior space, (3) a display aperture that admits image light emitted by a display screen into the interior space, (4) a lens aperture, and (5) a lateral aperture that admits the light from the interior space into the exterior space. The ocular assembly may also include an opaque covering for the lateral aperture that is moveable between (1) a closed position that prevents the image light from passing from the interior space through the lateral aperture to the exterior space and (2) an open position that allows the image light to pass from the interior space through the lateral aperture to the exterior space. Various other apparatuses, methods, and systems are also disclosed.","abstract_2":"A technique for operation of a display system includes displaying a display image from a liquid crystal display source, measuring a brightness of ambient light, and selecting a drive voltage for driving liquid crystal cells within the liquid crystal display source based upon the brightness of the ambient light. The drive voltage is used for driving the liquid crystal cells into an on-state or an off-state while displaying the display image.","priority_1":"2017-08-30T00:00:00","priority_2":"2015-10-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8519551367},{"pair":"US-10109067-B2 & US-10032074-B2","patent_1":"US-10109067-B2","title_1":"Corneal sphere tracking for generating an eye model ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10109067B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system comprises two or more illumination sources positioned relative to one another and an optical detector in order to capture. The optical detector is configured to capture images of the cornea based on one or more reflections. The eye tracking unit is configured to generate a model of the user's eye. The generated eye model is used to determine eye tracking information such as gaze direction as the user glances at different objects in the HMD.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-03-11T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8519140215},{"pair":"US-2019037137-A1 & US-2016323567-A1","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-2016323567-A1","title_2":"Virtual eyeglass set for viewing actual scene that corrects for different location of lenses than eyes ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160323567A1\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A virtual eyeglass set may include a frame, a first virtual lens and second virtual lens, and a processor. The frame may mount onto a user's head and hold the first virtual lens in front of the user's left eye and the second virtual lens in front of the user's right eye. A first side of each lens may face the user and a second side of each lens may face away from the user. Each of the first virtual lens and the second virtual lens may include a light field display on the first side, and a light field camera on the second side. The processor may construct, for display on each of the light field displays based on image data received via each of the light field cameras, an image from a perspective of the user's respective eye.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-04-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8518947805},{"pair":"US-2018173303-A1 & US-10572761-B1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-10572761-B1","title_2":"Virtual reality system using super-resolution ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10572761B1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"Displaying video in an HMD may include introducing unperceived noise to the video frame signal in order to enhance dynamic range. For example, each of a viewer's left and right eyes have a field of view (FOV) corresponding to a portion of pixels shown on the HMD. For each of these portions of pixels, the VR system may combine a noise signal (e.g., zero-mean Gaussian white noise) with the video signals corresponding to each of the portions of pixels. The introduction of such noise may improve the dynamic range of the viewer. Further, in some implementations, the noise signal that is combined with the left video signal may be slightly different from the noise signal that is combined with the right video signal. Such slightly different noise signals may provide further improvement to the image seen by the viewer due to binocular summation.","priority_1":"2016-12-21T00:00:00","priority_2":"2017-06-05T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8518867362},{"pair":"US-2019227321-A1 & US-2018136468-A1","patent_1":"US-2019227321-A1","title_1":"Rainbow reduction in waveguide displays ","patent_2":"US-2018136468-A1","title_2":"Freeform projected display ","link_1":"https:\/\/patents.google.com\/patent\/US20190227321A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180136468A1\/en","abstract_1":"A waveguide display includes a first substrate and one or more grating layers on a first surface of the first substrate. The one or more grating layers are configured to cause destructive interference between ambient light diffracted by at least two grating layers or between ambient light diffracted by different portions of one grating layer. In some embodiments, the waveguide display also includes an angular-selective transmissive layer. The angular-selective transmissive layer is configured to reflect, diffract, or absorb ambient light incident on the angular-selective reflective layer with an incidence angle greater than a threshold value.","abstract_2":"A freeform projection display includes an optical emitter configured to output one or more wavelengths of light and an optical diffuser optically coupled to receive and disperse the one or more wavelengths of light from the optical emitter, wherein the optical diffuser has at least one radius of curvature. The freeform projection display further includes a refractive lens optically coupled to receive the one or more wavelengths of light from the optical diffuser and to project the one or more wavelengths of light. The freeform projection display further may include a light modulator disposed between the optical emitter and the optical diffuser, wherein the light modulator oscillates to project the image on the optical diffuser. An illuminated area of the optical diffuser is dimensioned so that the image produced by the light modulator fills an aperture of the refractive lens.","priority_1":"2018-01-23T00:00:00","priority_2":"2016-11-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8518683707},{"pair":"US-10416461-B2 & US-2017293143-A1","patent_1":"US-10416461-B2","title_1":"Pancake lens with large FOV ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10416461B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A HMD includes an electronic display and a pancake lens block. The pancake lens block includes a back curved optical element and a front curved optical element. Light propagating through the pancake lens block undergoes multiple reflections and to mitigate parasitic reflections, there are no air gaps between optical elements of the pancake lens block. A hybrid film that operates as a waveplate surface and a mirrored surface can be placed between the front curved optical element and the back curved optical element. A wide FOV can be obtained by making the coupling surfaces of the front optical element and the back optical element to be based on a convex cylindrical surface profile and a concave cylindrical surface profile, with the axis of the cylinder surface in a vertical direction for a user wearing the HMD.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8518337162},{"pair":"US-10444510-B1 & US-2020041798-A1","patent_1":"US-10444510-B1","title_1":"Opposed gratings in a waveguide display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10444510B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A waveguide display includes a light source assembly, an output waveguide, and a controller. The light source assembly emits an image light that propagates along an input wave vector. The output waveguide includes a waveguide body with two opposite surfaces. The output waveguide includes a first grating receiving an image light propagating along the input wave vector, a second grating, and a third grating positioned opposite to the second grating and outputting an expanded image light with wave vectors matching the input wave vector. The controller controls the illumination of the light source assembly to form a two-dimensional image.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-10-11T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8518014734},{"pair":"US-10598938-B1 & US-2017235145-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2017235145-A1","title_2":"Dynamic lens for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170235145A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A Head Mounted Display (\u201cHMD\u201d) includes a display module to generate image light, an optical combiner, a stacked switchable lens, and control circuitry. The optical combiner combines the image light with external scene light. The optical combiner includes a reflective element coupled to receive the image light and direct the image light in an eye-ward direction. The stacked switchable lens is optically coupled to receive the image light. The stacked switchable lens includes at least a first switching optic and a second switching optic. The control circuitry is configured to selectively activate the first switching optic and the second switching optic. The first switching optic is configured to direct the image light toward a first eyeward region when activated by the control circuitry. The second switching optic is configured to direct the image light toward a second eyeward region when activated by the control circuitry.","priority_1":"2018-11-09T00:00:00","priority_2":"2014-01-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517755203},{"pair":"US-10600352-B1 & US-9285877-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9285877-B2","title_2":"Heads-up display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9285877B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"Embodiments of an apparatus comprising a light guide including a proximal end, a distal end, a display positioned near the proximal end, an eye-measurement camera positioned at or near the proximal end to image eye-measurement radiation, a proximal optical element positioned in the light guide near the proximal end and a distal optical element positioned in the light guide near the distal end. The proximal optical element is optically coupled to the display, the eye-measurement camera and the distal optical element and the distal optical element is optically coupled to the proximal optical element, the ambient input region and the input\/output region. Other embodiments are disclosed and claimed.","priority_1":"2018-12-04T00:00:00","priority_2":"2012-02-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517611477},{"pair":"US-2018267361-A1 & US-9851565-B1","patent_1":"US-2018267361-A1","title_1":"Liquid crystal display backlight utilizing reflective stack ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180267361A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A liquid crystal display (LCD) device including an LCD panel and a backlight. The backlight includes a plurality of light sources to emit light, and a reflective stack. The reflective stack is positioned to receive light emitted from the light sources and transmit the light to the LCD panel. The reflective stack includes optical elements providing a folded beam path for the light emitted from the light sources to the LCD panel. The light emitted from the light sources is diffused while propagating towards and away from the LCD panel along the folded beam path. The folded beam path has an optical distance that is longer than the spatial distance between the light sources and the LCD panel to improve light diffusion by the backlight without substantially increasing backlight thickness.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-03-16T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517605902},{"pair":"US-2018074318-A1 & US-2015169054-A1","patent_1":"US-2018074318-A1","title_1":"Hybrid Fresnel Lens with Reduced Artifacts ","patent_2":"US-2015169054-A1","title_2":"Imaging Method ","link_1":"https:\/\/patents.google.com\/patent\/US20180074318A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150169054A1\/en","abstract_1":"A lens defined by a first lens surface and a second lens surface opposite to the first lens surface is disclosed. A first portion of the first lens surface is defined by a smooth surface profile function, and a second portion of the first lens surface is defined by a Fresnel surface profile function. The second portion of the first lens surface is around the first portion of the first lens surface. Also disclosed is a display device that includes the lens and an array of light emitting devices coupled with the lens for outputting light through the lens.","abstract_2":"A wearable computing device or a head-mounted display (HMD) may be configured to track the gaze axis of an eye of the wearer. In particular, the device may be configured to observe movement of a wearer's pupil and, based on the movement, determine inputs to a user interface. For example, using eye gaze detection, the HMD may change a tracking rate of a displayed virtual image based on where the user is looking. Gazing at the center of the HMD field of view may, for instance, allow for fine movements of the virtual display. Gazing near an edge of the HMD field of view may provide coarser movements.","priority_1":"2016-09-13T00:00:00","priority_2":"2011-11-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517598781},{"pair":"US-2019311522-A1 & US-2017103091-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2017103091-A1","title_2":"Displaying objects based on a plurality of models ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170103091A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"A system and method is provided for displaying surfaces of an object from a vantage point different from the vantage point from which imagery of the object was captured. In some aspects, imagery may be generated for display by combining visual characteristics from multiple source images and applying greater weight to the visual characteristics of some of the source images relative to the other source images. The weight may be based on the orientation of the surface relative to the location from which the image was captured and the location from which the object will be displayed.","priority_1":"2018-04-05T00:00:00","priority_2":"2015-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517570661},{"pair":"US-2019311232-A1 & US-2015242414-A1","patent_1":"US-2019311232-A1","title_1":"Object tracking assisted with hand or eye tracking ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20190311232A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"Embodiments relate to tracking and determining a location of an object in an environment surrounding a user. A system includes one or more imaging devices and an object tracking unit. The system identifies an object in a search region, determines a tracking region that is smaller than the search region corresponding to the object, and scans the tracking region to determine a location associated with the object. The system may generate a ranking of objects, determine locations associated with the objects, and generate a model of the search region based on the locations associated with the objects.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2018-04-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517425805},{"pair":"US-2018074325-A1 & US-9851565-B1","patent_1":"US-2018074325-A1","title_1":"Fresnel Lens with Dynamic Pitch ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20180074325A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The respective Fresnel structure of the plurality of Fresnel structures is characterized by a representative pitch. The representative pitch of the respective Fresnel structure is based on a distance of the respective Fresnel structure from a reference axis of the lens. A display device that includes the lens and an electronic display coupled with the lens for outputting light through the lens and a method for transmitting light from an electronic display toward the lens are also described.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-09-13T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8517300197},{"pair":"US-10109067-B2 & US-10546518-B2","patent_1":"US-10109067-B2","title_1":"Corneal sphere tracking for generating an eye model ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10109067B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system comprises two or more illumination sources positioned relative to one another and an optical detector in order to capture. The optical detector is configured to capture images of the cornea based on one or more reflections. The eye tracking unit is configured to generate a model of the user's eye. The generated eye model is used to determine eye tracking information such as gaze direction as the user glances at different objects in the HMD.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-03-11T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851673912},{"pair":"US-2017352183-A1 & US-2015242414-A1","patent_1":"US-2017352183-A1","title_1":"Face and eye tracking using facial sensors within a head-mounted display ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US20170352183A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"A head mounted display (HMD) in a VR system includes sensors for tracking the eyes and face of a user wearing the HMD. The VR system records calibration attributes such as landmarks of the face of the user. Light sources illuminate portions of the user's face covered by the HMD. In conjunction, facial sensors capture facial data. The VR system analyzes the facial data to determine the orientation of planar sections of the illuminated portions of face. The VR system aggregates planar sections of the face and maps the planar sections to landmarks of the face to generate a facial animation of the user, which can also include eye orientation information. The facial animation is represented as a virtual avatar and presented to the user.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2016-06-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8516725078},{"pair":"US-2019369390-A1 & US-2019086675-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-06-04T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8516574081},{"pair":"US-10261592-B2 & US-2019033988-A1","patent_1":"US-10261592-B2","title_1":"Optical hand tracking in virtual reality systems ","patent_2":"US-2019033988-A1","title_2":"Controller tracking for multiple degrees of freedom ","link_1":"https:\/\/patents.google.com\/patent\/US10261592B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190033988A1\/en","abstract_1":"A system tracks movement of the VR input device relative to a portion of a user's skin, track movement of the VR input device relative to a physical surface external to the VR input device, or both. The system includes an illumination source integrated with a tracking glove coupled to a virtual reality console, and the illumination source is configured to illuminate a portion of skin on a finger of a user. The system includes an optical sensor integrated with the glove, and the optical sensor is configured to capture a plurality of images of the illuminated portion of skin. The system includes a controller configured to identify differences between one or more of the plurality of images, and to determine estimated position data based in part on the identified differences.","abstract_2":"A method for controller tracking with multiple degrees of freedom includes generating depth data at an electronic device based on a local environment proximate the electronic device. A set of positional data is generated for at least one spatial feature associated with a controller based on a pose of the electronic device, as determined using the depth data, relative to the at least one spatial feature associated with the controller. A set of rotational data is received that represents three degrees-of-freedom (3DoF) orientation of the controller within the local environment, and a six degrees-of-freedom (6DoF) position of the controller within the local environment is tracked based on the set of positional data and the set of rotational data.","priority_1":"2015-10-08T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8516468625},{"pair":"US-2020018962-A1 & US-2019086675-A1","patent_1":"US-2020018962-A1","title_1":"Adaptive lenses for near-eye displays ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20200018962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"A lens assembly includes two or more polarization-dependent lenses sensitive to either linear or circular polarization, and at least one switchable polarization converter. The switchable polarization converter is configured to rotate linearly polarized light or change the handedness of circularly polarized light when switched on. The lens assembly is configurable to project displayed images on two or more different image planes. For example, when the switchable polarization converter is switched off, the lens assembly projects a displayed image on a first image plane. When the switchable polarization converter is switched on, the lens assembly projects a displayed image on a second image plane different from the first image plane.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-07-11T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8516345461},{"pair":"US-10154254-B2 & US-10546518-B2","patent_1":"US-10154254-B2","title_1":"Time-of-flight depth sensing for eye tracking ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10154254B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) includes an eye tracking system that determines user's eye tracking information based on depth information derived from time-of-flight methods. The eye tracking system includes an illumination source, an imaging device and a controller. The illumination source illuminates the user's eye with a temporally varying irradiance pattern. The imaging device includes a detector that captures temporal phase shifts (temporal distortions) caused by a local geometry and the illumination pattern being reflected from a portion of the eye. The detector comprises multiple pixels, each pixel having multiple units for capturing, over multiple time instants, light signals related to the temporally distorted illumination pattern. The controller determines phase differences between the temporally distorted illumination pattern and the temporally varying irradiance pattern, based on the captured light signals. The controller determines depth information related to eye surfaces and updates a model of the eye, based on the phase differences.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-01-17T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8516183144},{"pair":"US-2018284884-A1 & US-2019265477-A1","patent_1":"US-2018284884-A1","title_1":"Waveguide display with spatially switchable grating ","patent_2":"US-2019265477-A1","title_2":"Augmented reality light field head-mounted displays ","link_1":"https:\/\/patents.google.com\/patent\/US20180284884A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190265477A1\/en","abstract_1":"A near-eye-display (NED) includes an eye tracking system and a waveguide display. The eye tracking system tracks locations based on a location of the user's eyes. The waveguide display includes a light source, an output waveguide and a controller. The output waveguide includes a dynamic output grating that outputs an expanded image light to the tracked eyebox locations. The decoupling grating is a 2D array of spatially switchable liquid crystal (LC) pixels including an active subset of LC pixels emitting light to regions within the tracked eyebox locations. The decoupling grating dynamically out-couples the expanded image light to the tracked location based on switching instructions generated and provided by the controller.","abstract_2":"A near-eye display system includes a transmissive display panel to display a near-eye light field frame comprising an array of elemental images. The transmissive display panel is configured to transmit light rays of the near-eye light field frame away from the user's eye and towards an array of curved beam splitters. The curved beam splitters collimate the transmitted light rays and reflect the collimated light rays back towards the transmissive display panel for passing to the user's eye.","priority_1":"2017-04-03T00:00:00","priority_2":"2018-02-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8516083131},{"pair":"US-9984507-B2 & US-9405977-B2","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-9405977-B2","title_2":"Using visual layers to aid in initiating a visual search ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9405977B2\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"Methods and devices for initiating a search are disclosed. In one embodiment, a method is disclosed that includes causing a camera on a wearable computing device to record video data, segmenting the video data into a number of layers and, based on the video data, detecting that a pointing object is in proximity to a first layer. The method further includes initiating a first search on the first layer. In another embodiment, a wearable computing device is disclosed that includes a camera configured to record video data, a processor, and data storage comprising instructions executable by the processor to segment the video data into a number of layers and, based on the video data, detect that a pointing object is in proximity to a first layer. The instructions are further executable by the processor to initiate a first search on the first layer.","priority_1":"2015-11-19T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851589932},{"pair":"US-10417784-B1 & US-2017147859-A1","patent_1":"US-10417784-B1","title_1":"Boundary region glint tracking ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10417784B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"Embodiments relate to a head-mounted display including an eye tracking system. The eye tracking system includes a source assembly, a camera, and a controller. In some embodiments, the source assembly is a plurality of sources and are positioned to illuminate at least a peripheral area of a cornea of an eye. In some embodiments, the sources are masked to be a particular shape. The peripheral region is a location on the eye where the cornea transitions to the sclera. In some embodiments, the camera can detect a polarization of the reflected light, and uses polarization to disambiguate possible reflection locations. Similarly, time of flight may also be used to disambiguate potential reflection locations. The controller uses information from the detector to track positions of the user's eyes.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2018-06-29T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515779761},{"pair":"US-10109067-B2 & US-9934583-B2","patent_1":"US-10109067-B2","title_1":"Corneal sphere tracking for generating an eye model ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10109067B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system comprises two or more illumination sources positioned relative to one another and an optical detector in order to capture. The optical detector is configured to capture images of the cornea based on one or more reflections. The eye tracking unit is configured to generate a model of the user's eye. The generated eye model is used to determine eye tracking information such as gaze direction as the user glances at different objects in the HMD.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-03-11T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515736221},{"pair":"US-10379359-B2 & US-9798147-B1","patent_1":"US-10379359-B2","title_1":"Fresnel lens with dynamic draft for reduced optical artifacts ","patent_2":"US-9798147-B1","title_2":"Near-eye display with phase map ","link_1":"https:\/\/patents.google.com\/patent\/US10379359B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9798147B1\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The draft facet is characterized by a draft angle which is based on a distance of the respective Fresnel structure from a reference axis of the lens. The draft angle is between a first angle and a second angle, the first angle corresponding to a direction of a ray, in a first medium, transmitted from a reference off-axis position through the respective Fresnel structure toward a reference pupil. The second angle corresponding to a direction of the ray, in the optically transparent substrate, transmitted from the reference off-axis position through the respective Fresnel structure toward the reference pupil.","abstract_2":"A near-eye display includes a light source, an optical system, and a phase map. The light source emits illumination light. The optical system is configured to receive the illumination light from the light source and output the illumination light as an in-phase wavefront. The phase map is configured to adjust a phase of the in-phase wavefront to form an image in response to being illuminated by the in-phase wavefront. The phase map is pre-recorded with a phase pattern that generates the image.","priority_1":"2016-09-13T00:00:00","priority_2":"2015-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851558561},{"pair":"US-2017358136-A1 & US-10546518-B2","patent_1":"US-2017358136-A1","title_1":"Focus adjusting virtual reality headset ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20170358136A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A virtual scene presented on a display of a virtual reality headset can be adjusted using a varifocal element by changing the shape of one or more optical elements of a pancake lens block, by varying the distance between the two optical elements, or both, based on where in a virtual scene a user is looking. The headset tracks a user's eyes to determine a vergence depth from gaze lines in order to accommodate the user's eye for the determined vergence depth. Accordingly, the shape of one or more optical elements is adjusted, the distance between the two optical elements, or both, is changed to focus light from the display of the virtual reality headset at the vergence depth to keep the user's eye in a zone of comfort as vergence and accommodation change.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-06-10T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851554467},{"pair":"US-10379348-B2 & US-2016057339-A1","patent_1":"US-10379348-B2","title_1":"Hybrid fresnel lens with increased field of view ","patent_2":"US-2016057339-A1","title_2":"Image Capture Technique ","link_1":"https:\/\/patents.google.com\/patent\/US10379348B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160057339A1\/en","abstract_1":"A lens defined by a first lens surface and a second lens surface opposite to the first lens surface is disclosed. The lens includes a first portion; and a second portion that is distinct from the first portion and is located around the first portion. The first lens surface for the first portion of the lens is defined by a Fresnel surface profile. The second lens surface for the first portion of the lens is defined by a smooth surface profile. The first lens surface for a second portion of the lens is defined by a Fresnel surface profile. The second lens surface for the second portion of the lens is defined by a Fresnel surface profile.","abstract_2":"This disclosure relates to winking to capture image data using an image capture device that is associated with a head-mountable device (HMD). An illustrative method includes detecting a wink gesture at an HMD. The method also includes causing an image capture device to capture image data, in response to detecting the wink gesture at the HMD.","priority_1":"2016-09-13T00:00:00","priority_2":"2012-04-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515476622},{"pair":"US-10379348-B2 & US-2020041798-A1","patent_1":"US-10379348-B2","title_1":"Hybrid fresnel lens with increased field of view ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10379348B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens defined by a first lens surface and a second lens surface opposite to the first lens surface is disclosed. The lens includes a first portion; and a second portion that is distinct from the first portion and is located around the first portion. The first lens surface for the first portion of the lens is defined by a Fresnel surface profile. The second lens surface for the first portion of the lens is defined by a smooth surface profile. The first lens surface for a second portion of the lens is defined by a Fresnel surface profile. The second lens surface for the second portion of the lens is defined by a Fresnel surface profile.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-09-13T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515471789},{"pair":"US-10200624-B2 & US-10545215-B2","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-10545215-B2","title_2":"4D camera tracking and optical stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545215B2\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"A light-field video stream may be processed to modify the camera pathway from which the light-field video stream is projected. A plurality of target pixels may be selected, in a plurality of key frames of the light-field video stream. The target pixels may be used to generate a camera pathway indicative of motion of the camera during generation of the light-field video stream. The camera pathway may be adjusted to generate an adjusted camera pathway. This may be done, for example, to carry out image stabilization. The light-field video stream may be projected to a viewpoint defined by the adjusted camera pathway to generate a projected video stream with the image stabilization.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-09-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515119875},{"pair":"US-2019212546-A1 & US-2018343443-A1","patent_1":"US-2019212546-A1","title_1":"Varifocal apparatuses, systems, and methods employing a deformable stepped lens ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20190212546A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"The disclosed apparatus may include (1) a deformable stepped lens that (a) provides a first optical power when a shape of the deformable stepped lens includes a first state, and (b) provides a second optical power different from the first optical power when the shape of the deformable stepped lens includes a second state different from the first state and (2) an actuator coupled to the deformable stepped lens that, when actuated, applies force to the deformable stepped lens to alter the shape of the deformable stepped lens from the first state to the second state. Various other apparatuses, systems, and methods are also disclosed.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-01-08T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515106997},{"pair":"US-10520729-B1 & US-10241329-B2","patent_1":"US-10520729-B1","title_1":"Light scattering element for providing optical cues for lens position adjustment ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10520729B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A method includes displaying a high contrast image on a display screen; and projecting the high contrast image through a Fresnel lens to provide a cue for adjusting a position of the Fresnel lens. Also disclosed is a device for determining and\/or adjusting an offset of a Fresnel lens. The device includes a Fresnel lens and a display screen configured to project a high contrast image through the Fresnel lens. Further disclosed is a method for adjusting a position of a Fresnel lens. The method includes receiving a projection of a high contrast image transmitted through a Fresnel lens; and adjusting a position of the Fresnel lens based on the projection of the high contrast image.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-04-25T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8515083372},{"pair":"US-10529276-B2 & US-2017289529-A1","patent_1":"US-10529276-B2","title_1":"Apparatus, systems, and methods for preventing display flicker ","patent_2":"US-2017289529-A1","title_2":"Anaglyph head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10529276B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170289529A1\/en","abstract_1":"A display device may include (1) a display panel with at least one pixel element and (2) a display driver configured to (a) transition the pixel element to a first state, (b) illuminate, after the pixel element transitions to the first state, the pixel element for a first period of illumination, (c) refrain, after the first period of illumination, from illuminating the pixel element for a period of no illumination, (d) illuminate, while the pixel element is still in the first state and after the period of no illumination, the pixel element for a second period of illumination to at least reduce perceived flickering of the display panel, and (e) transition, after the second period of illumination, the pixel element from the first state to a second state. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"In one general aspect, a binocular anaglyph head mounted display (HMD) device can include a first monocular including a first display device and a first optical system. The first display device can be a single color display device configured to display image content on the first display device in a first color. The binocular anaglyph head mounted display (HMD) device can include a second monocular including a second display device and a second optical system. The second display device can be a two color display device configured to display image content on the second display device in a second color that is chromatically opposite to the first color.","priority_1":"2018-01-05T00:00:00","priority_2":"2016-03-29T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8514827416},{"pair":"US-10540930-B1 & US-9934583-B2","patent_1":"US-10540930-B1","title_1":"Apparatus, systems, and methods for temperature-sensitive illumination of liquid crystal displays ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10540930B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A display device may include (1) a liquid crystal (LC) panel with rows of pixel elements that include LC material capable of transitioning between two states, (2) a backlight coupled to the LC panel behind the rows of pixel elements and configured to emit light towards the rows of pixel elements, (3) a temperature sensor configured to measure a temperature of the LC panel, and (4) a display driver configured to (a) scan data to the rows of pixel elements such that the LC material makes a transition between the two states, (b) read, from the temperature sensor, the temperature of the LC panel, (c) calculate, based on the temperature of the LC panel, an estimated transition period for the transition, and (d) initiate, after the estimated transition period, an illumination of the backlight to illuminate the rows of pixel elements. Various other apparatus, systems, and methods are also disclosed.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-01-05T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8514580986},{"pair":"US-2017295354-A1 & US-2018329602-A1","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8514220014},{"pair":"US-2020090406-A1 & US-9626790-B1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-9626790-B1","title_2":"View-dependent textures for interactive geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9626790B1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a polygon mesh to provide a textured three-dimensional model of a geographic area are provided. The view-dependent texture can be optimized for viewing the three-dimensional model from a single reference direction. When a user navigates to a camera viewpoint of the three-dimensional model associated with the single reference direction, the view-dependent texture can be rendered in conjunction with the three-dimensional model to provide a more realistic representation of the geographic area to the user. When a user navigates to a camera viewpoint of the three-dimensional model that is not associated with the single reference direction, a base texture can be rendered in conjunction with the three-dimensional model. The base texture can be optimized based on viewing the three-dimensional model from a plurality of differing viewpoints.","priority_1":"2018-09-17T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8514205931},{"pair":"US-2019227322-A1 & US-2017293143-A1","patent_1":"US-2019227322-A1","title_1":"Light projection system including an optical assembly for correction of differential distortion ","patent_2":"US-2017293143-A1","title_2":"Curved eyepiece with color correction for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190227322A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170293143A1\/en","abstract_1":"A light projection system includes a light source configured to emit image light and an optical assembly configured to provide positive optical power to the image light and optically correct the image light. The optical assembly comprises a plurality of optical elements configured to correct differential distortion related to the image light across a field of view (FOV) within a threshold amount. The differential distortion is corrected based in part on asymmetry of the plurality of optical elements relative to an optical axis shared by the plurality of optical elements.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light to a viewing region offset from a peripheral location and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes a curved lightguide to guide the display light, an eye-ward facing surface that is concave, a world facing surface that is convex and opposite the eye-ward facing surface, and an optical combiner disposed at the viewing region to redirect the display light towards the eye-ward direction for output from the curved lightguide. The optical combiner is partially transmissive to ambient light incident through the world facing surface such that the viewing region is see-through. In some embodiments, a prism is disposed proximate to the input surface to pre-compensate the display light for lateral chromatic aberrations resulting the curved lightguide.","priority_1":"2018-01-25T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851359274},{"pair":"US-10210660-B2 & US-10540818-B2","patent_1":"US-10210660-B2","title_1":"Removing occlusion in camera views ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US10210660B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"An image processing system is designed to generate a canvas view that has smooth transition between binocular views and monocular views. Initially, the image processing system receives top\/bottom images and side images of a scene and calculates offsets to generate synthetic side images for left and right view of a user. To realize smooth transition between binocular views and monocular views, the image processing system first warps top\/bottom images onto corresponding synthetic side images to generate warped top\/bottom images, which realizes the smooth transition in terms of shape. The image processing system then morphs the warped top\/bottom images onto the corresponding synthetic side images to generate blended images for left and right eye views with the blended images. The image processing system creates the canvas view which has smooth transition between binocular views and monocular views in terms of image shape and color based on the blended images.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8513536318},{"pair":"US-10109067-B2 & US-2017147859-A1","patent_1":"US-10109067-B2","title_1":"Corneal sphere tracking for generating an eye model ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10109067B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to enable eye-tracking using light. The eye tracking system comprises two or more illumination sources positioned relative to one another and an optical detector in order to capture. The optical detector is configured to capture images of the cornea based on one or more reflections. The eye tracking unit is configured to generate a model of the user's eye. The generated eye model is used to determine eye tracking information such as gaze direction as the user glances at different objects in the HMD.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2016-03-11T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8513283509},{"pair":"US-2019361518-A1 & US-10591731-B2","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2018-05-22T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851295695},{"pair":"US-10200624-B2 & US-2018342075-A1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-2018342075-A1","title_2":"Multi-view back-projection to a light-field ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180342075A1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"Dense light-field data can be generated from image data that does not include light-field data, or from image data that includes sparse light-field data. In at least one embodiment, the source light-field data may include one or more sub-aperture images that may be used to reconstruct the light-field in denser form. In other embodiments, the source data can take other forms. Examples include data derived from or ancillary to a set of sub-aperture images, synthetic data, or captured image data that does not include full light-field data. Interpolation, back-projection, and\/or other techniques are used in connection with source sub-aperture images or their equivalents, to generate dense light-field data.","priority_1":"2016-04-06T00:00:00","priority_2":"2017-05-25T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8512373948},{"pair":"US-2020018962-A1 & US-9709797-B2","patent_1":"US-2020018962-A1","title_1":"Adaptive lenses for near-eye displays ","patent_2":"US-9709797-B2","title_2":"Doublet eyepiece for head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20200018962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9709797B2\/en","abstract_1":"A lens assembly includes two or more polarization-dependent lenses sensitive to either linear or circular polarization, and at least one switchable polarization converter. The switchable polarization converter is configured to rotate linearly polarized light or change the handedness of circularly polarized light when switched on. The lens assembly is configurable to project displayed images on two or more different image planes. For example, when the switchable polarization converter is switched off, the lens assembly projects a displayed image on a first image plane. When the switchable polarization converter is switched on, the lens assembly projects a displayed image on a second image plane different from the first image plane.","abstract_2":"An eyepiece for a head mounted display (\u201cHMD\u201d) includes a doublet lens that includes a first optical element and a second optical element. The first optical element has an entry surface to receive the display light from a micro display and a first coupling surface. The second optical element has an exit surface and a second coupling surface paired to the first coupling surface of the first optical element. The doublet lens is configured to direct the display light through the first coupling surface, the second coupling surface, and through the exit surface.","priority_1":"2018-07-11T00:00:00","priority_2":"2014-02-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8512295187},{"pair":"US-2020064633-A1 & US-10345589-B1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-10345589-B1","title_2":"Compact near-eye hologram display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10345589B1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An apparatus includes a holographic film having one or more reflective holograms recorded therein. One or more light sources positioned to direct light toward a corresponding one of the one or more holograms, and a dynamic mask positioned between the one or more light sources and the holographic film to spatially modulate light traveling between the one or more light sources and the one or more reflective holograms but not spatially modulate ambient light traveling through the hologram.","priority_1":"2018-08-23T00:00:00","priority_2":"2015-06-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851227014},{"pair":"US-10574938-B1 & US-10591731-B2","patent_1":"US-10574938-B1","title_1":"Variable frame rate depth camera assembly ","patent_2":"US-10591731-B2","title_2":"Ocular video stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10574938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10591731B2\/en","abstract_1":"A depth camera assembly (DCA) for depth sensing of a local area. The DCA includes a light generator, a detector, and a controller. The light generator illuminates a local area with a light pattern. The detector captures portions of the light pattern reflected from an object in the local area. The detector includes pixel rows and pixel columns that form a dynamically adjustable read-out area. The controller reads first data of the captured portions of the reflected light pattern that correspond to a first read-out area, and locates the object based on the first data. The controller determines a second read-out area of the detector based on a portion of the read-out area associated with the object. The controller reads second data of the captured portions of the reflected light pattern that correspond to the second read-out area, and determines depth information for the object based on the second data.","abstract_2":"A system and method for ocular stabilization of video images is disclosed. While capturing video images in a forward field of view with a forward-facing video camera of a wearable head-mountable device (HMD), binocular eye-gaze directions of left and right eyes of a user of the HMD may be obtained with an eye-tracking device of the HMD. Based on the obtained binocular eye-gaze directions of left and right eyes of the user of the HMD, convergent gaze directions of the user may be determined as a function of time during an interval concurrent with the capturing of the video images. The captured video images may then be stabilized by compensating for motion of the forward-facing video camera with an intersection of the convergent gaze directions of the user with an image plane of the forward-facing video camera.","priority_1":"2017-06-27T00:00:00","priority_2":"2016-12-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8512102944},{"pair":"US-2018157320-A1 & US-10546518-B2","patent_1":"US-2018157320-A1","title_1":"Air spaced optical assembly with integrated eye tracking ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180157320A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) includes a display, an optical assembly and an eye tracking system that determines user's eye tracking information. The optical assembly comprises a front optical element in series with a back optical element adjacent to the display. One surface of the back optical element is coated to reflect infrared (IR) light. The eye tracking system includes an illumination source and an imaging device positioned between the front optical element and the back optical element. The illumination source emits IR light that illuminates the coated surface and reflects towards the user's eye. The imaging device captures an image of the user's eye based on light reflected from the user's eye and from the coated surface. The eye tracking information is determined based on the captured image. The HMD adjusts presentation of images displayed on the display, based on the eye tracking information.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-12-01T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.851189981},{"pair":"US-2016085301-A1 & US-2019311467-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2019311467-A1","title_2":"Enhanced specular reflections for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311467A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Systems and methods for enhanced specular reflections are provided. An example method may include determining a first portion of a specular reflection associated with a computer-generated object based on a first contribution from an environment map component at a shading point of the computer-generated object and determining a second portion of the specular reflection associated with the computer-generated object based on a second contribution from a camera feed component at an intersection point of a camera feed and a reflection vector associated with the environment map component. The example method may further include determining the specular reflection, at the shading point, associated with the computer-generated object based on a blending of the first and second portions of the specular reflection.","priority_1":"2014-09-22T00:00:00","priority_2":"2018-04-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8511873046},{"pair":"US-2020064641-A1 & US-10241329-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8511604464},{"pair":"US-10509228-B1 & US-2018343443-A1","patent_1":"US-10509228-B1","title_1":"Low field myopia for artificial reality systems ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US10509228B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"A head-mounted display (HMD) presented herein comprises an electronic display and an optical assembly. The electronic display is configured to emit image light. The optical assembly is configured to direct the image light to an eye-box of the HMD corresponding to a location of a user's eye. The electronic display is positioned with respect to an optical axis of the HMD such that a first portion of the image light emitted by a first portion of the electronic display and a second portion of the image light emitted by a second portion of the electronic display appear to originate at different distances from the optical assembly such that the optical assembly generates at least a first image plane associated with the first portion of the electronic display and a second image plane associated with the second portion of the electronic display.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2017-12-20T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510954303},{"pair":"US-2018033405-A1 & US-2019037194-A1","patent_1":"US-2018033405-A1","title_1":"Adaptive parameters in image regions based on eye tracking information ","patent_2":"US-2019037194-A1","title_2":"Depth data adjustment based on non-visual pose data ","link_1":"https:\/\/patents.google.com\/patent\/US20180033405A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190037194A1\/en","abstract_1":"A display system divides a screen into regions and applies a different set of rendering\/encoding parameters to each region. The system applies a first set of parameters to a first region that is being viewed by a fovea of an eye of a user. The system may also apply a second set of parameters to a second region that is being viewed by a parafovea of the eye, and apply a third set of parameters to a third region that is being viewed by the area of the eye outside of the parafovea. The first set of parameters are selected to yield relatively high image quality, while the second set of parameters are yield intermediate quality, and the third set of parameters yield lower quality. As a result, the second region and the third region can be rendered, encoded, and transmitted with less computing power and less bandwidth.","abstract_2":"An HMD adjusts adjusting depth information based on detected motion of the system. The HMD includes a depth camera that collects depth data for objects in the local environment of the HMD. The HMD further includes an inertial measurement unit (IMU) including non-visual motion sensors such as one or more accelerometers, gyroscopes, and the like. The HMD adjusts the received depth information based on motion data provided by the IMU, thereby improving the accuracy of the depth information, and in turn reducing visual artifacts that can result from inaccuracies in the depth information.","priority_1":"2016-08-01T00:00:00","priority_2":"2017-07-26T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510680843},{"pair":"US-10466779-B1 & US-9934583-B2","patent_1":"US-10466779-B1","title_1":"Event camera for eye tracking ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10466779B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An eye tracking system includes an event camera. The event camera includes an event sensor and a controller. The event sensor includes a plurality of photodiodes that asynchronously output data values corresponding to relative intensity changes of light reflected from a user's eyes. The controller populates an event matrix based in part on data values asynchronously received from the event sensor and positions of photodiodes associated with the received data values over a first time period. The controller populates a change matrix based in part on a threshold intensity value and the photodiodes associated with the received data values over the first time period, and generates an image of the user's eyes for the first time period using the event matrix and the change matrix. The eye tracking system uses the image of the user's eyes to determine eye tracking information indicating positions, orientations and\/or movement of the user's eyes.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-07-24T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510544183},{"pair":"US-2017263007-A1 & US-10032074-B2","patent_1":"US-2017263007-A1","title_1":"Eye tracking system with single point calibration ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20170263007A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A head mounted display (HMD) comprises an eye tracking system configured to perform a calibration process using an eye tracking system of the HMD that includes determining a pupillary axis and\/or determining an angular offset between the pupillary axis and the eye's true line of sight. The eye tracking system obtains an eye model captures images of the user's pupil while the user is looking at a target or other content displayed on the HMD. In some embodiments, the calibration process is based on a single image of the user's eye and is performed only once. For example, the process can be performed the first time the user uses the HMD, which stores the calibration data for the user in a memory for future use.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-03-11T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510196893},{"pair":"US-10429657-B1 & US-10546518-B2","patent_1":"US-10429657-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10429657B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light undergoes multiple reflections before being captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block. Moreover, each reflection results in a particular view of the eye that results in multiple views of the eye being received by the image capturing element.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-01-18T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510139066},{"pair":"US-10429656-B1 & US-10546518-B2","patent_1":"US-10429656-B1","title_1":"Eye tracking for a head mounted display including a pancake lens block ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10429656B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted display (HMD) includes a pancake lens block, an eye tracking system, and an electronic display. The electronic display is coated with a dichroic film that transmits visible light and reflects infrared light (IR). An IR emitter illuminates an eye of the user, and infrared light is reflected from an eye through the pancake lens block and is incident on the dichroic film. The reflected light is captured by an image capturing element of the eye tracking system that is positioned at a periphery of HMD located off-axis relative to an optical axis of the pancake lens block.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-01-18T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510139066},{"pair":"US-10152121-B2 & US-9851565-B1","patent_1":"US-10152121-B2","title_1":"Eye tracking through illumination by head-mounted displays ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10152121B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted display (HMD) presents content for viewing by users. The HMD includes a display element, an optics block, and a camera. The display element includes content pixels for providing light corresponding to the displayed content and one or more tracking pixels for providing tracking light used for tracking the user's eye movements. The optics block directs light from the display element (light corresponding to the displayed content and that of tracking light) to an exit pupil of the HMD. The camera captures one or images of an eye of the user in response to projecting tracking light on the eye, where the one or more captured images include a distortion of the projected tracking light and are used in determining an orientation of the eye at a time of capturing the one or more images of the eye.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-01-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510138671},{"pair":"US-10600352-B1 & US-2020041790-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2020041790-A1","title_2":"Catadioptric freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041790A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An optical device, such as a head mounted display, includes a display that emits light, a reflector, and a partially reflective circular polarizer (RCP) positioned between the reflector and a user's eye or eyes. The reflector can be partially reflective. The partially reflective circular polarizer, the reflector, or both, can be curved. Light from the display is reflected one or more times by the reflector. The RCP can include one or more of a quarter-wave plate (QWP), a reflective polarizer layer, a linear polarizer, a supportive substrate, and an anti-reflective film. The reflector can include a mirror coating and an anti-reflection coating.","priority_1":"2018-12-04T00:00:00","priority_2":"2018-08-02T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510110646},{"pair":"US-2016085301-A1 & US-9377869-B2","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-9377869-B2","title_2":"Unlocking a head mountable device ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9377869B2\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Embodiments described herein may help to provide a lock-screen for a computing device. An example method involves, while a computing device is in a locked mode, the computing device: (a) analyzing head-pose data to determine whether a head pose associated with the computing device matches a predetermined head pose, (b) analyzing touchpad data associated with the computing device to detect a predetermined sequence of touch gestures, (c) if both (i) the head pose matches the predetermined head pose and (ii) the predetermined sequence of touch gestures is detected, then the computing device switching to an unlocked mode, and (d) otherwise, refraining from causing computing device switch to the unlocked mode.","priority_1":"2014-09-22T00:00:00","priority_2":"2013-06-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8510079302},{"pair":"US-10248890-B2 & US-9892496-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9892496-B2","title_2":"Edge-aware bilateral image processing ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9892496B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Example embodiments may allow for the efficient, edge-preserving filtering, upsampling, or other processing of image data with respect to a reference image. A cost-minimization problem to generate an output image from the input array is mapped onto regularly-spaced vertices in a multidimensional vertex space. This mapping is based on an association between pixels of the reference image and the vertices, and between elements of the input array and the pixels of the reference image. The problem is them solved to determine vertex disparity values for each of the vertices. Pixels of the output image can be determined based on determined vertex disparity values for respective one or more vertices associated with each of the pixels. This fast, efficient image processing method can be used to enable edge-preserving image upsampling, image colorization, semantic segmentation of image contents, image filtering or de-noising, or other applications.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-11-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8509683735},{"pair":"US-10497295-B1 & US-10546518-B2","patent_1":"US-10497295-B1","title_1":"Near-eye display assembly with adjustable resolution and frame rate ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10497295B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near-eye display (NED) comprises an electronic display, an optical assembly, a scanning assembly, and a controller. The controller generates display instructions based in part on content. The display instructions describe a resolution within an adjustable range of resolutions and a frame rate within adjustable range of frame rates. The electronic display emits a plurality of light rays at the frame rate based on the display instructions. The scanning assembly shifts a direction of at least one of the plurality of light rays in accordance with the display instructions. The optical assembly controls a field of view at an eye box and directs the plurality of light rays including the at least one shifted light ray toward the eye box. The plurality of light rays form a virtual display that displays the content at the resolution and the frame rate.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-03-14T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8509608481},{"pair":"US-2018173303-A1 & US-2017180721-A1","patent_1":"US-2018173303-A1","title_1":"Eye tracking using a light field camera on a head-mounted display ","patent_2":"US-2017180721-A1","title_2":"System and method for performing electronic display stabilization via retained lightfield rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20180173303A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170180721A1\/en","abstract_1":"A head mounted display (HMD) includes one or more light field cameras for tracking one or both eyes of a user wearing the HMD. The HMD optionally includes light sources positioned inside the HMD and that illuminate one or both of the eyes of the user. The light field camera captures a plenoptic image of the user's eye. The plenoptic image includes light intensity data and direction data of the captured light rays. An eye tracking system updates a 3D light field model of the user's eye based on depth information from the plenoptic image frame. The eye tracking system identifies an iris plane of the user's eye using the 3D light field model. The eye tracking system determines a gaze direction of the user's eye by identifying the normal to the center of the iris plane.","abstract_2":"In a system having a user-portable display device, a method includes maintaining a lightfield data structure representing at least a portion of a four-dimensional (4D) lightfield for a three-dimensional (3D) world in association with a first pose of the user-portable display device relative to the 3D world. The method further includes determining a second pose of the user-portable display device relative to the 3D world, the second pose comprising an updated pose of the user-portable display device. The method additionally includes generating a display frame from the lightfield data structure based on the second pose, the display frame representing a field of view of the 3D world from the second pose.","priority_1":"2016-12-21T00:00:00","priority_2":"2015-12-22T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8509469519},{"pair":"US-10529087-B1 & US-9551579-B1","patent_1":"US-10529087-B1","title_1":"System for a depth mapping device ","patent_2":"US-9551579-B1","title_2":"Automatic connection of images using visual features ","link_1":"https:\/\/patents.google.com\/patent\/US10529087B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551579B1\/en","abstract_1":"A depth mapping device comprises a plurality of imaging components arranged among one or more rings. A depth mapping device may be designed by identifying a plurality of configurations satisfying a set of input parameters that includes a number of imaging components, each configuration indicating a different arrangement of imaging components among one or more rings. Coverages for different configuration parameter sets for the configuration are analyzed to determine a configuration parameter set associated with the configuration having a highest coverage, where the coverage is indicative of an amount of a local area viewable by a depth mapping device using the configuration and associated configuration parameter set. A target configuration having a highest coverage is selected and used to generate a depth mapping device design to be manufactured.","abstract_2":"Aspects of the disclosure relate generating navigation paths between images. A first image taken from a first location and a second image taken from a second location may be selected. A position of the first location in relation to the second location may be determined. First and second frames for the first and second images may be selected based on the position. First and second sets of visual features for each of the first and second image frames may be identified. Matching visual features between the first set of visual features and the second set of visual features may be determined. A confidence level for a line-of-sight between the first and second images may be determined by evaluating one or more positions of the matching visual features. Based on at least the confidence level, a navigation path from the first image to the second image is generated.","priority_1":"2017-09-26T00:00:00","priority_2":"2015-08-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.85093387},{"pair":"US-10557994-B1 & US-9671614-B2","patent_1":"US-10557994-B1","title_1":"Waveguide grating with spatial variation of optical phase ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10557994B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An optical waveguide is disclosed. The optical waveguide includes a plate of transparent material comprising opposed first and second surfaces for guiding an optical beam between the surfaces by at least one of reflection or diffraction. A diffraction grating is disposed at the first surface for spreading the optical beam by diffracting portions thereof into a non-zero diffraction order to propagate inside the plate. The first diffraction grating includes an array of parallel grooves structured to provide a spatial variation of optical phase of the portions of the optical beam diffracted by the first diffraction grating into the non-zero diffraction order.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-09-24T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508962219},{"pair":"US-10394040-B2 & US-2019271844-A1","patent_1":"US-10394040-B2","title_1":"Head mounted display including pancake lens block ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10394040B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head mounted display (HMD) includes a display and a pancake lens block. The display with a circular polarizer, comprised of an initial linear polarizer and a first quarter-waveplate with polarizer transmission axis 45\u00b0 from the waveplate fast axis, emits polarized light. The pancake lens includes a partial reflector, a second quarter-waveplate, and a beam splitting polarizer. The pancake lens receives polarized light from the display. Light propagating through the pancake lens undergoes multiple reflections and transmissions achieved by coordinating changes in polarization of light through these optical elements. To mitigate parasitic light from degrading image quality of the HMD, the fast axis orientation of the first quarter-waveplate is oriented 90\u00b0 relative to the fast axis orientation of the second quarter-waveplate, and thus the transmission axis of the first polarizer is oriented 90\u00b0 relative to the transmission axis of the beam splitting polarizer.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2016-10-12T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508948227},{"pair":"US-2017295354-A1 & US-10038887-B2","patent_1":"US-2017295354-A1","title_1":"Efficient determination of optical flow between images ","patent_2":"US-10038887-B2","title_2":"Capture and render of panoramic virtual reality content ","link_1":"https:\/\/patents.google.com\/patent\/US20170295354A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10038887B2\/en","abstract_1":"A canvas generation system generates a canvas view of a scene based on a set of original camera views depicting the scene, for example to recreate a scene in virtual reality. Canvas views can be generated based on a set of synthetic views generated from a set of original camera views. Synthetic views can be generated, for example, by shifting and blending relevant original camera views based on an optical flow across multiple original camera views. An optical flow can be generated using an iterative method which individually optimizes the optical flow vector for each pixel of a camera view and propagates changes in the optical flow to neighboring optical flow vectors.","abstract_2":"Systems and methods are described for defining a set of images based on captured images, receiving a viewing direction associated with a user of a virtual reality (VR) head mounted display, receiving an indication of a change in the viewing direction. The methods further include configuring, a re-projection of a portion of the set of images, the re-projection based at least in part on the changed viewing direction and a field of view associated with the captured images, and converting the portion from a spherical perspective projection into a planar perspective projection, rendering by the computing device and for display in the VR head mounted display, an updated view based on the re-projection, the updated view configured to correct distortion and provide stereo parallax in the portion, and providing, to the head mounted display, the updated view including a stereo panoramic scene corresponding to the changed viewing direction.","priority_1":"2016-04-06T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508702579},{"pair":"US-10495882-B1 & US-9934583-B2","patent_1":"US-10495882-B1","title_1":"Positioning cameras in a head mounted display to capture images of portions of a face of a user ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10495882B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A virtual reality (VR) or augmented reality (AR) head mounted display (HMD) includes multiple image capture devices positioned within and on the HMD to capture portions of a face of a user wearing the HMD. Multiple image capture devices are included within the HMD to capture different portions of the face of the user within the HMD, and one or more other image capture devices are positioned to capture portions of the face of the user external to the HMD. Captured images from various image capture devices may be communicated to a console or a controller that generates a graphical representation of the user's face based on the captured images.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-06-04T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508579831},{"pair":"US-2019197667-A1 & US-2017336511-A1","patent_1":"US-2019197667-A1","title_1":"Computing high-resolution depth images using machine learning techniques ","patent_2":"US-2017336511-A1","title_2":"System and method for concurrent odometry and mapping ","link_1":"https:\/\/patents.google.com\/patent\/US20190197667A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170336511A1\/en","abstract_1":"A system trains a machine learning model to generate a high-resolution depth image. During a training phase, the system generates an accurate three dimensional reconstruction of a training scene such that the machine learning model is iteratively trained to minimize an error between the higher resolution depth image and the depth information in the accurate three dimensional reconstruction. During a real-time phase, the system applies the trained machine learning model to images captured from a scene of interest and generates a higher resolution depth image with higher accuracy. Thus, the higher resolution depth image can be subsequently used to solve computer vision problems.","abstract_2":"An electronic device tracks its motion in an environment while building a three-dimensional visual representation of the environment that is used to correct drift in the tracked motion. A motion tracking module estimates poses of the electronic device based on feature descriptors corresponding to the visual appearance of spatial features of objects in the environment. A mapping module builds a three-dimensional visual representation of the environment based on a stored plurality of maps, and feature descriptors and estimated device poses received from the motion tracking module. The mapping module provides the three-dimensional visual representation of the environment to a localization module, which identifies correspondences between stored and observed feature descriptors. The localization module performs a loop closure by minimizing the discrepancies between matching feature descriptors to compute a localized pose. The localized pose corrects drift in the estimated pose generated by the motion tracking module.","priority_1":"2017-12-26T00:00:00","priority_2":"2016-05-18T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508514774},{"pair":"US-10504243-B2 & US-2019020869-A1","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508207202},{"pair":"US-2016085301-A1 & US-2016080672-A1","patent_1":"US-2016085301-A1","title_1":"Display visibility based on eye convergence ","patent_2":"US-2016080672-A1","title_2":"Preparation of Image Capture Device in Response to Pre-Image-Capture Signal ","link_1":"https:\/\/patents.google.com\/patent\/US20160085301A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160080672A1\/en","abstract_1":"Gaze information of a user can be determined by a computing device that analyzes images of the user. Gaze information of a user includes information such as the user's line of sight, point of regard information, the direction of the user's gaze, the depth of convergence of the user's gaze, and the like. The computing device is able to estimate the distance from the user at which the user is focusing (for example, at a screen near the user or at an object farther away). The visibility and display characteristics of objects displayed on the HUD may be based on the gaze information. For example, content on a heads-up display (HUD) on a windshield may be more transparent while the user is looking through the windshield and more opaque (or otherwise enhanced) while the user is focusing on the HUD.","abstract_2":"Embodiments may be implemented by a computing device, such as a head-mountable display or mobile phone, in order to pre-emptively warm up the device's camera, when it is probable that a user will be taking a photo. An illustrative method involves a computing device (a) receiving sensor data from one or more sensors associated with the computing device, wherein the computing device comprises an image-capture device, (b) analyzing the sensor data to detect at least one pre-image-capture signal, wherein the at least one pre-image-capture signal indicates a subsequent image-capture signal is likely to be received, and (c) in response to detecting the at least one pre-image-capture signal, causing the computing device to initiate an image-capture preparation process that prepares the image-capture device to capture an image.","priority_1":"2014-09-22T00:00:00","priority_2":"2013-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8508112331},{"pair":"US-2019318706-A1 & US-2017270637-A1","patent_1":"US-2019318706-A1","title_1":"Display device with dynamic resolution enhancement ","patent_2":"US-2017270637-A1","title_2":"Electro-optic beam steering for super-resolution\/lightfield imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20190318706A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170270637A1\/en","abstract_1":"A display apparatus includes an electronic display having a pixel array configured to display a sequence of subframes, and an image shifting electro-optic device that is operable to shift at least a portion of an image of the display pixel array synchronously with displaying the sequence of subframes, so as to form a sequence of offset subframe images for providing an enhanced image resolution and pixel correction in a compound image. The image shifting electro-optic device may include a polarization switch in series with a polarization grating, for shifting image pixels between offset image positions in coordination with displaying consecutive subframes.","abstract_2":"A near-eye display system includes a display panel, a beam steering assembly facing the display panel, a display controller, and a beam steering controller. The beam steering assembly imparts one of a plurality of net deflection angles to incident light. The display controller drives the display panel to display a sequence of images, and the beam steering controller controls the beam steering assembly to impart a different net deflection angle for each displayed image of the sequence. The sequence of images, when displayed within the visual perception interval, may be perceived as a single image having a resolution greater than the resolution of the display panel or having larger apparent pixel sizes that conceal the black space between pixels of the display, or the sequence of images may represent a lightfield with the angular information represented in the net deflection angles imparted into the images as they are projected.","priority_1":"2018-04-16T00:00:00","priority_2":"2016-03-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8507903202},{"pair":"US-10521658-B2 & US-9870049-B2","patent_1":"US-10521658-B2","title_1":"Embedded eye tracker with dichroic mirror ","patent_2":"US-9870049-B2","title_2":"Reflective lenses to auto-calibrate a wearable system ","link_1":"https:\/\/patents.google.com\/patent\/US10521658B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9870049B2\/en","abstract_1":"An eyewear device has an optical element, a source, a dichroic mirror, and a camera. The optical element has a front surface, a back surface, a rim, and an angled portion of the rim. The source emits light in a first band of light and is configured to illuminate a portion of an eye of a user of the eyewear device. The dichroic mirror is arranged proximate to the angled portion of the rim, is reflective in the first band of light, is transmissive in a second band of light, and is configured to direct light in the first band reflected from the portion of the eye toward a first position. The camera is located in the first position that is located in a plane of the optical element, and the camera is configured to capture images of the light in the first band reflected by the dichroic mirror.","abstract_2":"Example embodiments include a lens having an IR-reflective coating that is selectively applied to form a variable infrared (IR) interaction pattern on the lens. The variable IR interaction pattern may vary in the manner it interacts with IR wavelengths, so as to provide a machine-readable code when the lens is illuminated by IR light. Accordingly, variable IR interaction patterns may be used to identify particular lenses. Accordingly, a glasses-style, modular, head-mountable device (HMD) may identify which of a number of different possible lenses are currently attached to the HMD, and update certain processes according to the lens or lenses is or are attached. For example, an HMD may calibrate an eye-tracking process according to the particular lens that is attached.","priority_1":"2017-07-07T00:00:00","priority_2":"2015-07-31T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.850710182},{"pair":"US-2019369390-A1 & US-2020041790-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2020041790-A1","title_2":"Catadioptric freeform head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041790A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An optical device, such as a head mounted display, includes a display that emits light, a reflector, and a partially reflective circular polarizer (RCP) positioned between the reflector and a user's eye or eyes. The reflector can be partially reflective. The partially reflective circular polarizer, the reflector, or both, can be curved. Light from the display is reflected one or more times by the reflector. The RCP can include one or more of a quarter-wave plate (QWP), a reflective polarizer layer, a linear polarizer, a supportive substrate, and an anti-reflective film. The reflector can include a mirror coating and an anti-reflection coating.","priority_1":"2018-06-04T00:00:00","priority_2":"2018-08-02T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8506946978},{"pair":"US-10248890-B2 & US-2020021796-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2020021796-A1","title_2":"Stereo weaving for head-tracked autostereoscopic displays ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200021796A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods are described for determining a tracked position associated with viewing an emitting interface of a display device, generating, using the tracked position, a first mask representing a first set of values associated with the emitting interface of the display device, generating, using the tracked position, a second mask representing a second set of values associated with the emitting interface of the display device, and generating an output image using the first mask and the second mask.","priority_1":"2017-04-13T00:00:00","priority_2":"2018-07-10T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8506936914},{"pair":"US-10495882-B1 & US-2018101984-A1","patent_1":"US-10495882-B1","title_1":"Positioning cameras in a head mounted display to capture images of portions of a face of a user ","patent_2":"US-2018101984-A1","title_2":"Headset removal in virtual, augmented, and mixed reality using an eye gaze database ","link_1":"https:\/\/patents.google.com\/patent\/US10495882B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180101984A1\/en","abstract_1":"A virtual reality (VR) or augmented reality (AR) head mounted display (HMD) includes multiple image capture devices positioned within and on the HMD to capture portions of a face of a user wearing the HMD. Multiple image capture devices are included within the HMD to capture different portions of the face of the user within the HMD, and one or more other image capture devices are positioned to capture portions of the face of the user external to the HMD. Captured images from various image capture devices may be communicated to a console or a controller that generates a graphical representation of the user's face based on the captured images.","abstract_2":"A camera captures an image of a user wearing a head mounted device (HMD) that occludes a portion of the user's face. A three-dimensional (3-D) pose that indicates an orientation and a location of the user's face in a camera coordinate system is determined. A representation of the occluded portion of the user's face is determined based on a 3-D model of the user's face. The representation replaces a portion of the HMD in the image based on the 3-D pose of the user's face in the camera coordinate system. In some cases, the 3-D model of the user's face is selected from 3-D models of the user's face stored in a database that is indexed by eye gaze direction. Mixed reality images can be generated by combining virtual reality images, unoccluded portions of the user's face, and representations of an occluded portion of the user's face.","priority_1":"2018-06-04T00:00:00","priority_2":"2016-10-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8506439226},{"pair":"US-2019265514-A1 & US-2018343443-A1","patent_1":"US-2019265514-A1","title_1":"Systems and methods for astigmatism correction in a head-mounted display ","patent_2":"US-2018343443-A1","title_2":"Near-eye display with extended accommodation range adjustment ","link_1":"https:\/\/patents.google.com\/patent\/US20190265514A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180343443A1\/en","abstract_1":"The disclosed system may include (1) a lens assembly that provides an electronically controllable cylindrical power, oriented along an electronically controllable axis, on an optical path between a display device and an eye of a viewer in response to at least one first control signal, and (2) a controller that (a) receives information indicating a cylindrical power component and a cylindrical axis component of an eyeglass prescription for the viewer, and (b) generates, based on the information, the at least one first control signal to cause the lens assembly to provide the cylindrical power component, oriented along the cylindrical axis component, for the viewer. Various other systems and methods are also disclosed.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a lenslet array and a rendering component to adjust the focal points of the array of elemental images in the integral lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using an eye tracking component of the near-eye display system, a first pose of a user's eye and determining a desired focal point for an array of elemental images forming an integral lightfield frame based on the first pose of the user's eye. The method further includes changing the focal length of light projecting out of a lenslet array based on the first pose of the user's eye.","priority_1":"2018-02-27T00:00:00","priority_2":"2017-05-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8506058855},{"pair":"US-10338379-B1 & US-2017123209-A1","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2017-10-09T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505760577},{"pair":"US-10598928-B1 & US-2016240013-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-12-21T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505720747},{"pair":"US-2020018962-A1 & US-2019271844-A1","patent_1":"US-2020018962-A1","title_1":"Adaptive lenses for near-eye displays ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200018962A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly includes two or more polarization-dependent lenses sensitive to either linear or circular polarization, and at least one switchable polarization converter. The switchable polarization converter is configured to rotate linearly polarized light or change the handedness of circularly polarized light when switched on. The lens assembly is configurable to project displayed images on two or more different image planes. For example, when the switchable polarization converter is switched off, the lens assembly projects a displayed image on a first image plane. When the switchable polarization converter is switched on, the lens assembly projects a displayed image on a second image plane different from the first image plane.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-07-11T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505538659},{"pair":"US-2019361518-A1 & US-2017363949-A1","patent_1":"US-2019361518-A1","title_1":"Apparatus, system, and method for accelerating positional tracking of head-mounted displays ","patent_2":"US-2017363949-A1","title_2":"Multi-tier camera rig for stereoscopic image capture ","link_1":"https:\/\/patents.google.com\/patent\/US20190361518A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170363949A1\/en","abstract_1":"The disclosed special-purpose hardware device may include an image signal processor that receives, from a camera device of a head-mounted-display system, image frames of a physical environment. The special-purpose hardware device may also include a positional tracking component that (1) stores at least a portion of the image frames in a cache of the special-purpose hardware device that has a faster access speed than a main memory of the special-purpose hardware device, (2) tracks, based on the portion of the image frames stored in the cache, a change in the position of the head-mounted display system within the physical environment, and (3) stores the change in the position of the head-mounted-display system in the main memory for use in generating one or more augmented-reality frames. The special-purpose hardware device may further include a frame-output interface that feeds the augmented-reality frames to a display device of the head-mounted-display system.","abstract_2":"In on the general aspect, a camera rig can include a first tier of images sensors including a first plurality of image sensors where the first plurality of image sensors are arranged in a circular shape and oriented such that a field of view of each of the first plurality of image sensors has an axis perpendicular to a tangent of the circular shape. The camera rig can include a second tier of image sensors including a second plurality of image sensors where the second plurality of image sensors are oriented such that a field of view of each of the second plurality of image sensors has an axis non-parallel to the field of view of each of the first plurality of image sensors.","priority_1":"2018-05-22T00:00:00","priority_2":"2015-05-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505502878},{"pair":"US-10338379-B1 & US-2017147859-A1","patent_1":"US-10338379-B1","title_1":"Lenses with consistent distortion profile ","patent_2":"US-2017147859-A1","title_2":"Prism-based eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10338379B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170147859A1\/en","abstract_1":"A head-mounted display device includes a display and a lens that provides consistent distortion independent of a rotational position of a wearer's eye. The lens includes an optically transparent substrate with first and second lens surfaces. The lens is configured to focus light from a first location of the display on a pupil of the eye in a first rotational position at a first time and focus light from a second location of the display on the pupil of the eye in a second rotational position at a second time. The light from the first location of the display to the pupil of the eye in the first rotational position and the light from the second location of the display to the pupil of the eye in the second rotational position have a same optical path length.","abstract_2":"An HMD device includes a display panel and an x-prism beamsplitter disposed along a first axis between the display panel and an expected position of an eye of a user. The x-prism beamsplitter directs a first light beam in a first direction from the display panel to the eye along the first axis, directs a second light beam in a second direction along a second axis substantially perpendicular to the first axis, and directs a third light beam in the second direction along the second axis, wherein the second light beam is representative of the first light beam and the third light beam is representative of a reflection of the first light beam off of the eye. The HMD device further includes an imaging camera to capture a composite image comprising a combination of both a representation of the second light beam and a representation of the third light beam.","priority_1":"2017-10-09T00:00:00","priority_2":"2015-11-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505355027},{"pair":"US-10330789-B1 & US-2017123209-A1","patent_1":"US-10330789-B1","title_1":"Proximity sensor system with an infrared optical element ","patent_2":"US-2017123209-A1","title_2":"Display of binocular overlapping images in a head mounted display ","link_1":"https:\/\/patents.google.com\/patent\/US10330789B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170123209A1\/en","abstract_1":"A proximity sensor system for detecting the presence of an object includes a light emitter configured to project light in a first direction, an optical element configured to steer the light, and a sensor. The optical element has a first surface configured to receive the light from the light emitter and a second surface that is non-parallel to the first surface. The second surface is configured to transmit a first portion of the light in a second direction and internally reflect a second portion of the light from the light emitter. The optical element includes a third surface configured to prevent internal reflection of the second portion of the light by the third surface. The sensor is configured to detect at least a portion of the first portion of the light returned from the object and transmitted through the second surface and the first surface of the optical element.","abstract_2":"A head mounted display (HMD) device may include a housing coupled to a frame, and a display device disposed in the housing. A first lens may be disposed along a first optical axis in the housing, and a second lens may be disposed along a second optical axis in the housing. A divider may be positioned between the first lens and the second lens, with a front end portion of the divider positioned adjacent to the display device. The divider may include display capability so that images displayed on the display device may extend onto the divider. The divider may emit diffused light having chrominance and\/or luminance levels corresponding to images displayed on the display device. The divider may reflect diffused light from images displayed on the display device. The divider may transmit diffused light from images displayed on the display device.","priority_1":"2018-04-10T00:00:00","priority_2":"2015-11-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505263289},{"pair":"US-2020090406-A1 & US-2019147642-A1","patent_1":"US-2020090406-A1","title_1":"Reconstruction of essential visual cues in mixed reality applications ","patent_2":"US-2019147642-A1","title_2":"Learning to reconstruct 3d shapes by rendering many 3d views ","link_1":"https:\/\/patents.google.com\/patent\/US20200090406A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190147642A1\/en","abstract_1":"A mixed reality (MR) simulation system includes a console and a head mounted device (HMD). The MR system captures stereoscopic images from a real-world environment using outward-facing stereoscopic cameras mounted to the HMD. The MR system preprocesses the stereoscopic images to maximize contrast and then extracts a set of features from those images, including edges or corners, among others. For each feature, the MR system generates one or more two-dimensional (2D) polylines. Then, the MR system triangulates between 2D polylines found in right side images and corresponding 2D polylines found in left side images to generate a set of 3D polylines. The MR system interpolates between 3D vertices included in the 3D polylines or extrapolates additional 3D vertices, thereby generating a geometric reconstruction of the real-world environment. The MR system may map textures derived from the real-world environment onto the geometric representation faster than the geometric reconstruction is updated.","abstract_2":"Methods, systems, and apparatus for obtaining first image features derived from an image of an object, providing the first image features to a three-dimensional estimator neural network, and obtaining, from the three-dimensional estimator neural network, data specifying an estimated three-dimensional shape and texture based on the first image features. The estimated three-dimensional shape and texture are provided to a three-dimensional rendering engine, and a plurality of three-dimensional views of the object are generated by the three-dimensional rendering engine based on the estimated three-dimensional shape and texture. The plurality of three-dimensional views are provided to the object recognition engine, and second image features derived from the plurality of three-dimensional views are obtained from the object recognition engine. A loss is computed based at least on the first and second image features, and the three-dimensional estimator neural network is trained based at least on the computed loss.","priority_1":"2018-09-17T00:00:00","priority_2":"2017-11-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505169724},{"pair":"US-10140695-B2 & US-10241329-B2","patent_1":"US-10140695-B2","title_1":"Head-mounted compound display including a high resolution inset ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10140695B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted display (HMD) that includes a high resolution (HR) inset display and a peripheral display. The HR inset display is configured to display an inset region that includes a portion of an image at a first resolution that corresponds to a resolution of a fovea region of a human eye. The peripheral display displays a background region, the background region having a second resolution that is less than the first resolution, the second resolution corresponding to a resolution of a non-fovea region of the human eye. The HMD includes an optics block that combines the inset region and the background region to create composite content at retinal resolution, and direct the composite content to an exit pupil of the HMD corresponding to a location of an eye of a user of the HMD.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-10-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.850498669},{"pair":"US-2019369390-A1 & US-2020073123-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2020073123-A1","title_2":"Near-eye display system with polarization-based optical path folding and variable focus catadioptric lens assembly ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200073123A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A near-eye display system includes an optical system facing a display panel. The optical system includes an input filter, and output filter, and a variable-power catadioptric lens assembly disposed between the input and output filters. The input and output filters are configured, along with the catadioptric lens assembly to fold a path of display light from the display panel to a user's eye. The catadioptric lens assembly includes two or more lens elements disposed along an optical axis, each lens element having at least one surface with a freeform curvature. One of the lens elements is configured to be laterally translated relative to the other lens elements so as to change an optical power of the catadioptric lens assembly.","priority_1":"2018-06-04T00:00:00","priority_2":"2018-08-31T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8504721638},{"pair":"US-10200624-B2 & US-9723203-B1","patent_1":"US-10200624-B2","title_1":"Three-dimensional, 360-degree virtual reality exposure control ","patent_2":"US-9723203-B1","title_2":"Method, system, and computer program product for providing a target user interface for capturing panoramic images ","link_1":"https:\/\/patents.google.com\/patent\/US10200624B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9723203B1\/en","abstract_1":"A camera system is configured to capture, via a plurality of cameras, 360 degree image information of a local area, at least a portion of which is in stereo. The camera system determines respective exposure settings for the plurality of cameras. A minimum shutter speed and a maximum shutter speed are determined from the determined exposure settings. A set of test exposure settings is determined using the determined minimum shutter speed and maximum shutter speed. A set of test images is captured using the plurality of cameras at each test exposure setting in the set of test exposure settings. Each set of test images includes images from each of the plurality of cameras that are captured using a same respective test exposure setting. A global exposure setting is selected based on the captured sets of test images. The selected global exposure setting is applied to the plurality of cameras.","abstract_2":"Systems, methods, and computer readable mediums are provided for generating a panoramic image that includes, in at least some aspects, generating targets that are each associated with a portion of the panoramic image, displaying the targets, shifting the targets when the user device is repositioned, capturing images when the targets are within a threshold distance of the center of the display, and generating the panoramic image from the captured images.","priority_1":"2016-04-06T00:00:00","priority_2":"2012-10-26T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8504637884},{"pair":"US-2019311522-A1 & US-2019311467-A1","patent_1":"US-2019311522-A1","title_1":"Vertex shift for rendering 360 stereoscopic content ","patent_2":"US-2019311467-A1","title_2":"Enhanced specular reflections for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US20190311522A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190311467A1\/en","abstract_1":"A 360 video system can render 360 stereoscopic content based on a virtual environment using a standard GPU rendering pipeline. In some embodiments, in order to improve efficiency in generating 360 stereoscopic content, a vertex shift technique can be used to approximate multiple viewpoints in a single 360 stereoscopic eye view. When rendering the virtual environment, each triangle of the virtual environment can be shifted to represent the view from a viewpoint corresponding to that triangle. Using vertex shift techniques, a virtual environment can be rendered into a 360 stereoscopic eye view in one pass of a GPU rendering pipeline, according to some embodiments.","abstract_2":"Systems and methods for enhanced specular reflections are provided. An example method may include determining a first portion of a specular reflection associated with a computer-generated object based on a first contribution from an environment map component at a shading point of the computer-generated object and determining a second portion of the specular reflection associated with the computer-generated object based on a second contribution from a camera feed component at an intersection point of a camera feed and a reflection vector associated with the environment map component. The example method may further include determining the specular reflection, at the shading point, associated with the computer-generated object based on a blending of the first and second portions of the specular reflection.","priority_1":"2018-04-05T00:00:00","priority_2":"2018-04-06T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8504624286},{"pair":"US-2020027261-A1 & US-9384596-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-07-20T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8504329747},{"pair":"US-10598942-B1 & US-10546518-B2","patent_1":"US-10598942-B1","title_1":"Mounting assembly with reworkable active alignment ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10598942B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A mounting assembly for optical elements in a head-mounted display. The mounting assembly includes a housing and an element retainer. The housing encloses an optical element. The element retainer includes a first surface and a second surface. The first surface is fixed to the optical element via a first adhesive element. The second surface is fixed to the housing via a second adhesive element.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-10-05T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8503353186},{"pair":"US-10416461-B2 & US-9946074-B2","patent_1":"US-10416461-B2","title_1":"Pancake lens with large FOV ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10416461B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A HMD includes an electronic display and a pancake lens block. The pancake lens block includes a back curved optical element and a front curved optical element. Light propagating through the pancake lens block undergoes multiple reflections and to mitigate parasitic reflections, there are no air gaps between optical elements of the pancake lens block. A hybrid film that operates as a waveplate surface and a mirrored surface can be placed between the front curved optical element and the back curved optical element. A wide FOV can be obtained by making the coupling surfaces of the front optical element and the back optical element to be based on a convex cylindrical surface profile and a concave cylindrical surface profile, with the axis of the cylinder surface in a vertical direction for a user wearing the HMD.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2016-10-27T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8503343247},{"pair":"US-2020057304-A1 & US-2019086675-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2019086675-A1","title_2":"Compact near-eye display optics for higher optical performance ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190086675A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"Systems and apparatus are described for a head-mounted display apparatus comprising at least one optical assembly. Each optical assembly may include a first curved lens including a first surface and a second surface, a second curved lens including a third surface and a fourth surface, the third surface being concave and including a beam splitter layer, the second curved lens being disposed between the first curved lens and an input filter assembly, and a display panel adapted to receive image content from an image projecting device and transmit the image content through the at least one optical assembly. The third surface of the second curved lens may have a radius of curvature that is larger than a radius of curvature of the second surface of the first curved lens.","priority_1":"2018-08-16T00:00:00","priority_2":"2016-02-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8503323751},{"pair":"US-10460500-B1 & US-2019102935-A1","patent_1":"US-10460500-B1","title_1":"Glyph rendering in three-dimensional space ","patent_2":"US-2019102935-A1","title_2":"Shadows for inserted content ","link_1":"https:\/\/patents.google.com\/patent\/US10460500B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190102935A1\/en","abstract_1":"In one embodiment, a computing system may determine a pixel area in a display coordinate system and project it into a three-dimensional coordinate system to determine a projected area. Based on the projected area, the system may determine a portion of a data structure that contains an analytical definition of a glyph in a two-dimensional coordinate system. The system may access a portion of the analytical definition associated with the selected portion of the data structure, the portion of the analytical definition defining one or more areas of the glyph. The system may project the portion of the analytical definition into the display coordinate system and compute a coverage proportion of the pixel area that overlaps with one or more areas defined by the projected portion of the analytical definition. Based on the coverage, the system may determine a color for the pixel and render the glyph.","abstract_2":"Systems and methods for generating shadows for inserted content are provided. The inserted content may include augmented reality content that is inserted into an image of a physical space. An example includes determining a location to insert content within an image. The content may include a polygonal mesh defined in part by a skeleton that has a plurality of joints. Examples may further include selecting a plurality of selected joints form the plurality of joints. Examples may also include generating a shadow polygon based on the content and determining shadow contributions values for the plurality of selected joints for pixels of the shadow polygon. Examples may also include combining the shadow contribution values from the selected joints to generate shadow magnitude values for the pixels, rendering the shadow polygon using the shadow magnitude values, and overlaying the inserted content on the rendered shadow polygon.","priority_1":"2018-04-13T00:00:00","priority_2":"2017-10-04T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8502483095},{"pair":"US-2019037137-A1 & US-10084962-B2","patent_1":"US-2019037137-A1","title_1":"Parallax viewer system for 3d content ","patent_2":"US-10084962-B2","title_2":"Spherical video stabilization based on accelerometer data ","link_1":"https:\/\/patents.google.com\/patent\/US20190037137A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10084962B2\/en","abstract_1":"A parallax viewer system allows 3D content, such as 360 degree 3D panoramas or other 3D environments, to be viewed by a user through a traditional 2D screen. A parallax viewer system operating on a user device can use a user-facing camera and a 2D screen to simulate a 3D environment for a user viewing the 2D screen. By changing the rendered view of the 3D environment as the user's head moves with respect to the screen, the parallax viewer system can provide many of the immersion benefits of a VR or 3D display using a traditional 2D display. In some implementations, the parallax viewer system can be calibrated to work in new situations (for example, on a new user device) by determining the relationship between the user-facing camera and the screen used to display the virtual environment.","abstract_2":"A method includes identifying a frame of a spherical video as a key frame, storing a compensation component based on position data of a camera in association with the key frame, and compensating for a movement of the camera in a subsequent frame of the spherical video based on the key frame and the compensation component associated with the key frame.","priority_1":"2017-07-31T00:00:00","priority_2":"2015-11-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8502387935},{"pair":"US-2019369390-A1 & US-9851565-B1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8502333319},{"pair":"US-10497320-B1 & US-2019271844-A1","patent_1":"US-10497320-B1","title_1":"Transparent and reflective illumination source ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10497320B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted display (HMD) includes a display illuminated by one or more illumination sources. An illumination source is coupled to a partially transparent circuit board and is configured to emit light onto a compound mirror. The compound mirror is farther from an exit pupil of the HMD than the display and reflects light from the illumination source back towards the exit pupil of the HMD. Light reflected by the compound mirror is transmitted through the partially transparent circuit board onto the display, illuminating the display.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-05-07T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.850226375},{"pair":"US-2018074325-A1 & US-10032074-B2","patent_1":"US-2018074325-A1","title_1":"Fresnel Lens with Dynamic Pitch ","patent_2":"US-10032074-B2","title_2":"Systems and methods for high-resolution gaze tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20180074325A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10032074B2\/en","abstract_1":"A lens includes an optically transparent substrate having a first lens surface and a second lens surface opposite to the first lens surface. The first lens surface includes a plurality of Fresnel structures. A respective Fresnel structure of the plurality of Fresnel structures includes a slope facet and a draft facet. The respective Fresnel structure of the plurality of Fresnel structures is characterized by a representative pitch. The representative pitch of the respective Fresnel structure is based on a distance of the respective Fresnel structure from a reference axis of the lens. A display device that includes the lens and an electronic display coupled with the lens for outputting light through the lens and a method for transmitting light from an electronic display toward the lens are also described.","abstract_2":"A system mounted within eyewear or headwear to unobtrusively produce and track reference locations on the surface of one or both eyes of an observer is provided to improve the accuracy of gaze tracking. The system utilizes multiple illumination sources and\/or multiple cameras to generate and observe glints from multiple directions. The use of multiple illumination sources and cameras can compensate for the complex, three-dimensional geometry of the head and the significant anatomical variations of the head and eye region that occurs among individuals. The system continuously tracks the initial placement and any slippage of eyewear or headwear. In addition, the use of multiple illumination sources and cameras can maintain high-precision, dynamic eye tracking as an eye moves through its full physiological range. Furthermore, illumination sources placed in the normal line-of-sight of the device wearer increase the accuracy of gaze tracking by producing reference vectors that are close to the visual axis of the device wearer.","priority_1":"2016-09-13T00:00:00","priority_2":"2011-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8502025438},{"pair":"US-10504243-B2 & US-10545215-B2","patent_1":"US-10504243-B2","title_1":"Calibration system for a head-mounted display tracking system ","patent_2":"US-10545215-B2","title_2":"4D camera tracking and optical stabilization ","link_1":"https:\/\/patents.google.com\/patent\/US10504243B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10545215B2\/en","abstract_1":"A calibration system is configured to determine calibration information of a head-mounted display (HMD). The calibration system comprises a first, second, and third planar grid, a movable platform, and a calibration controller. Each planar grid includes a plurality of fiducial markers that are displayed in accordance with a display pattern. The HMD is coupled to the movable platform, which moves the HMD before the planar grids as a plurality of cameras on the HMD captures images of the planar grids with fiducial markers. The calibration controller controls a motion sequence of the movable platform and determines calibration information for each of the cameras on the HMD and calibration information for an inertial measurement unit (IMU) within the HMD. The calibration information is based in part on a parameterized model of the motion sequence of the HMD.","abstract_2":"A light-field video stream may be processed to modify the camera pathway from which the light-field video stream is projected. A plurality of target pixels may be selected, in a plurality of key frames of the light-field video stream. The target pixels may be used to generate a camera pathway indicative of motion of the camera during generation of the light-field video stream. The camera pathway may be adjusted to generate an adjusted camera pathway. This may be done, for example, to carry out image stabilization. The light-field video stream may be projected to a viewpoint defined by the adjusted camera pathway to generate a projected video stream with the image stabilization.","priority_1":"2017-10-09T00:00:00","priority_2":"2017-09-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8501538509},{"pair":"US-2019049720-A1 & US-10546518-B2","patent_1":"US-2019049720-A1","title_1":"Camera assembly with programmable diffractive optical element for depth sensing ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190049720A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A depth camera assembly (DCA) for depth sensing of a local area includes a structured light generator, an imaging device, and a controller. The structured light generator illuminates the local area with a structured light pattern. The structured light generator includes a programmable diffractive optical element (PDOE) that generates diffracted scanning beams using optical beams. The PDOE functions as a dynamic diffraction grating that dynamically adjusts diffraction of the optical beams to generate the diffracted scanning beams of different patterns. The diffracted scanning beams are projected as the structured light pattern into the local area, wherein the structured light pattern is dynamically adjustable based on the PDOE. The imaging device captures image(s) of at least a portion of the structured light pattern reflected from object(s) in the local area. The controller determines depth information for the object(s) based on the captured image(s).","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-08-14T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8501369074},{"pair":"US-9984507-B2 & US-2015242414-A1","patent_1":"US-9984507-B2","title_1":"Eye tracking for mitigating vergence and accommodation conflicts ","patent_2":"US-2015242414-A1","title_2":"Object Occlusion to Initiate a Visual Search ","link_1":"https:\/\/patents.google.com\/patent\/US9984507B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20150242414A1\/en","abstract_1":"A headset (e.g., VR headset or AR headset) displays a three-dimensional (3D) virtual scene and includes a distance element to dynamically adjust a distance between an optics block and an electronic display included in the headset based on a location in the virtual scene where the user is looking. The headset tracks the user's eyes to approximate gaze lines and determines a plane of focus for a frame of the virtual scene as the intersection of the gaze lines. The distance element adjusts a distance between an optics block and an electronic display so that the optics block is focused at the plane of focus, which keeps the user's eyes in a zone of comfort as vergence and accommodation change.","abstract_2":"Methods and devices for initiating a search of an object are disclosed. In one embodiment, a method is disclosed that includes receiving video data recorded by a camera on a wearable computing device, where the video data comprises at least a first frame and a second frame. The method further includes, based on the video data, detecting an area in the first frame that is at least partially bounded by a pointing device and, based on the video data, detecting in the second frame that the area is at least partially occluded by the pointing device. The method still further includes initiating a search on the area.","priority_1":"2015-11-19T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8501311205}]