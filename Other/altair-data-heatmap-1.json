[{"pair":"US-2019313087-A1 & US-9851565-B1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-04-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9234032067},{"pair":"US-2019313087-A1 & US-2020041798-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9209473667},{"pair":"US-2020081252-A1 & US-9851565-B1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-03-15T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9108401606},{"pair":"US-2020027261-A1 & US-2018329602-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9085872257},{"pair":"US-10481321-B1 & US-2020041798-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-09-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9068852595},{"pair":"US-10600352-B1 & US-9851565-B1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-12-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9063001902},{"pair":"US-2019313087-A1 & US-2016240013-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-04-06T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9034492898},{"pair":"US-2020064641-A1 & US-9851565-B1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-24T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9024479216},{"pair":"US-10473939-B1 & US-2020041798-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9008515638},{"pair":"US-2020027261-A1 & US-9704282-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8989890799},{"pair":"US-2020064641-A1 & US-2020041798-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8929483764},{"pair":"US-2020064641-A1 & US-2016240013-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-08-24T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8880298738},{"pair":"US-10481321-B1 & US-9851565-B1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-09-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8873156593},{"pair":"US-2019353898-A1 & US-2020041798-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.88671025},{"pair":"US-10133168-B1 & US-2020041798-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-02-01T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8849436295},{"pair":"US-10571692-B2 & US-2020041798-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-03-02T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8843284795},{"pair":"US-10466496-B2 & US-9851565-B1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8836374296},{"pair":"US-2019384070-A1 & US-2020041798-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8833528434},{"pair":"US-2019353898-A1 & US-9851565-B1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8818218486},{"pair":"US-10598928-B1 & US-9851565-B1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8799172467},{"pair":"US-10495798-B1 & US-2020041798-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8773964257},{"pair":"US-10248890-B2 & US-2018329602-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.877088995},{"pair":"US-10248890-B2 & US-2018061119-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8755670186},{"pair":"US-10495798-B1 & US-9851565-B1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-07T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8753752462},{"pair":"US-10534177-B1 & US-2020041798-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-10-10T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8735125187},{"pair":"US-2019101767-A1 & US-2020041798-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.873185017},{"pair":"US-10598928-B1 & US-2020041798-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-12-21T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8728458887},{"pair":"US-2020057304-A1 & US-9851565-B1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-16T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8725074773},{"pair":"US-2019101767-A1 & US-9851565-B1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711038571},{"pair":"US-10598938-B1 & US-9934583-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-11-09T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8710207531},{"pair":"US-2020027261-A1 & US-10593098-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8709841148},{"pair":"US-10248890-B2 & US-10593098-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8703605162},{"pair":"US-10248890-B2 & US-9734579-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702980191},{"pair":"US-2020027261-A1 & US-9734579-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8690764519},{"pair":"US-10120193-B2 & US-9851565-B1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-27T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8675055268},{"pair":"US-10571692-B2 & US-9851565-B1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-03-02T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.865449355},{"pair":"US-2020027261-A1 & US-10460505-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8650544383},{"pair":"US-2019369390-A1 & US-2020041798-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8649562971},{"pair":"US-2020064633-A1 & US-9851565-B1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-23T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8647501894},{"pair":"US-2019384070-A1 & US-9851565-B1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8644134436},{"pair":"US-2020081252-A1 & US-2020041798-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-03-15T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8627301402},{"pair":"US-2020064633-A1 & US-2020041798-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-23T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8620107699},{"pair":"US-2019313087-A1 & US-10546518-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8617816698},{"pair":"US-10598938-B1 & US-2020041798-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-11-09T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8612809145},{"pair":"US-2020064633-A1 & US-2016240013-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-08-23T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8608595051},{"pair":"US-2019313087-A1 & US-10241329-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8608496796},{"pair":"US-10248890-B2 & US-10460505-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8606411082},{"pair":"US-10248890-B2 & US-9704282-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8601906921},{"pair":"US-2020027261-A1 & US-2018061119-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597558841},{"pair":"US-2020027261-A1 & US-9672656-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9672656-B1","title_2":"Variable level-of-detail map rendering ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9672656B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"To render features on a digital map, a position and orientation of a virtual camera relative to a plane of the digital map is determined. The plane is tilted so that a plane of a viewport of the digital map is not parallel to the plane of the digital map, where the viewport delimiting a view of the digital map. Map features are selected for inclusion in the view of the digital map in accordance with the determined position and orientation of the virtual camera. A level-of-detail (LOD) is determined for each of the map features in accordance with a distance between the virtual camera and the map feature. The map features are rendered, using a rendering engine, in accordance with the determined LODs.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-12-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8587617666},{"pair":"US-2020027261-A1 & US-2017032568-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858702826},{"pair":"US-2020027261-A1 & US-2018089791-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018089791-A1","title_2":"Rendering map data using descriptions of raster differences ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180089791A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A network server receives, from a client device, an indication of a first raster map image that depicts a geographic map of a certain region and a certain zoom level. The network server obtains a second raster map image corresponding to the geographic region and the zoom level and generating a description of a difference in pixels between the indicated first raster map image and the second raster map image. The network server then provides the description of the determined difference in pixels to the client device for generating the second raster map image at the client device.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8584545433},{"pair":"US-10120193-B2 & US-2020041798-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-01-27T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8583164911},{"pair":"US-2019313087-A1 & US-2019020869-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-04-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8572710255},{"pair":"US-10481321-B1 & US-2016240013-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-09-06T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8567746896},{"pair":"US-10466496-B2 & US-2020041798-A1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-12-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562625649},{"pair":"US-10598938-B1 & US-10546518-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-11-09T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562258424},{"pair":"US-10481321-B1 & US-10546518-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-09-06T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8560445642},{"pair":"US-2020057304-A1 & US-2020041798-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-16T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547035732},{"pair":"US-2019101767-A1 & US-2016240013-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-10-03T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8537996342},{"pair":"US-2020081252-A1 & US-2016240013-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-03-15T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8529061098},{"pair":"US-2019384070-A1 & US-2016240013-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-06-18T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8528063244},{"pair":"US-2020064641-A1 & US-10241329-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8511604464},{"pair":"US-10598928-B1 & US-2016240013-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-12-21T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8505720747},{"pair":"US-2020027261-A1 & US-9384596-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2018-07-20T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8504329747},{"pair":"US-2019369390-A1 & US-9851565-B1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8502333319},{"pair":"US-10534177-B1 & US-9851565-B1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-10-10T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8494224811},{"pair":"US-10600352-B1 & US-2020041798-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-12-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8484852928},{"pair":"US-10120193-B2 & US-2016240013-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-01-27T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8482288833},{"pair":"US-2020027261-A1 & US-10460510-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.847477747},{"pair":"US-2019339447-A1 & US-2020041798-A1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8473400084},{"pair":"US-2020027261-A1 & US-2020013214-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8471709275},{"pair":"US-10481321-B1 & US-10241329-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-09-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8465575842},{"pair":"US-10248890-B2 & US-10467820-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10467820-B2","title_2":"Image style transfer for three-dimensional models ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10467820B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Example aspects of the present disclosure are directed to systems and methods that perform image style transfer for three-dimensional models. In some implementations, the systems and methods can use machine-learned models such as, for example, convolutional neural networks to generate image style and content information used to perform style transfer. The systems and methods of the present disclosure can operate in a rendered image space. In particular, a computing system can iteratively modify an attribute rendering map (e.g., texture map, bump map, etc.) based on information collected from a different rendering of the model at each of a plurality of iterations, with the end result being that the attribute rendering map mimics the style of one or more reference images in content-preserving way. In some implementations, a computation of style loss at each iteration can be performed using multi-viewpoint averaged scene statistics, instead of treating each viewpoint independently.","priority_1":"2017-04-13T00:00:00","priority_2":"2018-01-24T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8463245586},{"pair":"US-10534177-B1 & US-10546518-B2","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-10-10T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.845514505},{"pair":"US-10495798-B1 & US-2016240013-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-08-07T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8445105623},{"pair":"US-10600352-B1 & US-2016240013-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-12-04T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8440030459},{"pair":"US-2020027261-A1 & US-9911205-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9911205-B1","title_2":"Visual continuity for arbitrary length stipple patterns ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9911205B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"An indication of a polyline having multiple vertices and a stipple pattern of a not-a-power-of-two length are received. The stipple pattern is to be repeatedly rendered along the polyline. To reduce visual discontinuity, a texture of a power-of-two length, to be repeatedly applied along the polyline, is generated. The texture is made up of several whole instances of the stipple pattern and a portion of another instance of the stipple pattern defining remainder texels. The texture is modified so that visual pattern discontinuity substantially aligns with a vertex of the polyline at which a maximum amount of change in direction of the polyline occurs.","priority_1":"2018-07-20T00:00:00","priority_2":"2014-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8426553644},{"pair":"US-2020027261-A1 & US-2016307294-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2016307294-A1","title_2":"Systems and Methods for Displaying Patterns of Recurring Graphics on Digital Maps ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307294A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"To smoothly transition between zoom levels for patterns displayed along paths (such as roads and other paths) depicted on interactive digital maps, instances of a graphic element (such as a dash, a dot, a two-way arrow, etc.) may be arranged along a path. The displayed instances may appear to increase or decrease in density as zoom levels change. For example, a plurality of instances of the graphic element may be displayed when displaying a digital map at a first zoom level. A first subset of the plurality of instances of the graphic element may be displayed when displaying the digital map at a second zoom level. The transition from displaying the plurality of instances to displaying the first subset of the plurality of instances may be gradual. In some embodiments, the size and\/or transparency of the displayed instances may change in accordance with changed zoom levels.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-07-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8422719802},{"pair":"US-10598938-B1 & US-9851565-B1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-11-09T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8410816719},{"pair":"US-10598938-B1 & US-10241329-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-11-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8397856496},{"pair":"US-2020027261-A1 & US-10089796-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8396304021},{"pair":"US-2020064641-A1 & US-10546518-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8372186361},{"pair":"US-10248890-B2 & US-2020013214-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2020013214-A1","title_2":"Methods and Systems for Viewing a Three-Dimensional (3D) Virtual Object ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200013214A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8366164274},{"pair":"US-10248890-B2 & US-10460510-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10460510-B2","title_2":"Methods and systems for viewing a three-dimensional (3D) virtual object ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460510B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Instructions indicative of changing a view of a virtual object may be received by a device. At least a portion of the virtual object may be viewable from a viewpoint that is at a given distance from a surface of the virtual object. The device may cause a change of the view along a rotational path around the virtual object in response to the receipt of the instructions based on the given distance being greater than a threshold distance. The device may cause a change of the view along a translational path indicative of a shape of the surface of the virtual object in response to the receipt of the instructions based on the given distance being less than the threshold distance.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8361590425},{"pair":"US-10598938-B1 & US-2019020869-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-11-09T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8358796822},{"pair":"US-2020057304-A1 & US-2016240013-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-08-16T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.834546946},{"pair":"US-10248890-B2 & US-2017032568-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8338619884},{"pair":"US-10534177-B1 & US-2016240013-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-10-10T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8336204993},{"pair":"US-10120193-B2 & US-10546518-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-01-27T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8327704597},{"pair":"US-10598938-B1 & US-2016240013-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-11-09T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8326592094},{"pair":"US-10133168-B1 & US-9851565-B1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-02-01T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8320132427},{"pair":"US-10248890-B2 & US-2018089791-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018089791-A1","title_2":"Rendering map data using descriptions of raster differences ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180089791A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A network server receives, from a client device, an indication of a first raster map image that depicts a geographic map of a certain region and a certain zoom level. The network server obtains a second raster map image corresponding to the geographic region and the zoom level and generating a description of a difference in pixels between the indicated first raster map image and the second raster map image. The network server then provides the description of the determined difference in pixels to the client device for generating the second raster map image at the client device.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-09-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8317857118},{"pair":"US-10248890-B2 & US-10089796-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10089796-B1","title_2":"High quality layered depth image texture rasterization ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10089796B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"In one general aspect, a method can include combining a partition polygon and a generated texture map to form a model of a scene for rendering in three dimensions in a virtual reality space. The generating of the texture map can include projecting a Layered Depth Image sample in a partition polygon to a point in a source camera window space, projecting the point back into the partition polygon as a surface element (surfel), projecting the surfel to a surfel footprint in a target camera window space, projecting from the target camera window space to the partition polygon, sub-pixel samples included in pixels covered by the surfel footprint, projecting the sub-pixel samples from the partition polygon and into the source camera window space, and applying a color weight to each sub-pixel sample based on the location of the sample in the source camera window space.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-11-01T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8316986693},{"pair":"US-10248890-B2 & US-9911205-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9911205-B1","title_2":"Visual continuity for arbitrary length stipple patterns ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9911205B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"An indication of a polyline having multiple vertices and a stipple pattern of a not-a-power-of-two length are received. The stipple pattern is to be repeatedly rendered along the polyline. To reduce visual discontinuity, a texture of a power-of-two length, to be repeatedly applied along the polyline, is generated. The texture is made up of several whole instances of the stipple pattern and a portion of another instance of the stipple pattern defining remainder texels. The texture is modified so that visual pattern discontinuity substantially aligns with a vertex of the polyline at which a maximum amount of change in direction of the polyline occurs.","priority_1":"2017-04-13T00:00:00","priority_2":"2014-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8313793588},{"pair":"US-10473939-B1 & US-9851565-B1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-08T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8313586813},{"pair":"US-10481321-B1 & US-2019020869-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-09-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8299532532},{"pair":"US-10600352-B1 & US-9934583-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-12-04T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8286528731},{"pair":"US-10120193-B2 & US-10241329-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-01-27T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8259887624},{"pair":"US-2019101767-A1 & US-10546518-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-10-03T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8246618058},{"pair":"US-10261324-B2 & US-2016240013-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-08-10T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8239327066},{"pair":"US-2019313087-A1 & US-9934583-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-04-06T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.822955494},{"pair":"US-2019369390-A1 & US-2016240013-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-06-04T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8221129231},{"pair":"US-10600352-B1 & US-10546518-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-12-04T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8203341786},{"pair":"US-10248890-B2 & US-9384596-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9384596-B2","title_2":"Visualization of obscured objects in 3D space ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9384596B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A system, method and software application implement a visualization scheme for presenting information in a 3D map. A set of rules specifies the visualization scheme, particularly with respect to how the system renders background objects that are obscured by a foreground object. The objects include elements such as building surfaces, streets, pointers, icons, labels, floor plans, and the like. The rules specify details such as stroke, fill, transparency, opacity, and visibility of the elements. Some of the rules may specify relationships between an object and elements that are considered \u201cinternal\u201d to the object, while others of the rules may specify relationships between an object and other elements considered \u201cexternal\u201d to the object.","priority_1":"2017-04-13T00:00:00","priority_2":"2012-11-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8196438529},{"pair":"US-10571692-B2 & US-10546518-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2016-03-02T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8194958005},{"pair":"US-10600352-B1 & US-10241329-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-12-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.81907964},{"pair":"US-2019353898-A1 & US-10546518-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-05-18T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8178656402},{"pair":"US-2020081252-A1 & US-10546518-B2","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-03-15T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8175878769},{"pair":"US-10600352-B1 & US-2019020869-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-12-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8173928575},{"pair":"US-2020057304-A1 & US-10546518-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-08-16T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8157216231},{"pair":"US-10495798-B1 & US-10546518-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-08-07T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8151421132},{"pair":"US-2020064641-A1 & US-2019020869-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-08-24T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8141418778},{"pair":"US-10261324-B2 & US-2020041798-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-08-10T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8137980332},{"pair":"US-2019339447-A1 & US-9851565-B1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8132364106},{"pair":"US-2020064633-A1 & US-10546518-B2","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-08-23T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8129517114},{"pair":"US-10598928-B1 & US-10546518-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-12-21T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8122839396},{"pair":"US-10571692-B2 & US-2016240013-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2016-03-02T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8116338532},{"pair":"US-10133168-B1 & US-2016240013-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-02-01T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8102223346},{"pair":"US-10534177-B1 & US-2019020869-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-10-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8088261258},{"pair":"US-10120193-B2 & US-2019020869-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-01-27T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8079958293},{"pair":"US-10473939-B1 & US-10546518-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-01-08T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8079277809},{"pair":"US-2020064641-A1 & US-9934583-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-08-24T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8072823106},{"pair":"US-10473939-B1 & US-2016240013-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-01-08T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8071778069},{"pair":"US-10534177-B1 & US-10241329-B2","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-10-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8066500774},{"pair":"US-10248890-B2 & US-9672656-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9672656-B1","title_2":"Variable level-of-detail map rendering ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9672656B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"To render features on a digital map, a position and orientation of a virtual camera relative to a plane of the digital map is determined. The plane is tilted so that a plane of a viewport of the digital map is not parallel to the plane of the digital map, where the viewport delimiting a view of the digital map. Map features are selected for inclusion in the view of the digital map in accordance with the determined position and orientation of the virtual camera. A level-of-detail (LOD) is determined for each of the map features in accordance with a distance between the virtual camera and the map feature. The map features are rendered, using a rendering engine, in accordance with the determined LODs.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-12-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8052799272},{"pair":"US-10466496-B2 & US-10546518-B2","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-12-06T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8032117258},{"pair":"US-10495798-B1 & US-10241329-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-08-07T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.801262181},{"pair":"US-2019353898-A1 & US-10241329-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-05-18T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8007528996},{"pair":"US-10261324-B2 & US-10241329-B2","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-08-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7999844109},{"pair":"US-10466496-B2 & US-2016240013-A1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2017-12-06T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7995793155},{"pair":"US-10481321-B1 & US-9934583-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-09-06T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7991944478},{"pair":"US-10534177-B1 & US-9934583-B2","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-10-10T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.795795924},{"pair":"US-2020081252-A1 & US-2019020869-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-03-15T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7944572008},{"pair":"US-2019353898-A1 & US-9934583-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-05-18T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7944101583},{"pair":"US-2019369390-A1 & US-10546518-B2","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-06-04T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7943708289},{"pair":"US-10248890-B2 & US-10241329-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7935687646},{"pair":"US-2019353898-A1 & US-2016240013-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-05-18T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7934747202},{"pair":"US-10495798-B1 & US-2019020869-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-08-07T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7933581873},{"pair":"US-10495798-B1 & US-9934583-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-08-07T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7931310498},{"pair":"US-2019384070-A1 & US-10546518-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-06-18T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7909763866},{"pair":"US-2019101767-A1 & US-2019020869-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-10-03T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7909192511},{"pair":"US-10466496-B2 & US-9934583-B2","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-12-06T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7907478528},{"pair":"US-10248890-B2 & US-2019020869-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7905886559},{"pair":"US-2020081252-A1 & US-10241329-B2","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-03-15T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7905622913},{"pair":"US-2020057304-A1 & US-10241329-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-08-16T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7896594256},{"pair":"US-10248890-B2 & US-2016307294-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2016307294-A1","title_2":"Systems and Methods for Displaying Patterns of Recurring Graphics on Digital Maps ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307294A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"To smoothly transition between zoom levels for patterns displayed along paths (such as roads and other paths) depicted on interactive digital maps, instances of a graphic element (such as a dash, a dot, a two-way arrow, etc.) may be arranged along a path. The displayed instances may appear to increase or decrease in density as zoom levels change. For example, a plurality of instances of the graphic element may be displayed when displaying a digital map at a first zoom level. A first subset of the plurality of instances of the graphic element may be displayed when displaying the digital map at a second zoom level. The transition from displaying the plurality of instances to displaying the first subset of the plurality of instances may be gradual. In some embodiments, the size and\/or transparency of the displayed instances may change in accordance with changed zoom levels.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-07-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7877854909},{"pair":"US-10261324-B2 & US-2019020869-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-08-10T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.785241568},{"pair":"US-10248890-B2 & US-10546518-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7837157244},{"pair":"US-2020064633-A1 & US-10241329-B2","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-08-23T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7836810061},{"pair":"US-10571692-B2 & US-2019020869-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2016-03-02T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7830905024},{"pair":"US-2019101767-A1 & US-10241329-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-10-03T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7812218109},{"pair":"US-2019101767-A1 & US-9934583-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7808403549},{"pair":"US-10133168-B1 & US-10546518-B2","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-02-01T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7803216964},{"pair":"US-2020027261-A1 & US-10467820-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10467820-B2","title_2":"Image style transfer for three-dimensional models ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10467820B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Example aspects of the present disclosure are directed to systems and methods that perform image style transfer for three-dimensional models. In some implementations, the systems and methods can use machine-learned models such as, for example, convolutional neural networks to generate image style and content information used to perform style transfer. The systems and methods of the present disclosure can operate in a rendered image space. In particular, a computing system can iteratively modify an attribute rendering map (e.g., texture map, bump map, etc.) based on information collected from a different rendering of the model at each of a plurality of iterations, with the end result being that the attribute rendering map mimics the style of one or more reference images in content-preserving way. In some implementations, a computation of style loss at each iteration can be performed using multi-viewpoint averaged scene statistics, instead of treating each viewpoint independently.","priority_1":"2018-07-20T00:00:00","priority_2":"2018-01-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7778065681},{"pair":"US-10598928-B1 & US-2019020869-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-12-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7777907647},{"pair":"US-2019339447-A1 & US-2016240013-A1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-2016240013-A1","title_2":"Combining a high resolution narrow field display and a mid resolution wide field display ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160240013A1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"A head mounted display (HMD) includes a first display portion included in the HMD, the first display portion having a first pixel density, a second display portion included in the HMD, the second display portion having the first pixel density, a third display portion attached to the HMD, the third display portion having a second pixel density, and at least one image combiner configured to combine two images by reflecting an image projected by the first display portion and the second display portion and allowing an image projected by the third display portion to pass through the at least one image combiner.","priority_1":"2018-05-04T00:00:00","priority_2":"2015-02-12T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7773025035},{"pair":"US-2019384070-A1 & US-2019020869-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-06-18T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7743818929},{"pair":"US-2020057304-A1 & US-9934583-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-08-16T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7736389173},{"pair":"US-10598928-B1 & US-9934583-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-12-21T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7736287299},{"pair":"US-10571692-B2 & US-10241329-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2016-03-02T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7732111565},{"pair":"US-10466496-B2 & US-2019020869-A1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2017-12-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7727815505},{"pair":"US-2020057304-A1 & US-2019020869-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-08-16T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7721565626},{"pair":"US-2020064633-A1 & US-2019020869-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-08-23T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7706315874},{"pair":"US-2020081252-A1 & US-9934583-B2","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-03-15T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7701940262},{"pair":"US-2019353898-A1 & US-2019020869-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-05-18T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7685687455},{"pair":"US-2019369390-A1 & US-2019020869-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2019020869-A1","title_2":"Non-planar computational displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190020869A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A near-eye display system includes one or more non-planar display panels and a lenslet array to display a near-eye lightfield frame. The near-eye display system further includes a rendering component to render, based on a stereoscopic focus volume associated with a set of display geometry data of the one-or more non-planar display panels, the array of elemental images in the near-eye lightfield frame such that objects within the stereoscopic focus volume are perceived to be in focus by the user's eye. A method of operation of the near-eye display system includes receiving display geometry data for one or more non-planar display panels of the near-eye display system and rendering, based on a stereoscopic focus volume, an array of elemental images at a position within a near-eye lightfield frame such that the non-planar display panels presents objects within the stereoscopic focus volume to be in focus.","priority_1":"2018-06-04T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7661913041},{"pair":"US-10466496-B2 & US-10241329-B2","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-12-06T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7637733069},{"pair":"US-10598928-B1 & US-10241329-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2017-12-21T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7633138625},{"pair":"US-10248890-B2 & US-9934583-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2017-04-13T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7582306864},{"pair":"US-2019339447-A1 & US-10546518-B2","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-10546518-B2","title_2":"Near-eye display with extended effective eyebox via eye tracking ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10546518B2\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"A near-eye display system includes a display panel to display a near-eye lightfield frame comprising an array of elemental images and an eye tracking component to track a pose of a user's eye. The system further includes a rendering component to position the array of elemental images within the near-eye lightfield frame based on the pose of the user's eye. A method of operation of the near-eye display system includes determining, using the eye tracking component, a first pose of the user's eye and determining a shift vector for an array of elemental images forming a near-eye lightfield frame based on the first pose of the user's eye. The method further includes rendering the array of elemental images at a position within the near-eye lightfield frame that is based on the shift vector.","priority_1":"2018-05-04T00:00:00","priority_2":"2017-05-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7530703053},{"pair":"US-10261324-B2 & US-9851565-B1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-08-10T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7529675461},{"pair":"US-10571692-B2 & US-9934583-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2016-03-02T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7517408753},{"pair":"US-2019384070-A1 & US-10241329-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-10241329-B2","title_2":"Varifocal aberration compensation for near-eye displays ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10241329B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A method of operation in a near-eye display system includes determining, using an eye tracking component of the near-eye display system, a pose of a user's eye. A shift vector is determined for a magnifier lens of the near-eye display system based on the pose of the user's eye, and the shift vector is communicated to an actuator of the near-eye display system to instruct translation of the magnifier lens relative to the user's eye. After translation of the magnifier lens, an array of elemental images is rendered at a position within a near-eye lightfield frame and communicated for display at a display panel of the near-eye display system.","priority_1":"2018-06-18T00:00:00","priority_2":"2017-07-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7515186203},{"pair":"US-2020064633-A1 & US-9934583-B2","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-9934583-B2","title_2":"Expectation maximization to determine position of ambient glints ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9934583B2\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"Exemplary embodiments may involve analyzing reflections from an eye to help determine where the respective sources of the reflections are located. An exemplary method involves: (a) analyzing eye-image data to determine observed movement of a reflected feature on an eye surface; (b) determining an expected movement of the reflected feature on the eye surface given a value of a z-distance parameter; (c) determining a difference between the observed movement of the reflected feature on the eye surface and the expected movement of the reflected feature on the eye surface; (d) if the difference is less than a threshold, then associating the value of the z-distance parameter with a source of the reflected feature; and (e) if the difference is greater than the threshold, then: (i) making a predetermined adjustment to the value of the z-distance parameter; and (ii) repeating (a) to (d) with the adjusted value of the z-distance parameter.","priority_1":"2018-08-23T00:00:00","priority_2":"2012-01-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7505719093}]