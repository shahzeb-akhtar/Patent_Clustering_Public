[{"pair":"US-2019313087-A1 & US-2019271844-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9270114741},{"pair":"US-2019313087-A1 & US-9851565-B1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-04-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9234032067},{"pair":"US-2019313087-A1 & US-2020041798-A1","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-04-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9209473667},{"pair":"US-2020081252-A1 & US-9851565-B1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-03-15T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9108401606},{"pair":"US-2020027261-A1 & US-2018329602-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9085872257},{"pair":"US-2019313087-A1 & US-9671614-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-04-06T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9076408118},{"pair":"US-10481321-B1 & US-2020041798-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-09-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9068852595},{"pair":"US-10600352-B1 & US-9851565-B1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-12-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9063001902},{"pair":"US-2020027261-A1 & US-2018329485-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9043198163},{"pair":"US-2019313087-A1 & US-9946074-B2","patent_1":"US-2019313087-A1","title_1":"Pupil swim corrected lens for head mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190313087A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens for a head mounted display is configured for directing and collimating image light from pixels of an electronic display to a pupil of a user's eye to lessen a pupil swim effect. A method of configuring a lens for directing and collimating image light from an electronic display to a pupil of a user's eye includes configuring the lens to lessen a difference between observed distortions of imagery displayed by the electronic display at different gaze angles of the user's eye.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-04-06T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9033010894},{"pair":"US-2020064641-A1 & US-9851565-B1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-24T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9024479216},{"pair":"US-2020027261-A1 & US-10540818-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9021774382},{"pair":"US-10473939-B1 & US-2020041798-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.9008515638},{"pair":"US-2020027261-A1 & US-9704282-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8989890799},{"pair":"US-2020064641-A1 & US-2020041798-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8929483764},{"pair":"US-2020064641-A1 & US-9671614-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-24T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8886646294},{"pair":"US-10248890-B2 & US-2018158198-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018158198-A1","title_2":"Multi-view rotoscope contour propagation ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180158198A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A video stream may be captured, and may have a plurality of frames including at least a first frame and a second frame. Each of the frames may have a plurality of views obtained from viewpoints that are offset from each other. A source contour, associated with a source view of the first frame, may be retrieved. Camera parameters, associated with the image capture device used to capture the video stream, may also be retrieved. The camera parameters may include a first offset between the source view and a destination view of the first frame. At least the first offset may be used to project the source contour to the destination view to generate a destination contour associated with the destination view.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-12-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8885768128},{"pair":"US-10481321-B1 & US-9851565-B1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-09-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8873156593},{"pair":"US-2019353898-A1 & US-2020041798-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.88671025},{"pair":"US-2019384070-A1 & US-9671614-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-06-18T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.885923051},{"pair":"US-10481321-B1 & US-9671614-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-09-06T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8858122192},{"pair":"US-10133168-B1 & US-2020041798-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-02-01T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8849436295},{"pair":"US-10571692-B2 & US-2020041798-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2016-03-02T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8843284795},{"pair":"US-10248890-B2 & US-9551579-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9551579-B1","title_2":"Automatic connection of images using visual features ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551579B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Aspects of the disclosure relate generating navigation paths between images. A first image taken from a first location and a second image taken from a second location may be selected. A position of the first location in relation to the second location may be determined. First and second frames for the first and second images may be selected based on the position. First and second sets of visual features for each of the first and second image frames may be identified. Matching visual features between the first set of visual features and the second set of visual features may be determined. A confidence level for a line-of-sight between the first and second images may be determined by evaluating one or more positions of the matching visual features. Based on at least the confidence level, a navigation path from the first image to the second image is generated.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-08-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8837408689},{"pair":"US-10466496-B2 & US-9851565-B1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-06T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8836374296},{"pair":"US-2019384070-A1 & US-2020041798-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-18T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8833528434},{"pair":"US-2019384070-A1 & US-2019271844-A1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-06-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8831837},{"pair":"US-2019369390-A1 & US-9671614-B2","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-06-04T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8830280025},{"pair":"US-2019353898-A1 & US-9851565-B1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8818218486},{"pair":"US-2019101767-A1 & US-2019271844-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8806087911},{"pair":"US-10598928-B1 & US-9851565-B1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-12-21T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8799172467},{"pair":"US-10600352-B1 & US-2019271844-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-12-04T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8797010751},{"pair":"US-10248890-B2 & US-2018329485-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018329485-A1","title_2":"Generation of virtual reality with 6 degrees of freedom from limited viewer data ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329485A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A virtual reality or augmented reality experience may be presented for a viewer through the use of input including only three degrees of freedom. The input may include orientation data indicative of a viewer orientation at which a head of the viewer is oriented. The viewer orientation may be mapped to an estimated viewer location. Viewpoint video may be generated of a scene as viewed from a virtual viewpoint with a virtual location corresponding to the estimated viewer location, from along the viewer orientation. The viewpoint video may be displayed for the viewer. In some embodiments, mapping may be carried out by defining a ray at the viewer orientation, locating an intersection of the ray with a three-dimensional shape, and, based on a location of the intersection, generating the estimated viewer location. The shape may be generated via calibration with a device that receives input including six degrees of freedom.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8795585856},{"pair":"US-2020027261-A1 & US-2017228926-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017228926-A1","title_2":"Determining Two-Dimensional Images Using Three-Dimensional Models ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170228926A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for determining two-dimensional (2D) images are presented. For instance, data indicative of a three-dimensional (3D) model of a geographic area can be obtained. A 2D output image can be generated depicting at least a portion of the geographic area based at least in part on the 3D model. Each pixel in the output image can then be reprojected to the 3D model. A plurality of aerial images depicting the geographic area can be obtained. A source image can then be determined for each pixel in the output image from the plurality of aerial images. The source image can be determined based at least in part on the reprojection of the pixel in the output image to the three-dimensional model.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-11-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8784422389},{"pair":"US-10248890-B2 & US-10540818-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10540818-B2","title_2":"Stereo image generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10540818B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Video data of an environment may be prepared for stereoscopic presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate stereoscopic viewpoint video of the scene, as viewed from at least two virtual viewpoints corresponding to viewpoints of an actual viewer's eyes within the viewing volume.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-04-15T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8779725292},{"pair":"US-10495798-B1 & US-2020041798-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8773964257},{"pair":"US-10248890-B2 & US-2018329602-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018329602-A1","title_2":"Vantage generation and interactive playback ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180329602A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Video data of an environment may be prepared for presentation to a user in a virtual reality or augmented reality experience. According to one method, a plurality of locations distributed throughout a viewing volume may be designated, at which a plurality of vantages are to be positioned to facilitate viewing of the environment from proximate the locations. For each location, a plurality of images of the environment, captured from viewpoints proximate the location, may be retrieved. For each location, the images may be reprojected to a three-dimensional shape and combined to generate a combined image. The combined image may be applied to one or more surfaces of the three-dimensional shape to generate a vantage. The vantages may be stored such that the vantages can be used to generate viewpoint video of the scene, as viewed from a virtual viewpoint corresponding to an actual viewer's viewpoint within the viewing volume.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-09T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.877088995},{"pair":"US-2019384070-A1 & US-9946074-B2","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-06-18T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8770034703},{"pair":"US-2019369390-A1 & US-2019271844-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-06-04T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8763612821},{"pair":"US-2020064641-A1 & US-9946074-B2","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-08-24T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8755901481},{"pair":"US-10248890-B2 & US-2018061119-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8755670186},{"pair":"US-10495798-B1 & US-9851565-B1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-07T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8753752462},{"pair":"US-10248890-B2 & US-2017358092-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017358092-A1","title_2":"Multi-view scene segmentation and propagation ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170358092A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A depth-based effect may be applied to a multi-view video stream to generate a modified multi-view video stream. User input may designate a boundary between a foreground region and a background region, at a different depth from the foreground region, of a reference image of the video stream. Based on the user input, a reference mask may be generated to indicate the foreground region and the background region. The reference mask may be used to generate one or more other masks that indicate the foreground and background regions for one or more different images, from different frames and\/or different views from the reference image. The reference mask and other mask(s) may be used to apply the effect to the multi-view video stream to generate the modified multi-view video stream.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-06-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8751229416},{"pair":"US-10481321-B1 & US-2019271844-A1","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-09-06T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8745814808},{"pair":"US-10133168-B1 & US-9946074-B2","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-02-01T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8739086909},{"pair":"US-10534177-B1 & US-2020041798-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-10-10T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8735125187},{"pair":"US-2019101767-A1 & US-2020041798-A1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-10-03T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.873185017},{"pair":"US-10598928-B1 & US-2020041798-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-12-21T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8728458887},{"pair":"US-10598928-B1 & US-2019271844-A1","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-12-21T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8728365145},{"pair":"US-2020057304-A1 & US-9851565-B1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-16T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8725074773},{"pair":"US-10571692-B2 & US-2019271844-A1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2016-03-02T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8715394594},{"pair":"US-10571692-B2 & US-9671614-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2016-03-02T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711694583},{"pair":"US-2019101767-A1 & US-9851565-B1","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-10-03T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8711038571},{"pair":"US-2020027261-A1 & US-10593098-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8709841148},{"pair":"US-10248890-B2 & US-10593098-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10593098-B2","title_2":"Smooth draping layer for rendering vector data on complex three dimensional objects ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10593098B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for rendering vector data in conjunction with a three-dimensional model are provided. In particular, a smooth transparent draping layer can be generated and rendered overlaying the three-dimensional model. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along a surface in the three-dimensional model. The three-dimensional model can be a model of a geographic area and can include terrain geometry that models the terrain of the geographic area and building geometry that models buildings, bridges, and other objects in the geographic area. The smooth transparent draping layer can conform to the surfaces defined by the terrain geometry. The vector data can be texture mapped to the smooth transparent draping layer such that the vector data appears to be located along the surface of the terrain geometry but can be occluded by the building geometry.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-03-14T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8703605162},{"pair":"US-10248890-B2 & US-9734579-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8702980191},{"pair":"US-2019101767-A1 & US-9946074-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-10-03T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8699785297},{"pair":"US-2020027261-A1 & US-9734579-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9734579-B1","title_2":"Three-dimensional models visual differential ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9734579B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and systems for rendering a three-dimensional (3D) data model of an object are provided. An example method may include receiving information associated with a first 3D data model and a second 3D data model of an object. The method may also include rendering a first set of images of the first 3D data model, and rendering a second set of images of the second 3D data model. The method may also include comparing respective images of the first set of images to images of the second set of images to determine a plurality of image difference scores between the respective images of the first set of images and the images of the second set of images. The method may also include determining an object difference score based on the determined plurality of image difference scores.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-02-03T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8690764519},{"pair":"US-2020027261-A1 & US-2017103091-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017103091-A1","title_2":"Displaying objects based on a plurality of models ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170103091A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A system and method is provided for displaying surfaces of an object from a vantage point different from the vantage point from which imagery of the object was captured. In some aspects, imagery may be generated for display by combining visual characteristics from multiple source images and applying greater weight to the visual characteristics of some of the source images relative to the other source images. The weight may be based on the orientation of the surface relative to the location from which the image was captured and the location from which the object will be displayed.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8679976054},{"pair":"US-10120193-B2 & US-9851565-B1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-01-27T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8675055268},{"pair":"US-10571692-B2 & US-9851565-B1","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2016-03-02T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.865449355},{"pair":"US-2020027261-A1 & US-10460505-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8650544383},{"pair":"US-2019369390-A1 & US-2020041798-A1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-06-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8649562971},{"pair":"US-2020064633-A1 & US-9851565-B1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-08-23T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8647501894},{"pair":"US-2019384070-A1 & US-9851565-B1","patent_1":"US-2019384070-A1","title_1":"Optical assembly with curved reflective polarizer for head mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190384070A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a flat partially reflective layer. The second optical element includes a curved reflective polarizer layer.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-18T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8644134436},{"pair":"US-10598928-B1 & US-9671614-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-12-21T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8641843254},{"pair":"US-2020064641-A1 & US-2019271844-A1","patent_1":"US-2020064641-A1","title_1":"Near-eye display (ned) system and method using flexible reflector ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064641A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A device and method are provided. The device comprises a reflector having variable optical power; and a waveguide display assembly optically coupled to the reflector and having a light source. The waveguide display assembly is configured to guide light from the light source to transmit in a first direction towards the reflector for a first optical path, and in a second direction towards an eye-box of the device for a second optical path. The reflector is configured to reflect the light in the first direction towards the eye-box.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-08-24T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8633758825},{"pair":"US-10473939-B1 & US-2019271844-A1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-01-08T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8633059291},{"pair":"US-2020027261-A1 & US-2016307368-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8632637853},{"pair":"US-10133168-B1 & US-2019271844-A1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-02-01T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8628803835},{"pair":"US-2020027261-A1 & US-9665989-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9665989-B1","title_2":"Feature agnostic geometric alignment ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9665989B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and apparatus for aligning objects are provided. A computing device can receive first and second object representations that are respectively associated with first and second surface representations. The computing device can apply an object transformation to the respective first and second object representations to modify geometric features of the respective first and second object representations based on one or more values of one or more characteristics of the respective first and second surface representation. The computing device can align the first object representation and the second object representation using an alignment of the transformed first object representation and the transformed second object representation. The computing device can provide an output based on the aligned first object representation and second object representation.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-02-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8628348967},{"pair":"US-2020081252-A1 & US-2020041798-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-03-15T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8627301402},{"pair":"US-2019353898-A1 & US-2019271844-A1","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-05-18T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8625053627},{"pair":"US-10495798-B1 & US-2019271844-A1","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-08-07T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8624005801},{"pair":"US-10248890-B2 & US-2016005145-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2016005145-A1","title_2":"Aligning Ground Based Images and Aerial Imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160005145A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for aligning ground based images of a geographic area taken from a perspective at or near ground level and a set of aerial images taken from, for instance, an oblique perspective, are provided. More specifically, candidate aerial imagery can be identified for alignment with the ground based image. Geometric data associated with the ground based image can be obtained and used to warp the ground based image to a perspective associated with the candidate aerial imagery. One or more feature matches between the warped image and the candidate aerial imagery can then be identified using a feature matching technique. The matched features can be used to align the ground based image with the candidate aerial imagery.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8623923544},{"pair":"US-2020064633-A1 & US-2020041798-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-23T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8620107699},{"pair":"US-10598938-B1 & US-2020041798-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-11-09T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8612809145},{"pair":"US-10248890-B2 & US-9736451-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9736451-B1","title_2":"Efficient dense stereo computation ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9736451B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Example embodiments may allow for the efficient determination of disparity information for a stereo image pair by embedding pixels of the image pair in a multidimensional dimensional vertex space. Regularly-spaced vertices in the vertex space are associated with pixels of the stereo image pair and disparity loss functions are determined for each of the vertices based on disparity loss functions of the associated pixels. The determined vertex-disparity loss functions can be used to determine vertex disparity values for each of the vertices. Disparity values for pixels of the stereo image pair can be determined based on determined vertex disparity values for respective one or more vertices associated with each of the pixels. The determined pixel disparity values can be used to enable depth-selective image processing, determination of pixel depth maps, mapping and\/or navigation of an environment, human-computer interfacing, biometrics, augmented reality, or other applications.","priority_1":"2017-04-13T00:00:00","priority_2":"2014-09-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8612785523},{"pair":"US-10495798-B1 & US-9671614-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-07T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8610852264},{"pair":"US-10248890-B2 & US-10460505-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-10460505-B2","title_2":"Systems and methods for lightfield reconstruction utilizing contribution regions ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US10460505B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A method for rendering a view from a lightfield includes identifying a ray associated with a portion of the view and selecting a set of camera views from a plurality of camera views representing the lightfield based on an intersection point of the ray with a plane. Each camera view has an associated contribution region disposed on the plane. The associated contribution region overlaps contribution regions associated with other camera views of the set of camera views at the intersection point. The method also includes determining a characteristic of the ray based on a contribution factor for each camera view of the set of camera views. The contribution factor is determined based on the relative position of the intersection point within the associated contribution region.","priority_1":"2017-04-13T00:00:00","priority_2":"2016-12-30T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8606411082},{"pair":"US-10248890-B2 & US-9704282-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9704282-B1","title_2":"Texture blending between view-dependent texture and base texture in a geographic information system ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9704282B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for rendering a view-dependent texture in conjunction with a three-dimensional model of a geographic area are provided. A view-dependent texture can be rendered in conjunction with at least portions of the three-dimensional model. A base texture can be rendered for portions of the three-dimensional model in the same field of view that are viewed from a slightly different perspective than a reference direction associated with the view-dependent texture. For instance, a stretching factor can be determined for each portion of the three-dimensional model based on the reference direction and a viewpoint direction associated with the portion of the three-dimensional model. A base texture, a view-dependent texture, or a blended texture can be selected for rendering at the portion of the three-dimensional model based on the stretching factor.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-06-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8601906921},{"pair":"US-10600352-B1 & US-9671614-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-12-04T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8599281596},{"pair":"US-2020027261-A1 & US-2018061119-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018061119-A1","title_2":"Quadrangulated layered depth images ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180061119A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"In one general aspect, a computer-implemented method can include identifying a plurality of pixel samples included in a layered depth image (LDI) representation of a scene for rendering in a three-dimensional (3D) image in a virtual reality (VR) space, grouping, by a processor, a subset of the plurality of pixel samples into a block of data, including extracting each pixel sample included in the subset of the plurality of pixel samples from the LDI representation of the scene for inclusion in the block of data based on an error metric associated with the respective pixel sample, creating, by the processor, a texture map for a block of data, the texture map being associated with the block of data, storing the block of data and the texture map, and triggering a rendering of the 3D image in the VR space using the block of data and the texture map.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-08-24T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597558841},{"pair":"US-10248890-B2 & US-9916679-B2","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9916679-B2","title_2":"Deepstereo: learning to predict new views from real world imagery ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9916679B2\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A system and method of deep learning using deep networks to predict new views from existing images may generate and improve models and representations from large-scale data. This system and method of deep learning may employ a deep architecture performing new view synthesis directly from pixels, trained from large numbers of posed image sets. A system employing this type of deep network may produce pixels of an unseen view based on pixels of neighboring views, lending itself to applications in graphics generation.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-05-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8597007932},{"pair":"US-10473939-B1 & US-9671614-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-01-08T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8595536003},{"pair":"US-10473939-B1 & US-9946074-B2","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-01-08T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.859522026},{"pair":"US-10248890-B2 & US-2016307368-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2016307368-A1","title_2":"Compression and interactive playback of light field pictures ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160307368A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A compressed format provides more efficient storage for light-field pictures. A specialized player is configured to project virtual views from the compressed format. According to various embodiments, the compressed format and player are designed so that implementations using readily available computing equipment are able to project new virtual views from the compressed data at rates suitable for interactivity. Virtual-camera parameters, including but not limited to focus distance, depth of field, and center of perspective, may be varied arbitrarily within the range supported by the light-field picture, with each virtual view expressing the parameter values specified at its computation time. In at least one embodiment, compressed light-field pictures containing multiple light-field images may be projected to a single virtual view, also at interactive or near-interactive rates. In addition, virtual-camera parameters beyond the capability of a traditional camera, such as \u201cfocus spread\u201d, may also be varied at interactive rates.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-04-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8592087468},{"pair":"US-10598928-B1 & US-9946074-B2","patent_1":"US-10598928-B1","title_1":"Light redirection structures for eye tracking systems ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598928B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A head-mounted device (HMD) contains a display, an optics block, a redirection structure, and an eye tracking system. The display is configured to emit image light and provide it to an eye of a user. The optics block is configured to direct the emitted light in order to allow it to reach the eye. The eye tracking system contains a camera, an illumination source, and a controller. The camera is configured to capture image data using infrared light reflected from the eye. The controller is configured to use this image data to determine eye tracking information. The illumination source is configured to illuminate the eye with infrared light for the purpose of taking eye tracking measurements. The redirection structure is configured to direct infrared light reflected from the eye to the eye tracking system. In multiple embodiments, redirection structures may comprise prism arrays, lenses, liquid crystal layers, or grating structures.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-12-21T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8590667937},{"pair":"US-2019101767-A1 & US-9671614-B2","patent_1":"US-2019101767-A1","title_1":"Fresnel assembly for light redirection in eye tracking systems ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190101767A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A head-mounted device (HMD) comprises a display element, a Fresnel assembly, an illumination source, and a camera assembly. The display element outputs image light in a first band of light through a display surface. The optics block directs light from the display element to a target region (e.g., includes a portion of a user's face, eyes, etc.). The Fresnel assembly transmits light in the first band and directs light in a second band different than the first band to a first position. The source illuminates the target area with light in the second band. The camera is located in the first position and captures light in the second band corresponding to light reflected from the target area that is then reflected by the Fresnel assembly toward the camera. A controller may use the captured light to determine tracking information for areas of a user's face (e.g., eyes).","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-10-03T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8589508093},{"pair":"US-2019369390-A1 & US-9946074-B2","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-06-04T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8588407863},{"pair":"US-2020027261-A1 & US-2017032568-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.858702826},{"pair":"US-10120193-B2 & US-2020041798-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-01-27T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8583164911},{"pair":"US-2020057304-A1 & US-9671614-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-16T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8575011094},{"pair":"US-10571692-B2 & US-9946074-B2","patent_1":"US-10571692-B2","title_1":"Field curvature corrected display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10571692B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A head mounted display (HMD) includes a field curvature corrected (FC) display to mitigate field curvature in an image that is output to a user's eyes. The FC display includes elements that generate the image light and elements to mitigate field curvature from the image light. The FC display may include a display panel with lenses, a display panel with a reflective polarizer and reflective surface, or other optical elements. The FC display may include a pancake lens configuration including a polarized display with a quarter wave plate, a reflective mirror, and a polarization reflective mirror.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2016-03-02T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8569783669},{"pair":"US-10466496-B2 & US-2020041798-A1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-12-06T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8562625649},{"pair":"US-10261324-B2 & US-2019271844-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-08-10T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8557154089},{"pair":"US-2020081252-A1 & US-2019271844-A1","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-03-15T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.854999105},{"pair":"US-2020057304-A1 & US-2020041798-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-08-16T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8547035732},{"pair":"US-10600352-B1 & US-9946074-B2","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-12-04T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8533781314},{"pair":"US-2019353898-A1 & US-9671614-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-05-18T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527778277},{"pair":"US-2019353898-A1 & US-9946074-B2","patent_1":"US-2019353898-A1","title_1":"Eye Tracking Based On Waveguide Imaging ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190353898A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"An optical system includes an optical waveguide, and a first optical element configured to direct a first ray, having a first circular polarization and impinging on the first optical element at a first incidence angle, in a first direction so that the first ray propagates through the optical waveguide via total internal reflection toward a second optical element. The first optical element is configured to also direct a second ray, having a second circular polarization that is distinct from the first circular polarization and impinging on the first optical element at the first incidence angle, in a second direction that is distinct from the first direction so that the second ray propagates away from the second optical element. The second optical element is configured to direct the first ray propagating through the optical waveguide toward a detector.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-05-18T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8527605529},{"pair":"US-2019369390-A1 & US-9851565-B1","patent_1":"US-2019369390-A1","title_1":"Optical assembly with waveplate configuration for ghost image reduction ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190369390A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly includes a first optical element and a second optical element. The first optical element includes a partially reflective layer and a waveplate. The second optical element includes a reflective polarizer configured to reflect a first polarization orientation of display light back to the first optical element and transmit a second polarization orientation of the display light.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-06-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8502333319},{"pair":"US-2020027261-A1 & US-2018342075-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018342075-A1","title_2":"Multi-view back-projection to a light-field ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180342075A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Dense light-field data can be generated from image data that does not include light-field data, or from image data that includes sparse light-field data. In at least one embodiment, the source light-field data may include one or more sub-aperture images that may be used to reconstruct the light-field in denser form. In other embodiments, the source data can take other forms. Examples include data derived from or ancillary to a set of sub-aperture images, synthetic data, or captured image data that does not include full light-field data. Interpolation, back-projection, and\/or other techniques are used in connection with source sub-aperture images or their equivalents, to generate dense light-field data.","priority_1":"2018-07-20T00:00:00","priority_2":"2017-05-25T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8498090688},{"pair":"US-2020057304-A1 & US-2019271844-A1","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-08-16T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8495899094},{"pair":"US-10534177-B1 & US-9851565-B1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-10-10T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8494224811},{"pair":"US-10248890-B2 & US-2018342075-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2018342075-A1","title_2":"Multi-view back-projection to a light-field ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180342075A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Dense light-field data can be generated from image data that does not include light-field data, or from image data that includes sparse light-field data. In at least one embodiment, the source light-field data may include one or more sub-aperture images that may be used to reconstruct the light-field in denser form. In other embodiments, the source data can take other forms. Examples include data derived from or ancillary to a set of sub-aperture images, synthetic data, or captured image data that does not include full light-field data. Interpolation, back-projection, and\/or other techniques are used in connection with source sub-aperture images or their equivalents, to generate dense light-field data.","priority_1":"2017-04-13T00:00:00","priority_2":"2017-05-25T00:00:00","earlier_priority":"Facebook","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8486476867},{"pair":"US-10600352-B1 & US-2020041798-A1","patent_1":"US-10600352-B1","title_1":"Display device with a switchable window and see-through pancake lens assembly ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10600352B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A display device is configured to be operable in a normal mode that blocks ambient light or a see-through mode that allows ambient light to be visible to a user. The display device includes an emission surface configured to output image light, a switchable window configurable to block ambient light in the normal mode or to transmit ambient light in the see-through mode, and an optical assembly. The optical assembly includes a first region configured to receive image light from the emission surface and to direct the image light toward the eyes of a user. The optical assembly also includes a second region configured to receive ambient light from the switchable window and to allow at least a portion of the ambient light to pass through. A method of setting the display device in normal mode or see-through mode is also disclosed.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-12-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8484852928},{"pair":"US-2019339447-A1 & US-9946074-B2","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-05-04T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8481329431},{"pair":"US-2019339447-A1 & US-2020041798-A1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2018-05-04T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8473400084},{"pair":"US-2020081252-A1 & US-9671614-B2","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-03-15T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8447536005},{"pair":"US-10248890-B2 & US-2017103091-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017103091-A1","title_2":"Displaying objects based on a plurality of models ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170103091A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"A system and method is provided for displaying surfaces of an object from a vantage point different from the vantage point from which imagery of the object was captured. In some aspects, imagery may be generated for display by combining visual characteristics from multiple source images and applying greater weight to the visual characteristics of some of the source images relative to the other source images. The weight may be based on the orientation of the surface relative to the location from which the image was captured and the location from which the object will be displayed.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-10-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8441380128},{"pair":"US-10248890-B2 & US-2017228926-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017228926-A1","title_2":"Determining Two-Dimensional Images Using Three-Dimensional Models ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170228926A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Systems and methods for determining two-dimensional (2D) images are presented. For instance, data indicative of a three-dimensional (3D) model of a geographic area can be obtained. A 2D output image can be generated depicting at least a portion of the geographic area based at least in part on the 3D model. Each pixel in the output image can then be reprojected to the 3D model. A plurality of aerial images depicting the geographic area can be obtained. A source image can then be determined for each pixel in the output image from the plurality of aerial images. The source image can be determined based at least in part on the reprojection of the pixel in the output image to the three-dimensional model.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-11-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8441083235},{"pair":"US-2020081252-A1 & US-9946074-B2","patent_1":"US-2020081252-A1","title_1":"Polarization-sensitive components in optical systems for large pupil acceptance angles ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200081252A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A near eye display (NED) includes an electronic display configured to output image light. Further, the NED includes an eye tracking module and multiple optical elements that are combined to form an optical system to allow for changes in position of one or both eyes of a user of the NED. Various types of such optical elements, which may have optical states that are switchable, may be used to steer a light beam toward the user's eye. A direction of the steering may be based on eye tracking information measured by the eye tracking module.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-03-15T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.842559257},{"pair":"US-2020027261-A1 & US-9736451-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9736451-B1","title_2":"Efficient dense stereo computation ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9736451B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Example embodiments may allow for the efficient determination of disparity information for a stereo image pair by embedding pixels of the image pair in a multidimensional dimensional vertex space. Regularly-spaced vertices in the vertex space are associated with pixels of the stereo image pair and disparity loss functions are determined for each of the vertices based on disparity loss functions of the associated pixels. The determined vertex-disparity loss functions can be used to determine vertex disparity values for each of the vertices. Disparity values for pixels of the stereo image pair can be determined based on determined vertex disparity values for respective one or more vertices associated with each of the pixels. The determined pixel disparity values can be used to enable depth-selective image processing, determination of pixel depth maps, mapping and\/or navigation of an environment, human-computer interfacing, biometrics, augmented reality, or other applications.","priority_1":"2018-07-20T00:00:00","priority_2":"2014-09-16T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8417135451},{"pair":"US-10598938-B1 & US-9851565-B1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-11-09T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8410816719},{"pair":"US-10466496-B2 & US-2019271844-A1","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-12-06T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8410055145},{"pair":"US-10133168-B1 & US-9671614-B2","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-02-01T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8402480586},{"pair":"US-10248890-B2 & US-9665989-B1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-9665989-B1","title_2":"Feature agnostic geometric alignment ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9665989B1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods and apparatus for aligning objects are provided. A computing device can receive first and second object representations that are respectively associated with first and second surface representations. The computing device can apply an object transformation to the respective first and second object representations to modify geometric features of the respective first and second object representations based on one or more values of one or more characteristics of the respective first and second surface representation. The computing device can align the first object representation and the second object representation using an alignment of the transformed first object representation and the transformed second object representation. The computing device can provide an output based on the aligned first object representation and second object representation.","priority_1":"2017-04-13T00:00:00","priority_2":"2015-02-17T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8395662109},{"pair":"US-2020027261-A1 & US-2016005145-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2016005145-A1","title_2":"Aligning Ground Based Images and Aerial Imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20160005145A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Systems and methods for aligning ground based images of a geographic area taken from a perspective at or near ground level and a set of aerial images taken from, for instance, an oblique perspective, are provided. More specifically, candidate aerial imagery can be identified for alignment with the ground based image. Geometric data associated with the ground based image can be obtained and used to warp the ground based image to a perspective associated with the candidate aerial imagery. One or more feature matches between the warped image and the candidate aerial imagery can then be identified using a feature matching technique. The matched features can be used to align the ground based image with the candidate aerial imagery.","priority_1":"2018-07-20T00:00:00","priority_2":"2013-11-27T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8392211367},{"pair":"US-2020027261-A1 & US-9916679-B2","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9916679-B2","title_2":"Deepstereo: learning to predict new views from real world imagery ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9916679B2\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A system and method of deep learning using deep networks to predict new views from existing images may generate and improve models and representations from large-scale data. This system and method of deep learning may employ a deep architecture performing new view synthesis directly from pixels, trained from large numbers of posed image sets. A system employing this type of deep network may produce pixels of an unseen view based on pixels of neighboring views, lending itself to applications in graphics generation.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-05-13T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8382826976},{"pair":"US-2020064633-A1 & US-9946074-B2","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-08-23T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8360878428},{"pair":"US-2020057304-A1 & US-9946074-B2","patent_1":"US-2020057304-A1","title_1":"Transmission improvement for flat lens based ar\/vr glasses ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US20200057304A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"An artificial-reality display uses an anisotropic material to circularly-polarize light exiting a waveguide so that the artificial-reality display is relatively transparent.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-08-16T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8348611702},{"pair":"US-10598938-B1 & US-2019271844-A1","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-11-09T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8348493979},{"pair":"US-10495798-B1 & US-9946074-B2","patent_1":"US-10495798-B1","title_1":"Switchable reflective circular polarizer in head-mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10495798B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"Disclosed herein are techniques for displaying images on multiple image planes in a near-eye display system. A switchable optical device includes a first polarizer configurable to polarize incident light into light of a first circular polarization state, and a second polarizer configurable to transmit light of a second circular polarization state and reflect light of the first circular polarization state into light of the first circular polarization state. The switchable optical device also includes a partial reflector positioned between the first polarizer and the second polarizer. The partial reflector is configured to transmit light from the first polarizer and reflect light from the second polarizer, where the reflected light and the light from the second polarizer have different polarization states. At least one of the first polarizer or the second polarizer includes a cholesteric liquid crystal (CLC) circular polarizer that is switchable by a voltage signal.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-08-07T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8345616802},{"pair":"US-10248890-B2 & US-2017032568-A1","patent_1":"US-10248890-B2","title_1":"Panoramic camera systems ","patent_2":"US-2017032568-A1","title_2":"Methods and Systems for Providing a Preloader Animation for Image Viewers ","link_1":"https:\/\/patents.google.com\/patent\/US10248890B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170032568A1\/en","abstract_1":"A camera system captures images from a set of cameras to generate binocular panoramic views of an environment. The cameras are oriented in the camera system to maximize the minimum number of cameras viewing a set of randomized test points. To calibrate the system, matching features between images are identified and used to estimate three-dimensional points external to the camera system. Calibration parameters are modified to improve the three-dimensional point estimates. When images are captured, a pipeline generates a depth map for each camera using reprojected views from adjacent cameras and an image pyramid that includes individual pixel depth refinement and filtering between levels of the pyramid. The images may be used generate views of the environment from different perspectives (relative to the image capture location) by generating depth surfaces corresponding to the depth maps and blending the depth surfaces.","abstract_2":"Methods and systems for providing a preloader animation for image viewers is provided. An example method includes receiving an image of an object, determining an edge gradient value for pixels of the image, and selecting pixels representative of the object that have a respective edge gradient value above a threshold. The example method also includes determining a model of the object including an approximate outline of the object and structures internal to the outline that are oriented based on the selected pixels being coupling points between the structures, and providing instructions to display the model in an incremental manner so as to render given structures of the model over time.","priority_1":"2017-04-13T00:00:00","priority_2":"2013-12-10T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8338619884},{"pair":"US-10466496-B2 & US-9671614-B2","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-12-06T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8336720982},{"pair":"US-10120193-B2 & US-2019271844-A1","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-01-27T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8332038732},{"pair":"US-10481321-B1 & US-9946074-B2","patent_1":"US-10481321-B1","title_1":"Canted augmented reality display for improved ergonomics ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10481321B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"An augmented-reality system has canted waveguides. The waveguides are canted at a wrap angle and\/or a tilt angle. Input couplers to the waveguides are designed differently because of the different cant angles. Having canted waveguides allows waveguides to be formed in glasses and\/or sunglass that have a base curvature.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-09-06T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8330148776},{"pair":"US-10534177-B1 & US-9946074-B2","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-10-10T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8329666022},{"pair":"US-10598938-B1 & US-9671614-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-11-09T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8326106771},{"pair":"US-10120193-B2 & US-9671614-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-01-27T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8320601762},{"pair":"US-10133168-B1 & US-9851565-B1","patent_1":"US-10133168-B1","title_1":"Compact light projection system including an anamorphic reflector assembly ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10133168B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A compact light projection system. The light projection system includes a light source, an anamorphic reflector assembly, and a correction element that is configured to mitigate aberration. The light source is configured to emit image light. The anamorphic reflector assembly includes a first surface and a second surface. The first surface is configured to reflect the image light toward the second surface which reflects the reflected image light to output it from the anamorphic reflector assembly. And the first surface and the second surface are both curved and non-rotationally symmetric such that the light output from the anamorphic reflector assembly is collimated image light. The collimated image light is optically corrected based in part on mitigation of aberration by the correction element.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-02-01T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8320132427},{"pair":"US-10473939-B1 & US-9851565-B1","patent_1":"US-10473939-B1","title_1":"Waveguide display with holographic Bragg grating ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10473939B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A near-eye display includes a light source assembly, a first waveguide, an output waveguide, and a controller. The light source assembly emits image light including light within a first band and a second band. The first waveguide receives the image light, expands the received image light in at least one dimension, and outputs an image light. The output waveguide includes an output area and a plurality of input areas. Each input area receives the image light from the first waveguide. The output waveguide includes a holographic Bragg grating and the output waveguide expands the image light at least along two dimensions to form an expanded image light, and outputs the expanded image light toward an eyebox. The controller controls the scanning of the light source assembly and the first waveguide.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-01-08T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8313586813},{"pair":"US-2020027261-A1 & US-2018158198-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2018158198-A1","title_2":"Multi-view rotoscope contour propagation ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20180158198A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A video stream may be captured, and may have a plurality of frames including at least a first frame and a second frame. Each of the frames may have a plurality of views obtained from viewpoints that are offset from each other. A source contour, associated with a source view of the first frame, may be retrieved. Camera parameters, associated with the image capture device used to capture the video stream, may also be retrieved. The camera parameters may include a first offset between the source view and a destination view of the first frame. At least the first offset may be used to project the source contour to the destination view to generate a destination contour associated with the destination view.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-12-05T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8298066721},{"pair":"US-10466496-B2 & US-9946074-B2","patent_1":"US-10466496-B2","title_1":"Compact multi-color beam combiner using a geometric phase lens ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10466496B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"Disclosed is a multi-color light source device including a first light source configured to emit light of a first color, a second light source configured to emit light of a second color that is distinct from the first color, and a first geometric phase lens associated with a first focal length for the light of the first color and a second focal length, distinct from the first focal length, for the light of the second color. The first light source is located at a first distance from the first geometric phase lens, and the second light source is located at a second distance, distinct from the first distance, from the geometric phase lens. Also disclosed is a head mounted display system including the multi-color light source device, a light modulator configured for modulating light from the multi-color light source device, and one or more lenses.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-12-06T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8245806454},{"pair":"US-2020027261-A1 & US-9551579-B1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-9551579-B1","title_2":"Automatic connection of images using visual features ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9551579B1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"Aspects of the disclosure relate generating navigation paths between images. A first image taken from a first location and a second image taken from a second location may be selected. A position of the first location in relation to the second location may be determined. First and second frames for the first and second images may be selected based on the position. First and second sets of visual features for each of the first and second image frames may be identified. Matching visual features between the first set of visual features and the second set of visual features may be determined. A confidence level for a line-of-sight between the first and second images may be determined by evaluating one or more positions of the matching visual features. Based on at least the confidence level, a navigation path from the first image to the second image is generated.","priority_1":"2018-07-20T00:00:00","priority_2":"2015-08-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8245545245},{"pair":"US-10120193-B2 & US-9946074-B2","patent_1":"US-10120193-B2","title_1":"Geometric phase lens alignment in an augmented reality head mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10120193B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A HMD includes a display block. The display block combines light from a local area with image light to form an augmented scene. The display block also provides the augmented scene to an eyebox corresponding a location of a user's eye. The display block includes a waveguide display, a focusing assembly and a compensation assembly. The waveguide display emits the image light. The focusing assembly includes a focusing geometric phase lens and presents the augmented scene at a focal distance. The compensation assembly includes a compensation geometric phase lens that has an axis of orientation orthogonal to an axis of orientation of the focusing geometric phase lens. The compensation assembly compensates the optical power of the focusing assembly.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-01-27T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8240689856},{"pair":"US-2020027261-A1 & US-2017358092-A1","patent_1":"US-2020027261-A1","title_1":"Rendering 360 depth content ","patent_2":"US-2017358092-A1","title_2":"Multi-view scene segmentation and propagation ","link_1":"https:\/\/patents.google.com\/patent\/US20200027261A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20170358092A1\/en","abstract_1":"As user device can receive and display 360 panoramic content in a 360 depth format. 360 depth content can comprise 360 panoramic image data and corresponding depth information. To display 360 depth content, the user device can generate a 3D environment based on the 360 depth content and the current user viewpoint. A content display module on the user device can render 360 depth content using a standard 3D rendering pipeline modified to render 360 depth content. The content display module can use a vertex shader or fragment shader of the 3D rendering pipeline to interpret the depth information of the 360 depth content into the 3D environment as it is rendered.","abstract_2":"A depth-based effect may be applied to a multi-view video stream to generate a modified multi-view video stream. User input may designate a boundary between a foreground region and a background region, at a different depth from the foreground region, of a reference image of the video stream. Based on the user input, a reference mask may be generated to indicate the foreground region and the background region. The reference mask may be used to generate one or more other masks that indicate the foreground and background regions for one or more different images, from different frames and\/or different views from the reference image. The reference mask and other mask(s) may be used to apply the effect to the multi-view video stream to generate the modified multi-view video stream.","priority_1":"2018-07-20T00:00:00","priority_2":"2016-06-09T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8236009242},{"pair":"US-10261324-B2 & US-9946074-B2","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2017-08-10T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8192628773},{"pair":"US-10534177-B1 & US-2019271844-A1","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2017-10-10T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8159513209},{"pair":"US-2019339447-A1 & US-9671614-B2","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-05-04T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8158127421},{"pair":"US-2020064633-A1 & US-9671614-B2","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2018-08-23T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8157998178},{"pair":"US-10534177-B1 & US-9671614-B2","patent_1":"US-10534177-B1","title_1":"Scanning assembly with gratings in waveguide displays with a large eyebox ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10534177B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A near-eye-display is used for presenting media to a user. The near-eye-display includes a light source assembly, a scanning assembly, one or more output waveguides, and a controller. The light source assembly emits light that is at least partially coherent. The scanning assembly includes grating elements associated with a wave vector that diffract the emitted light into several beams, and scan the beams in accordance with display instructions. The output waveguide includes several input areas, and an output area. Each input area includes one or more coupling elements associated with respective wave vectors that receive a respective beam. The output waveguide expands the beam at least along two dimensions to form expanded light for each respective beam toward a different portion of an eyebox with an overlap in at least some portions of the eyebox. The controller controls the scanning of the scanning assembly to form a two-dimensional image.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-10-10T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8146545563},{"pair":"US-10261324-B2 & US-2020041798-A1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-2020041798-A1","title_2":"Head wearable display using powerless optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US20200041798A1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"An optical apparatus includes a lightguide and an optical combiner. The lightguide receives display light having an initial cross-section size and guides the display light down the lightguide. The lightguide includes internal optical elements that redirect the display light out of the lightguide with an expanded cross-section size that is larger than the initial cross-section size. The optical combiner combines the display light having the expanded cross-section with ambient scene light. The optical combiner includes an ambient scene side, an eye-ward side, and one or more reflective optical elements that pass at least a portion of the ambient scene light incident along an eye-ward direction on the ambient scene side through to the eye-ward side and redirect the display light having the expanded cross-section and incident on the eye-ward side to the eye-ward direction. The one or more reflective optical elements are substantially without lensing power.","priority_1":"2017-08-10T00:00:00","priority_2":"2014-05-28T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8137980332},{"pair":"US-2019339447-A1 & US-9851565-B1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2018-05-04T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8132364106},{"pair":"US-10598938-B1 & US-9946074-B2","patent_1":"US-10598938-B1","title_1":"Angular selective grating coupler for waveguide display ","patent_2":"US-9946074-B2","title_2":"See-through curved eyepiece with patterned optical combiner ","link_1":"https:\/\/patents.google.com\/patent\/US10598938B1\/en","link_2":"https:\/\/patents.google.com\/patent\/US9946074B2\/en","abstract_1":"An optical coupler for a waveguide-based display includes a slanted surface-relief grating that includes a plurality of regions. Different regions of the plurality of regions of the slanted surface-relief grating have different angular selectivity characteristics for incident display light. Display light for different viewing angles is diffracted by different regions of the slanted surface-relief grating.","abstract_2":"An apparatus for use with a head wearable display includes a curved eyepiece for guiding display light received at an input surface peripherally located from a viewing region and emitting the display light along an eye-ward direction in the viewing region. The curved eyepiece includes an optical combiner, an eye-ward facing surface that is concave, a world facing surface that is convex, and a curved lightguide disposed between the eye-ward facing and world facing surfaces to guide the display light via total internal reflections from the input surface to the viewing region. The optical combiner is disposed within the curved eyepiece at the viewing region to redirect the display light towards the eye-ward direction. The optical combiner includes a pattern of reflective elements separated by interstitial regions. The interstitial regions pass ambient light incident through the world facing surface such that the viewing region is partially see-through.","priority_1":"2018-11-09T00:00:00","priority_2":"2016-04-07T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.8102686286},{"pair":"US-2019339447-A1 & US-2019271844-A1","patent_1":"US-2019339447-A1","title_1":"Diffraction gratings for beam redirection ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20190339447A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A diffraction grating with independently controlled diffraction angles for optical beams at different wavelengths may be used to redirect and couple light to a waveguide in an efficient, space-saving manner. The diffraction grating can include a layer with optical permittivity and associated index contrast of the grating grooves at different grating periods dependent on wavelength.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-05-04T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7992331146},{"pair":"US-2020064633-A1 & US-2019271844-A1","patent_1":"US-2020064633-A1","title_1":"Projector-combiner display with beam replication ","patent_2":"US-2019271844-A1","title_2":"Lightguide optical combiner for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US20200064633A1\/en","link_2":"https:\/\/patents.google.com\/patent\/US20190271844A1\/en","abstract_1":"A near-eye display (NED) includes an image replicator and an image combiner. The image replicator is configured for receiving a beam of image light from a source such as an image projector, and splitting the beam into a plurality of second beams of image light. The combiner is configured to relay the plurality of second beams to an eyebox of the NED such that the second beams at the eyebox are laterally offset from one another. The etendue of the NED may be increased by replicating and relaying the image beams.","abstract_2":"An eyepiece for a head wearable display includes a lightguide component for guiding display light and emitting the display light along at a viewing region. The light guide component includes an input surface oriented to receive the display light into the lightguide component at the peripheral location, a first folding surface disposed to reflect the display light received through the input surface, a second folding surface disposed to reflect the display light received from the first folding surface, an eye-ward facing surface disposed opposite to the second folding surface to reflect the display light received from the second folding surface, and a curved reflective surface having reflective optical power disposed at the viewing region to receive the display light reflected from the eye-ward facing surface and to reflect the display light for emission out through the eye-ward facing surface.","priority_1":"2018-08-23T00:00:00","priority_2":"2014-05-06T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7973597394},{"pair":"US-10261324-B2 & US-9671614-B2","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-9671614-B2","title_2":"See-through eyepiece for head wearable display ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9671614B2\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"An eyepiece for a head wearable display includes a light guide component for guiding display light received at a peripheral location and emitting the display light at a viewing region. The light guide component includes an eye-ward facing surface having a reflection portion and a viewing portion, a folding surface oriented to reflect the display light received into the light guide component to the reflection portion of the eye-ward facing surface, and a first interface surface oriented to receive the display light reflected from the reflection portion of the eye-ward facing surface. A partially reflective layer is disposed on the first interface surface in the viewing region to reflect the display light through viewing portion of the eye-ward facing surface.","priority_1":"2017-08-10T00:00:00","priority_2":"2013-12-19T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7970000563},{"pair":"US-10261324-B2 & US-9851565-B1","patent_1":"US-10261324-B2","title_1":"Removable lens assembly for a head-mounted display ","patent_2":"US-9851565-B1","title_2":"Increasing effective eyebox size of an HMD ","link_1":"https:\/\/patents.google.com\/patent\/US10261324B2\/en","link_2":"https:\/\/patents.google.com\/patent\/US9851565B1\/en","abstract_1":"A lens assembly can be removably attached to an eye cone of a HMD. The eye cone displays images to an eye of a user of the HMD. The eye cone includes a peripheral wall that extends towards rear of the HMD. The lens assembly includes a corrective lens and a frame. The corrective lens corrects a vision error of the eye of the user. The frame includes an inner surface onto which the corrective lens is attached. The frame also includes a wall that receives a peripheral wall of the eye cone for removably securing the lens assembly to the HMD. The HMD can include another eye cone that displays images to the other eye of the user. Another lens assembly can be removably attached to the other eye cone.","abstract_2":"A method of dynamically increasing an effective size of an eyebox of a head mounted display includes displaying a computer generated image (\u201cCGI\u201d) to an eye of a user wearing the head mounted display. The CGI is perceivable by the eye within an eyebox. An eye image of the eye is captured while the eye is viewing the CGI. A location of the eye is determined based upon the eye image. A lateral position of the eyebox is dynamically adjusted based upon the determined location of the eye thereby extending the effective size of the eyebox from which the eye can view the CGI.","priority_1":"2017-08-10T00:00:00","priority_2":"2012-03-21T00:00:00","earlier_priority":"Google","assignee_1":"Facebook","assignee_2":"Google","similarity":0.7529675461}]